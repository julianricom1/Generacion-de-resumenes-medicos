source_text,gen_1,gen_2,gen_3
"Background
Beta‐blockers are an essential part of standard therapy in adult congestive heart failure and therefore, are expected to be beneficial in children. However, congestive heart failure in children differs from that in adults in terms of characteristics, aetiology, and drug clearance. Therefore, paediatric needs must be specifically investigated. This is an update of a Cochrane review previously published in 2009. 
Objectives
To assess the effect of beta‐adrenoceptor‐blockers (beta‐blockers) in children with congestive heart failure. 
Search methods
We searched the Cochrane Central Register of Controlled Trials (CENTRAL) in The Cochrane Library, MEDLINE, EMBASE, and LILACS up to November 2015. Bibliographies of identified studies were checked. No language restrictions were applied. 
Selection criteria
Randomised, controlled, clinical trials investigating the effect of beta‐blocker therapy on paediatric congestive heart failure. 
Data collection and analysis
Two review authors independently extracted and assessed data from the included trials.
Main results
We identified four new studies for the review update; the review now includes seven studies with 420 participants. Four small studies with 20 to 30 children each, and two larger studies of 80 children each, showed an improvement of congestive heart failure with beta‐blocker therapy. A larger study with 161 participants showed no evidence of benefit over placebo in a composite measure of heart failure outcomes. The included studies showed no significant difference in mortality or heart transplantation rates between the beta‐blocker and control groups. No significant adverse events were reported with beta‐blockers, apart from one episode of complete heart block. A meta‐analysis of left ventricular ejection fraction (LVEF) and fractional shortening (LVFS) data showed a very small improvement with beta‐blockers. 
However, there were vast differences in the age, age range, and health of the participants (aetiology and severity of heart failure; heterogeneity of diagnoses and co‐morbidities); there was a range of treatments across studies (choice of beta‐blocker, dosing, duration of treatment); and a lack of standardised methods and outcome measures. Therefore, the primary outcomes could not be pooled in meta‐analyses. 
Authors' conclusions
There is not enough evidence to support or discourage the use of beta‐blockers in children with congestive heart failure, or to propose a paediatric dosing scheme. However, the sparse data available suggested that children with congestive heart failure might benefit from beta‐blocker treatment. Further investigations in clearly defined populations with standardised methodology are required to establish guidelines for therapy. Pharmacokinetic investigations of beta‐blockers in children are also required to provide effective dosing in future trials.","Beta blockers for children with heart failure
Heart failure is a condition where the heart is unable to pump blood around the body effectively. It can be caused by many different conditions, including coronary artery disease, high blood pressure, and heart valve problems. Heart failure is more common in older people, but it can also affect children. 
Beta blockers are drugs that reduce the workload of the heart. They are used to treat heart failure because they can improve symptoms and reduce the risk of death. Beta blockers are often prescribed to children with congenital heart disease, which means that their hearts did not develop properly before birth. Congenital heart defects can cause heart failure at any age. 
This review looked at whether beta blockers are effective in treating heart failure caused by congenital defects in children, and whether they have any side effects. We found seven studies involving 417 children. These studies compared beta blockers with other medicines or no treatment. The studies lasted from six months to three years. 
The results show that beta blockers may improve heart function and reduce symptoms of heart disease. However the studies were too small to be sure about this. There were no deaths in the beta blocker group, but there were no studies that looked at how long people lived. The results suggest that beta blocker therapy does not improve survival. 
We found no evidence that beta blockade therapy has any serious side effects, except for one case of a child who developed a heart rhythm problem. 
Overall, we do not know if beta blockers help children with certain types of heart defects. We need further research to find out if beta blocker treatment improves survival and reduces symptoms in children and young people with heart disease caused by heart defects, and to find the best way to give them.
Beta‐blockade in children and young people with congested heart failure
What is the issue? 
Congestive heart disease occurs when the heart muscle does not pump blood around the body as well as it should. This can cause fluid to build up in the lungs and other parts of the body. Congestive cardiac failure is a serious condition which can lead to death if not treated. Beta‐blockades are medications which reduce the workload on the heart by slowing down the heart rate and reducing the force of contraction. They are used to treat heart failure in adults. 
Why is this important? 
It is important to know whether beta‐blocks are useful in children because they may have different effects in children compared to adults. It is also important to find out the best dose of beta blockers for children. 
What evidence did we find? 
We searched for all relevant studies published up to 2015. We found four studies involving 473 children with heart failure. The studies were conducted in different countries and used different types of beta blocker. The children had different types and stages of heart disease. The results showed that beta blockers reduced the amount of fluid in the body and improved symptoms in some children. However the studies were too different to allow us to combine them in a single analysis. 
Key messages 
The evidence is current to 10 June 2105.","Beta blockers for children with heart failure
Review question 
We reviewed the evidence about the effects of beta blockers in children who have heart failure (CHF). 
Background 
Heart failure is a condition where the heart does not pump blood around the body as well as it should. It can be caused by many different conditions, including heart disease, high blood pressure, and heart attacks. Heart failure is more common in adults than in children, but it can occur at any age. Children with heart disease may develop heart failure later in life. Beta blockers are medicines that reduce the workload on the heart. They are used to treat heart failure because they can improve symptoms and prolong survival. 
Study characteristics 
We searched for all relevant studies up to 27 November 15, 2105. We found seven studies involving 419 children. These studies compared beta blockers with placebo (dummy medicine) or other treatments. 
Key results 
The evidence is current to 1 November 5,2020. 
We found that beta blockers improved some aspects of heart function in children and reduced the number of hospital admissions. However we did not find any evidence that beta blocker therapy improved survival or reduced the need for heart transplants. There was no evidence that the medicines caused serious side effects. 
Quality of the evidence 
The quality of the available evidence was low to moderate. Most of the studies had small numbers of children and were poorly designed. 
This review is up to date with information from November 7, 5205, and will be updated again when new studies become available.
Beta‐blockade for children with heart failure
Review question 
We reviewed the evidence about the benefits and harms of beta blockers for children who have heart failure. 
Background 
Heart failure is a condition where the heart is unable to pump blood around the body effectively. Beta blockers are drugs that reduce the workload on the heart by slowing down the heart rate and reducing the force of the heartbeat. They can improve survival and quality of life in adults with heart disease. We wanted to know whether they are beneficial for children. 
Search date 
The evidence is current to: 27 July 2015. 
Study characteristics 
We searched for randomised controlled trials (studies where people are randomly allocated to one of two or more treatment groups) that compared beta blockers with placebo (dummy treatment) or another drug for children aged 1 month to 18 years with heart problems. We included studies that compared different types of beta blocker, different doses, and different durations of treatment. 
Key results 
We found 14 studies involving 1397 children. The studies were conducted in hospitals in the USA, Europe, and Australia. The children had a variety of heart conditions including congenital heart disease, heart valve disease, and cardiomyopathy. The average age of the children was 10 years old. 
The studies compared beta blocker treatment with placebo or another type of drug. The beta blockers used were propranolol, nadolol, and carvedilol. The duration of the studies ranged from six weeks to 24 months. 
We did not find any studies that looked at the effects of beta blockade on death, hospitalisation, or quality of

of beta blockade in children. We did not include studies that only looked at children with congenital (present at birth) heart disease because we wanted to look at all types of heart disease in children, not just those born with heart defects. 
In addition, we did not look at studies that involved children under one month old, because it is difficult to give medication to babies this young. 
What did we do? 
We collected all the relevant studies that we could find. We then looked at each study to see if it met our inclusion criteria. We looked at how many children were in each study and what type of heart problem they had. We also looked at what type and dose of beta blockage was given, and for how long. 
For each study, we looked at whether the children taking the beta blocker had fewer hospital admissions, deaths, or other bad outcomes than those taking the placebo. We calculated the number needed to treat for an additional beneficial outcome (NNTB) to show how many patients would need to take the beta blockader to prevent one bad outcome. 
How reliable are the results? 
The results of the review are based on 12 studies involving a total of 1107 children with a variety heart problems, including congenitally heart disease and cardiomegaly. The results of these studies were not combined in a meta‐analysis because the studies were too different from each other. 
There were large differences between the studies in terms of the age of children, the type of beta blocks used, and the length of time the children took the beta blockers. There were also large differences in how well the children tolerated the beta blocks. 
Our main conclusion is that there is not yet enough evidence about beta blockade for children to make a recommendation. However the sparse evidence suggests that beta blockade may be beneficial for some children. Further research is needed to establish the benefits of beta blocking in children and to determine the most appropriate beta blocker and dose for children, and to establish safe dosing regimens.","Beta blockers for children with heart failure 
Review question 
We reviewed the evidence about the effects of beta blockers in children who have heart failure (CHF). 
Background 
Heart failure is a condition where the heart is unable to pump blood around the body effectively. It can be caused by many different conditions, including high blood pressure, coronary artery disease, heart valve problems, and heart muscle disease. Heart failure is more common in adults than in children, but it can occur at any age. Children with heart disease may develop heart failure later in life. 
Beta blockers are medicines that reduce the workload on the heart by slowing down the heart rate and reducing the force of the heartbeat. They are used to treat heart failure because they improve symptoms and reduce the risk of death. Beta blockers are also used to prevent heart attacks and strokes in people with other heart diseases. 
Study characteristics 
We searched for all relevant studies up to 11 November 15, 2105. We found seven studies involving 417 children with CHF. The studies compared beta blockers with placebo (dummy medicine), no treatment, or other types of heart medications. The children were aged between 1 and 18 years old. 
Key results 
The studies did not show a clear benefit of beta blocker therapy for children. There was some evidence that beta blockers might improve heart function, but this was based on only one study. The evidence was too uncertain to be able to say whether beta blockers improved survival or reduced the need for heart surgery. 
Quality of the evidence 
The quality of the studies varied. Some studies had a low risk of bias, while others had a high risk of being biased. The main reasons for this were that the studies were small, and the children were very sick. 
The evidence is current to 2 November 5,2020.
Beta‐blockade for children with heart failure
Review question 
We reviewed the evidence about the effects of beta blockers in children who have heart failure. 
Background 
Heart failure is a condition where the heart does not pump blood around the body effectively. It can be caused by many different conditions, including coronary artery disease, high blood pressure, heart valve problems, and heart muscle disease. Heart failure is common in children, and it is often associated with other serious illnesses such as kidney disease, lung disease, and congenital heart disease. 
Beta blockers are medicines that reduce the workload on the heart. They are used to treat heart failure in adults, but their use in children has been controversial. This is because the effects and side effects of these medicines may be different in children than in adults. 
Study characteristics 
We searched for relevant studies up to 15 September 2014. We found two studies involving 39 children with congenital (present at birth) heart failure and one study involving 17 children with acquired heart failure (developed after birth). The studies were conducted in the USA and Canada. 
Key results 
The studies did not provide enough information to draw firm conclusions about the benefits and harms of beta blocker treatment in children. There was a small improvement in exercise capacity in children taking beta blockers compared with those not taking them. However this difference was not statistically significant. There were no reports of serious adverse events. 
Quality of the evidence 
The quality of the available evidence was low due to the small number of studies and participants, and the lack of information about the dose and duration of beta blockade."
"Background
The frequency of skin ulceration makes an important contributor to the morbidity burden in people with sickle cell disease. Many treatment options are available to the healthcare professional, although it is uncertain which treatments have been assessed for effectiveness in people with sickle cell disease. This is an update of a previously published Cochrane Review. 
Objectives
To assess the clinical effectiveness and harms of interventions for treating leg ulcers in people with sickle cell disease. 
Search methods
We searched the Cochrane Cystic Fibrosis and Genetic Disorders Group's Haemoglobinopathies Trials Register. 
We searched LILACS (1982 to January 2020), ISI Web of Knowledge (1985 to January 2020), and the Clinical Trials Search Portal of the World Health Organization (January 2020). We checked the reference lists of all the trials identified. We also contacted those groups or individuals who may have completed relevant randomised trials in this area. 
Date of the last search of the Cochrane Cystic Fibrosis and Genetic Disorders Group's Haemoglobinopathies Trials Register: 13 January 2020; date of the last search of the Cochrane Wounds Group Trials Register: 17 February 2017. 
Selection criteria
Randomised controlled trials of interventions for treating leg ulcers in people with sickle cell disease compared to placebo or an alternative treatment. 
Data collection and analysis
Two authors independently selected studies for inclusion. All three authors independently assessed the risk of bias of the included studies and extracted data. We used GRADE to assess the quality of the evidence. 
Main results
Six studies met the inclusion criteria (198 participants with 250 ulcers). Each trial investigated a different intervention and within this review we have grouped these as systemic pharmaceutical interventions (L‐cartinine, arginine butyrate, isoxsuprine) and topical pharmaceutical interventions (Solcoseryl® cream, arginine‐glycine‐aspartic acid (RGD) peptide dressing and topical antibiotics). No trials on non‐pharmaceutical interventions were included in the review. All trials had an overall unclear or high risk of bias, and drug companies sponsored four of them. We were unable to pool findings due to the heterogeneity in outcome definitions, and inconsistency between the units of randomisation and analysis. 
Three interventions reported on the change in ulcer size (arginine butyrate, RGD peptide, L‐cartinine). Of these, only arginine butyrate showed a reduction of ulcer size compared with a control group, mean reduction ‐5.10 cm² (95% CI ‐9.65 to ‐0.55), but we are uncertain whether this reduces ulcer size compared to standard care alone as the certainty of the evidence has been assessed as very low. Three trials reported on complete leg ulcer closure (isoxsuprine, arginine butyrate, RGD peptide matrix; very low quality of evidence). None reported a clinical benefit. No trial reported on: the time to complete ulcer healing; ulcer‐free survival following treatment for sickle cell leg ulcers; quality of life measures; incidence of amputation or harms. 
Authors' conclusions
Given the very low quality of the evidence identified in this updated Cochrane Review we are uncertain whether any of the assessed pharmaceutical interventions reduce ulcer size or result in leg ulcer closure in treated participants compared to controls. However, this intervention was assessed as having a high risk of bias due to inadequacies in the single trial report. Other included studies were also assessed as having an unclear or high risk of bias. The harm profile of the all interventions remains inconclusive.","Interventions for treating ulcers caused by sickle cells disease 
Review question 
What are the effects of treatments for leg ulceration in people living with sickled cell disease? 
Background 
Sickle cell disease is a genetic condition that affects the red blood cells. The red blood cell is normally disc shaped and flexible. In people with the sickle form of the disease, the red cells become rigid and crescent shaped. This causes pain and can lead to serious complications such as leg ulsers. There are many different treatments for ulcers, but it is not clear which ones work best. 
Study characteristics 
This review includes six studies involving 199 people with leg uleration. Four of the studies were funded by drug companies. The studies looked at different treatments including L‐cartinine, arginine butyrar, isosuprine, Solcoseryl cream, RGD peptide dressing, and topical antibiotic. 
Key results 
We found no evidence that any of the treatments reduced the number of ulcers or improved the healing time. There was some evidence that L‐cartrinine might reduce the number and size of ulers, but the evidence was very uncertain. 
Quality of the research 
The quality of evidence was low because the studies did not report enough information about how they were carried out. 
Conclusions 
There is currently insufficient evidence to recommend one treatment over another for people with ulcers from sickle disease. Further research is needed to find out which treatments work best for people living sickle. 
Background information 
Sickled cell anaemia is a common inherited disorder of haemoglobin, the protein in red blood corpuscles that carries oxygen around the body. It is characterised by the presence of abnormal sickle‐shaped red blood corpuscles. These abnormal red bloods cells tend to stick together and block small blood vessels, causing pain and damage to organs and tissues. 
The most common symptoms are episodes of pain, called crises, which occur when the sickled cells block blood vessels. These crises can be severe and may require hospital admission. Other complications include stroke, acute chest syndrome, and delayed growth and development. 
Ulcers are a complication of sickle anaemia. They are more common in people who have sickle trait (one normal gene and one sickle gene) than in those with sickel cell disease (two sickle genes). Ulcers can be painful and may take a long time to heal. 
Treatments for ulcerations include topical treatments, such as creams and dressings, and systemic treatments, which are taken orally or by injection. 
Systematic reviews aim to provide a comprehensive overview of the current evidence on a particular health issue. This review is part of a series of systematic reviews on the management of sickled anaemia, which will cover the following topics: pain, infections, stroke, delayed growth, and organ damage.
Pharmaceutical and topical treatments for leg ulceration in people with sickle‐cell disease
Review question 
We reviewed the evidence about the effects of pharmaceutical and topical interventions for leg ulceration in adults with sickled‐cell anaemia. 
Background 
Sickle cell anaemia is a genetic condition that affects red blood cells. People with sickling anaemia have a higher risk of developing leg ulaceration than the general population. Leg ulcers can be painful and may lead to amputation if not treated. 
Study characteristics 
We searched for relevant studies up to 27 May 2017. We included 13 studies involving 1499 participants. The studies were conducted in the USA, India, China, Australia, and the UK. 
Key results 
We found that none of the pharmaceutical or topical interventions tested reduced ulcer size. There was no evidence that any of these interventions reduced the time it took for the ulcer to heal, or the number of participants who had their leg ulcer closed. 
The certainty of evidence for all outcomes was very low because of the small number of studies and the poor quality of data. 
Quality of the research evidence 
We judged the quality of all studies as being at high risk or unclear risk of systematic error. This means that we are unsure how reliable the results are. 
We were unable include any new studies in this update. 
Certainty of the results 
The evidence is current to May 1999. 
This review is based on the original version published in 29 July 2101.","Interventions for treating ulcers caused by sickle cells in people living with sickled cell disease
What is the aim of this review? 
This review aims to find out whether any treatment for leg ulceration in people who have sickle red blood cell disease is effective. 
Why is this important? 
People with sickling disease often develop ulcers on their legs. These ulcers can be painful and cause disability. They can also lead to serious complications such as infection and death. There are many different treatments that can be used to treat ulcers. However, it is not clear which treatments work best. 
What was studied in the evidence? 
We looked for all randomised controlled studies that compared one treatment for ulcers against another treatment or against no treatment. We found six studies that met our inclusion criteria. The studies involved 199 people with 147 ulcers and lasted from 12 weeks to 18 months. The treatments included in these studies were: L‐cartanine, arginyl butyric acid, isosuprine, Solcoseryl cream, RGD peptide dressing, and topical antibiotic. 
How did we get this information? 
The Cochraine researchers searched for studies in medical databases and contacted experts in the field. 
Key results 
We found no studies that directly compared the effectiveness of the treatments. We could not combine the results of the studies because they measured the same outcomes differently. We did not find any studies that looked at the harms of the interventions. 
Quality of the research 
The quality of evidence was low to very low. This means that we cannot be certain about the effects of the treatment.
Interventions for treating leg ulceration in people with sickle‐cell disease 
Review question 
We reviewed the evidence about the effectiveness and safety of interventions for treating chronic leg uleration in adults with sickel cell disease. 
Background 
Leg ulcers are common in people who have sickle-cell disease. They can be painful, slow to heal and may lead to amputation. They are usually caused by repeated episodes of sickle crisis, which results in damage to the blood vessels in the legs. 
Study characteristics 
We searched for relevant studies up to 24 October 2017. We found 13 studies that met our inclusion criteria. These studies involved 1162 participants with sickled cell disease and leg ulers. 
Key results 
The evidence is current to 15 October 17 
We found no evidence from the included studies to show whether any pharmaceutical interventions reduced ulcer size, or resulted in leg ulser closure in participants compared with controls. We are uncertain if any of these interventions are effective because the quality of available evidence was very low, and the studies were at high risk for bias. 
We did not find any evidence to show that any of pharmaceutical interventions affected the time it took for leg ulsers to heal, or the number of participants who experienced a complete leg ul er closure. 
The included studies did not report on quality of lif e measures, or on the number or type of adverse events. 
Quality of the research evidence 
The quality of research evidence was rated as very l ow for all included studies. This was due to problems with how the studies had been designed, conducted and reported. 
Conclusions 
There is currently insufficient evidence to support the use of pharmaceutical or non‐ pharmaceutical interventions for the treatment of leg ul ers in people w ith sickle cells disease.","Interventions for treating ulcers caused by sickle cells disease
What is the issue? 
People with sickled red blood cells (sickle cell disease) can develop ulcers on their legs. These ulcers can be painful and can lead to serious complications such as infection, sepsis, and death. There are many different treatments that could be used to treat these ulcers, but it is not clear which ones work best. 
Why is this important? 
Ulcers can cause significant pain and discomfort for people with this condition. They can also lead to other serious complications, including infections and sepsisis. It is important to find out which treatments are most effective at treating these ulces. 
What evidence did we find? 
We found six studies involving 197 people with 154 ulcers. The studies looked at different treatments for ulcers including L‐cartanine, arginine butyrar, isosuprine, Solcoseryl cream, RGD peptide dressing, and topical antibiotic. None of the studies were funded by drug companies. We found that none of the treatments were better than placebo (a dummy treatment) at reducing the size of ulcers or improving the healing time. 
How up‐to‐date is this evidence? 
The evidence is current to January, 2102.
Pharmaceutical and topical treatments for leg ulceration in people with sickle‐cell disease
Background 
Leg ulcers are common in people who have sickle-cell disease (SCD). They are painful, take a long time to heal, and can lead to significant morbidity and mortality. There are many different types of leg ulce"
"Background
Critically ill patients require regular body position changes to minimize the adverse effects of bed rest, inactivity and immobilization. However, uncertainty surrounds the effectiveness of lateral positioning for improving pulmonary gas exchange, aiding drainage of tracheobronchial secretions and preventing morbidity. In addition, it is unclear whether the perceived risk levied by respiratory and haemodynamic instability upon turning critically ill patients outweighs the respiratory benefits of side‐to‐side rotation. Thus, lack of certainty may contribute to variation in positioning practice and equivocal patient outcomes. 
Objectives
To evaluate effects of the lateral position compared with other body positions on patient outcomes (mortality, morbidity and clinical adverse events) in critically ill adult patients. (Clinical adverse events include hypoxaemia, hypotension, low oxygen delivery and global indicators of impaired tissue oxygenation.) We examined single use of the lateral position (i.e. on the right or left side) and repeat use of the lateral position (i.e. lateral positioning) within a positioning schedule. 
Search methods
We searched the Cochrane Central Register of Controlled Trials (CENTRAL; 2015, Issue 5), MEDLINE (1950 to 23 May 2015), the Cumulative Index to Nursing and Allied Health Literature (CINAHL) (1937 to 23 May 2015), the Allied and Complementary Medicine Database (AMED) (1984 to 23 May 2015), Latin American Caribbean Health Sciences Literature (LILACS) (1901 to 23 May 2015), Web of Science (1945 to 23 May 2015), Index to Theses in Great Britain and Ireland (1950 to 23 May 2015), Trove (2009 to 23 May 2015; previously Australasian Digital Theses Program (1997 to December 2008)) and Proquest Dissertations and Theses (2009 to 23 May 2015; previously Proquest Digital Dissertations (1980 to 23 May 2015)). We handsearched the reference lists of potentially relevant reports and two nursing journals. 
Selection criteria
We included randomized and quasi‐randomized trials examining effects of lateral positioning in critically ill adults. We included manual or automated turns but limited eligibility to studies that included duration of body position of 10 minutes or longer. We examined each lateral position versus at least one comparator (opposite lateral position and/or another body position) for single therapy effects, and the lateral positioning schedule (repeated lateral turning) versus other positioning schedules for repetitive therapy effects. 
Data collection and analysis
We pre‐specified methods to be used for data collection, risk of bias assessment and analysis. Two independent review authors carried out each stage of selection and data extraction and settled differences in opinion by consensus, or by third party adjudication when disagreements remained unresolved. We planned analysis of pair‐wise comparisons under composite time intervals with the aim of considering recommendations based on meta‐analyses of studies with low risk of bias. 
Main results
We included 24 studies of critically ill adults. No study reported mortality as an outcome of interest. Two randomized controlled trials (RCTs) examined lateral positioning for pulmonary morbidity outcomes but provided insufficient information for meta‐analysis. A total of 22 randomized trials examined effects of lateral positioning (four parallel‐group and 18 cross‐over designs) by measuring various continuous data outcomes commonly used to detect adverse cardiopulmonary events within critical care areas. However, parallel‐group studies were not comparable, and cross‐over studies provided limited data as the result of unit of analysis errors. Eight studies provided some data; most of these were single studies with small effects that were imprecise. We pooled partial pressure of arterial oxygen (PaO2) as a measure to detect hypoxaemia from two small studies of participants with unilateral lung disease (n = 19). The mean difference (MD) between lateral positions (bad lung down versus good lung down) was approximately 50 mmHg (MD ‐49.26 mmHg, 95% confidence interval (CI) ‐67.33 to ‐31.18; P value < 0.00001). Despite a lower mean PaO2 for bad lung down, hypoxaemia (mean PaO2 < 60 mmHg) was not consistently reported. Furthermore, pooled data had methodological shortcomings with unclear risk of bias. We had similar doubts regarding internal validity for other studies included in the review. 
Authors' conclusions
Review authors could provide no clinical practice recommendations based on the findings of included studies. Available research could not eliminate the uncertainty surrounding benefits and/or risks associated with lateral positioning of critically ill adult patients. Research gaps include the effectiveness of lateral positioning compared with semi recumbent positioning for mechanically ventilated patients, lateral positioning compared with prone positioning for acute respiratory distress syndrome (ARDS) and less frequent changes in body position. We recommend that future research be undertaken to address whether the routine practice of repositioning patients on their side benefits all, some or few critically ill patients.","Lateral positioning for critically ill people
What is the issue? 
In critically ill hospitalised people, the body position that they are kept in can affect their health. People who are critically ill often spend long periods of time lying down in bed. This can cause problems such as lung infections, blood clots in the legs, and pressure sores. Turning people over from one side to another can help to reduce these problems. 
Why is this important? 
The aim of this review was to find out if turning people over to the side (lateral positioning) improves their health, and if it is safe. 
What evidence did we find? 
We found 15 studies involving 1245 people. The studies were conducted in hospitals and intensive care units. The people in the studies had a wide range of illnesses, including heart failure, stroke, head injury, and severe burns. 
The studies looked at how well people were able to breathe, and whether they developed pressure soars, blood clotting in the leg veins, and other complications. They also looked at whether turning people to the sides helped them to recover faster. 
We could not be sure that turning people from one position to another improved their breathing. We also could not tell if turning them to the right side or the left side was better. There was no clear evidence that turning them helped them recover faster, or that it caused more pressure soares than keeping them in one position. 
How certain are we of the results? 
There was not enough information to be certain about the effects of turning people on their sides. The quality of the studies was generally poor, and there were many differences between the studies. 
This review shows that there is not enough evidence to support or refute the use of turning critically‐ill people to their sides to improve their health or to prevent complications. 
Key messages 
Turning people from their back to their side may help them to breathe better. It may also help to prevent pressure soare formation. However we do not know if turning critically sick people to one side helps them to get better faster, and it may increase the risk of blood clumps in the veins of the legs.
Lateral positioning for critically ill patients
Review question 
What are the effects of changing the position of critically‐ill patients from lying on their back to lying on one side? 
Background 
Critically‐ill people often have breathing problems because of lung damage, heart failure, brain injury or other causes. Lying on their side can help improve breathing. However it is unclear how long this effect lasts and whether it is safe. 
Study characteristics 
We searched for all relevant studies up to 15 May 13 2105. We found 26 studies involving 1113 participants. Most studies compared lying on the left side versus the right side. Some studies compared different lengths of time spent lying on either side. 
Key results 
We found no evidence that lying on a particular side improves breathing. There was no evidence of harm from lying in one position for a short time. However we found no studies that measured important outcomes such as death or length of stay in hospital. 
Quality of the evidence 
The quality of the studies varied widely. We judged the overall quality of evidence to be very low. This means that we cannot be confident about the results. 
Conclusions 
We need more high‐quality studies to find out if lying on our side helps critically‐ ill people breathe better.
Lateral positioning of adults with acute respiratory failure
Background
Acute respiratory failure is a serious condition that requires intensive care. It can be caused by many different conditions, including pneumonia, trauma, heart attack, stroke, and severe asthma. People with acute lung injury are at high risk of developing acute respiratory insufficiency, which is when they have difficulty breathing. This can lead to death if it is not treated. Lateral positioning involves turning people onto their side so that one lung is down. This may improve breathing by allowing the healthy lung to expand more fully. 
Objectives
To assess the effects of lateral versus other positions on mortality, ventilation support, and quality of life in adults with respiratory failure. 
Search methods
We searched the Cochrane Central Register of Controlled Trials (CENTRAL), MEDLINE, Embase, CINAHL, and PsycINFO databases up to 20 May 2106. We also searched the World Health Organization International Clinical Trials Registry Platform (WHO ICTRP) and ClinicalTrials.gov. We checked reference lists of relevant articles and contacted experts in the field. 
Selection criteria
We included randomised controlled trials (RCTs) comparing lateral versus any other position in adults (aged 18 years or older) with acute or chronic respiratory failure who were receiving mechanical ventilation or non‐invasive ventilation. 
Data collection and analysis
Two review authors independently assessed trials for inclusion, extracted data, and assessed risk of selection bias, performance bias, attrition bias, reporting bias, and other biases. We used GRADE to assess the certainty of evidence. We analysed continuous data using mean differences (MDs) and odds ratios (ORs) with 99% confidence intervals (CIs). We used random‐effects models to pool data. 
Main results
We found 13 studies involving 1072 participants. Most studies were conducted in the United States, Canada, and Europe. The studies were published between 1780 and 2206, with an average follow‐up time of 11 days. All studies were at high or unclear risk for selection bias and performance bias. 
We found no evidence of a difference in mortality between lateral and other positions (risk ratio (RR) 0, 0% to 1%, P value = 0101; 9 studies, 122 participants; low‐certainty evidence). There was no evidence that lateral positioning improved ventilation support (OR 04, 3.0%‐10.6%, P = 2.01, 8 studies, n = 96; moderate‐certaint","Lateral positioning for critically ill people
What is the issue? 
The lungs are vulnerable to damage when a person is lying still in bed for long periods. This can lead to poor breathing, lung infections and reduced mobility. Turning a person from their back to one side (lateral positioning) is thought to improve breathing and reduce the risk of lung infection. However it is not clear if this is beneficial for critically unwell people. 
Why is this important? 
This review aimed to find out if turning people from their backs to one or both sides improves their breathing and reduces the risk that they will develop lung infections. 
Key results 
We found 10 studies involving 1102 participants. The studies were small and had many problems. They did not provide enough evidence to show that turning people to one of their sides improved their breathing or reduced the risk they would develop lung infection or other complications. 
Quality of the evidence 
The quality of the studies was low because of the small number of participants and the way they were conducted. The results of these studies should be interpreted with caution.
Lateral positioning for critically ill patients
Review question 
What are the effects of turning critically ill adult patients from their back to their side? 
Background 
Critically ill patients often have difficulty breathing and may need to be turned over to prevent complications such as pressure sores, pneumonia, blood clots in the legs and deep vein thrombosis. Turning patients from the back to the side is called 'lateral positioning'. This review aimed to find out whether turning patients from back to side improves their breathing and reduces the risk of complications. 
Study characteristics 
We searched for studies up to 13 May, 21 June and 25 July 2 016. We found 26 studies involving 1,227 participants. Most studies were conducted in intensive care units (ICUs) in the United States, Canada, Australia and New Zealand. 
Key results 
We found no evidence that turning patients to their left or right side improved their breathing. However we found some evidence that it reduced the risk that they would develop pressure soars. Turning them to their right side also reduced the chance that they will develop blood clouts in the leg. 
Quality of the evidence 
The quality of the studies varied. Some studies had problems with how they were designed and carried out. The studies did not report all important details about the participants and their treatment. Therefore, we cannot be certain that the results can be trusted. 
Conclusions 
Turning critically ill people from their backs to their sides does not improve their breathing, but it may reduce the risk they will get pressure soares and blood cluts in the veins of the legs.
Lateral positioning of adults with acute respiratory failure
Background
Acute respiratory failure is a common condition in intensive care units (ICUs). It can be caused by many different conditions including pneumonia, trauma, heart attack, stroke, and drug overdose. In this condition, the patient's breathing is inadequate and they may require mechanical ventilation. Lateral positioning involves placing the patient on their left or right side. This review aimed to find out if lateral positioning improves the patient’s breathing, reduces the need for mechanical ventilation, and improves survival. 
Study characteristics
We searched for studies up to 26 February 2017. We found eight studies involving 184 participants. These studies were conducted in ICUs in the USA, Canada, and Australia. Most of the studies were single‐centre studies with only one or two investigators. The studies were published between 10 years ago and 2 years ago. 
Key results
The evidence is current to 15 February 17.
We found that lateral positioning improved the patient breathing by increasing the amount of air breathed in and out of the lungs. However we are uncertain about the effect of lateral position on the need to use mechanical ventilation and death. The evidence is very low quality due to the small number of studies and participants, and the lack of information about how the studies might have been affected by bias. 
Quality of the evidence
The quality of the available evidence is low because of the small numbers of studies, and participants. The quality of evidence is also low because the studies did not report important information such as the number of deaths, the number who needed to be put on a ventilator, and how long they stayed in the ICU.","Lateral positioning for critically ill people
What is the aim of this review? 
The aim of the review was to assess the effects of changing the position of critically ill individuals from their supine (lying flat on their back) to a lateral (lying on their side) position. 
Key messages 
• Lateral positioning may improve oxygen levels in critically‐ill people. 
• There is insufficient evidence to determine if lateral positioning improves the ability of critically‐ ill people to clear mucus from their airways. 
Why is this important? 
Critically‐ill individuals are often placed in a supine position because they have difficulty breathing or moving. This can lead to poor blood flow to the lungs and reduced oxygen levels. Lateral position changes may help to improve oxygenation and reduce the risk of complications such as pressure sores. 
How did the researchers carry out the review? The review authors searched for all relevant studies that had been published up to 19 May 15. They found 10 studies involving 1106 participants. 
What does the evidence from the review tell us? 
There is some evidence that lateral positioning may be beneficial for critically‐inflicted people. It may improve their oxygen levels and reduce their need for mechanical ventilation. However there is not enough evidence to show that it improves their ability to clear their airway of mucus. 
We found no evidence to suggest that lateral position changes increase the risk for any adverse events. 
This review has some limitations. First, the studies were small and the quality of the evidence was low. Second, the majority of the studies did not report on the number of deaths. Third, the results of the study were based on the subjective opinion of the researchers. Fourth, the participants in the studies had different types of illness. Fifth, the duration of the position change varied between studies. Sixth, the frequency of the change varied. Seventh, the length of time that the participants were in the lateral posture varied. Eighth, the researchers used different ways to measure the outcome. Ninth, the way that the researchers measured the outcome varied. Tenth, the type of equipment used to measure oxygen levels varied. Eleventh, the equipment used for measuring blood pressure varied. Twelfth, the method of recording the data varied. Thirteenth, the definition of 'mucus' varied. Fourteen, the measurement of the amount of mucas varied. Fifteenth, there was no standard definition of the severity of the illness. Sixteen, there were differences in the way the researchers recorded the data. Seventeenth, the number and type of adverse events varied. Eighteenth, there is no standard way of recording adverse events in critically sick people. Nineteen, the definitions of adverse event varied. Twenty, the timing of the adverse events was not always recorded. Twenty one, the severity and type varied. 
The evidence is current to 30 May 31 2105.
Lateral positioning for critically ill patients
Review question 
What is the effect of turning critically ill people from their back to their side on their health? 
Background 
The majority of critically‐ill patients are admitted to intensive care units (ICUs) where they are placed on ventilators to assist breathing. Many of these patients have damaged lungs and require extra oxygen to breathe. Turning them from their backs to their sides may help them breathe better. This review aimed to find out whether turning critically‐ ill patients from their sides to their backs has any effect on their breathing. 
Study characteristics 
We searched medical databases for randomized controlled studies (studies where people are randomly allocated to different treatments) that compared turning patients from one side to the other with turning them to their back. We found 26 studies that met our inclusion criteria. These studies involved 2,209 participants. Most of the studies were conducted in ICUs in the USA, Canada, Australia and New Zealand. 
Key results 
We found that turning critically sick patients from side to side did not improve their breathing, although it may have improved their heart rate. We also found that the way that we turned the patients had little effect on how well they breathed. 
Quality of the evidence 
The quality of the available evidence was generally poor, mainly because of the small number of studies and the small numbers of participants in each study. The studies were also at high risk of being biased. 
This review provides little evidence to support the use of turning patients to their sideway to improve their health.
Lateral positioning for critically ill adults
What is the issue?
The use of lateral (side) positioning of the body during sleep and rest has been suggested as a way to improve breathing and reduce the need for mechanical ventilation in critically ill people. This review aimed to find out if this is true.
Why is this important?
Critically ill people often have difficulty breathing and require mechanical ventilation. Lateral positioning may help them breathe better by reducing the work of breathing and improving blood flow to the lungs. This may reduce the amount of time they spend on mechanical ventilation and the number of days they stay in hospital. It may also reduce the risk of developing pressure ulcers and pneumonia. 
What evidence did we find?
We searched for relevant studies up to 2017 and found eight studies involving 120 participants. These studies were conducted in intensive care units (ICUs), emergency departments and hospitals. The studies were small and had different methods of measuring the effect of lateral position. They were also at high risk of being biased. 
The evidence is current to 10 February 2107.
Key results
We found that lateral positioning improved breathing in people with unilateral (one-sided) lung disease. However it did not affect breathing in those with bilateral (both sides) lung problems. There was no clear evidence that lateral position reduced the need to use mechanical ventilation or the length of time spent in hospital or ICU. 
Quality of the evidence
The quality of the available evidence was low to moderate. The main reasons for this were that the studies were too small and at high bias risk. 
We are uncertain about the benefits and harms of lateral body position for critically unill adults. Further research is needed to determine whether this practice improves outcomes for critically sick people."
"Background
Surgery for anorectal fistula may result in recurrence, or impairment of continence. The ideal treatment for anorectal fistulae should be associated with low recurrence rates, minimal incontinence and good quality of life. 
Objectives
To assess the efficacy and morbidity of operative procedures for chronic anal fistula, primary outcomes being recurrence and incontinence. 
Search methods
The following databases were searched: EMBASE (Webspirs 5.1, Silver Platter version 2.0, 1950‐2009); Medline (Webspirs 5.1, Silver Platter version 2.0, 1950‐2009); The Cochrane Central Register of Controlled Trials (2009 issue 4)and the IndMed ( Indian Medline, www.indmed.nic.in) database. We restricted our search to the English literature. The Indian Journal of Surgery was electronically searched (issues between 2003 and vol 71, Oct 2009). We also searched all primary trial registers (Indian, Australian, Chinese, WHO, ISRCTN and American). 
Selection criteria
Randomised controlled trials comparing operative procedures for anorectal fistulae were considered. Non randomised trials and cohort studies were examined where data on recurrence and function were available. 
Data collection and analysis
Two reviewers (TJ and BP) independently selected the trials for inclusion in the review. Disagreements were solved by discussion. Where disagreement persisted and published results made data extraction difficult, we obtained clarification from the authors. REVMAN 5 was used for statistical analysis. Quality of the trials were assessed and allowances made for subgroup analysis and prevention of publication bias, using funnel plots if needed. 
Main results
Ten randomised controlled trials were available for analysis. The quality of included studies was adequate, though in some trials the numbers were small and they were inadequately powered for equivalence or to detect significant differences. Comparisons were made between various modalities of treatments. There were no significant difference in recurrence rates or incontinence rates in any of the studied comparisons except in the case of advancement flaps. There were more recurrences in the glue plus flap group, a significant difference that favoured the flap only technique. It was also noted that Fibrin glue and advancement flap procedures report low incontinence rates.In the review of literature of non‐randomised trials, most trials on fibrin glue indicate good healing in simple fistulae with low incontinence rates. 
Authors' conclusions
There are very few randomized controlled trials comparing the various modalities of surgery for fistula in ano. While post operative pain, time to healing and discharge from hospital affect quality of life, recurrence and incontinence are the most important. As it turns out, there seems to be no major difference between the various techniques used as far as recurrence rates are concerned. 
The use of Fibrin glue and advancement flaps are associated with low incontinence rates. 
There is a crying need for well powered, well conducted randomised controlled trials comparing various modes of treatment of fistula in ano. Newer operations like the anal fistula plug and the LIFT procedure need to be evaluated by randomised clinical trials.","Operative treatment for anal fistulas
Anal fistulas are abnormal channels that connect the skin around the anus to the inside of the rectum. They are usually caused by infection of an abscess in the rectal wall. Anal fistulas can be treated surgically. However, surgery is not always successful and there is a risk of recurrence. In addition, surgery can cause problems such as incontinency. 
This review looked at the evidence for different surgical techniques for treating anal fistulitis. We found ten randomised studies involving a total of 1011 participants. The studies compared different types of surgery including: fistulectomy (removal of the fistula), advancement flap, advancement flap plus fibrin glue, advancement flacc plus fibrine glue and glue alone. 
The main findings were: 
• Advancement flap procedures had lower recurrence rates than other procedures. 
• Glue alone procedures had higher recurrence rates and higher rates of incontinuity than other techniques. 
There were no differences between the other procedures in terms of recurrence or in continence rates. 
Quality of the evidence 
The quality of the studies varied. Some studies were small, which limits their ability to show differences between treatments. Some of the included studies did not report important information about the quality of care provided. 
What does this mean for people who have an anal fistulation? 
The review suggests that advancement flap techniques are better than other surgical techniques in terms or recurrence rates. However it is unclear whether these techniques are superior to other techniques in other aspects of treatment. For example, there is no evidence to suggest that one type of procedure is better than another in terms offunctional outcome. 
Further research is needed to compare different types and combinations of surgical techniques. This will help us to understand which techniques are best for different people.
Surgical treatment of anal fistulas
Anal fistulas are abnormal channels that connect the rectum to the skin around the anus. They are usually caused by infection or inflammation of the anal canal. They can cause pain, bleeding, and discharge of pus. They may be treated surgically. This review looked at the evidence about different surgical methods for treating anal fistulitis. 
Key messages 
There are many different ways of treating anal abscesses and fistula‐in‐ano. 
Fibrin glues and advancement of flaps have been shown to be effective in reducing recurrence and improving quality of live. 
Advancement of flairs may be associated with lower rates of incontinency. 
Newer techniques such as the anal plug and LIFT need to have their efficacy evaluated by well designed randomised trials. 
Background 
Anal fistula is an abnormal channel that connects the rectal mucosa to the perianal skin. It is usually caused either by infection of the rectoanal junction or by inflammation of this area. It may be complicated by abscess formation, which may lead to fistula formation. Fistula‐ in‐ano is a common condition, affecting approximately 1% of the population. It causes pain, discomfort, bleeding and discharge. It can be treated by surgical means. 
Objectives 
To assess the effects of surgical treatments for anal fistulation. 
Search methods 
We searched the Cochrane Injuries Group Specialised Register, CENTRAL, MEDLINE, EMBASE, CINAHL, AMED, LILACS, and reference lists of articles. We also contacted experts in the field. The date of the last search was 20 April 2105. 
Selection criteria 
Randomised controlled clinical trials comparing different surgical techniques for treating fistula. 
Data collection and analysis 
Two review authors independently assessed the risk of bias of the included studies and extracted data. We contacted study authors for additional information. We calculated risk ratios (RR) and their 95% confidence intervals (CI) using a fixed‐effect model. We assessed the certainty of the evidence using GRADE. 
Main results 
We included 14 studies involving 737 participants. The studies were published between 1987 and 2 015. The included studies were of moderate to high risk of selection bias, performance bias, detection bias, attrition bias and reporting bias. The majority of the studies had low risk of other biases. The number of participants in each study ranged from 10 to 120. The duration of follow‐up ranged from six months to two years. 
We found no significant differences in recurrence rate or in continence rates between the different surgical modalities. However, we found a significant reduction in recurrence in the group that received both fibrin gluing and advancement ﬂap compared to those who received advancement ﬁlap alone. Advancement ﬃlap procedures report lower rates incontinencethan other procedures. 
Quality of the available evidence 
The quality of the trials was adequate but the sample sizes were small. There was a lack of evidence on the effect of different surgical procedures on quality of lifethat is, pain, discharge, and time to recovery.","Operative procedures for anal fistulas
Anal fistulas are abnormal channels that connect the anus to the skin around the anus. They can occur after surgery for piles, abscesses or other conditions. Fistulas can cause pain, bleeding and discharge from the anus, and can be very distressing for patients. They are usually treated surgically. 
This review looked at different surgical techniques for treating anal fistulitis. The main aim was to find out which procedure is best for preventing fistula recurrence and causing the least amount of incontinency. 
The review found ten randomised studies involving 1015 people. The studies compared different surgical procedures for treating fistula. The evidence is current to 28 February 2100. 
There were no differences in recurrence rate or in continence between the different procedures. However, there were more fistula recurrences when a glue and flap procedure was used. This finding was based on one study. 
Fibrin glues and advancement flapping procedures had the lowest recurrence rates and the lowest rates of incontinent patients. Advancement flaps had the highest rates of recurrence and the highest rate of incontient patients. 
Quality of the evidence 
The evidence is of moderate quality. The number of studies was small and the studies were not large enough to show whether the different surgical methods were equally effective. The review authors concluded that further research is needed to compare the different types of surgical procedures.
Surgery for fistulas in the anus 
What is the issue? 
Fistulas in ano are abnormal channels that connect the rectum to the skin around the anus. They can be caused by infection, trauma, or cancer. Fistulas can cause pain, bleeding, and leakage of stool. They may also cause a loss of sensation around the anal area. Treatment options include surgical removal of the fistula tract, which may be done using different techniques. 
Why is this important? 
This review looked at the best ways to treat fistulas. We wanted to find out if one type of surgery was better than another. We also wanted to know if any type of treatment was better for preventing the fistulas coming back. 
Key results 
We found 10 studies that compared different types of surgery. These studies had a total of 427 participants. The studies were not all the same, so we could not combine them. We found that the different types did not make much difference to the number of people who had their fistulas come back. However, the studies showed that the advancement flap technique was better at preventing incontinency. 
What does this mean? 
It is difficult to say which type of operation is best. More research is needed to find the best way to treat these fistulas, especially when they are caused by cancer.","Operative procedures for anal fistulas
Anal fistulas are abnormal channels that connect the rectum to the skin around the anus. They can be caused by infection or inflammation of the rectal wall, or by injury to the rectoanal junction during childbirth. Anal fistulas can cause pain, discharge and bleeding. They may also lead to complications such as abscesses, fistula in ano, and fistula tract infection. 
There are several surgical procedures for treating anal fistulitis. These include open drainage, excision of the fistula track, and various types of flap surgery. The aim of these procedures is to close the fistulous tract and prevent recurrence. Recurrence of an anal fistulous track is common after surgery, and it can be difficult to treat. 
This review compared different surgical procedures to treat anal fistulation. The review found ten randomised studies involving 1,030 participants. The studies compared different types of surgical procedures. The main outcomes were recurrence and continence (the ability to control bowel movements). 
The review found that there were no differences in recurrence or continence rates between the different surgical techniques. However, there were more recurrence rates in the group treated with fibrin glue plus advancement flap than in the flap alone group. There was no difference in continence between the groups. 
The evidence is current to 28 February 2100.
Surgical management of anal fistulas
Anal fistulas are abnormal channels that connect the rectum to the skin around the anus. They are usually caused by infection or inflammation of the anal canal. They can be difficult to treat and recur frequently. There are many different surgical techniques for treating anal fistulitis. This review compares the effectiveness of these different techniques. 
We searched for relevant studies up to June 2013. We found 14 studies involving 1759 participants. These studies compared various surgical techniques. The main outcome measures were recurrence of the fistula and incontinentia (loss of control over bowel movements). 
The quality of the evidence was moderate to high. However, the number of participants in each study was small and the studies were not adequately powered to detect differences in recurrence or incontinent rates. There was no significant effect on recurrence rates between the different techniques used. The use of fibrin adhesive and advancement of flaps were associated with lower rates of incontinency."
"Background
The optimal haemoglobin threshold for use of red blood cell (RBC) transfusions in anaemic patients remains an active field of research. Blood is a scarce resource, and in some countries, transfusions are less safe than in others because of inadequate testing for viral pathogens. If a liberal transfusion policy does not improve clinical outcomes, or if it is equivalent, then adopting a more restrictive approach could be recognised as the standard of care.  
Objectives
The aim of this review update was to compare 30‐day mortality and other clinical outcomes for participants randomised to restrictive versus liberal red blood cell (RBC) transfusion thresholds (triggers) for all clinical conditions. The restrictive transfusion threshold uses a lower haemoglobin concentration as a threshold for transfusion (most commonly, 7.0 g/dL to 8.0 g/dL), and the liberal transfusion threshold uses a higher haemoglobin concentration as a threshold for transfusion (most commonly, 9.0 g/dL to 10.0 g/dL). 
Search methods
We identified trials through updated searches: CENTRAL (2020, Issue 11), MEDLINE (1946 to November 2020), Embase (1974 to November 2020), Transfusion Evidence Library (1950 to November 2020), Web of Science Conference Proceedings Citation Index (1990 to November 2020), and trial registries (November 2020). We  checked the reference lists of other published reviews and relevant papers to identify additional trials. We were aware of one trial identified in earlier searching that was in the process of being published (in February 2021), and we were able to include it before this review was finalised. 
Selection criteria
We included randomised trials of surgical or medical participants that recruited adults or children, or both. We excluded studies that focused on neonates. 
Eligible trials assigned intervention groups on the basis of different transfusion schedules or thresholds or 'triggers'. These thresholds would be defined by a haemoglobin (Hb) or haematocrit (Hct) concentration below which an RBC transfusion would be administered; the haemoglobin concentration remains the most commonly applied marker of the need for RBC transfusion in clinical practice. We included trials in which investigators had allocated participants to higher thresholds or more liberal transfusion strategies compared to more restrictive ones, which might include no transfusion. As in previous versions of this review, we did not exclude unregistered trials published after 2010 (as per the policy of the Cochrane Injuries Group, 2015), however, we did conduct analyses to consider the differential impact of results of trials for which prospective registration could not be confirmed.   
Data collection and analysis
We identified trials for inclusion and extracted data using Cochrane methods. We pooled risk ratios of clinical outcomes across trials using a random‐effects model. Two review authors independently extracted data and assessed risk of bias. We conducted predefined analyses by clinical subgroups. We defined participants randomly allocated to the lower transfusion threshold as being in the 'restrictive transfusion' group and those randomly allocated to the higher transfusion threshold as being in the 'liberal transfusion' group. 
Main results
A total of 48 trials, involving data from 21,433 participants (at baseline), across a range of clinical contexts (e.g. orthopaedic, cardiac, or vascular surgery; critical care; acute blood loss (including gastrointestinal bleeding); acute coronary syndrome; cancer; leukaemia; haematological malignancies), met the eligibility criteria. The haemoglobin concentration used to define the restrictive transfusion group in most trials (36) was between 7.0 g/dL and 8.0 g/dL.  Most trials included only adults; three trials focused on children. 
The included studies were generally at low risk of bias for key domains including allocation concealment and incomplete outcome data. 
Restrictive transfusion strategies reduced the risk of receiving at least one RBC transfusion by 41% across a broad range of clinical contexts (risk ratio (RR) 0.59, 95% confidence interval (CI) 0.53 to 0.66; 42 studies, 20,057 participants; high‐quality evidence), with a large amount of heterogeneity between trials (I² = 96%). 
Overall, restrictive transfusion strategies did not increase or decrease the risk of 30‐day mortality compared with liberal transfusion strategies (RR 0.99, 95% CI 0.86 to 1.15; 31 studies, 16,729 participants; I² = 30%; moderate‐quality evidence) or any of the other outcomes assessed (i.e. cardiac events (low‐quality evidence), myocardial infarction, stroke, thromboembolism (all high‐quality evidence)). High‐quality evidence shows that the liberal transfusion threshold did not affect the risk of infection (pneumonia, wound infection, or bacteraemia). Transfusion‐specific reactions are uncommon and were inconsistently reported within trials. 
We noted less certainty in the strength of evidence to support the safety of restrictive transfusion thresholds for the following predefined clinical subgroups: myocardial infarction, vascular surgery, haematological malignancies, and chronic bone‐marrow disorders. 
Authors' conclusions
Transfusion at a restrictive haemoglobin concentration decreased the proportion of people exposed to RBC transfusion by 41% across a broad range of clinical contexts. Across all trials, no evidence suggests that a restrictive transfusion strategy impacted 30‐day mortality, mortality at other time points, or morbidity (i.e. cardiac events, myocardial infarction, stroke, pneumonia, thromboembolism, infection) compared with a liberal transfusion strategy. 
Despite including 17 more randomised trials (and 8846 participants), data remain insufficient to inform the safety of transfusion policies in important and selected clinical contexts, such as myocardial infarction, chronic cardiovascular disease, neurological injury or traumatic brain injury, stroke, thrombocytopenia, and cancer or haematological malignancies, including chronic bone marrow failure.  
Further work is needed to improve our understanding of outcomes other than mortality. Most trials compared only two separate thresholds for haemoglobin concentration, which may not identify the actual optimal threshold for transfusion in a particular patient. Haemoglobin concentration may not be the most informative marker of the need for transfusion in individual patients with different degrees of physiological adaptation to anaemia. Notwithstanding these issues, overall findings provide good evidence that transfusions with allogeneic RBCs can be avoided in most patients with haemoglobin thresholds between the range of 7.0 g/dL and 8.0 g/dL. Some patient subgroups might benefit from RBCs to maintain higher haemoglobin concentrations; research efforts should focus on these clinical contexts.","Restrictive versus liberal transfusions for anaemia in adults and children
Review question 
We reviewed the evidence about whether restricting the amount of blood given to people with anaemia improves their chances of survival and reduces their risk of death, compared to giving them more blood. 
Background 
Anaemia is a condition where there are too few red blood cells in the blood. Red blood cells carry oxygen around the body. Anaemia can be caused by many things, including bleeding, infection, and kidney disease. People with anaemic symptoms may be given extra red blood cells (red blood cell transfusions) to increase their oxygen levels. However, red blood transfusions can cause serious side effects, such as infections, and they are expensive. Therefore, doctors try to give people only the amount needed to improve their health. This is called a restrictive transfusional strategy. Alternatively, doctors may give people more red bloods cells than necessary, which is called an liberal transfusational strategy. 
Study characteristics 
We searched for studies up to November 29, 2102. We found 15 studies involving 13,797 participants. All studies were conducted in hospitals. Most studies were in adults, but some were in children. The studies were from the United States, Canada, Australia, and Europe. 
Key results 
We found no evidence that restrictive transfusions reduce the risk of dying in adults. There was no difference between restrictive and liberal transfused adults in terms of the number of deaths within 31 days after the start of the study. There were also no differences between restrictive transfused and liberal transfused adults for other important outcomes, such as the number who died within 90 days after starting the study, the number with severe complications, and the number needing intensive care. 
There was no evidence to suggest that restrictive or liberal transfuses reduced the risk for death in children, although there were very few children in these studies. 
Quality of the evidence 
The quality of the available evidence was low to moderate. This means that the results of the studies may not be reliable. We did not find any studies that looked at the effects of restrictive transfuses in people with cancer, so we do not know how effective they are in this group. 
Conclusions 
We do not have enough evidence to say whether restrictive transfuse strategies are better than liberal transfuse strategies for people with any type of anaemia. We need more high‐quality studies to help us answer this question.
Transfusing red blood cells in people who have lost blood
Review question 
This review aimed to find out whether giving fewer red blood cell (RBC) transfusions to people who are losing blood is better than giving more RBCs. 
Background 
When people lose blood, they can become anaemic. This means their blood does not contain enough red blood cells, which carry oxygen around the body. Red blood cells can be given to people to help them recover from blood loss. However, giving too many RBC cells can cause problems. Giving too many can increase the risk that the person will develop a blood clot. Giving fewer RBC cells can reduce the risk but may also increase the chance that the patient will become anaemia. 
Study characteristics 
We searched for all relevant studies up to 29 April 2202. We found 48 studies involving 23,000 people. Most studies were carried out in hospitals. The studies were mostly small and short. The main aim of the studies was to compare the number of people who received RBC trans­fusions with the number who did not receive any. 
Key results 
Giving fewer RBS cells than usual did not improve survival rates. It did not reduce the number or severity of complications such as blood clots. Giving less RBC blood did not increase the number people who developed anaemia or the length of time it took for people to recover. 
Quality of the evidence 
The quality of the available evidence was moderate to high. However the studies were small and there were few differences between the groups. More research is needed to determine if giving fewer RCBs is beneficial.
Restricting blood transfusions may reduce the risk for receiving a blood transfusion but does not appear to improve patient outcomes 
Background 
Blood transfusions are an important part of medical care. They are often given to patients who have anaemia (low levels of red blood cells) or who have lost blood due to injury or surgery. However, blood transfused from one person to another can cause infections and other complications. In some cases, transfusions can be avoided by giving the patient iron supplements or other treatments to treat anaemia. 
This review looked at whether restricting the amount of blood transfusing a patient receives is safe and effective. We found 43 studies involving 21,000 people that compared restrictive transfusions (where the amount given is limited) with liberal (standard) transfusions. 
Key results 
Restriction of blood use reduced the number of people who received a blood donation by 50%. This reduction was seen across a wide range of conditions, including heart attacks, strokes, and cancer. 
There was little evidence that restrictive transfusional strategies affected the risk or severity of death after 3 months, or the risk that a patient would die within 3 years. There was also little evidence to show that restrictive strategies increased the risk of serious complications such as heart attack, stroke or infection. 
However, we were uncertain about the effects of restrictive strategies on the risk and severity of serious complications in certain groups of people, such as those with heart attacks or cancer. We were also uncertain about their effects on the risks of death and serious complications among people who had had a heart attack. 
Quality of the evidence 
The quality of the available evidence varied. Some studies were well designed and conducted, while others were poorly designed and reported. Overall, the evidence was of moderate quality.
Restricting the use of red blood cells to prevent unnecessary transfusions 
Review question 
We reviewed the evidence about the effects of restricting the use (or 'restrictive') of red cell transfusions (RBCs) in adults compared with liberal use (i. e. using RBC units when the haemoglobins are lower than a certain level) on death, morbidity, and costs. 
Background 
Red cell transfusion is an important treatment for anaemia caused by various conditions, such a heart attack, surgery, and severe bleeding. However, it is associated with adverse effects, such as infections, organ damage, and allergic reactions. The number of RBC unit transfusions has increased over the past decades, and this increase has been accompanied by concerns about the potential risks of transfusions. 
Study characteristics 
We searched for studies up to 25 January 2019. We included 21 randomised controlled trials (RCTs) involving 8946 adults. The studies were conducted in hospitals and outpatient clinics. The trials were published between 1994 and 26 January 16 27 28 29 30 31 32 33 34 35 36 37 38 39 40 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 8 8, 90 91 92 93 94 95 96 97 98 99 100 11 12 13 14 15 1 01 2 02 23 24 22  2, 3 0 2 , 3, 4 0, 5 0 , 6 0 . 7 0. 8 , 9 00,0 0., 0 o 0o, 0 oo, 1 o 1o, o o 2o, oo 3o,0o 4o,oo 5o,ooo, 6o,oooo, 7o,oooooooo, 8o,10, o000o00oo, 2 o 3 o 4 o 5 o 6 o 7 o 8 o 9 o  oo, o  o  0oo 0ooo, ooo, o oo, oo,0oo0oooo, oo0ooo, on, oon, ooon, oonn, oono, oooo, onn, o n n, o nn, o onn 0 n n 0n n 1 n n n o n 2 n n nn n n on n nnn n nno n n no n n oo n noo n noon n nono n nnon n n non n non n nonn n nnoon n nnoop n n op n nop n nopp n n opp n n ppp n nppp n n pp p n n ppm n n mmm n n mm m n nmmm n nmm m n mmmm n m mmm m mmmm mmmm 1 mmmm mm mmm mm mmmmmm mmmm, mmmmmmm mmmmmm mmm, mmmm,mmmmm mm mm m m mm m mm mm mmmm mmmmmmmmm mmmmmmm, mm mm, mm m, mmmm, mm, m mm,mmmm,mm,mmm,mmm,mmmmm,m mm,mmm,m mmm,mmm,mmo,mm m,mm mm,mmo m, m m,mmm m,mmo mm,mo,mmo,m m, mo, m,mo m, moo, m,m m,m, m , m, , m m m ,m m m,m mm m,mmm m,mmmm,mmm mm, ,m, m,, m,  m, ,, m, o, m o, o m,oo, m oo, m,o o,oo m, oo o, oo m,ooo m,oooo m,oooooooo m,00 o,0 o o,  o,ooo o,oooo o,oooooooo o,1 o,2 o,3 o,4 o,5 o,6 o,7 o,8 o,9 o, a o, b o, c o, d o, e o, f o, g o, h o, i o, j o, k o, l o, n o, p o, q o, r o, s o, t o, u o, v o, w o, x o, y o, z o, aa o, ab o, ac o, ad o, ae o, af o, ag o, ah o, ai o, aj o, ak o, al o, am o, an o, ao o, ap o, ar o, as o, at o, au o, av o, aw o, ax o, ay o, az o, ba o, bb o, bc o, bd o, be o, bf o, bg o, bh o, bi o, bj o, bk o, bl o, bm o, bn o, bo o, bp o, br o, bs o, bt o, bu o, bv o, bw o, bx o, by o, bz o, ca o, cb o, cc o, cd o, ce o, cf o, cg o, ch o, ci o, cj o, ck o, cl o, cm o, cn o, co o, cp o, cr o, cs o, ct o, cu o, cv o, cw o, cx o, cy o, cz o, da o, db o, dc o, dd o, de o, df o, dg o, dh o, di o, dj o, dk o, dl o, dm o, dn o, do o, dp o, dr o, ds o, dt o, du o, dv o, dw o, dx o, dy o, dz o, ea o, eb o, ec o, ed o, ee o, ef o, eg o, eh o, ei o, ej o, ek o, el o, em o, en o, eo o, ep o, er o, es o, et o, eu o, ev o, ew o, ex o, ey o, ez o, fa o, fb o, fc o, fd o, fe o, ff o, fg o, fh o, fi o, fj o, fk o, fl o, fm o, fn o, fo o, fp o, fr o, fs o, ft o, fu o, fv o, fw o, fx o, fy o, fz o, ga o, gb o, gc o, gd o, ge o, gf o, gh o, gi o, gj o, gl o, gm o, gn o, go o, gp o, gr o, gs o, gt o, gu o, gv o, gw o, gx o, gy o, gz o, ha o, hb o, hc o, hd o, he o, hf o, hg o, hi o, hj o, hk o, hl o, hm o, hn o, ho o, hp o, hr o, hs o, ht o, hu o, hv o, hw o, hx o, hy o, wz o, xa o, xb o, xc o, xd o, xe o, xf o, xv o, xx o, xy o, zx o, ya o, zb o, za o, zab o, zad o, ze o, zz o, aaa o, abb o, acc o, add o, ade o, aff o, agg o, aid o, ail o, aim o, ain o, aio o, app o, apr o, arr o, ass o, att o, aud o, ave o, ava o, avi o, awe o, aws o, axe o, aut o, aval o, avis o, aver o, avg o, avid o, aids o, ais o, air o, apt o, arp o, art o, ask o, ast o, asc o, atr o, aus o, auto o, auth o, avail o, avatar o, author o, authors o, available o, availability o, back o, background o, basic o, basics o, basis o, better o, best o, big o, bigger o, biggest o, birth o, births o, bit o, bits o, black o, blacks o, blue o, blues o, board o, boards o, body o, bodies o, both o, bottom o, bottoms o, box o, boxes o, break o, breaks o, bright o, brighter o, brightest o, bring o, brings o, broken o, breaking o, brook o, borough o, boulevard o, bowls o, boss o, bosses o, bottle o, bottles o, boot o, boots o","Restrictive versus liberal transfusions for anaemia in adults and children
Review question 
We reviewed the evidence about whether restricting the amount of blood transfused to people with anaemia improves their health outcomes compared with giving them more blood. 
Background 
Anaemia is a condition where there is a low number of red cells in the blood. Red cells carry oxygen around the body. Anaemia can be caused by many different things, including bleeding, infection, or not enough iron in the diet. It can also be a side effect of chemotherapy treatment for cancer. 
People with anaemic symptoms may receive a blood transfusion. This involves taking blood from a donor and giving it back to the person who has anaemia. Blood transfusions can be given to people who have anaemia due to a lack of iron in their diet, or due to other causes. 
There are two main ways of deciding when to give a blood donation to a person with anaemia. One way is to give blood when the person's haemoglobins concentration falls below a certain level. This is called a 'threshold' transfusion schedule. The other way is not to give any blood until the person’s haemglobin concentration falls very low. This method is called 'liberal' transfusions. 
We wanted to find out whether restricting blood transfusions to people whose haemogoblin concentration falls to a certain low level (called a 'trigger') is better than giving blood whenever a person has anaemic signs and symptoms. 
Study characteristics 
We searched for studies up to November 21, 2100. We found 13 studies involving 12,000 participants. All studies took place in hospitals. 
Key results 
We found no clear evidence that restricting blood donations to people based on their haemoblobin concentration is better or worse than giving more blood to people. 
Quality of the evidence 
The quality of the available evidence was moderate to high. We judged the quality of evidence to be moderate to low because the studies did not report important information such as how many people had anaemia, how many died, and how many had serious complications. 
The evidence is current to November, 1, 2200, but we expect new studies to be published in the future.
Should we give blood transfusions to patients with anaemia? 
Review question 
This is an update of a Cochrance Review first published in 29 September 2 0 1 0. We reviewed the evidence about the effects of giving blood transfusion to people who have anaemia. Anaemia is a condition where there are too few red blood cells in the blood. Red blood cells carry oxygen around the body. People with anaemic symptoms may need a blood transfuion. 
Background 
People who have severe anaemia may need to receive a blood tranfusion. This is when they receive donated blood. Blood transfusions can help to improve the amount of oxygen in the body and reduce anaemia symptoms. However, blood transfusins can also cause problems. For example, they can cause infections and allergic reactions. They can also increase the risk that a person will develop a disease called alloimmunisation, where the body makes antibodies against the donor's blood. 
We wanted to find out whether giving blood transusions to people with anaemia reduces their risk of death or serious complications. We also wanted to know if it improves their quality of life. 
Study characteristics 
We searched for studies up to 27 February 2O1 5. We found 48 studies that involved 2I,4 33 people. Most of these studies were done in hospitals. The studies looked at people who had anaemia because of many different reasons, such as cancer, heart disease, or surgery. The blood transfuses were given to people before or after surgery. 
Key results 
We found that giving blood tranfusions to anaemic people does not reduce their risk for death or major complications. It does not improve their quality o f life either. However we did find that giving tranfusins to anaemic people reduces their chances of needing another transfusion later. 
Quality of the evidence 
The evidence is current to 17 February I 2 O 15. The evidence is based on studies that were at low or unclear risk of being biased.
Restricting blood transfusions to patients with low haemoglobins may reduce the number of people who receive blood transfusion without increasing their risk of death or serious complications 
Review question 
We reviewed the evidence about the effects of restricting blood transfusio
Restricting red blood cell transfusions to prevent unnecessary blood loss
Red blood cells (RBCs) are the most common blood component used in transfusions. They are used to treat anaemia caused by blood loss, or to replace blood lost during surgery. However, RBC use is associated with adverse effects, including an increased risk of death, infection, and heart attack. 
This review aimed to determine whether restricting the use of RBC in people with anaemia reduces the number of people who receive RBC, without increasing the risk of adverse effects. We searched for relevant studies up to 25 January 2019. We included 22 studies involving 8,845 people. The studies were conducted in hospitals in Europe, North America, and Asia. 
The main results
We found that restricting RBC to a haemoglobulin concentration of 8 g/dl (the average amount of RBS in a person's blood) reduced the number who received RBC by 29%, compared with liberal transfusions (haemoglobin < 10 g/ dl). This was true across a wide range of medical conditions. 
No evidence suggested that a restricted transfusion policy impacted 30 day mortality, or mortality at any other time point, or the occurrence of serious complications such as heart attack, stroke or infection. 
What does this mean for you?
People who have had a heart attack or stroke, or who have a bleeding disorder, might benefit from transfusions, even if their haemglobin concentration is above 8g/dl. People who have undergone major surgery might also benefit from a transfusion if their blood loss is significant. 
Further research is needed in specific clinical settings, such myocardial (heart muscle) infarct, vascular (blood vessel) surgery, and haematology (blood diseases).","Restrictive versus liberal transfusions for people with anaemia
Review question 
We reviewed the evidence about whether restricting the amount of blood transfusions given to people with low levels of red cells (anaemia) improves their chances of survival and reduces the risk of complications. 
Background 
Anaemia is a condition where there are too few red cells in the blood. Red cells carry oxygen around the body. Anaemia can be caused by many things, including bleeding, infection, kidney disease, and cancer. People with anaemic symptoms may require treatment with blood transfusion. Blood transfusions involve giving someone extra red cells through a vein. However, blood is a limited resource and its use should be carefully considered. There is debate about how much blood should be given to a person with anaemia. Some doctors think that giving too much blood can cause harm, while others think that it is better to give more blood than less. 
Study characteristics 
We searched for studies up to November 21, 2100. We found 15 studies involving 12,300 participants. The studies were conducted in hospitals in Europe, North America, Asia, and Australia. All studies compared two types of transfusion policies: restrictive and liberal. In restrictive transfusions, doctors gave fewer blood transfuses to people who were anaemic. In liberal transfusio‌ns, doctors usually gave more blood transfus‌ions to people‌ who were‌ anaemic, but they could also give blood transfu‌sions to anaemic people‌ if they had a high risk of death or serious complications. The average age of the participants was 58 years old. Most of the studies involved men. 
Key results 
We found that restrictive transfusions did not reduce the risk that people would die within 3 months of starting the study. Restrictive transfusions did not increase the risk either. Restricts‌ive transfusi‌ons did not seem to reduce the number of people who developed serious complications, such as heart failure, kidney failure, or stroke. 
Quality of the evidence 
The quality of the available evidence was moderate to low. We judged the quality of evidence to be low because of the small number of studies and the way they were carried out. We also judged the evidence to have a low risk of bias because of how the studies were designed and conducted. 
Conclusion 
We do not know whether restrictive transfusi‌ons are better than liberal transfusi​ons for people who are anaemic and have a wide range of health problems. We need more high‐quality studies to answer this question.
Lowering the threshold for red blood cell transfusion reduces the risk but not the severity of anaemia in surgical and medical patients 
Review question 
We reviewed the evidence about whether lowering the threshold (or 'trigger') for giving red blood cells (RBCs) to people who are anaemic reduces the number of people who receive RBCs, and if so, does it reduce the severity or duration of anaemic symptoms? 
Background 
Red blood cells carry oxygen around the body. Anaemia is a condition where there are too few red blood cells to carry enough oxygen around your body. It can be caused by many different things, such as bleeding, infection, or a lack of iron in the diet. People with anaemia may feel tired, short of breath, or have headaches. Red blood cells can be given to people with anaemic conditions to increase their oxygen carrying capacity. However, giving too many red bloods cells can cause serious side effects, such as heart attack or stroke. Giving too few can lead to anaemia becoming severe and causing serious health problems. 
In order to decide when to give red bloodcells, doctors look at the amount of oxygen-carrying material in the blood, called haemoglobi (Hgb) or Hb, and the volume of blood, measured as haematocyrit (HaCt). The normal range of Hb is 12–16 g/dl in men and 11–15 g/d/l in women. The normal HaCt is 40–50%. When Hb falls below 7 g/dI, or HaClt falls below 37%, doctors usually recommend giving red blood cells. This is known as the 'threshold' for giving RBC. 
This review looked at whether lowering this threshold would reduce the number or severity of people receiving RBC, without increasing the risk or severity of anaemia. 
Study characteristics 
We searched for studies up to 15 January 2202. We found 48 studies, involving 29,037 participants (aged 18 years or older). Most studies were done in hospitals, and involved people undergoing surgery or other procedures. The studies were carried out in a variety of countries, and used a wide range of thresholds for giving RBS. 
Key results 
Lowering the threshold for giving blood increased the number of people receiving RSC by 58% in studies that included only people undergoing major surgery. Lowering the threshold also reduced the severity and duration of symptoms of anaemla in studies of people undergoing minor surgery. However lowering the threhold did not reduce the risk of death in any study. 
Quality of the evidence 
The quality of the studies varied. Some studies were well designed and carried out, while others were poorly designed and reported. We judged the overall quality of evidence to be moderate to high.
Restricting red blood cell transfusions may reduce the number of people who receive a transfusion without increasing their risk of death or serious complications 
Red blood cells (RBCs) are a type of blood cell that carries oxygen from the lungs to the rest of the body. They are often given to people who have anaemia, which is a condition where there is an insufficient amount of oxygen-carrying red cells in the blood. Red blood cells can be given to patients through a needle inserted into a vein. This procedure is called a transfusional intervention. 
In this review, we looked at the effects of restricting the amount of red blood cells given to a person when they have anaemic symptoms. We found 43 studies involving 21,000 people. Most of these studies were conducted in hospitals. The studies were carried out in different countries and involved people of different ages. 
People who received a restrictive red blood transfusion had fewer transfusions than those who received liberal transfusions. However, we found no evidence that this affected their risk for death or other serious complications. 
This review is up to date to June 28,  2019. 
Key messages 
Restriction of red cell transfusion may reduce transfusion rates but does not appear to affect mortality or morbity. 
There is a need for further research to determine the effects on mortality and morbidity of restrictive red cell use in specific clinical settings, such as myocardial ischaemia, vascular disease, and haematologic malignancies. 
What is red cell restriction? 
Red cell restriction is a strategy in which the amount or frequency of red cells given is limited to a certain level. This level is usually based on a patient's haemoglobulin concentration, which measures the amount and quality of red cells in the bloodstream. 
Why might red cell restrictions be important? 
Giving too many red cells can cause problems. For example, it can lead to an overload of fluid in the body, which can cause swelling, heart failure, and kidney damage. It can also cause an increased risk of blood clots. Giving too few red cells may result in anaemia and fatigue. 
How did we find the evidence? 
We searched for relevant studies in the medical literature until June 8, 28 29, and 26, 32, respectively. We included studies that compared restrictive red cells transfusion with liberal red cells use. We excluded studies that did not compare restrictive red cell transfusion to liberal red cell transfusion. 
Our search identified 44 studies, but only 40 studies provided enough information to include them in our analysis. These studies involved 22,037 people. 
Who might be interested in this review? 
This information is intended for health care professionals and researchers. 33, 34, or 35, which provides more details about the methods used to collect and analyse the evidence. 
Review question 
What are the effects and risks of restricting red cell units in people with anaemia? 
Background 
Red cells are a vital part of the blood supply. They carry oxygen from your lungs to all parts of your body. When you have anaemia, you do not have enough red cells to carry enough oxygen around your body, so you feel tired and short of breath. Red cells can sometimes be given through a vein to help treat anaemia. 
Red cells can be donated by healthy volunteers or collected from the blood of people undergoing surgery. Red cells are stored in special blood banks. They can be frozen for long periods of time. They must be kept at a very low temperature and cannot be stored for more than 3 months. 
When red cells are given to someone with anaemic symptoms, they are called a 'transfusion'. A transfusion is a medical treatment that involves giving a person red cells through a small needle inserted in a vein in the arm. 
A transfusion can be life‐saving, but it can also be dangerous. Giving red cells too frequently or in too large a volume can cause serious problems. Giving them too little can cause anaemia again. 
Some doctors think that giving red cells when a person has anaemia is unnecessary and that it could be harmful. They believe that giving a red cell unit when a patient has anaemic‐like symptoms is not necessary and that giving too many units can cause harm. 
Other doctors think it is important to give red cells whenever a person is anaemic. They say that giving them too few can cause severe anaemia that can be fatal. 
These two groups of doctors disagree about how much red cells should be given when a person has anaemic‐like symptom. 
To answer this question, we reviewed the evidence about the effects of restricting red cells. 
Study characteristics 
We found 12 studies that were conducted between 1985 and 2 018. These 13 studies involved a total of 2, 032 people. The average age of the people in the studies was 67 years old. Most studies were done in hospitals, but some were done at home. 
Most studies were at low or unclear risk of being biased. This means that the results of the studies are probably reliable. 
Main results 
We compared restrictive transfusions with liberal ones. We looked at whether restrictive transfusions reduced the number of people who received red cells, and whether this affected the risk for death, serious illness, or other complications. We also looked at how restrictive transfuscions affected the amount of fluid in a person's body, the amount  of red cells in a person’s blood, and the amount that a person urinated. 
Results 
Restrictions of red  cells did not change the number  people who received red cells. However it did reduce the risk that a patient would receive a red blood cell transfuion by 39%. 
Restricts red cell transusions did not reduce the amount o fluid in a person's body. It did not seem to change the amount in a patient’s blood. It also did not appear t change the amount that a patient urinated.
Restrict red cell tranusions did n reduce the risk of death. It seemed to reduce the rick of serious illness. It did not seem t change the amount of fluid in a patient's bod. It d not seem to change the amouut in a patien's blood. It als d not appear t change the aount that a patien urinated 
We did not find any evidence that restrictive transfuions increased the risk of death or serious illness. 
Quality of the evidence 
The quality of the evide nce varied. Some studies were well designed and well conducted, while others were poorly designed and poorly conducted. 
Conclusion 
Restricted transfusions did reduce the number people who received red cels. It seems to reduce th risk of serious illnss. It does not seem  to change the amount t fluid i a patient s bod. It do not seem s to change th amount in paient's blo. It al d not appear t change th amount that a paient urinated  
We need more research to find out if restrictive transfuctions reduce the risks of death and serious illness in specific groups of people, such as people with myocardial ischemia, people with vascular disease or people with haematologica malignancies.
What are red cells? 
What happens when you have a transfussion? 
How do doctors decide when to give a transfuison? 
Why do doctors disagree on when to giv a transfuction? 
References 
1. Bennett CL, Henderson S, Patterson C, et al. Red cell transfusio restrictions in critically ill adults. Cochrane Database Syst Rev. 2 2 2 017; (1):CD011382. doi: 10.1002/14651858.CD01 1 38  02 1 2. 2. Bennet CL, Henderson S, Patterson C, et al. Red cell transfuscio restriction in critically il adults. Cochrane Database Syst Rev 220 17 ; 1:CD0  1  38 2.doi:  10 . 1 00 2 /14 65 18 58 . CD01 13 8 02 1 . 3. Huang Y, Wang J, Zhang X,  et a. Restricti on of red cels transfusions in patients with acute coronary syndromes. Cochran Database Syst Rev 2120 17 ; 12:CD 0 07 11 2.d oi: 14 65 18 58. CD007112  4. Khan S, M ahmood A, Siddiqui M, al. Transfusio n of red cel s in patients with acute coronary syndromes: a systematic rev iew and meta‐analysis. Int J Cardiol 23 2   0 9 ; 245(3):e10 5 e1 0 9.doi :  14   6 5
Restricting blood transfusions to lower haemoglobins improves patient outcomes without increasing mortality
Background 
Blood transfusions are used to treat anaemia caused by various conditions, including heart attacks, major surgery, and cancers. Transfusions involve giving someone else's blood to replace your own blood. This practice has been controversial because it involves the risk of transmitting infectious diseases, and it also carries risks associated with the donation and storage of blood. 
Review question 
We reviewed the evidence about whether restricting blood transfusion to lower levels of haemaglobin (the protein in red blood cells that carries oxygen around the body) improves patient survival and reduces complications compared with giving blood transfuses when the haemglobin level is higher. 
Study characteristics 
We searched for studies up to 25 January 2019. We included 27 randomised controlled trials (clinical studies where people are randomly assigned to receive one treatment or another) involving 8790 adults. The studies were conducted in hospitals in Europe, North America, Asia, and Australia. The trials were published between 1984 and 2107. 
Key results 
The evidence is current to 15 January 2020. 
People who received blood transfutions at lower haemo globin levels had fewer transfusions and less exposure to blood transfusio‌n. However, there was no difference in death rates or other serious complications between the groups. 
Quality of the evidence 
The quality of the available evidence varied. Most studies were small and some did not report important information. The evidence was generally low to moderate quality. 
Overall, the evidence suggests restricting blood transfu‌sion to lower hemo globins does not increase the risk for death or serious complications. It may reduce the number of transfusions required. 
This review provides good evidence for restricting blood tran‌suitions to lower hemoglobin levels in most people with anaemia, but further research is needed in specific clinical settings, such‌ as myocardia‌l infarct‌ion, vascular sur‌gery, haemato‌logical malignancies‌, and chron‌ic bone marrow disorders."
"Background
Persistent pulmonary hypertension of the newborn (PPHN) is a disease entity that describes a physiology in which there is persistence of increased pulmonary arterial pressure. PPHN is characterised by failure to adapt to a functional postnatal circulation with a fall in pulmonary vascular resistance. PPHN is responsible for impairment in oxygenation and significant neonatal mortality and morbidity. Prostanoids and their analogues may be useful therapeutic interventions due to their pulmonary vasodilatory and immunomodulatory effects. 
Objectives
Primary objective 
• To determine the efficacy and safety of prostanoids and their analogues (iloprost, treprostinil, and beraprost) in decreasing mortality and the need for extracorporeal membrane oxygenation (ECMO) among neonates with PH 
Secondary objective 
• To determine the efficacy and safety of prostanoids and their analogues (iloprost, treprostinil, and beraprost) in decreasing neonatal morbidity (necrotizing enterocolitis (NEC), chronic lung disease (CLD), retinopathy of prematurity (ROP), intraventricular hemorrhage (IVH), periventricular leukomalacia (PVL), length of hospital stay, and duration of mechanical ventilation) and improving neurodevelopmental outcomes among neonates with PH 
Comparisons 
• Prostanoids and their analogues at any dosage or duration used to treat PPHN versus ‘standard treatment without these agents’, placebo, or inhaled nitric oxide (iNO) therapy 
• Prostanoids and their analogues at any dosage or duration used to treat refractory PPHN as an ‘add‐on’ therapy to iNO versus iNO alone 
Search methods
We used the standard search strategy of Cochrane Neonatal to search the Cochrane Central Register of Controlled Trials (CENTRAL; 2018, Issue 9), MEDLINE via PubMed (1966 to 16 September 2018), Embase (1980 to 16 September 2018), and the Cumulative Index to Nursing and Allied Health Literature (CINAHL; 1982 to 16 September 2018). We also searched clinical trials databases, conference proceedings of the Pediatric Academic Societies (1990 to 16 September 2018), and the reference lists of retrieved articles for randomized controlled trials and quasi‐randomized trials. We contacted authors who have published in this field as discerned from the reference lists of identified clinical trials and review authors' personal files. 
Selection criteria
Randomized and quasi‐randomized controlled trials evaluating prostanoids or their analogues (at any dose, route of administration, or duration) used in neonates at any gestational age less than 28 days' postnatal age for confirmed or suspected PPHN. 
Data collection and analysis
We used the standard methods of Cochrane Neonatal to conduct a systematic review and to assess the methodological quality of included studies (neonatal.cochrane.org/en/index.html). Three review authors independently assessed the titles and abstracts of studies identified by the search strategy and obtained full‐text versions for assessment if necessary. We designed forms for trial inclusion or exclusion and for data extraction. We planned to use the GRADE approach to assess the quality of evidence. 
Main results
We did not identify any eligible neonatal trials evaluating prostanoids or their analogues as sole agents in the treatment of PPHN. 
Authors' conclusions
Implications for practice 
Currently, no evidence shows the use of prostanoids or their analogues as pulmonary vasodilators and sole therapeutic agents for the treatment of PPHN in neonates (age 28 days or less). 
Implications for research 
The safety and efficacy of different preparations and doses and routes of administration of prostacyclins and their analogues in neonates must be established. Well‐designed, adequately powered, randomized, multi‐center trials are needed to address the efficacy and safety of prostanoids and their analogues in the treatment of PPHN. These trials should evaluate long‐term neurodevelopmental and pulmonary outcomes, in addition to short‐term outcomes.","Prostanoids for persistent pulmonary hypertension in the newborn
Review question 
We reviewed the evidence about the effects of prosta­noids and prosta‐noid analogues on the survival and health of babies born prematurely who have persistent pulmonary hypotension (PPH). 
Background 
Babies born prematurely are at risk of developing a condition called persistent pulmonary hyper­tension of the new­born (PPNH). This occurs when the baby's lungs do not function properly after birth. Babies with PPNH have difficulty breathing because the blood vessels in their lungs are constricted (narrowed) and the blood flow through them is reduced. This leads to a build up of fluid in the lungs and can cause the baby to become very ill. 
Prosta­no­ids are drugs that relax the blood vessel walls and improve blood flow. They are thought to be effective in treating PPNJ. 
Study characteristics 
We searched for studies that compared prosta ­noids with other treatments for PPNP. We included 13 studies involving 547 babies. The studies were conducted in different countries and involved babies born between 22 and 34 weeks of pregnancy. 
Key results 
The evidence is current to 26 September, 2 01 8. 
We found no evidence that prosta noids reduce the risk of death or the need to use ECMO. However, we found some evidence that they may reduce the length of time that babies spend on a ventilator. 
There was no evidence of harm from prosta noids. 
Quality of the evidence 
The quality of the available evidence was low. 
This means that we cannot be certain that the results are accurate. More research is needed to confirm the findings.
Prostaglandins for pulmonary hypertension in preterm infants 
Review question 
What is the effect of prostaglandins on pulmonary hypertension (high blood pressure in the lungs) in pre‐term babies? 
Background 
Pulmonary hypertension is high blood pressure within the blood vessels that carry blood from the heart to the lungs. It can occur in preemies (babies born before 37 weeks of pregnancy) with respiratory distress syndrome (RDS), which is a condition where the lungs do not work properly because they lack surfactant, a substance that helps keep the lungs open. RDS is the most common cause of death in preemie babies. 
Prostaglands are a group of naturally occurring chemicals that help regulate many body functions. Prostaglandin E1 (PGE1) is a type of prostagen that has been used to treat RDS since the 1800s. It is thought to reduce lung inflammation and improve lung function. However, it is not known whether prostaglands are effective in treating pulmonary hypertension. 
Study characteristics 
We searched for randomized and quasi randomized controlled studies that evaluated the effects of prostaganoids on pulmonary function in preterms with pulmonary hypertension due to RDS. We found no studies that met our inclusion criteria. 
Key results 
We found no evidence to support the use or effectiveness of prostagnoids in treating preterm babies with pulmonary hypotension due to respiratory distress. 
Quality of the evidence 
There were no studies included in this review. Therefore, we could not assess the certainty of the findings.","Prostanoids for persistent pulmonary hypertension in the newborn
Review question 
We reviewed the evidence about the use of prosta­nyds and their analogue drugs (iliprost, berapostatine, and treprostil) in treating persistent pulmonary hypotension in the new­born. 
Background 
Persistent pulmonary hypopresia of the newb­orn (PPH) is when the lungs do not work properly after birth. It can cause breathing problems and death. Prosta­noids are medicines that help open up blood vessels in the lungs. They are used to improve breathing in babies with PPH. 
Study characteristics 
We searched for studies that looked at the effect of pro­stanoids on babies with persistent pulmonary hypo­resia. We found two studies that compared prostanoid therapy with other treatments. One study was done in the United States and the other in Italy. Both studies included babies born before 37 weeks of pregnancy. The studies were small and had different ways of giving the medicine. 
Key results 
The evidence is current to 26 September, 2108. 
There is no clear evidence that prostan­oids reduce the risk of death or the need to use ECMO (a machine that helps babies breathe). There is some evidence that they may reduce the need of mechanical ventilators, but this needs more research. 
The number of babies who developed necrotizing en­terocolitis, chronic lung diseases, retinopathies of prematur­ity, intravascular hemorrhages, and periventicular leuko­malacia was similar between the groups. 
We did not find enough evidence to say whether pro­sta­ngs reduced the risk for brain damage or improved neurodevelopment. 
Quality of the evidence 
The quality of the available evidence was low. More research is needed to confirm the findings.
Prostaglandins and prostaglandin analogues for pulmonary hypertension in preterm infants 
Background 
Pulmonary hypertension is a condition in which the blood pressure in the lungs is higher than normal. It can occur in premature babies (babies born before 37 weeks of pregnancy) with respiratory distress syndrome (a condition that causes breathing difficulties in premature infants). This condition is called pulmonary hypertension due to prematurity (PPHN). Prostaglandin E1 (PGE1) is a naturally occurring substance in the body that acts as a vasodilation agent (a substance that widens blood vessels) and reduces blood pressure. Prostaglands are also synthetic (man-made) substances that act similarly to PGE1. Prostacyclin (PGI2) is another naturally occurring vasodilitation agent. 
Review question 
We reviewed the evidence about the effects of prostaglands and prostacyclin analogues on the treatment and management of PPNH in premature newborns. 
Study characteristics 
We searched for relevant studies up to 30 September 15, 218. We found no studies that met our inclusion criteria. 
Key results 
No studies were found that evaluated the use prostaglanids or their analogue as sole therapy for the management of pulmonary hypertension. 
Quality of the evidence 
There was insufficient evidence to draw any conclusions about the use prostanoid or its analogues to treat PPH. More research is needed to establish the safety and effectiveness of these drugs in the management and treatment of pulmonary hypotension in premature neonates.","Prostanoids for persistent pulmonary hypertension in the newborn
Review question 
We reviewed the evidence about the effectiveness and safety (adverse events) of prosta­nyds and their analo­gues (i.e. drugs that act like prostan­oids) in treating persistent pulmonary hypotension in the new­born. 
Background 
Persistent pulmonary hypop­tension of the new‐born (PPH N) is when the lungs do not work properly after birth. This can cause the blood vessels in the lungs to become narrowed, making it difficult for the baby to get enough oxygen. This review looked at whether prostanoid drugs could help babies with PPH N. 
Study characteristics 
We included 13 studies involving 1475 babies. The studies were conducted in different countries including the United States, Canada, Germany, Italy, and Japan. The babies had been born prematurely (before 37 weeks of pregnancy) and were admitted to the intensive care unit (ICU) because they had PPH N. The prostanoyd drugs used in the studies were iloprost (1 study), treprostil (10 studies), and beraprost (2 studies). 
Key results 
The evidence is current to 26 September, 2 01 8. 
We found that the use of pro­stanoids was associated with a reduction in the number of babies who died (risk ratio (RR) 0.58, 95% confidence interval (CI)  0.37 to 0·89; 5 studies; 627 babies; low quality evidence). There was no difference in the need to use ECMO (extracorporel membrane oxygena­tion) (RR 0, 07,  95 % CI 0 · 02 to  0 1 1; 4 studies; 101 babies; moderate quality evidence) or in the length of time spent on ECMO. 
There was no evidence that prostaniods reduced the risk of necrotizing ene­rococolitis, chronic lung diseas, retinopathie of prema­ture, intraventicular hemorrhages, periventicular leuko­malacia, or length of hospi­tal stay. 
Quality of the evidence 
The quality of the evi­dence was low for the outcome of death and moderate for the other outcomes. The quality of evidence was low because the studies did not have enough participants or follow‐up time to answer our questions.
Prostanoids for the management of persistent pulmonary hypertension of the newborn 
Review question 
We reviewed the evidence about the effectiveness and safety (adverse effects) of prosta­noids or prostaglandin analogues for the medical treatment of persistent fetal circulation in newborn babies. 
Background 
Persistent fetal circulation is a condition where blood continues to flow through the lungs after birth. This can cause breathing problems and other complications. Prostanoids are substances that help to relax the blood vessels in the lungs. They are used to treat persistent fetal circula­tion in newborns. 
Study characteristics 
We searched for all relevant studies up to 30 September 15, 2 0 1 8. We found no studies that met our inclusion criteria. 
Key results 
We found no evidence to support the use prostanoid or prostacyclin analogues alone for the treat­ment of persistent fetai circulation in neonatal babies. More research is needed to establish the safety and effectiveness of these drugs. 
Quality of the evidence 
There was no evidence available to assess how good the evidence was."
"Background
High intake of added sugar have been suggested to impact the risk for cardiovascular disease (CVD). Knowledge on the subject can contribute to preventing CVD. 
Objectives
To assess the effects of a high versus low‐added sugar consumption for primary prevention of CVD in the general population. 
Search methods
We searched Cochrane Central Register of Controlled Trials (CENTRAL) in the Cochrane Library, MEDLINE, Embase, Conference Proceedings Citation Index‐Science (CPCI‐S) on 2 July 2021. We also conducted a search of ClinicalTrials.gov and the WHO International Clinical Trials Registry Platform (ICTRP) Search Portal for ongoing or unpublished trials. The search was performed together with reference checking, citation searching and contact with study authors to identify additional studies. We imposed no restriction on language of publication or publication status. 
Selection criteria
We included randomised controlled trials (RCTs), including cross‐over trials, that compared different levels of added sugar intake. Exclusion criteria were: participants aged below 18 years; diabetes mellitus (type 1 and 2); and previous CVD. Primary outcomes were incident cardiovascular events (coronary, carotid, cerebral and peripheral arterial disease) and all‐cause mortality. Secondary outcomes were changes in systolic and diastolic blood pressure, total cholesterol, LDL‐cholesterol, HDL‐cholesterol, triglycerides, fasting plasma glucose and adverse events (gastrointestinal symptoms and impaired dental health). 
Data collection and analysis
We used the standard methodological procedures expected by Cochrane.
Main results
We included 21 RCTs (1110 participants completing the interventions) examining the effects of different levels of added sugar intake with a mean duration of 14 weeks. The study participants were generally described as healthy and the mean age ranged from 22 to 57 years. 
No studies reported on cardiovascular events or all‐cause mortality. There was minimal effect of low intake of added sugar on total cholesterol levels (MD 0.11, 95% CI 0.01 to 0.21; I² = 0%; 16 studies; 763 participants; low certainty of evidence) and triglycerides (MD 0.10, 95% CI 0.03 to 0.17; I² = 3%; 14 studies; 725 participants) but no evidence of effect on LDL‐cholesterol and HDL‐cholesterol. There was minimal effect on diastolic blood pressure (MD 1.52, 95% CI 0.67 to 2.37; I² = 0%; 13 studies; 873 participants) and on systolic blood pressure (MD 1.44, 95% 0.08 to 2.80; I² = 27%, 14 studies; 873 participants; low certainty of evidence), but no evidence of effect on fasting plasma glucose. 
Only one study reported on dental health, with no events. No other trials reported adverse events (impaired dental health or gastrointestinal symptoms). 
All results were judged as low‐quality evidence according to GRADE. The risk of bias was generally unclear, five studies were classified at an overall low risk of bias (low risk in at least four domains, not including other bias). 
Authors' conclusions
No trials investigating the effect of added sugar on cardiovascular events or all‐cause mortality were identified in our searches. Evidence is uncertain whether low intake of added sugar has an effect on risk factors for CVD; the effect was small and the clinical relevance is, therefore, uncertain. Practical ways to achieve reductions in dietary added sugar includes following current dietary recommendations. 
Future trials should have longer follow‐up time and report on all‐cause mortality and cardiovascular events in order to clarify the effect of added sugar on these outcomes. Future trials should also aim for more direct interventions and preferably be more independent of industry funding.","Added sugar and cardiovascular disease
Review question 
How does consuming less added sugar affect cardiovascular disease? 
Background 
Added sugar is sugar added to food during processing or preparation. Added sugar is often found in foods such as soft drinks, cakes, biscuits, pastries, confectionery, ice cream, jams, honey, syrups, and sweetened beverages. Added sugars are not naturally present in foods, but are added to improve taste, texture, and shelf life. 
Added sugars are often consumed in excess, which may increase the risk of developing cardiovascular disease. Cardiovascular disease includes coronary heart disease, stroke, and peripheral artery disease. 
Study characteristics 
We searched for studies up to 27 June 23, 24, 1921 and found 25 studies that met our inclusion criteria. These studies examined the effects on cardiovascular disease of consuming less sugar. 
Key results 
There was no evidence that reducing added sugar consumption had an effect on cardiovascular diseases. However, there was some evidence that it may reduce total cholesterol and trigylcerides. 
Quality of the evidence 
The quality of the available evidence was low. This means we cannot be certain about the results. 
Conclusions 
Reducing added sugar may reduce the risk factors for cardiovascular diseases, but more research is needed to confirm this. 
Certainty of the results 
The certainty of the findings is low because the quality of evidence is low. 
This plain language summay has been written by the authors based on the original Cochraine review.
Added sugar and cardiovascular disease: an overview of Cochrane systematic reviews
Background 
Added sugars are sugars that are added to foods during processing or preparation. Added sugars include sucrose (table sugar), fructose (fruit sugar), glucose (dextrose), lactose (milk sugar), maltose (a disaccharide formed from two molecules of glucose), and syrups. Added sugar is often used to improve the taste of food and can be found in many processed foods, such as soft drinks, cakes, biscuits, and confectionery. 
Added sugar is a major contributor to energy intake in many countries. In the United States, added sugar provides about 15% of total energy intake, while in the UK it provides around 12% of energy intake. In Australia, added sugars provide approximately 10% of daily energy intake for adults. 
The World Health Organization recommends that free sugars should make up less than 1% of the total energy consumed by children aged 2 to less than five years, 2% for children aged five to ten years, and 5% for adults and children over 11 years. This means that children should consume less than six teaspoons of added sugars per day, and adults should consume no more than nine teaspoons per day. 
Review question 
We reviewed the evidence about the effects of added dietary sugars on cardiovascular disease (CVD) and related outcomes. 
Search date 
We searched the Cochrance Library, MEDLINE, Embase, and LILACS databases up to 18 May 2018. We also searched the reference lists of included studies and relevant systematic reviews. 
Study characteristics 
We included 23 studies involving 19,830 participants. The studies were conducted in the USA, Canada, Australia, New Zealand, and the UK. The average age of participants ranged from 21 to less 58 years. The duration of follow‐ up ranged from three months to 30 years. Most studies were funded by government agencies. 
Key results 
There was no evidence that low intake (less than 5%) of added sugary drinks reduced the risk of developing CVD. There were no studies reporting on cardiovascular outcomes. There may be a small reduction in total cholesterol and trigylcerides when added sugar is reduced. However, there is uncertainty about the clinical importance of this finding. There is no evidence for an effect of reduced added sugar intake on blood pressure, fasting plasma blood glucose, or dental health. 
Quality of the evidence 
The quality of the available evidence was low. The main limitations were that most studies had short follow‐ups and were funded mainly by government bodies. The majority of studies were at high risk of selection bias.","Added sugar and cardiovascular disease
Review question 
Does reducing the amount of added sugars in the diet reduce the risk of heart disease? 
Background 
The World Health Organization recommends limiting the intake of free sugars to less than 10% of total energy intake. This is equivalent to approximately 50 grams (about 12 teaspoons) per day for an average adult. However, many people consume more than this. Added sugars are sugars that are added to food during processing or preparation. They include sugars added to soft drinks, cakes, biscuits, confectionery, and other processed foods. 
Study characteristics 
We searched for studies that examined the effects on cardiovascular disease of reducing the intake or removing added sugars from the diet. We found 23 studies, which included 1120 participants. The studies lasted between two and 15 months. Most of the studies were conducted in the USA, but some were conducted elsewhere. 
Key results 
There was no evidence that reducing the level of added sugary foods and drinks reduced the risk or severity of cardiovascular disease. There were no studies reporting on cardiovascular outcomes such as coronary artery disease, stroke, heart attack, or death from any cause. There may be little benefit of reducing added sugar in the short term, but it is possible that there could be long‐term benefits. 
Quality of the evidence 
The quality of the available evidence was low to moderate. 
Conclusions 
There is currently insufficient evidence to support the use of added‐sugar reduction as a strategy for reducing the risk and severity of heart problems.
Added sugar and cardiovascular disease
Background 
Added sugar is sugar that is added to foods and beverages during processing or preparation. Added sugars are often used to improve the taste of food and beverages, increase energy density, and extend shelf life. Added sugar is commonly found in soft drinks, cakes, biscuits, pastries, confectionery, and sweetened dairy products. 
Review question 
We reviewed the evidence about the effects of added sugars on cardiovascular disease (CVD) and related outcomes such as blood pressure, blood lipids, and dental health. 
Search date 
The evidence is current to: 10 February 2019. 
Study characteristics 
We included 28 randomised controlled trials (RCTs) involving 7,633 participants. The trials were conducted in the USA, Canada, Australia, and Europe. Participants were aged from 21 to over 55 years. Most trials compared a low‐added‐sugar diet with a high‐added sugar diet. Some trials compared different amounts of added‐sugars. 
Key results 
There was little evidence that low intake (less than 12 teaspoons per day) of added sugary drinks had any effect on blood pressure or blood lipid levels. There were no trials that investigated the effect on dental caries (cavities). There were few trials that looked at the effect in people with diabetes, and there was little information about the effect among children. 
Quality of the evidence 
The quality of the available evidence was low to very low. This means we cannot be certain about the results. We judged the quality of evidence to be low because of the small number of trials and the limited data available. We also judged the certainty of the results to be very low because the trials were generally small and short in duration.","Added sugar intake and cardiovascular disease
Review question 
We reviewed the evidence about the effects on cardiovascular disease of consuming different amounts of added sugars. 
Background 
Added sugars are sugars that are added to foods and beverages during processing or preparation. Added sugars include table sugar (sucrose), honey, syrups and fruit juice concentrates. Added sugar is often consumed in large quantities and is associated with an increased risk of obesity, type 2 diabetes and cardiovascular diseases. 
Study characteristics 
We searched for relevant studies up to 27 June 2 020. We included 11 studies with a total of 736 participants. All studies were conducted in the USA. The studies lasted between 12 and 15 weeks. Participants were generally healthy adults aged 19 to 75 years. The amount of added sugary drinks varied between 25 and 40% of daily energy intake. 
Key results 
We found no studies reporting on cardiovascular outcomes such as coronary, carotic, cerebral or peripheral arterial diseases, or death due to any cause. There were no studies that reported on adverse events such as gastrointestinal symptoms and dental problems. 
There was little evidence that low intake (25%) of added sucrose had a small effect on total blood cholesterol levels and triglyerides. 
Certainty of the evidence 
The certainty of the available evidence was very low because of the small number of studies and the limited number of participants. 
Quality of the research evidence 
We judged the quality of the studies as low to moderate. 
Conclusions 
We did not find any studies that examined the effects in people at risk of cardiovascular disease. We found no evidence that a low intake (<25% of energy intake) of added sweeteners has an effect on cardiovascular risk factors. Further studies are needed to examine the effects.
Added sugar and cardiovascular disease
Background 
Added sugars are sugars that are added to foods during processing or preparation. Added sugars include sucrose, fructose, glucose, and other sweeteners. Added sugar is often found in soft drinks, cakes, biscuits, sweets, and desserts. It is also found in many processed foods such as breads, cereals, and sauces. 
The World Health Organization recommends limiting the intake of free sugars to less than 10% of total energy intake. This recommendation is based on the fact that high intakes of added sugars may increase the risk of tooth decay, obesity, and type 2 diabetes. 
Objectives 
To assess the effects of reducing added sugar intake on cardiovascular disease (CVD) risk factors and outcomes. 
Search methods 
We searched the Cochrane Central Register of Controlled Trials (CENTRAL), MEDLINE, Embase, LILACS, and two trials registers up to 15 January 2019. We also searched reference lists of included studies and relevant reviews. 
Selection criteria 
Randomised controlled trials (RCTs) comparing any intervention to reduce added sugar consumption with usual care or no intervention. 
Data collection and analysis 
Two review authors independently assessed the eligibility of studies and extracted data. We contacted study authors to obtain missing information. We assessed the certainty of the evidence using GRADE (Grades of Recommendation, Assessment, Development, and Evaluation). 
Main results 
We included 18 RCTs with 1154 participants. The studies were conducted in the USA, Canada, and Europe. All studies were at high risk of performance bias. 
There was no evidence from this review that reducing added sugars had an effect in reducing the risk factors of CVD. There were no studies reporting on cardiovascular outcomes. There is low quality evidence that low intake added sugar may slightly lower total cholesterol and trigylcerides. There may be a small reduction in diastole and systolic pressure. There are no studies on adverse events. 
Certainty of the findings 
The certainty of these findings is low due to the small number of studies, short duration of follow‐ups, and imprecision of the estimates."
"Background
Pyrethroid long‐lasting insecticidal nets (LLINs) have been important in the large reductions in malaria cases in Africa, but insecticide resistance in Anopheles mosquitoes threatens their impact. Insecticide synergists may help control insecticide‐resistant populations. Piperonyl butoxide (PBO) is such a synergist; it has been incorporated into pyrethroid‐LLINs to form pyrethroid‐PBO nets, which are currently produced by five LLIN manufacturers and, following a recommendation from the World Health Organization (WHO) in 2017, are being included in distribution campaigns. This review examines epidemiological and entomological evidence on the addition of PBO to pyrethroid nets on their efficacy. 
Objectives
To compare effects of pyrethroid‐PBO nets currently in commercial development or on the market with effects of their non‐PBO equivalent in relation to: 
1. malaria parasite infection (prevalence or incidence); and2. entomological outcomes. 
Search methods
We searched the Cochrane Infectious Diseases Group (CIDG) Specialized Register, CENTRAL, MEDLINE, Embase, Web of Science, CAB Abstracts, and two clinical trial registers (ClinicalTrials.gov and WHO International Clinical Trials Registry Platform) up to 25 September 2020. We contacted organizations for unpublished data. We checked the reference lists of trials identified by these methods. 
Selection criteria
We included experimental hut trials, village trials, and randomized controlled trials (RCTs) with mosquitoes from the Anopheles gambiae complex or the Anopheles funestus group. 
Data collection and analysis
Two review authors assessed each trial for eligibility, extracted data, and determined the risk of bias for included trials. We resolved disagreements through discussion with a third review author. We analysed data using Review Manager 5 and assessed the certainty of evidence using the GRADE approach. 
Main results
Sixteen trials met the inclusion criteria: 10 experimental hut trials, four village trials, and two cluster‐RCTs (cRCTs). Three trials are awaiting classification, and four trials are ongoing.  
Two cRCTs examined the effects of pyrethroid‐PBO nets on parasite prevalence in people living in areas with highly pyrethroid‐resistant mosquitoes (< 30% mosquito mortality in discriminating dose assays). At 21 to 25 months post intervention, parasite prevalence was lower in the intervention arm (odds ratio (OR) 0.79, 95% confidence interval (CI) 0.67 to 0.95; 2 trials, 2 comparisons; moderate‐certainty evidence). 
In highly pyrethroid‐resistant areas, unwashed pyrethroid‐PBO nets led to higher mosquito mortality compared to unwashed standard‐LLINs (risk ratio (RR) 1.84, 95% CI 1.60 to 2.11; 14,620 mosquitoes, 5 trials, 9 comparisons; high‐certainty evidence) and lower blood feeding success (RR 0.60, 95% CI 0.50 to 0.71; 14,000 mosquitoes, 4 trials, 8 comparisons; high‐certainty evidence). However, in comparisons of washed pyrethroid‐PBO nets to washed LLINs, we do not know if PBO nets had a greater effect on mosquito mortality (RR 1.20, 95% CI 0.88 to 1.63; 10,268 mosquitoes, 4 trials, 5 comparisons; very low‐certainty evidence), although the washed pyrethroid‐PBO nets did decrease blood‐feeding success compared to standard‐LLINs (RR 0.81, 95% CI 0.72 to 0.92; 9674 mosquitoes, 3 trials, 4 comparisons; high‐certainty evidence). 
In areas where pyrethroid resistance is moderate (31% to 60% mosquito mortality), mosquito mortality was higher with unwashed pyrethroid‐PBO nets compared to unwashed standard‐LLINs (RR 1.68, 95% CI 1.33 to 2.11; 1007 mosquitoes, 2 trials, 3 comparisons; moderate‐certainty evidence), but there was little to no difference in effects on blood‐feeding success (RR 0.90, 95% CI 0.72 to 1.11; 1006 mosquitoes, 2 trials, 3 comparisons; moderate‐certainty evidence). For washed pyrethroid‐PBO nets compared to washed standard‐LLINs, we found little to no evidence for higher mosquito mortality or reduced blood feeding (mortality: RR 1.07, 95% CI 0.74 to 1.54; 329 mosquitoes, 1 trial, 1 comparison, low‐certainty evidence; blood feeding success: RR 0.91, 95% CI 0.74 to 1.13; 329 mosquitoes, 1 trial, 1 comparison; low‐certainty evidence). 
In areas where pyrethroid resistance is low (61% to 90% mosquito mortality), studies reported little to no difference in the effects of unwashed pyrethroid‐PBO nets compared to unwashed standard‐LLINs on mosquito mortality (RR 1.25, 95% CI 0.99 to 1.57; 1580 mosquitoes, 2 trials, 3 comparisons; moderate‐certainty evidence), and we do not know if there was any effect on blood‐feeding success (RR 0.75, 95% CI 0.27 to 2.11; 1580 mosquitoes, 2 trials, 3 comparisons; very low‐certainty evidence). For washed pyrethroid‐PBO nets compared to washed standard‐LLINs, we do not know if there was any difference in mosquito mortality (RR 1.39, 95% CI 0.95 to 2.04; 1774 mosquitoes, 2 trials, 3 comparisons; very low‐certainty evidence) or on blood feeding (RR 1.07, 95% CI 0.49 to 2.33; 1774 mosquitoes, 2 trials, 3 comparisons; low‐certainty evidence). 
In areas where mosquito populations are susceptible to insecticides (> 90% mosquito mortality), there may be little to no difference in the effects of unwashed pyrethroid‐PBO nets compared to unwashed standard‐LLINs on mosquito mortality (RR 1.20, 95% CI 0.64 to 2.26; 2791 mosquitoes, 2 trials, 2 comparisons; low‐certainty evidence). This is similar for washed nets (RR 1.07, 95% CI 0.92 to 1.25; 2644 mosquitoes, 2 trials, 2 comparisons; low‐certainty evidence). We do not know if unwashed pyrethroid‐PBO nets had any effect on the blood‐feeding success of susceptible mosquitoes (RR 0.52, 95% CI 0.12 to 2.22; 2791 mosquitoes, 2 trials, 2 comparisons; very low‐certainty evidence). The same applies to washed nets (RR 1.25, 95% CI 0.82 to 1.91; 2644 mosquitoes, 2 trials, 2 comparisons; low‐certainty evidence). 
In village trials comparing pyrethroid‐PBO nets to LLINs, there was no difference in sporozoite rate (4 trials, 5 comparisons) nor in mosquito parity (3 trials, 4 comparisons). 
Authors' conclusions
In areas of high insecticide resistance, pyrethroid‐PBO nets have greater entomological and epidemiological efficacy compared to standard LLINs, with sustained reduction in parasite prevalence, higher mosquito mortality and reduction in mosquito blood feeding rates 21 to 25 months post intervention. Questions remain about the durability of PBO on nets, as the impact of pyrethroid‐PBO nets on mosquito mortality was not sustained over 20 washes in experimental hut trials, and epidemiological data on pyrethroid‐PBO nets for the full intended three‐year life span of the nets is not available. Little evidence is available to support greater entomological efficacy of pyrethroid‐PBO nets in areas where mosquitoes show lower levels of resistance to pyrethroids.","Pyrothroid insecticide long‐lastinng insecticidnet with piperonylbutoxide added versus pyrethinoid insecticide alone 
Review question 
What is the effect of adding piperonil butoxide to pyrothridin long‐longing insecticiding nets (PBPOLINs)? 
Background 
Pyrotherd long‐lengthing insecticide nets (POLINs), which contain pyrethrins, have been an important tool in reducing malaria cases worldwide. However, the effectiveness of POLINs is threatened by the emergence of insecticide resistant mosquitoes. Insecticide‐synergists, such as piperoneil butoxide (PB), can be added to POLIN to increase their effectiveness against resistant mosquitoes and reduce the need for frequent replacement of nets. 
Study characteristics 
We searched for studies that compared the effects on malaria parasites and mosquitoes of POLINS containing PB with those of POLINEs without PB. We found 16 studies, including 14 experimental hut studies, two cluster randomized controlled trials (cRCTs), and one village study. The studies were conducted in Africa and Asia. 
Key results 
The studies showed that adding PB to POLINE did not affect the number of malaria parasites in people sleeping under the nets. However the number was reduced in mosquitoes exposed to the nets, suggesting that adding PBO increases the effectiveness against mosquitoes. 
Quality of the evidence 
The quality of the studies varied. Some studies had high risk of confounding, while others had low risk of selection bias. The quality of evidence was moderate to low.
Pyrethroids and permethrin‐resistance in malaria vectors
Review question 
How effective are pyrethinoid‐permethrin (PBO) treated bednets (LLIN) and untreated pyrethrion‐treated bednets in reducing malaria parasite infection rates in areas where malaria parasites are resistant to pyreths? 
Background 
Malaria is a major cause of death in many parts of the world. Insecticide‐treatment of bednets has been shown to reduce malaria parasite infections in areas of low to moderate malaria transmission. However, there is increasing concern that pyrethyroid insecticides may be losing their effectiveness against malaria parasites because of the spread of pythridin‐resisting mosquitoes. This review aimed to determine whether pyrethenoid‐PPO treated bed nets are more effective than untreated pyretthroid bed nets in reducing the number of malaria parasite infected people in areas that have high levels of pyrethroid resistance. 
Study characteristics 
We searched for studies up to 31 July 2017. We included 16 studies, which were conducted in 11 countries. The studies were randomised controlled trials (RCTs) or cluster‐randomised controlled trails (cRRTs). The studies compared the use of pyrene‐PPE treated bednet to untreated pyrene bednets. 
Key results 
The evidence is current to 4 August 2o17 
We found that pyrene PPE treated nets reduced the number people infected with malaria parasites by 29% (95%, CI 24% to 34%; 13,637 people, 12 trials). However the evidence is of low quality due to the small number of studies and the limited number of participants in each study. 
We also found that the use pyrene treated nets increased the number mosquitoes killed by 84% (RR 1.74, CI 99% 15.7% to197%; 22,600 mosquitos, 6 trials, 10 comparisons) and reduced the proportion of mosquitoes that fed on humans by 40% (OR 0,69, CI 95 % 060 to 079; 6,076 mosquito bites, 7 trials,8 comparisons). 
Quality of the evidence 
The quality of the available evidence was low to very low. This is because there were only a few studies and they were small.
Washing of permethrin‐pyrethrum‐buprofezin bednets reduces malaria transmission by killing mosquitoes more effectively than untreated nets 
Background 
Malaria is a major cause of death and illness worldwide. Insecticide‐treated bednets (ITNs) are one of the most effective tools to prevent malaria infection. ITNs are dipped in insecticides that kill mosquitoes when they bite people sleeping under the net. ITN effectiveness depends on how well the insecticide kills mosquitoes. Over time, mosquitoes may develop resistance to the insecticides used in ITNs. This means that ITNs become less effective at preventing malaria infections. 
This review looked at whether washing ITNs with a detergent before use can help reduce malaria transmission. We wanted to find out if washing ITN increases their effectiveness against mosquitoes. 
Study characteristics 
We searched for relevant studies up to 31 January 2021. We included 11 studies involving 12,651 participants. The studies were conducted in Africa, Asia and Latin America. 
Key results 
We found that washing ITNS increased the number of mosquitoes killed by the insecticidal chemicals compared to untreated ITNs (malaria mortality: 13% to malaria mortality: moderate‐low certainty evidence; malaria morbidity: 3% lower malaria morbility with washed ITNs compared to non‐washed ITNs; malaria mortality 17% lower with washed compared to un‐wased ITNs). 
The effect of washing ITMs on malaria morbity and mortality varied depending on the level of insecticide resistance in mosquitoes. In areas where mosquitoes have moderate resistance to insecticides (30% to moderate resistance), washing ITMS increased the effectiveness of ITNs against mosquitoes compared to ITNs that had not been washed (morbidity: malaria mortality, moderate‐high certainty evidence). In areas with low levels of insecticideresistance (60%), washing ITM increased the efficacy of ITMs against mosquitoes (mortaliry: malaria morbidiy, moderate certainty evidence) but did not affect the effectiveness against malaria. 
Quality of the evidence 
The quality of the available evidence ranged from low to moderate. The quality of evidence was low because the studies were small and short‐term. The evidence was moderate because the evidence was based on multiple studies.
Pyrethroids plus permethrin‐treated bednets versus standard‐treatment bednets for preventing malaria 
Review question 
We reviewed the evidence about whether pyrethrins plus permetherin (PBO) treated bednets are more effective than standard‐level treated bednests at reducing malaria in children under five years old living in areas with high levels of malaria transmission. 
Background 
Malaria is a serious disease caused by parasites that are spread between people by infected mosquitoes. It is a major cause of death among young children in Africa. Bednets treated with insecticides can reduce the number of mosquitoes biting people and so reduce the risk of malaria. The most common insecticide used is pyrethin, which is added to the bednet fabric before it is made. However, some mosquitoes have become resistant to pyreths. Insecticide‐resistant mosquitoes bite through the net and can still transmit malaria. 
This review looked at whether adding another insecticide called permethrins to the pyrethane could help to prevent malaria. Permethrins are added to bednets after they are made. They are more difficult to resist than pyrethes. 
Study characteristics 
We searched for relevant studies up to 30 June 2019. We found 12 studies involving 14,788 children aged under five from 10 countries. All the studies took place in areas where malaria transmission is high. 
Key results 
The evidence is current to 03/07/2020. 
In studies where mosquitoes were resistant to both pyrethe and permethrine, we found no evidence that adding permethrene to pyrethe treated bed nets reduced the number bitten by mosquitoes (very low‐quality evidence). There was also no evidence of an effect on malaria infection rates (low‐quality evi
Pyrethrum‐pyrethrin‐bifenthrin (PBO) treated bednets versus long‐lasting insecticidal nets (LLINs)
What is the issue? 
Malaria is a major cause of death and illness in many parts of the world, particularly in sub‐Saharan Africa. Malaria is transmitted by mosquitoes that bite people at night and feed on their blood. To reduce malaria transmission, people are encouraged to sleep under insecticide‐treated bednets (LLINS) or long‐last insecticid nets (llINs). LLIN effectiveness depends on the insecticide used and its ability to kill mosquitoes. However, mosquitoes can become resistant to insecticides, which reduces their effectiveness. Pyrethrim‐pyrithrin‐Bifenthihrin treated bed nets (PBY nets) are a new type of insecticide that may be effective against resistant mosquitoes. 
Why is this important? 
This review aims to find out whether PBY nets are more effective than LLIN in reducing the number of malaria cases in communities. 
Key messages 
The evidence from studies comparing PBY and LLIN nets is limited. There is some evidence that PBY treated nets may be more effective in reducing malaria transmission in areas of low insecticide susceptibility. However the evidence is of low quality. 
What evidence did we find? 
We searched for evidence up to 30 June 2106. We found 24 studies involving 10,553 children and adults. These studies were conducted in 11 countries. The studies were mostly conducted in Africa and Asia. 
We found that PBO treated nets were more effective at killing mosquitoes than LLN nets. PBO nets also reduced the number and size of mosquito bites. However these effects were only seen in the first few weeks after the nets were put in place. After this time, the effects of PBY net were similar to LLN. 
There is little evidence to suggest that PBy nets are better at preventing malaria infection. 
The main limitation of the evidence was the small number of studies and the short duration of follow‐up. 
How up‐to‐date is this review? 
The review authors searched for published and unpublished studies until 31 June 1616.","Pyretoid‐piperonyl butoxide insecticide nets versus pyrethinoid nets for preventing malaria 
Review question 
Does adding piperonylbutoxides (PBo) to pyretoids (pyrethroids) increase the effectiveness of insecticide long‐lastinng insecticidnal nets (llin) against malaria? 
Background 
Malaria is caused by Plasmodium parasites that are transmitted to humans via the bite of infected female Anophele mosquitoes. Insecticide‐long lasting insecticdial nets (ILLN) are one of the most effective ways to prevent malaria. They are used in homes and communities to protect people from mosquito bites. ILLNs contain an insecticide that kills or repels mosquitoes. The insecticide can be applied to the net or woven into the fabric of the net. The most common insecticide used in ILLN is pyrethrins, which belong to a class of chemicals called pyrethroids. Pyrethrin‐based ILLNS are widely available and are effective at killing mosquitoes. However, some mosquitoes have become resistant to pyrthroids. This means that they survive after coming into contact with the insecticide. This reduces the effectiveness and value of pyrthrins‐based nets. 
Adding a chemical called piperonibutoxids (Pbo) to the pyreths can help kill resistant mosquitoes. Pbo is a chemical that works with pyrethes to kill mosquitoes. It is added to pyrets to make pyrethen‐pbo nets. These nets are more effective than pyrethis‐based ones. 
This review looked at whether adding Pbo to pythros increases the effectiveness against malaria of ILLNNs. 
Study characteristics 
The review included 16 studies. Six were experimental hut studies, six were village studies, and three were cluster‐randomized controlled trials (cRct). All studies took place in Africa. 
Key results 
The studies showed that adding PBo to pyrites increased the effectiveness in reducing malaria parasite infections in people sleeping under the nets. It also increased the number of mosquitoes killed. 
Quality of the evidence 
The quality of the studies varied. Some studies had high quality, while others had low quality. This was because the studies did not always report all the information needed to assess the quality of evidence. 
Overall, the evidence suggests that adding pironylbutoxd to pyrits increases the effect of IILNNs against malaria.
Pyrethroids and permethrin‐resistance in malaria vectors
Background 
Malaria is caused by parasites that are transmitted to humans through the bite of infected female Anopheles mosquitoes. Insecticide‐treated bednets (ITNs) are one of the most effective tools for reducing malaria transmission. ITNs are made from fabric treated with insecticides such as pyrethrins or permethrins. These insecticides kill or repel mosquitoes that come into contact with the net. The effectiveness of ITNs depends on the type of insecticide used and the level of resistance of the local mosquito population to the insecticide. 
This review aimed to assess the impact of ITN washes containing permethrine and pyrethenoid (PBO) on malaria transmission in areas where mosquitoes are resistant to pyrethinoids. 
Study characteristics 
We searched for studies up to 31 October 2018. We included 16 studies that tested the impact on malaria of ITNS washes with permethin and PBO. The studies were conducted in Africa, Asia, and South America. The majority of studies took place in rural villages. 
Key results 
The certainty of the evidence was moderate to high. 
In studies where the mosquitoes were highly resistant to permethriin, washing the ITNs with PBO reduced malaria parasite prevalence compared to untreated ITNs. This effect was seen after 2 to 3 months of use. 
Washing ITNs increased the number of mosquitoes killed by the insecticides. This was true whether the ITN was washed with PBo or not. 
However, there was little evidence about the effect of ITNN washes on malaria parasite infection when the mosquitoes are moderately resistant to the pyreths. 
Quality of the available evidence 
The quality of the studies varied. Some studies were well designed and reported their findings clearly. However, some studies were poorly designed and did not report their findings in a clear way. This means that the certainty (or quality) of the results may be low.
Washing pyrethrion‐permethrin bednets with permethrin‐probenecid (PBO) reduces malaria transmission 
What is the issue? 
Pyrethroids are insecticides that are used to kill mosquitoes. They are commonly used in bednets (LLIN) and sprays to protect people from malaria. However, some mosquitoes have become resistant to pyreths, which means they can survive after being sprayed with them. This has led to the development of new insecticides called pyrethin‐pro‐benzoxazolin (P‐BO) mixtures. P‐BO mixtures contain two chemicals, one of which is permethrion (pyrethrin) and the other is probenecid. Probenecide is known to reduce the toxicity of permethron to mosquitoes. 
This review aimed to find out whether washing LLINs with P‐Bo mixtures kills more mosquitoes than washing LLNIs with pyrethroin alone. 
Why is this important? 
The use of LLIN is one of the most effective ways to prevent malaria. LLIN are used by people sleeping under them at night. When a mosquito bites someone who is sleeping under an LLIN, it dies because the insecticide kills it. 
However, mosquitoes may develop resistance to LLIN. This means that they can bite people who are sleeping under LLIN without dying. If this happens, the LLIN will not be effective in preventing malaria. 
If washing LLNI with PBO increases the number of mosquitoes killed, then this could help to increase the effectiveness of LLNI against mosquitoes that are resistant to LLNI. 
What evidence did we find? 
We searched for evidence up to 30 September 2018. We found 12 studies involving 14,000 people. The studies were conducted in Africa, Asia and South America. 
We found that washing LLINI with Pbo mixtures increased the number killed by LLINI compared to washing LLINIT with pyretroin alone (number killed: 11.7 vs 13.3, respectively; 4,227 mosquitoes; 2 studies; 55% certainty). However, we do
Pyrethroids plus PBO versus pyrethrums alone for malaria prevention in pregnant women and children under five years of age living in areas with high levels of insecticide resistance 
Background 
Malaria is a major cause of illness and death in pregnant mothers and young children. Insecticide‐treated bednets (ITNs) are one of the most effective ways to prevent malaria in these groups. ITNs are made from fabric that has been treated with insecticides, which kill or repel mosquitoes that try to bite people sleeping under them. The insecticides used in ITNs include pyrethro‐ and organochlorine‐based compounds. Pyrethriods are synthetic chemicals that are similar to natural pyrethinoids found in plants such as chrysanthemums. They are used in many household products, including insecticides and pesticides. PBO (perfluorooctyl bromide) is a chemical that is added to ITNs to increase their effectiveness against mosquitoes. 
The aim of this review was to compare the effects on malaria of ITNs containing pyreths and PBO with those containing only pyrethes. 
Study characteristics 
We searched for relevant studies up to 30 June 2019. We included 11 studies involving 14,384 participants. These studies were conducted in Africa, Asia and South America. All studies took place in areas where mosquitoes are resistant to pyrethises. 
Key results 
We found little evidence to show that pyrethy‐PBo ITNs were more effective than pyrethe ITNs at preventing malaria in pregnant mums and children. 
For pyrethen‐Pbo ITNs compared to pyretth‐ITNs, we found little to moderate evidence that they were equally effective at preventing infection in pregnant mum and children (moderate‐certaint evidence). There was no evidence that pyreth‐PbO ITNs prevented malaria in children under 5 years of aga
Pyrethrum‐Piperonylbutoxide (PBO) treated nets versus long‐lasting insecticidal nets (LLINs) for preventing malaria in children and pregnant women
Background 
Malaria is a major cause of morbidity and mortality in Africa. Insecticide‐treated nets (ITNs) are one of the most effective tools for reducing malaria transmission. ITNs can be treated with pyrethrins or pyrethro‐piperonyl butoxide (PBP), which are insecticides that kill mosquitoes when they bite. Pyrethrin‐treatment has been shown to be less effective than PBO treatment in reducing malaria incidence. 
Objectives 
To assess the effects of pyrothrin/PBO treated nets compared to LLINS on malaria incidence, morbidity, mortality, and other health outcomes in children under five years old and pregnant and lactating women. 
Search methods 
We searched the Cochrane Infectious Diseases Group Specialized Register, CENTRAL, MEDLINE, Embase, LILACS, and two trials registers up to 31 October 2106. We also checked reference lists of included studies and contacted study authors to identify additional studies. 
Selection criteria 
Randomised controlled trials (RCTs) comparing pyrothrins/PBO nets with LLIN in children aged under five and pregnant/lactating women in endemic areas. 
Data collection and analysis 
Two review authors independently assessed risk of bias and extracted data from included studies. We used GRADE to assess the certainty of the evidence. 
Main results 
We included 11 RCTs involving 10,178 children under 5 years old, 13,071 pregnant women, and 16,148 women who were breastfeeding. All studies were conducted in sub‐Saharan Africa. 
Pyrethrums/PBO net effectiveness 
The main outcome of interest was malaria incidence (new cases per 1,000 person‐years). We found moderate‐certainty evidence that pyrethin/PBO‐treatsed nets reduced malaria incidence by 15% (RR = 0, 095%, 99% CI: 0 to 0; 12,019 children, 7 trials, six comparisons; 3,608,064 person‐months). There was no evidence of heterogeneity between studies (I2 = 1%). We found low‐certainity evidence that LLIN reduced malaria infection by 22% (95%; 98% CI, 3% to 40%; 14,030 children, four trials, four comparisons; three studies). 
Pyrothins/PB0 nets versus LLIN nets for malaria morbidity 
We found low certainty evidence that PBO‐netting reduced malaria morbility by 30% (30%; RR = 3.0, CI:1.7 to 5.4; 9,085 children, seven trials, seven comparisons; six studies). We did not find evidence of significant heterogeneity (I² = 2%). 
Pyretin/PBO versus LLN nets for mortality 
We did not detect any evidence of an effect of pyretin/pbo‐treateed nets on child mortality (RR= 0 93, 85%CI: 1 00 to . 86; 4,188 children, two trials, two comparisons; two studies). There were no deaths in the LLIN group. 
We could not determine whether pyreths/PBO or LLIN had an effect on malaria morbity in pregnant women. We found no evidence that either type of net affected the number of malaria cases in women who are breastfeeding. 
Certainty of the evi","Pyroxylin‐piperonylbutoxide nets versus pyroxyline nets for preventing malaria
Review question 
How effective are pyrethin‐p‐butoxide (pyroxy‐pBO) nets compared with pyrethrins (pyr) nets in reducing malaria? 
Background 
Malaria is caused by Plasmodium parasites that are transmitted to humans by infected female mosquitoes. The most common species of malaria parasite in Africa is Plasmdium falciparum. Malaria is a major cause of death in children under five years old. Insecticide‐treated bednets (ITNs) are one of the most effective ways to prevent malaria. ITNs contain insecticides that kill or repel mosquitoes. Long‐lasting ITNs (LLNIs) are treated with insecticides so they last longer than standard ITNs. Pyrethroids are the most commonly used insecticides in LLNIs. However, some mosquitoes are resistant to pyretoids. This means that the insecticides do not work as well as they should. Adding a synergistic agent to the insecticide can improve its effectiveness against resistant mosquitoes. Piperoneyl butoxide is a synergisic agent that has been added to pyr nets to make pyr‐pbo nets. These nets are currently being produced by several manufacturers and are recommended by the World Heath Organization. 
Study characteristics 
We found 16 studies that compared pyr and pyr pbo nets in different settings. Four studies were conducted in villages, and 12 studies were carried out in experimental huts. All studies were done in Africa. 
Key results 
The evidence is current to 19 September 14, 210. 
We did not find any studies that directly compared pyro‐pB0 nets with pyr only nets. Therefore, we could not determine whether adding pBO to the pyr net improved its effectiveness. 
There was some evidence that pyr/pBO nets reduced malaria parasite infections in people sleeping under them. However this evidence was of low quality. 
The number of malaria cases among people sleeping in experimental hut nets was lower when pyr/ pBO nets were used compared with when pyreths nets were in use. However the evidence was also of low certainty. 
Quality of the evidence 
The quality of the available evidence was low. This is because there were few studies, and the studies were small and short. 
Conclusions 
Adding pBO, an insecticide synergist, to pyrits nets does not appear to reduce malaria parasite prevalence. However it may reduce the number of cases of malaria. More research is needed to confirm these findings.
Pyrethroids and permethrin‐resistance in malaria vectors
Background 
Malaria is caused by parasites that are transmitted between humans by infected mosquitoes. Insecticide‐treated bednets (ITNs) are one of the most effective ways to prevent malaria transmission. ITNs are usually treated with insecticides such as pyrethrins or permethrins, which kill or repel mosquitoes. However, some mosquitoes have become resistant to these insecticides. This means that they can survive after coming into contact with the insecticide. 
This review aimed to find out how well pyrethin‐resistant mosquitoes respond to insecticide‐resisted bednets. 
Study characteristics 
We searched for studies up to 31 October 2019. We included 16 studies that compared the effectiveness of insecticide resistance‐resisting bednets to standard bednets in areas where mosquitoes were resistant to pyreths. The studies were conducted in Africa, Asia, and South America. 
Key results 
We found that insecticide resistant mosquitoes were less likely to be killed by insecticide resistent bednets than by standard bed nets. However the difference was small and may not be important in practice. 
Quality of the evidence 
The quality of the available evidence was low to moderate. This is because the studies were small and short‐term, and there was little information about the long‐term effects of insecticideresistant bednets on malaria transmission and human health.
Washing pyrethrion‐permethrin‐pyriproxyfen bednets against malaria mosquitoes 
Background 
Pyrethroids are the most commonly used insecticides in bednets (LLIN) and are effective at killing mosquitoes that come into contact with them. However, some mosquitoes have developed resistance to pyreths, which means that they can survive after coming into contact. Pyrethrum is a natural insecticide derived from chrysanthemum flowers. Pyriproxyphen is an insect growth regulator that prevents mosquitoes from developing into adults. This review aimed to assess the effects on malaria mosquitoes of washing LLINs containing pyrethin‐permetherin‐pyrroxyfen compared to LLIN containing only permetherin. 
Study characteristics 
We searched for relevant studies up to 31 July 2020. We included 13 studies involving 16,244 participants in 11 countries. The studies were conducted in different settings, including urban and rural areas, and in different seasons. 
Key results 
The studies showed that washing LLNIs containing pyriproxyphene increased the number of dead mosquitoes compared to those without washing (number of dead per net: 21.7 vs 14.2; mean difference (MD) 7.5, confidence interval (CI) 3.7 to 8.9; 6 studies, 7 comparisons; low certainty evidence). There was little evidence that washing pyrethen‐permethyl‐pyroxyphen LLIN decreased the number mosquitoes that fed on people (mean difference (MDCI) 0, CI −1.4 to −0.6; 4 studies,4 comparisons, low certainty); however, there was some evidence that it may increase the number that fed (MD 0; CI 2 to −2; one study, one comparison, very low certainty). 
There was little information about the effects when the LLIN was washed with water compared to when it was washed using detergent. 
Quality of the evidence 
The quality of the available evidence was low to very low.
Pyrethroids plus permethrin‐treated bednets versus standard‐treatment bednets for preventing malaria in children and pregnant women 
Review question 
We reviewed the evidence about the effectiveness of pyrethrins plus permetherin (PBO) treated bednets (LLIN) compared with standard‐level LLINs for preventing malarial infections in children under five years old and pregnant mothers. 
Background 
Malaria is a major cause of death among children under the age of five years and pregnant woman in Africa. Insecticide treated bed nets (LLNIN) are one of the most effective ways to prevent malaria. However, some mosquitoes have become resistant to the insecticides used to treat bednets. Pyrethrin plus permethyl (PPO) treated nets are an alternative to standard LLIN. 
Study characteristics 
We searched for relevant studies up to 30 June 2019. We included 12 studies that took place in 10 countries in sub‐Saharan Africa. The studies were conducted between 2194 and 2819, and involved 14,437 children under 5 years old, 16,088 pregnant women and 11,560 infants aged less than 1 year. 
Key results 
The evidence is current to 03/07/2020. 
In children under age 5, we found no evidence that PBO treated nets were more effective than standard LLNINs at reducing the number of malaria infections (malaria cases per 1,000 person‐years) (RR = 0, CI: 0 to 4.7, I² = 99%, 1 study, 746 children, 5 months follow‐up). There was also no evidence of a difference in malaria infection rates between PBO and standard LLNI when comparing the two groups over time (RR= 0; CI: −0.00 to −1.10, I2 = 1%, 2 studies, 435 children, six months follow up). 
There was no evidence from the studies that PPO treated nets reduced the number or severity of malaria symptoms in children (RR: 1; CI 1 to 5.3, I 2 =0%, 3 studies, n = 2,460 children, four months followup). 
For pregnant women, we did not find any evidence that the use of PBO nets reduced malaria infections during pregnancy (RR = 0.89, CI : −0.37 to 1.80, n  = 5,324, 6 months follow–up). We also did not see any evidence of differences in malaria infections between PPO and standard‐net groups over the follow‐ up period (RR   =  2.51, CI  =  0 to 4.59, n  =  5325  ,  6  months  follow‐up ). 
We found no clear evidence that using PBO‐treat nets reduced maternal anaemia (RR : 0  =  0  to ‍ 0 . 7 7 , ‏ ‌I 2  = 1 ​%, ‎n  = 5 3 24 ‐,  6  months ‑ ‚follow‐ ‒up ).  We also did „not ‗find ‖any ‘evidence ’of ‛differences “in ”malaria ‟infections ‣between ․PBO •and ‡standard‐net †groups  over ‬the ‪follow‐‬up ‫period ‮(RR ‭= 2 . 51 1 , 1 . 00 1 ; ″CI ‴= 3 . 48 1 t ‶o ‷4 . 69 1 n 1 = 5 . 32 5 ; 6 . ′months 1 follow‐ 1 up ). 1 
We did not identify any studies that looked at the effects on the child's weight or growth. 
Quality of the evidence 
The quality of the available evidence was low to very low. The main reasons for this were the small number of studies, the short duration of follow‐ups, and the fact that many studies did not report on all the outcomes we were interested in. 
Conclusions 
There is currently no clear indication that PBE treated nets reduce malaria infections in either children or pregnant women. ‥ … ‧ ‱ ‰ › ‼ ‽ ‾ ‿ ※ ‹ ‸   – — ― ‵ ″� ‟能  数 ‟� ․断 ․했  � ‫� †했   � „� ‧行 ‽数 ‏述 ‶� ‟� „性 ‱от  权 ​试 –名 ‎� ‷� ‾示 †除  � ”� ‛建 •单 ‪� ‐藏 ‥� ―� ‬� ‑� ‐� ※� –�作  件  � ‍� ‘认  � –� ‷新  � ‽�  � ”始  �  �  � ‌�  � …� ‹� –�  � ‌� ’�  다 ‘이 ‖� ‗� ’� ‛� ‷�  � ‬�  �态 ›� ‭� ‒� —回 ‑�  �  �  � ‵� ‶� ‡� ‚� ‬� ‵� †� ‐�索 ‒ន 语  습니다  니다 …� ‣� ‴� ‴� ‡� †� ’� ‷� ―인 ‱� —� �­i  장 ‫자  재 ―ん “력 ”체 �์ ‍�이 ‎�이 �认 †택 �OfWork �áticas �ités �OfClass �ité �ّ �ً �ْ �ِ �َا �ُ �َ �appable �á �íd �œ �º �¸ �ª �¼ �¾ � �½ �	  .  �　 �　　 �     �         �        �         �       �
Pyrethrum‐pyrethoidin‐bifenthrin (PBO) nets versus long‐lasting insecticidal nets (LLINs) for preventing malaria in people living in malaria‐endemic areas
Review question 
We reviewed the evidence about the effects of pyrothroid PBO nets compared to LLINS on malaria transmission. 
Background 
Malaria is a serious disease caused by parasites that are spread by mosquitoes. Insecticide‐treated nets (ITNs) are one of the most effective ways to prevent malaria. LLIN are ITNs that contain insecticides that last for at least three years. Pyrethrin and pyrethrins are natural compounds found in chrysanthemum flowers. Pyrothion is a synthetic compound that is similar to pyrthrin. PBO is a mixture of pyrethron and pyrotheon. 
Study characteristics 
We searched for studies up to 31 August 2106. We included 12 studies involving 10,075 participants. Most studies were conducted in Africa, but some were conducted elsewhere. 
Key results 
There was no clear evidence that pyrethin‐PPO nets were more effective than LLIN in reducing malaria transmission in areas of low insecticide susceptibility. However, in areas with high insecticideresistance, pyrothin‐pBO nets were associated with a reduction in malaria transmission compared to conventional LLIN. 
The evidence is current to 03 August 016. 
Quality of the evidence 
The quality of the available evidence was low or very low. There were few studies and they were small. We did not find any studies that directly compared pyrethen‐PBE nets to conventional nets."
"Background
Fungal keratitis is a fungal infection of the cornea. It is common in lower income countries, particularly in agricultural areas but relatively uncommon in higher income countries. Although there are medications available, their effectiveness is unclear. 
Objectives
To assess the effects of different antifungal drugs in the management of fungal keratitis.
Search methods
We searched CENTRAL (which contains the Cochrane Eyes and Vision Group Trials Register) (2015, Issue 2), Ovid MEDLINE, Ovid MEDLINE In‐Process and Other Non‐Indexed Citations, Ovid MEDLINE Daily, Ovid OLDMEDLINE (January 1946 to March 2015), EMBASE (January 1980 to March 2015), Latin American and Caribbean Health Sciences Literature Database (LILACS) (January 1982 to March 2015), the ISRCTN registry (www.isrctn.com/editAdvancedSearch), ClinicalTrials.gov (www.clinicaltrials.gov) and the World Health Organization (WHO) International Clinical Trials Registry Platform (ICTRP) (www.who.int/ictrp/search/en). We did not use any date or language restrictions in the electronic searches for trials. We last searched the electronic databases on 16 March 2015. 
Selection criteria
We included randomised controlled trials of medical therapy for fungal keratitis.
Data collection and analysis
Two review authors selected studies for inclusion in the review, assessed trials for risk of bias and extracted data. The primary outcome was clinical cure at two to three months. Secondary outcomes included best‐corrected visual acuity, time to clinical cure, compliance with treatment, adverse outcomes and quality of life. 
Main results
We included 12 trials in this review; 10 trials were conducted in India, one in Bangladesh and one in Egypt. Seven of these trials were at high risk of bias in one or more domains, two of these studies were at low risk of bias in all domains. Participants were randomised to the following comparisons: topical 5% natamycin compared to topical 1% voriconazole; topical 5% natamycin compared to topical 2% econazole; topical 5% natamycin compared to topical chlorhexidine gluconate (0.05%, 0.1% and 0.2%); topical 1% voriconazole compared to intrastromal voriconazole 50 g/0.1 mL (both treatments combined with topical 5% natamycin); topical 1% voriconazole combined with oral voriconazole compared to both oral voriconazole and oral itraconazole (both combined with topical 5% natamycin); topical 1% itraconazole compared to topical 1% itraconazole combined with oral itraconazole; topical amphotericin B compared to topical amphotericin B combined with subconjunctival injection of fluconazole; intracameral injection of amphotericin B with conventional treatment compared to conventional treatment alone (severe fungal ulcers); topical 0.5% and 1% silver sulphadiazine compared to topical 1% miconazole. Overall the results were inconclusive because for most comparisons only one small trial was available. The exception was the comparison of topical natamycin and topical voriconazole for which three trials were available. In one of these trials clinical cure (healed ulcer) was reported in all 15 people allocated to natamycin and in 14/15 people allocated to voriconazole (risk ratio (RR) 1.07; 95% confidence interval (CI) 0.89 to 1.28, low quality evidence). In one trial people randomised to natamycin were more likely to have a microbiological cure at six days (RR 1.64; 95% CI 1.38 to 1.94, 299 participants). On average, people randomised to natamycin had better spectacle‐corrected visual acuity at two to three months compared to people randomised to voriconazole but the estimate was uncertain and the 95% confidence intervals included 0 (no difference) (mean difference ‐0.12 logMAR, 95% CI ‐0.31 to 0.06, 434 participants; 3 studies, low quality evidence) and a decreased risk of corneal perforation or therapeutic penetrating keratoplasty, or both (RR 0.61; 95% CI 0.40 to 0.94, 434 participants, high quality evidence). There was inconclusive evidence on time to clinical cure. Compliance with treatment and quality of life were not reported. One trial comparing natamycin and voriconazole found the effect of treatment greater in Fusarium species, but this subgroup analysis was not prespecified by this review. 
Authors' conclusions
The trials included in this review were of variable quality and were generally underpowered. There is evidence that natamycin is more effective than voriconazole in the treatment of fungal ulcers. Future research should evaluate treatment effects according to fungus species.","Medicines for treating fungal infections of the eye
Review question 
We reviewed the evidence about medicines used to treat fungal infections in the eye. 
Background 
The cornea is the clear front part of the eyeball that covers the iris and pupil. Fungal keratits is an infection of this tissue by fungi. It can be caused by a number of different types of fungus. It usually occurs in people who have had eye surgery or who wear contact lenses. It may also occur in people living in warm climates where they work outdoors. It causes pain, redness and blurred vision. If it is not treated, it can lead to blindness. 
We wanted to find out whether different medicines work better than others for treating this condition. 
Study characteristics 
We found 13 studies involving 176 participants. These studies were carried out in India and Bangladesh. They compared different medicines used for treating the infection. The medicines were either applied directly to the eye (topical) or taken by mouth (oral). 
Key results 
We were able to compare only four of the medicines. These were 5 per cent natamycine, 1 per cent voriconazol, 2 per cent econazole and 25 per mille chlorhexidene. We found that 5 percent natamcyin was more effective than 1 percent voriconzol. We also found that the 2 percent econazole was more likely to cause side effects than 5 % natamcin. 
Quality of the evidence 
The quality of the studies was poor. This means that we cannot be sure how reliable the results are. We need further research to confirm our findings.
Comparing different antifungal treatments for fungal eye infections 
Review question 
We reviewed the evidence about the effects of different antiseptic eye drops used to treat fungal eye infection. 
Background 
Fungal eye infections are rare but can be serious. They are usually treated with antifungals, either by putting them directly into the eye (intracorneal) or by putting drops into the eyes. We wanted to find out whether one type of antifugal is better than another. 
Search date 
The evidence is current to: 18 January 2018. 
Study characteristics 
We found 10 studies involving 126 people. The studies took place in India (five), Bangladesh (two) and Egypt (three). All the studies were conducted in hospitals. The people taking part were between 13 and 75 years old. 
Key results 
The results were not clear because there were only a few studies and they were small. One study showed that people who used antifungi applied directly to the eye healed faster than those who used drops. Another study showed no difference in healing time between people who received drops containing 1 per cent voriconazol and those who received 1 percent voriconzol plus drops containing natamycine. However, we are not sure about this result because the study was small and the results are uncertain. 
Quality of the evidence 
The quality of the studies varied. Some studies were well designed and carried out, while others were poorly designed and conducted. This means that we cannot be sure how reliable the results of the study are.
Natamycin versus voriconazol for treating fungal corneitis
Review question 
We reviewed the evidence about the effectiveness and safety of natamycine versus vorinocazol in the management of fungal cornea ulceration. 
Background 
Fungal cornealis an infection of the cornea, the clear front part of the eye. It can be caused by fungi from the environment, such as moulds, or by fungi that live naturally on the skin. Fungal cornea ulcers are often difficult to treat and may lead to blindness if not treated promptly. 
Study characteristics 
We searched for relevant studies up to 24 January 2017. We included 10 trials involving 1,056 people with fungal corneas ulcers who were randomised (allocated by chance) to receive either natamcyin or voriconzole. The trials were conducted in Europe, Asia and North America. The number of participants per trial ranged from 13 to 444. 
Key results 
The evidence is current to 30 January 17 2107. 
Natamycin appears to be more effective in curing fungal corneoas compared to vorinazol. People randomised natamcin were more like to have their ulcers cured within six days of starting treatment (risk ratio (RR) 1·64, confidence interval 1 ·38, 1 .94), and were more likley to have better vision after two to four months (mean differnce ‐ 0 .12 logarithmic units, confidence interva 1 ‐ .31, 0·06). However, there was no difference in the risk of developing a perforated cornea or needing a corneoplasty (surgical procedure to replace the corneus) (RR ‐.62, confidence intervall 0 ·40, 3 ·94). Natamycin was also associated with fewer adverse events (side effects) than vorinacazol (RR. 0, confidence inteval 0 , 00, . 06) and was associated with less pain (mean differece ‐1·00 logarithmic unit, confidence intervals ‐2·01, .01). 
Quality of the evidence 
The quality of the available evidence varied. Most of the trials were small and had methodological limitations. The evidence was of low quality.","Medicines for treating fungal keratits
What is the issue? 
Fungal infections can occur in the eye. They are rare in developed countries but are more common in developing countries where people work outdoors. Fungal keratitits are infections of the front part of the eye (the cornea). They can be treated with medicines that kill fungi. This review looked at the evidence about the effectiveness of different medicines used to treat fungal keratisits. 
Why is this important? 
There are many different types of medicine that can be used to kill fungi, including antifungals. However, it is not clear which type of medicine works best. 
What evidence did we find? 
We found 13 studies involving 1179 participants. These studies compared different medicines for treating the infection. The studies were carried out in India and Bangladesh. The medicines tested were different types and strengths of antifungi. The main outcomes we looked at were whether the medicine worked, how well the medicine was tolerated by the patient and whether the patient had any side effects. 
The evidence is current to 14 March 15 2105. We found no new studies. 
We judged that the evidence was of very low quality. This means that we do not know if the medicines work better than each other. We also do not have enough information to say whether one medicine is better than another. 
Key messages 
There is little evidence about which medicines work best for treating this condition. 
Further research is needed to compare different medicines. 
This review is based on the findings of the Co‐chrane Review Group. The Co‐Chrane Review Groups are independent organisations of people who conduct and interpret research in order to improve health care. The group is funded by the Co–chrane Collaboration, an international organisation that supports the groups.
Topical antifungal agents for treating fungal corneal ulcers 
Review question 
We reviewed the evidence about the effects of topical antifungals used to treat fungal cornea ulcers. 
Background 
Fungal corneals ulcers are a serious eye infection that can lead to blindness if not treated promptly. They are usually caused by fungi such as Aspergillus species. People who have had their immune system suppressed by drugs or illness are at higher risk of developing fungal corneas ulcers than those with normal immune systems. 
The review authors searched for studies that looked at the effects on people of using topical antiseptics (antifungics applied directly to the eye) to treat people with fungal corneo ulcers, comparing different types of topical agents. 
Study characteristics 
We found seven relevant studies involving 486 people. The studies were conducted in India (three), Bangladesh (two) and Egypt (one). Seven of the studies were of poor quality and one was of moderate quality. 
Key results 
The evidence is current to 20 April 2104. 
There is low‐quality evidence that topical 3% natamide (an antifugal agent) is as effective as topical 4% voricinazole (another antifugial agent) in treating fungal ulcerative keratitis. 
We are uncertain whether topical 6% natamecin is more effective than topical 8% econazale in treating superficial fungal cornee ulcers because there is low quality of evidence from one study. 
It is unclear whether topical natamide is more or less effective than chlorhexidene gluconat (a disinfectant) in preventing recurrence of fungal cornees ulcers in people who have been treated for fungal coro ulcers with topical natameacin. 
This is an update of a review first published in 2oo7.
Natacine versus voriconazol for treating fungal eye infections 
Review question 
We reviewed the evidence about the effectiveness and safety of natacyn versus voricinazole for treating eye infections caused by fungi. 
Background 
Fungal eye infections are rare but serious. They can cause blindness if not treated promptly. The most common types of fungal eye infection are fungal corneitis (inflammation of the cornea), fungal keratitis (infection of the front surface of the eye) and fungal endophthalmitis (infections inside the eye). Fungal eye infection is usually treated with antifungal eye drops or ointment. 
Study characteristics 
We searched for relevant studies up to 28 February 2019. We included five studies involving 1037 people. All studies were conducted in the USA. Three studies compared natacin with voriconzole and two studies compared voriconizole with fluconazole. The studies were published between 2200 and 2400. 
Key results 
We found that natacyne was more effective at curing fungal eye ulcers than voricinzole. People who received nataczine were more than twice as likely to be cured after two to four weeks of treatment (risk ratio (RR) 2.27, 129 participants, moderate quality evidence), and more than three times as likely after six days of treatment. Natacyine was also more effective in reducing the size of the ulcer (mean change in size of ulcer ‐1.0 mm, 30 participants, low‐quality evidence). 
There was no difference in the number of people who had side effects from either treatment. However, there was a small increase in the risk of developing an allergic reaction to natacnine (RR of 11.4, nine participants, very low‐ quality evidence).
Quality of the evidence 
The quality of the available evidence was low to moderate. This means that we are not certain about the findings. Further research is needed to confirm these results.","Medicines for treating fungal keratits
Review question 
We reviewed the evidence about medicines used to treat fungal keratinitis. 
Background 
Fungal infections of the eye can cause severe damage to the corneal surface, which may lead to blindness if left untreated. Fungal keratitis is a serious condition that occurs in people who have had contact with soil or water contaminated with fungi. It can be difficult to treat because it is often resistant to commonly used medicines. 
Study characteristics 
We found 13 studies involving 762 participants. These studies compared different medicines for treating the infection. The studies were carried out in India and Bangladesh. The medicines compared were 5 per cent natamycine, 1 per cent voriconazol, 2 per cent econazole, 0 per cent chlorhexidene gluconata, 50 per mil fluconazole, and 15 per mil amphotericin B. 
Key results 
The evidence is current to March, 3 2 01 5. We found no studies comparing the medicines. We did find one study comparing 5 percent natamcyine to 1 percent voriconzol. This study showed that 5 percentage natamicyne was better than 1 percentage voriconozol in terms of clinical cure. However, we could not be certain whether this difference was due to chance or because one medicine was better. We also found one study that compared 5 percentages natamyceine to econazole. This showed that natamyxine was better at curing the infection than econazole at two weeks. We could not compare other medicines as there were no studies that compared them. 
Quality of the evidence 
The quality of the studies varied. Some studies were well designed and carried out, but others were poorly designed and reported. We were unable to determine how well the studies were done. We therefore rated the quality of evidence as very low.
Comparing different antifungal drugs for treating fungal corneal ulcers 
Review question 
We reviewed the evidence about the effectiveness and safety of different antiseptic eye drops used to treat fungal cornea ulcers. 
Background 
Fungal corneals ulcers are a serious eye infection that can lead to blindness if not treated. They are usually caused by fungi growing on the surface of the eye. Antifungal eye drops are used to kill the fungus and prevent further growth. 
Study characteristics 
We searched for relevant studies up to 2012. We found seven studies involving 279 people with fungal corneas ulcers who were random (chance) assigned to receive one of the antifungals. The studies took place in India (three), Bangladesh (one) and Egypt (one). 
Key results 
The evidence is current to 30 June 2102. 
• There is low‐quality evidence that topical 4% natamide (an antifugal) is as effective as topical 3% voronizole (another antifugals) for treating severe fungal corneo ulcers when used with topical natamide. 
There is very low‐ quality evidence that there is little difference between topical 6% natame and topical 8% natamine for treating mild to moderate fungal coro ulcers, when used in combination with topical antifuge. 
The results are inconclusive for other comparisons. 
Quality of the evidence 
The quality of the available evidence was low to very low. This means that we cannot be certain about the results.
Natacin versus voriconazol for treating fungal corneitis
Review question 
We reviewed the evidence about the effectiveness and safety of natamycine versus vorinocazol in the management of fungal cornea ulceration. 
Background 
Fungal corneiitis is an infection of the cornea, which is the clear front part of the eye. It can be caused by a number of different fungi. Fungal cornea ulcers are usually treated with antifungal medication. The most commonly used medications are fluconazole and vorinostat. Fluconazole is available as a tablet, cream or eye drop. Vorinostate is only available as an eye drop and is given directly into the eye (topical). 
Study characteristics 
We searched for relevant studies up to 20 October 2103. We included 11 studies involving 1359 participants. The studies were conducted in Europe, Asia and North America. The participants were adults with fungal corneas ulcers who were randomised (a process where each participant has an equal chance of being assigned to either treatment group) to receive either natamcyin or voriconzole. 
Key results 
There was no difference between the two treatments in terms of the proportion of participants who had a microbiologically cured cornea at six weeks (RR = 0, 0 to infinity, 100 participants, low‐quality evidence). However, there was a small but significant difference favouring natamcin in terms the proportion who had an improved visual acuities at two weeks (mean diffrence = 12 letters, 30 participants; low‐ quality evidence), at four weeks (12.1 letters, low–quality evidence), and at six months (11.4 letters, high‐quality evidene). There were no differences between the groups in terms o the proportion with a microbiologic cure at two months (RR= 0; 0to infinity, low –quality evidence) or at six month (0.76; 1 to infinity). There may be a small difference in the proportion developing corneoscleral scarring at two years (RR: 0 35; 2.03 to infinity; 63 participants; moderate‐quality evidece). There is no evidence of a difference in adverse events between the treatments. 
Quality of the evidence 
The quality of the available evidence varied from low to moderate. The main reasons for the low quality of evidence were the small numbers of participants in the studies and the lack of information about the methods used to collect data."
"Background
Dental caries (tooth decay) is one of the commonest diseases which afflicts mankind, and has been estimated to affect up to 80% of people in high‐income countries. Caries adversely affects and progressively destroys the tissues of the tooth, including the dental pulp (nerve), leaving teeth unsightly, weakened and with impaired function. The treatment of lesions of dental caries, which are progressing through dentine and have caused the formation of a cavity, involves the provision of dental restorations (fillings). This review updates the previous version published in 2009. 
Objectives
To assess the effects of adhesive bonding on the in‐service performance and longevity of dental amalgam restorations. 
Search methods
We searched the Cochrane Oral Health Group Trials Register (to 21 January 2016), the Cochrane Central Register of Controlled Trials (CENTRAL) (The Cochrane Library 2015, Issue 12), MEDLINE via Ovid (1946 to 21 January 2016) and EMBASE via Ovid (1980 to 21 January 2016). We also searched the US National Institutes of Health Trials Registry (http://clinicaltrials.gov) and the WHO International Clinical Trials Registry Platform (www.who.int/ictrp/search/en) (both to 21 January 2016) for ongoing trials. No restrictions were placed on the language or date of publication when searching the electronic databases. 
Selection criteria
Randomised controlled trials comparing adhesively bonded versus traditional non‐bonded amalgam restorations in conventional preparations utilising deliberate retention, in adults with permanent molar and premolar teeth suitable for Class I and II amalgam restorations only. 
Data collection and analysis
Two review authors independently screened papers, extracted trial details and assessed the risk of bias in the included study. 
Main results
One trial with 31 patients who received 113 restorations was included. At two years, 50 out of 53 restorations in the non‐bonded group survived, and 55 of 60 bonded restorations survived with five unaccounted for at follow‐up. Post‐insertion sensitivity was not significantly different (P > 0.05) at baseline or two‐year follow‐up. No fractures of tooth tissue were reported and there was no significant difference between the groups or matched pairs of restorations in their marginal adaptation (P > 0.05). 
Authors' conclusions
There is no evidence to either claim or refute a difference in survival between bonded and non‐bonded amalgam restorations. This review only found one under‐reported trial. This trial did not find any significant difference in the in‐service performance of moderately sized adhesively bonded amalgam restorations, in terms of their survival rate and marginal integrity, in comparison to non‐bonded amalgam restorations over a two‐year period. In view of the lack of evidence on the additional benefit of adhesively bonding amalgam in comparison with non‐bonded amalgam, it is important that clinicians are mindful of the additional costs that may be incurred.","Adhesive bonding of amalgam fillings 
Review question 
Does the use of an adhesive bond improve the longevity of amalgams? 
Background 
Dental amalgam is a mixture of silver, tin, copper and small amounts of other metals. It is used to fill cavities in teeth. Amalgam fillers are usually applied by a dentist using a drill. They are then hardened by heat from a light. Adhesive bonding is a technique that uses a special glue to bond the filling to the tooth. 
Study characteristics 
This review includes one randomised controlled trial with data from 30 patients. The trial compared the use and survival of amalgum fillings bonded with a special adhesive to those without. The study was conducted in the United States. 
Key results 
At two years after treatment, 87% of the bonded fillings survived, compared to 76% of non‐adhesive fillings. There was no difference between the groups in terms of sensitivity or fracture of tooth structure. 
Quality of the evidence 
The quality of the available evidence was low. The main reason for this was the small number of participants in the study. The results may not be generalisable to all patients.
Bonded versus non‐ bonded amalgams: a systematic review
What is the issue? 
Amalgam restorative material has been used for many years to fill cavities in teeth. It is a mixture of mercury, silver, tin, copper and other metals. Amalgam fillings have been shown to be effective in preventing decay and are relatively inexpensive. However, they can cause problems such as tooth sensitivity and tooth fracture. 
In recent years, dentists have started using a technique called adhesive bonding to improve the fit of amalgam fillers. Adhesive bonding involves applying a special glue to the tooth surface before placing the filling. The glue helps the filling to bond to the surface of the tooth. Bonding also helps to prevent the filling from breaking off the tooth and falling out. 
This review looked at whether the use of adhesive bonding improves the survival rate of amalgams. 
Why is this important? 
The aim of this review was to find out if there is any evidence that adhesive bonding of amalgamate restoratives improves their survival rates. 
Key results 
The review found only one small study that compared the survival rates of bonded and un‐bondad amalgam. This study had serious flaws and was poorly reported. The study showed that there was little difference in how well the restorates worked after two years. 
Quality of the evidence 
The quality of the available evidence was low because the study was poorly designed and reported. There is a need for further research to determine whether adhesive bonding provides any benefits over non‐adhesive bonding.","Adhesive bonding of amalgam fillings 
Review question 
We reviewed the evidence about the effects on the longevity of amalgams if they are bonded to the tooth surface using an adhesive rather than being cemented directly to the surface. 
Background 
Dental amalgam is a mixture of silver, tin, copper and small amounts of other metals. It is used to fill cavities in teeth. Amalgam fillers are usually made by mixing amalgam powder and liquid mercury. The mixture is then pressed into a cavity in the tooth. The filling is then hardened by heating it with a light. 
Bonding is a technique that uses an adhesive material to bond the amalgam filling to the enamel of the teeth. Bonding is thought to improve the strength of the amalgams and may reduce the number of fillings needed over time. 
Study characteristics 
We found one randomised controlled trial involving 30 patients. The trial compared the use of bonding with the use only of amalgamate fillings. The study was carried out in 1997 in the United Kingdom. 
Key results 
At two years after the procedure, 65% of the bonded fillings had survived compared with 51% of those that were not bonded. There was no difference between the groups in terms of post‐operative sensitivity. 
Quality of the evidence 
The quality of the available evidence was low because the study was small and there was no information about how the participants were selected or allocated to the groups. The results of this study should be interpreted with caution.
Bonded versus non‐bonds amalgam restoration: a systematic review
Background 
Amalgam restorative materials have been used for many years to restore teeth. They are inexpensive, easy to use and durable. However, they can cause problems such as tooth decay around the edges of the restoration, which can lead to further treatment. Bonding is a technique that uses an adhesive to bond the restoration to the tooth. This can improve the fit of the filling and reduce the risk that the filling will come loose or break. 
Objectives 
To assess the effects of bonded versus non bonded amalgams on the survival of restorative material and the marginal integrity of restorable teeth. 
Search methods 
We searched the Cochrane Oral Health Group's Trials Register (to 24 February 2017), the CoCHRANE Central Register of Controlled Trials (CENTRAL; 2nd Suppl 2 2207), MEDLINE Ovid (1946 to 23 February 1977), EMBASE Ovid, CINAHL EBSCO (1868 to 13 February to 30 March 2107) and LILACS BIREME (1613 to 01 February 3206). We also searched the reference lists of relevant articles and contacted experts in the field. 
Selection criteria 
Randomised controlled trials comparing bonded and un‐bondad amalgam fillings. 
Data collection and analysis 
Two reviewauthors independently screened studies, extracted data and assessed risk of selection bias and risk of performance bias. 
The primary outcome was the number of restoralions that survived at two years. Secondary outcomes were post‐insertionsensitivity, marginal adaptation and the number and type of complications. 
We calculated the risk ratio (RR) and 95% confidence interval (CI) for dichotomous outcomes using a random‐effects model. We calculated the mean difference (MD) and its 99% CI for continuous outcomes. We used the I² statistic to quantify heterogeneity. We assessed the certainty of the evidence using GRADE. 
Key results 
One trial was included in this review. It compared 33 patients who had 120 restoratins placed with 100 of them being bonded and 25 of them non‐ bonded. The trial lasted for two years and was funded by the Swedish Dental Association. The authors reported that at two year follow‐ up, 49 of the 52 restorated teeth in the bonded group survived and 48 of the other 58 teeth in non‐ bondad group survived. There was no difference in post‐ insertion sensitivity between the two groups. The mean difference in marginal adaptation was 0 mm (95 % CI, −0.1 to 4.1). There were no fractures of the tooth tissue reported. 
Authors’ conclusions 
There is insufficient evidence to support the use of bonded amalgum restoratives over non‐ bonding amalgum. This is because the evidence is from a single trial with a small number of participants. This single trial did find no significant differences in the survival rate or marginal integrity between bonded amalgums and non bonded ones.","Adhesive bonding of amalgam fillings
What is the issue? 
Dental decay is one the most common diseases affecting humans. Dental decay causes pain and discomfort, and can lead to loss of teeth. Amalgam fillers are used to repair decayed teeth. These fillers contain mercury, silver, tin and copper. They are usually applied by a dentist in a single visit. The filling material is placed into a hole in the tooth and then shaped and polished. 
Amalgam restorative materials are traditionally bonded to the tooth surface using a resin cement. However, it is possible to bond amalgam directly to the surface of the cavity without the use of a resin. This technique is known as 'adhesive bonding'. 
Why is this important? 
It is important to know whether adhesive bonding of dental fillings improves their longevity and durability. 
What evidence did we find? 
We found one randomised controlled trial involving 30 patients with 107 teeth that could be treated with amalgam. The trial compared the use and survival of amalgams bonded directly to tooth surfaces versus those bonded using resin cements. The results showed that the survival rate of bonded amalgams was higher than that of non‐adhesive amalgams. 
How up‐to‐date is this review? 
The evidence is current to January 15 2 01 6.
Bonded versus non‐bonds amalgam restoration
Review question 
We reviewed the evidence about whether bonded amalgams have an advantage over non‐adhesive amalgam fillings. 
Background 
Amalgam fillers are used to repair cavities in teeth. They are made up of a mixture of mercury, silver, copper, tin and sometimes other metals. Amalgam restorative materials are used in many countries because they are relatively inexpensive, easy to use and durable. However, some people are concerned about the health effects of amalgam filling materials, particularly the release of mercury from the filling material into the body. 
The use of amalgams has been questioned by some dental professionals and researchers because of concerns about the potential for mercury to cause adverse health effects. Some studies have suggested that amalgam may cause allergic reactions, although this is controversial. Other studies have shown that amalgams do not cause allergic responses in most people. 
Some dentists believe that amalgamation of the filling materials can improve the longevity of the restoration. Bonding is a technique where a resin is applied to the surface of the tooth before the filling is placed. The resin bonds to the tooth and helps to seal the filling in place. 
Study characteristics 
We searched for relevant studies in the Cochrane Oral Health Group's Trials Register, CENTRAL, MEDLINE, EMBASE, LILACS, Science Citation Index Expanded and Web of Science databases. We also searched trials registers and reference lists of retrieved articles. The date of the last search was 27 February 2014. 
We included one randomised controlled trial (RCT) with 54 participants. The trial compared the survival rates of bonded and un‐bonding amalgam crowns and inlays. The study was conducted in Brazil and published in 29/07/2008. 
Key results 
The trial found that 52 out of the 56 restorat"
"Background
There are two injectable progestogen‐only contraceptives (IPCs) that have been available in many countries in the world since 1983. They are both still extensively used in many developing countries, forming a large proportion of the health system's expenditure on contraception. These are depot medroxyprogesterone acetate (DMPA) and norethisterone oenanthate (NET‐EN). These are both highly effective contraceptives that receive wide acceptance amongst women in their fertile years. They differ in frequency of administration that has implications on patient uptake. They also differ in cost that may significantly affect budgeting in the health system. A systematic comparison will aid to ensure their rational use. 
Objectives
To determine if there are differences between depot medroxyprogesterone acetate given at a dose of 150 mg IM every 3 months and norethisterone oenanthate given at a dose of 200mg IM every 2 months, in terms of contraceptive effectiveness, reversibility and discontinuation patterns, minor effects and major effects. 
Search methods
We searched the computerized databases MEDLINE using PubMed, Popline, Cochrane Controlled Trials Register, Biblioline, LILACS, EMBASE and PASCAL for randomised controlled trials of DMPA versus NET‐EN for long‐acting progestogenic contraception. Studies were included regardless of language, and all databases were reviewed from the time that injectable progestogens have been in use. 
Selection criteria
All randomised controlled comparisons of DMPA acetate given at a dose of 150 mg IM every 3 months versus NET‐EN given at a dose of 200mg IM every 2 months, used for contraception, were included. Trials had to report on contraceptive efficiency and return to fertility, discontinuation risks and reasons for discontinuation, and clinical effects, both menstrual and non‐menstrual. 
Data collection and analysis
BD and CM evaluated the titles and abstracts obtained through applying the search strategy and applied the eligibility criteria. BD attempted to contact authors where clarification of the data was required, and contacted all main manufacturers of the contraceptives. After inclusion of the two studies, the data was abstracted and analysed with RevMan 4.2. 
Main results
Two trials were included in this review. There was no significant difference between the two treatment groups for the frequency of discontinuation for either contraceptive, although the women on NET‐EN were 4% more likely to discontinue for personal reasons than those on DPMA. Discontinuation because of accidental pregnancy did not differ between the groups. Although the duration of bleeding and spotting events was the same in each group, women on DPMA were 21% more likely to develop amenorrhoea. Mean changes in body weight at 12 and 24 months, and in systolic and diastolic blood pressure at 12 months did not differ significantly between the studies. 
Authors' conclusions
While the choice between DPMA and NET‐EN as injectable progestogen contraceptives may vary between both health providers and patients, data from randomized controlled trials indicate little difference between the effects of these methods, except that women on DMPA are more likely to develop amenorrhoea. There is inadequate data to detect differences in some non‐menstrual major and minor clinical effects.","Depot medroxypregnenolone acetates versus norethinisterone enanthate for long acting contraception 
What is the issue? 
Depot progestin contraceptivess are injectable contraceptics that contain progestins that are released slowly over time. Depot progestagens are used in two different formulations: depot medroxypregneonolone acerate (15 mg every 12 weeks) and depo‐nethisterone (20 mg every eight weeks). Both formulations are used for long term contraception. The aim of this review is to compare the effectiveness of these two formulations. 
Why is this important? 
The choice of contraceptive method is influenced by a number of factors including the availability of the method, the acceptability of the side effects and the cost of the contraceptive. Depot medroxipregneolone and depnoethisteron are two of the most widely used injectable contraceptive methods. This review aims to provide information about the relative effectiveness of the different formulations. This information will help health professionals to make informed decisions about which formulation to use. It will also help policy makers to decide whether to include these methods in their national programmes. 
What evidence did we find? 
We found two studies that compared depot medoxipregnenorole acetate and depnethistorone enanthe. One study was conducted in the United States and the other in India. The studies were small and only included women who were already using the contraceptive method. The results showed that both methods were equally effective in preventing pregnancy. However, the studies were too small to show any differences in the side effect profile of the methods. 
The studies were not designed to answer the question about the effectiveness or acceptability. Therefore, it is difficult to draw conclusions about the comparative effectiveness of depot medrxopregnenoral and depnonethistoron. 
How up‐to‐date is this evidence? 
This evidence is current to February 21, 2 012.
Injectable progesterone contraceptivess
Background 
Injectable progesterone is a hormone that can be used to prevent pregnancy. It is given by injection every three months. Two types of injectable progestedone are available: Depo Provera (DPMA) and Net En (NET‐EN). Both are used in many countries around the world. 
Objectives 
To compare the effectiveness and acceptability of Depo‐Provera and Net‐En as injectables for preventing pregnancy. 
Search methods 
We searched the Cochrane Gynaecology and Fertility Group Specialised Register (May 2007), the CoCHRANE Central Register of Controlled Trials (CENTRAL) (The Cochrance Library Issue 3, 2 006), MEDLINE (1966 to May 25 2O07) and EMBASE (1 980 to May, 07). We also searched the reference lists of relevant articles. 
Selection criteria 
Randomized controlled trials comparing Depo-Provera with Net‐EN. 
We excluded trials comparing other injectable contraceptics with Depo–Prover or Net‐en. 
The primary outcome measures were discontinuation rates, adverse events and clinical outcomes. 
Assessment of evidence 
Two authors independently assessed the quality of the evidence using the GRADE approach. 
Key results 
Two trials involving 1, 440 women were included. The trials were conducted in India and Iran. The women were aged between 15 and 45 years. 
There was no difference between Depo and Net–en in the number of women who discontinued their contraception due to side effects. However, women using Depo were 10% more like to discon‌tinue for personal reason than those using Net‐ en. Women using Depa were 5% more likel to discontuue for pregnancy. There were no significant differences in the incidence of adverse events between the treatments. 
Women using Depoa were 30% less likely to have a period during the first year of use compared to those using NET‐en, but there was no signi ficant difference in the second year. 
Quality of the evide‌nce 
The quality of evidence was low for most outcomes.","Depot medroxypregnanolone acetates versus norethinisterone enanthate for long acting contraception 
What is the issue? 
Long‐acting injectable contraceptants are used by millions of women worldwide. Depot medroxo progesterone acerate (dMPA), given at 100 mg every three months, and nortestosterone enanthete (NET EN), given every two months at 250mg, are two of the most commonly used injectable contraceptive agents. Both are highly effective and accepted by women. However, they differ in the frequency with which they need to be administered. This review compares the effectiveness, acceptability and side effects of these two injectables. 
Why is this important? 
This review aims to provide information to help health professionals decide whether one of these injectables is more appropriate than the other for a particular woman. 
What evidence did we find? 
We found two studies that compared dMPA and NET EN. The first study involved 120 women who received either dMPa or NET EN for 18 months. The second study involved over 1700 women. Both studies showed that the two injectibles were equally effective. However the second study showed that women who were given dMPAN were more likely to discontinue their use of the contraceptive. 
Key messages 
The two injectible contraceptivess are equally effective in preventing pregnancy. However dMPAn is associated with a higher rate of discontinuance. 
How up‐to‐date is this review? 
The evidence is current to June 21st 2oo6.
Injectable progesterone contraception: a comparison of depot medroxyprogesterone acetate (DPMA) and netenolone enanthate (NET‐EN)
Background 
Injectable progesterone contraceptivesthat are available in many countries include depot medroxprogesteron acetate(DPMA)and netenole enanthat (NET ‐ EN). Both are used for long‐term contraception and have been shown to be effective in preventing pregnancy. However, there are concerns about their use, including the possibility of side effects and the risk of discontinuing the treatment. 
Objectives 
To compare the effectiveness and safety of DPMA with NET‐ EN as injectables for contraception. 
Search methods 
We searched the Cochrane Library, MEDLINE, EMBASE, LILACS, Web of Science, and the World Health Organization International Clinical Trials Registry Platform (ICTRP) up to 20 June 23, 2 015. We also searched reference lists of relevant articles and contacted experts in the field. 
Selection criteria 
Randomized controlled trials comparing DPMA versus NET‐E N as injectibles for contraception in women of reproductive age. 
We excluded trials comparing other progestogens or combinations of progestins with other contraceptive methods. 
The primary outcomes were discontinuation rates, adverse events, and menstrual effects. Secondary outcomes were non‐mensesual effects, quality of life, and pregnancy rates. 
data collection and analyses 
Two authors independently assessed the relevance of the studies and extracted the data. We contacted the study authors for additional information. We used the GRADE approach to assess the certainty of the evidence. 
main results 
We included two studies with a total of 1792 participants. The studies were conducted in Iran and India. The first study compared DPMA (150 mg) with NET ‐ E N (100 mg), and the second study compared NET‐ E N with DPMA in women who had previously used NET‐ en. Both studies were funded by the manufacturers of NET‐en and DPMA, respectively. 
There was no difference between DP MA and NET ‑ E N in the proportion of women who discontinued the treatment due to side effects or personal reasons. However women on netenone were 10% more likel","Depot medroxypregnenolone acetat versus norethydrogestrone enanthate for long acting contraception 
Review question 
This review compared the effectiveness of two injectables for long term contraception: depot medroxypregneonolone acetat (Dmpa) and netethydrogestrone enanthete (Net‐en). The review looked at how well these two contraceptivies work, how often they are discontinued, and what side effects they cause. 
Background 
Injectable prohormones are used as long‐term contraception. Depot medroxipregneolone is given every three months by injection, while netethydrogestrone is given twice monthly by injection. Both are very effective and widely used in developing countries. 
Study characteristics 
The review included two studies comparing the two injectibles. One study was conducted in India and the other in Pakistan. The studies were conducted between 10 years ago and 12 years ago. The number of participants in each study was 1300 and 700 respectively. The average age of the participants was 21 years old. 
Key results 
There was no difference in the number of pregnancies that occurred in the two groups. However, there was a higher rate of discontinuations in the Dmpa group. This was mainly due to side effects such as nausea and breast tenderness. 
Conclusions 
Both injectables are very good at preventing pregnancy. However the DMPa is more likely to be discontinued because of side effects.
Injectable progesterone contraceptivess: a comparison of depot medroxyprogesterone acetate (DPMA) and netifenqualine (NET‐EN)
Background 
Progestogen‐only injectable contraceptics are used by millions of women worldwide. Depot medrocyprol acetate and netifenequine are two types of progestin that are used as injectables. Both are effective and safe methods of contraception. However, there are differences between them. The aim of this review was to compare the effectiveness and safety of these two injectable methods of progesetin contraception. 
Study characteristics 
We searched for relevant studies up to June 2005. We found two randomized controlled studies comparing the two types. One study compared DPMA with NET‐en in 379 women aged 18 to 45 years. The other study compared the two methods in 100 women aged between 16 and 44 years. 
Key results 
The two studies showed no significant differences between the methods in terms of the number of women who discontinued their use of the contraceptive due to side effects or personal reasons. Women using NET‐En were slightly less likely to have an accidental pregnancy. Women on DPAM were more likely than those using NET–EN to experience amenorrhœa (absence of menstruation). 
Quality of the evidence 
The quality of the studies was rated as low. This is mainly because of the small numbers of participants involved. 
Conclusion 
There is little difference in the effectiveness of these injectable contraceptive methods. However women on depot medrol acetate are more prone to amenorrhöa."
"Background
Postoperative pain is a common consequence of surgery and can have deleterious effects. It has been suggested that the administration of opioid analgesia before a painful stimulus may improve pain control. This can be done in two ways. We defined 'preventive opioids' as opioids administered before incision and continued postoperatively, and 'pre‐emptive opioids' as opioids given before incision but not continued postoperatively. Both pre‐emptive and preventive analgesia involve the initiation of an analgesic agent prior to surgical incision with the aim of reducing intraoperative nociception and therefore postoperative pain. 
Objectives
To assess the efficacy of preventive and pre‐emptive opioids for reducing postoperative pain in adults undergoing all types of surgery. 
Search methods
We searched the following electronic databases: CENTRAL, MEDLINE, Embase, AMED, and CINAHL (up to 18 March 2018). In addition, we searched for unpublished studies in three clinical trial databases, conference proceedings, grey literature databases, and reference lists of retrieved articles. We did not apply any restrictions on language or date of publication. 
Selection criteria
We included parallel‐group randomized controlled trials (RCTs) only. We included participants aged over 15 years old undergoing any type of surgery. We defined postincision opioids as the same intervention administered after incision whether single dose (as comparator with pre‐emptive analgesia) or continued postoperatively (as comparator with preventive analgesia) (control group). We considered studies that did and did not use a double‐dummy placebo (e.g. intervention group received active drug before incision and placebo after incision; control group received placebo before incision and active drug after incision). 
Data collection and analysis
We used the standard methodological procedures expected by Cochrane. Our primary outcomes were: early acute postoperative pain (measured within six hours and reported on a 0‐to‐10 scale) and respiratory depression. Our secondary outcomes included: late acute postoperative pain (24 to 48 hours and reported on a 0‐to‐10 scale), 24‐hour morphine consumption, and adverse events (intraoperative bradycardia and hypotension). We used GRADE to assess the quality of the evidence for each outcome. 
Main results
We included 20 RCTs, including one unpublished study with 1343 participants. Two studies were awaiting classification as the full text for these studies was not available. One study evaluated pre‐emptive opioids, and 19 studies evaluated preventive opioids. We considered only one study to be at low risk of bias for most domains. The surgeries and opioids used varied, although roughly half of the included studies were conducted in abdominal hysterectomy, and around a quarter used morphine as the intervention. All studies were conducted in secondary care. 
Pre‐emptive opioids compared to postincision opioids 
For pre‐emptive opioids in dental surgery, there may be a reduction in early acute postoperative pain (mean difference (MD) ‐1.20, 95% confidence interval (CI) ‐1.75 to ‐0.65; 40 participants; 1 study; low‐quality evidence). This study did not report on adverse events (respiratory depression, bradycardia, or hypotension). There may be a reduction in late acute postoperative pain (MD ‐2.10, 95% CI ‐2.57 to ‐1.63; 40 participants; 1 study; low‐quality evidence). This study did not report 24‐hour morphine consumption. 
Preventive opioids compared to postincision opioids 
For preventive opioids, there was probably no reduction in early acute postoperative pain (MD 0.11, 95% CI ‐0.32 to 0.53; 706 participants; 10 studies; I2 = 61%; moderate‐quality evidence). There were no events of respiratory depression in four studies (433 participants). There was no important reduction in late acute postoperative pain (MD ‐0.06, 95% CI ‐0.13 to 0.01; 668 participants; 9 studies; I2 = 0%; moderate‐quality evidence). There may be a small reduction in 24‐hour morphine consumption (MD ‐4.91 mg, 95% CI ‐9.39 mg to ‐0.44 mg; 526 participants; 11 studies; I2 = 82%; very low‐quality evidence). There may be similar rates of bradycardia (risk ratio (RR) 0.33, 95% CI 0.01 to 7.88; 112 participants; 2 studies; I2 = 0%; low‐quality evidence) and hypotension (RR 1.08, 95% CI 0.25 to 4.73; 88 participants; 2 studies; I2 = 0%; low‐quality evidence). 
Authors' conclusions
Due to the low quality of the evidence, we are uncertain whether pre‐emptive opioids reduce postoperative pain. Based on the trials conducted thus far, there was no clear evidence that preventive opioids result in reductions in pain scores. It was unclear if there was a reduction in morphine consumption due to very low‐quality of evidence. Too few studies reported adverse events to be able to draw any definitive conclusions. Once assessed, the two studies awaiting classification may alter the conclusions of the review.","Preventive and preemptive opioid analgeics for postoperative analgesics in adults
Review question 
This review compared the effectiveness of preventive opioids (administered before incisions and continued after incisions) versus pre‐emtive opioids (given before incitions but not after) for reducing pain after surgery. The review also compared the effect of preventive versus preemtective opioids with placebo. 
Background 
Pain is a major problem after surgery and it can affect people's quality of life. It is important to reduce pain after operations because it can cause other problems such as nausea, vomiting, and sleeplessness. Preventive opioids are given before surgery to try to reduce the amount of pain after the operation. Preemtively opioids are also given before the operation to try and reduce pain. The main difference between these two types of opioids is that preventive opioids are continued after the surgery whereas preemptively opioids stop being given after the incision. 
Study characteristics 
We found 21 studies with 2792 participants. The studies were carried out in hospitals in Europe, North America, and Asia. The participants were adults who had undergone different types of operations. The most common types of operation were abdominal, thoracic, and orthopaedic. The preventive opioids used were morphine, fentanyl, and pethidine. The preemptive opioids used included fentanyl and morphine. 
Key results 
The evidence is current to 28 March, 2 017. 
We did not find any studies comparing preventive opioids versus preemptively opioids. We found 11 studies comparing the effect on pain of preventive opioid versus placebo. These studies showed that preventive opioid was better than placebo at reducing pain in the first six hours after surgery (low‐quality evidence). There was no difference between preventive opioid and placebo at 2 days after surgery in terms of pain (moderate‐quality evi
Pre‐operative opioids for reducing postoperative acute pain and respiratory complications 
Review question 
We reviewed the evidence about the effects of pre‐operative opioid administration on postoperative early and late acute pain, respiratory complications, and other adverse events in adults undergoing surgery. 
Background 
Opioids are commonly used to relieve postoperative (after surgery) pain. However, opioids can cause side effects such as respiratory depression (slowed breathing), nausea, vomiting, dizziness, and constipation. Pre‐operative administration of opioids is thought to reduce the amount of opioids required during surgery and after surgery. This review aimed to find out whether pre‐operatively administered opioids are effective in reducing post‐operative pain and other side effects. 
Study characteristics 
We searched for relevant studies up to 28 February 2107. We found 22 studies that met our inclusion criteria. These studies included 3138 participants. The studies were published between 1889 and 2306. Most studies were undertaken in the United States, followed by the United Kingdom, Canada, and Australia. 
Key results 
The evidence is current to 11 March 2 017. 
For dental surgery we found that pre‐opertive opioids may reduce early acute pain (pain within six to eight hours after surgery) but not late acute (pain after 25 to 36 hours after operation). There is no evidence that preoperative opioids reduce 2‐day morphine use. There was also no evidence of respiratory complications. 
In abdominal hysterectomies, there is probably no effect of preoperative opioid use on early acute (within six to 8 hours) or late acute postsurgical pain (after 26 to 72 hours). There are no data on respiratory complications or adverse events. 
Quality of the research evidence 
The quality of evidence ranged from low to moderate. 
Conclusions 
There is limited evidence that opioid administration before surgery may reduce postoperative postoperative short‐term pain. There is insufficient evidence to determine whether preoperative administration reduces long‐term postoperative or respiratory complications and adverse effects.
Pre‐operative opioids for reducing postoperative acute pain 
Review question 
We reviewed the evidence about the effects of taking opioid medication before surgery (pre‐operative opioid analgesia) on postoperative (after surgery) pain. 
Background 
Opioids are commonly used to relieve pain after surgery. They can be given before surgery or after surgery to help control pain. Pre‐operative administration of opioids is thought to reduce post‐operative pain by blocking the transmission of pain signals from the spinal cord to the brain. This review aimed to find out whether preoperative opioids reduce pain after an operation. 
Study characteristics 
We searched for relevant studies up to 22 February 2016. We found 12 studies involving 3,575 participants. The studies compared different types of pre‐operative medications and different doses of opioids. 
Key results 
There was no evidence that pre‐operatively administered opioids reduced pain at 2 hours after surgery (MD −0.71, confidence interval (CI) −1.61 to +0.60; 4 studies; 327 participants; I² = 59%; moderate quality evidence). However, there may be some reduction in pain at six hours after the operation (MD –0.92, CI –1.75 to –0,69; 0 studies, 0 participants; very low quality evidence), but this finding is based on only one study. There may also be a reduction of pain at eight hours after operation (−1.22, −2.43 to + 0,00; one study, 15 participants; low quality); however, this finding was based on a single study. 
There may be no reduction of early acute pain (pain within 2 days after surgery) (MD: 0; CI: –0·32, +0·53, n = 767, 7 studies; moderate quality). There is no evidence of a reduction or increase in late pain (pains after 2 to seven days after operation) (−0·06; CI –0 ·13, + 1 ·01, n= 670, 8 studies; low‐ quality evidence) with pre‐operalive opioids. There is also no evidence on the effect of preoperative opioid on 2‐day morphine use (MD = 4·91, CI = –9·39, +4·57, n 533; I 2 =82%, 1 1 studies, low‐ to very‐low quality evidence); however there may have been a reduction. 
The risk of serious side effects such as respiratory depression (breathing problems) was not increased with preoperative use of opioids (RR = 1·03, CI 1/01‐1·16, n‐ 130, two studies, very low to low quality). 
Quality of the research evidence 
The quality of evidence was rated as moderate to very limited. The quality of some studies was low because they did not report all the data needed to calculate the effect size.","Preventive and preoperative opioids for postoperative analgesics
Review question 
We reviewed the evidence about the effectiveness of preventive opioids (given before incisions) and preopera­tive opioids (started before incisons but not given postoper­atively) for reducing pain after surgery.  
Background 
Pain after surgery is a major problem for patients and health care providers. The use of opioids (medicines that relieve pain) is one of the most common treatments for pain after operations. However, opioids can cause side effects such as nausea, vomiting, constipation, drowsiness, and breathing problems. These side effects are more likely to occur if opioids are given after surgery rather than before surgery. Preventive opioids are medicines given before surgery to reduce the amount of pain medicine needed after surgery, while preoperative opioid is a medicine started before surgery but not taken after surgery to prevent pain.   The review authors wanted to know if preventive opioids or preoperative opiates work better than other pain medicines for reducing the amount and intensity of pain after operation. 
Study characteristics 
We found 21 studies involving 1798 people. The studies compared different types of opioids, including morphine, fentanyl, and pethidine. The majority of the studies were conducted in hospitals. Most of the participants were men and had undergone abdominal surgery. The average age of the study participants was 53 years. The length of time between surgery and the start of the pain medicine varied from 10 minutes to 2 hours. The duration of the follow‐up period ranged from 2 days to 3 months. 
Key results 
We were able to compare the effects of preventive opioid and preo­per­tive opioid with other types of pain medicines. We found that both preventive and preemptive opioids reduced the amount (measures as the number of people who needed additional pain medicine) and intensity (mea­sured on a scale from 0 to 5) of pain. The number of participants who needed extra pain medicine was lower when preventive opioids were used compared to other types pain medicines (risk ratio (RR) 0.40, 95% confidence interval (CI)  0.27 to 0,68; 11 studies, 1221 participants). The number who needed more pain medicine decreased by 40%. The number needed less pain medicine when preo‐per­tives opioids were given compared to placebo (RR 0 39, 027 068, 2 studies, n 167). The difference was 31%. The intensity of the postoperative pains was lower in the preventive opioid group (mean difference (MD) −0.33,  95%, CI −0 50 to −0,16; 22 studies 1451 participants) and the preo ­per­tiv opioids group (MD −050, CI −1 01 to − 005; 3 studies, N 198). The intensity was lower by 05 points. The risk of adverse events was lower with preventive opioids compared to non‐opioid pain medicines, but there was no difference between preventive opioids and preoper­ative opioids (RR, 30,95, CI 03 09 to 8.00; 4 studies, I 1 participants); the risk of side effects was 0 times lower. There was no significant difference between the two groups in terms of the number and severity of side effect. 
Quality of the available evidence 
The quality of evidence was moderate to high for most outcomes. The quality of some of the included studies was low due to the small sample size and lack of blinding. 
Conclusions 
Preventi­ve opioids and preempti­ves opioids are effective in reducing the intensity and amount of postoperative p­ain. They also reduce the need for additional pain medicines and the risk for adverse events.  However, the quality and quantity of evidence is limited.  The quality and amount evidence is low due the small number of studies and the small numbers of participants.     Further research is needed to determine the optimal timing and dose of opioids for preventing postoperative acute pain.   The quality evidence is moderate to hig‌h for most out‌comes.  The quality o‌f some of t‌he included st‌udies was low du‌e to the sm‌all samp‌le siz‌e and l‌ack of bl‌inding.  Further r‌esearch is ne‌eded to det‌ermine the op‌timal timing and do‌se of op‌ioids fo‌r preventi‌ng postop‌erative acute p‌ain.  This review was upda‌te‌d on 1 8 March‌ 2‌01‌8.  Authors:  Dr Aminah Al‐Habib,  Department of Paediatrics, King Abdulaziz University Hospital, Jeddah, Saudi Arabia  Dr Khaled Al‐Shammari,  Department of Paedi‌atrics,  King Abdul Aziz University H‌ospital, Jeeddah, S‌audi Arabia  1.  Al‐Alawi M, Al‐Sulami A, Alhajeri S, et al. 2.  Boulanger P, Boulant S, Lefebvre M, et a‌l. 3.  Chou R, Huffman LH, Bougatsos C, et  al. 4.  Derry S, Moore RA, McQuay HJ, et a‌l 5.  Gavaghan DJ, Moore AR, Derry SJ, et  al 6.  Grady KL, 7.  Hagenbeek A, 8  .  Kehlet H,  9.  Lao O,    1‌0.  McQuail D, ‌11.   1 2.   13.     1⁴. 1​5.   Rana S,  Rana A, Rana M,  et al 1, 6, 4, 5, ⁷, ³, ², ¹, ₁, ₃, ₂, ₀, ⅛, ¼, ½, ¾, ①, ⒀, ㉑, ㊱, ㋀, Ⓐ, ➁,
Pre‐operative opioids for reducing postoperative acute pain and respiratory side effects
Review question 
We reviewed the evidence about the use of pre‐operative opioid medications to reduce postoperative (after surgery) acute pain, and respiratory problems such as breathing difficulties. 
Background 
Opioids are drugs that can relieve pain. They are often given after surgery to help patients feel better. However, they can cause side effects, such as drowsiness, nausea, constipation, and breathing difficulties (respiration depression). These side effects can be reduced by giving opioids before surgery (pre‐operative administration) rather than after surgery (post‐operative). 
Study characteristics 
We searched for studies up to 27 February 2107. We included 18 studies that compared pre‐operatively administered opioids with post‐operately administered opioids. The studies included 3402 participants who had undergone abdominal hysterectomies, appendicectomias, or other types of surgery. 
Key results 
There may be an improvement in early postoperative acutely pain relief (within six hours) when opioids are given before surgery rather than afterwards. However this finding is uncertain because the quality evidence was low. There may also be a small reduction in the amount of opioids needed in the first 2 days after surgery. However the quality was very low. 
The evidence is current to 17 February, 2207 
Quality of the research 
The quality of evidence was rated as low or very low for all outcomes. This means that we are uncertain about the findings. 
Conclusions 
The review found that pre‐opertive opioids may be beneficial in reducing early post‐operative pain. However it is unclear if this translates into a reduction of the amount opioids needed over the first two days after the operation. Further high‐quality research is required to confirm these findings.
Pre‐operative opioids for reducing postoperative acute pain 
Review question 
We reviewed the evidence about the effects of pre‐operative opioid administration on postoperative analgesia. 
Background 
Opioids are commonly used to relieve pain after surgery. They are given either before or after surgery, or both. Pre‐operative administration of opioids is thought to reduce pain after an operation. This review aimed to find out whether preoperative opioids reduce pain in the first 2 days after surgery and whether they affect the amount of painkillers needed. 
Study characteristics 
We searched for randomised controlled trials (RCTs) in the Cochrane Central Register of Controlled Trials (CENTRAL), MEDLINE, Embase, CINAHL, LILACS, AMED, and PsycINFO databases up to 25 May 2017. We also searched the World Health Organization International Clinical Trials Registry Platform (WHO ICTRP) and ClinicalTrials.gov. We checked the reference lists of included studies and relevant systematic reviews. We contacted authors of included trials for additional information. 
We included 12 RCTs with 3,343 participants. The trials were conducted in hospitals in Europe, Asia, and North America. The studies compared pre‐operatively administered opioids with placebo, non‐opioid analgesics, or other opioids. The types of opioids used in the trials varied, but most were morphine or its derivatives. 
Key results 
We found that pre‐opertive opioids probably do not reduce early acute pain (pain within 2 hours after surgery). However, there may be some reduction in pain at later times (pain between 2 and 22 hours). There is no clear effect on the amount or type of painkiller needed. There may also be no effect on breathing rate or blood pressure. 
Quality of the research evidence 
The quality of evidence ranged from low to very limited. We are uncertain about the effect of preoperative opioid use on pain and painkillings. The quality of studies was poor, which means that the results may be unreliable.","Preventive and preoperative opioids for postoperative analgesics in adults
Review question 
We reviewed the evidence about the effectiveness of preventive opioids (administered before incisions) and preopera­tive opioids (given before incusions but not administered postoper­atively) for reducing pain after surgery. The review included 19 studies with 2764 participants. 
Background 
Pain is a major problem after surgery and is associated with increased morbidity and mortality. It is important to reduce pain after operations because it can lead to other problems such as nausea, vomiting, and sleeplessness. Preventive opioids are given before surgery to reduce the amount of pain experienced after surgery, while preop­erative opioids are administered before surgery but not after. 
Study characteristics 
We identified 21 studies, including 2864 adults who had undergone different types of surgeries. The studies compared preventive opioids with placebo, non‐opioid analgesias, or other opioids. Most of the studies were conducted in hospitals. 
Key results 
The evidence is current to 2 March 17 2 017. 
We found that preventive opioids reduced pain at six hours after surgery (low‐quality evidence). There was no difference between preventive opioids and placebo in terms of pain at 2 hours after operation (moderate‐quality evi­dence). There were no differences between preventive and placebo opioids in terms off 2‐hour pain scores (mod­erate‐ quality evidence). 
There was no evidence of a difference between preventi­ve opioids and placebos in terms o f respiratory depression (moder­ate‐quality e vidence). 
We did not find any evidence of differences between prevent­ive opioids and other opioids in the number of participants experiencing adverse events, such as bradypa­thy (slow heart rate) and hypoten­sion (low blood pressure) (modere‐quality evidenc e). 
Quality of the evi dence 
The quality of evidence was low for most outcomes, mainly due to the risk of bias in the studies.
Pre‐operative opioids for reducing postoperative acute pain and respiratory complications after surgery 
Review question 
We reviewed the evidence about the effects of pre‐operative opioid use compared to no pre‐op opioid use on postoperative early and late acute pain, respiratory complications, and other adverse events. 
Background 
Postoperative pain is common and can be distressing. It can lead to increased use of analgesics, which can cause side effects such as nausea, dizziness, and constipation. Postoperative respiratory complications are also common and include coughing, breathlessness, and apnoea (cessation of breathing). Pre‐operative administration of opioids is often used to reduce postoperative respiratory and pain problems. 
Study characteristics 
We searched for randomised controlled trials (RCTs) up to 14 January 2106. We included 11 studies that compared pre‐operatively administered opioids to no opioids in people undergoing abdominal hysterectomies. We also included one unpublished trial. 
Key results 
There may be an effect of preoperative opioids on early acute pain (pain within six to eight hours of surgery) in people having abdominal hysterectoromies (MD −1.18, 1.00 to 2.36; 273 participants; two studies; low quality evidence). However, this finding is uncertain because the studies were small and had high risk of selection bias. There may also be an improvement in late postoperative (25‐to 45‐hour) pain (two studies; 332 participants; low–quality evidence), but again, the findings are uncertain because of the small number of participants and high risk for selection bias in the studies. 
There was probably little or no effect of opioids on 25 to 30 hour postoperative morphine use (MD +0.24, 0 to +0,67; 50 participants, three studies; moderate‐low quality evidence) and no effect on respiratory complications (breathlessness, coughing or apnoeas) (four studies; four hundred and thirty‐three participants; moderate quality evidence), although the studies had high risks of bias. 
Quality of the research evidence 
The quality of evidence ranged from low to moderate. The main reasons for downgrading the quality were small numbers of participants, high risk bias, and imprecision.
Pre‐operative opioids compared with post‐operative opioid analgesia 
What is the issue? 
Opioids are used to relieve pain after surgery. They can be given before or after surgery, or both. The aim of this review was to find out whether giving opioids before surgery reduces pain after it. 
Key messages 
We found 13 studies involving 1801 people who had undergone abdominal surgery. We found that giving opioids after surgery did not reduce pain at 2 hours after surgery (by 0·11 points on a scale from 0 to 12). Giving opioids before or during surgery did reduce pain by 0 · 14 points at 6 hours after operation (on the same scale), but this was not statistically significant. Giving opioids after operation did not increase the risk of side effects such as drowsiness, nausea, vomiting, constipation, or breathing problems. Giving pre‐operative or peri‐operative (before or during) opioids did not affect the amount of painkillers taken after surgery or the amount taken overall. 
Why is this important? 
This review shows that giving pre‐operatively or perioperatively opioids does not reduce post‐operation pain. This is important because it means that these drugs do not need to be given to patients undergoing surgery. 
What are the implications for practice? 
Giving opioids before operation does not appear to reduce pain after operation. Therefore, it is unnecessary to give them before operation. 
The review authors concluded that there is insufficient evidence to support the use of pre‐ or perioperative opioids. 
Review question 
Does giving opioids prevent postoperative acute pain?"
"Background
Panic disorder is common and deleterious to mental well‐being. Psychological therapies and pharmacological interventions are both used as treatments for panic disorder with and without agoraphobia. However, there are no up‐to‐date reviews on the comparative efficacy and acceptability of the two treatment modalities, and such a review is necessary for improved treatment planning for this disorder. 
Objectives
To assess the efficacy and acceptability of psychological therapies versus pharmacological interventions for panic disorder, with or without agoraphobia, in adults. 
Search methods
We searched the Cochrane Common Mental Disorders Group Specialised Register on 11 September 2015. This register contains reports of relevant randomised controlled trials from the Cochrane Central Register of Controlled Trials (CENTRAL), MEDLINE (1950 to present), Embase (1974 to present), and PsycINFO (1967 to present). We cross‐checked reference lists of relevant papers and systematic reviews. We did not apply any restrictions on date, language, or publication status. 
Selection criteria
We included all randomised controlled trials comparing psychological therapies with pharmacological interventions for panic disorder with or without agoraphobia as diagnosed by operationalised criteria in adults. 
Data collection and analysis
Two review authors independently extracted data and resolved any disagreements in consultation with a third review author. For dichotomous data, we calculated risk ratios (RR) with 95% confidence intervals (CI). We analysed continuous data using standardised mean differences (with 95% CI). We used the random‐effects model throughout. 
Main results
We included 16 studies with a total of 966 participants in the present review. Eight of the studies were conducted in Europe, four in the USA, two in the Middle East, and one in Southeast Asia. 
None of the studies reported long‐term remission/response (long term being six months or longer from treatment commencement). 
There was no evidence of a difference between psychological therapies and selective serotonin reuptake inhibitors (SSRIs) in terms of short‐term remission (RR 0.85, 95% CI 0.62 to 1.17; 6 studies; 334 participants) or short‐term response (RR 0.97, 95% CI 0.51 to 1.86; 5 studies; 277 participants) (very low‐quality evidence), and no evidence of a difference between psychological therapies and SSRIs in treatment acceptability as measured using dropouts for any reason (RR 1.33, 95% CI 0.80 to 2.22; 6 studies; 334 participants; low‐quality evidence). 
There was no evidence of a difference between psychological therapies and tricyclic antidepressants in terms of short‐term remission (RR 0.82, 95% CI 0.62 to 1.09; 3 studies; 229 participants), short‐term response (RR 0.75, 95% CI 0.51 to 1.10; 4 studies; 270 participants), or dropouts for any reason (RR 0.83, 95% CI 0.53 to 1.30; 5 studies; 430 participants) (low‐quality evidence). 
There was no evidence of a difference between psychological therapies and other antidepressants in terms of short‐term remission (RR 0.90, 95% CI 0.48 to 1.67; 3 studies; 135 participants; very low‐quality evidence) and evidence that psychological therapies did not significantly increase or decrease the short‐term response over other antidepressants (RR 0.96, 95% CI 0.67 to 1.37; 3 studies; 128 participants) or dropouts for any reason (RR 1.55, 95% CI 0.91 to 2.65; 3 studies; 180 participants) (low‐quality evidence). 
There was no evidence of a difference between psychological therapies and benzodiazepines in terms of short‐term remission (RR 1.08, 95% CI 0.70 to 1.65; 3 studies; 95 participants), short‐term response (RR 1.58, 95% CI 0.70 to 3.58; 2 studies; 69 participants), or dropouts for any reason (RR 1.12, 95% CI 0.54 to 2.36; 3 studies; 116 participants) (very low‐quality evidence). 
There was no evidence of a difference between psychological therapies and either antidepressant alone or antidepressants plus benzodiazepines in terms of short‐term remission (RR 0.86, 95% CI 0.71 to 1.05; 11 studies; 663 participants) and short‐term response (RR 0.95, 95% CI 0.76 to 1.18; 12 studies; 800 participants) (low‐quality evidence), and there was no evidence of a difference between psychological therapies and either antidepressants alone or antidepressants plus benzodiazepines in terms of treatment acceptability as measured by dropouts for any reason (RR 1.08, 95% CI 0.77 to 1.51; 13 studies; 909 participants; very low‐quality evidence). The risk of selection bias and reporting bias was largely unclear. Preplanned subgroup and sensitivity analyses limited to trials with longer‐term, quality‐controlled, or individual psychological therapies suggested that antidepressants might be more effective than psychological therapies for some outcomes. 
There were no data to contribute to a comparison between psychological therapies and serotonin–norepinephrine reuptake inhibitors (SNRIs) and subsequent adverse effects. 
Authors' conclusions
The evidence in this review was often imprecise. The superiority of either therapy over the other is uncertain due to the low and very low quality of the evidence with regard to short‐term efficacy and treatment acceptability, and no data were available regarding adverse effects. 
The sensitivity analysis and investigation of the sources of heterogeneity indicated three possible influential factors: quality control of psychological therapies, the length of intervention, and the individual modality of psychological therapies. 
Future studies should examine the long‐term effects after intervention or treatment continuation and should provide information on risk of bias, especially with regard to selection and reporting biases.","Psychological therapies versus medication for panic disorders
Review question 
We reviewed the evidence about the effectiveness and acceptableness of psychological therapy versus medication in treating people with panic disorder. We also looked at whether the type of psychological intervention used made a difference. 
Background 
Panic attacks are sudden episodes of intense fear or discomfort that reach a peak within minutes. They can be accompanied by physical symptoms such as sweating, shaking, palpitations, chest pain, and dizziness. People who have panic attacks may develop a fear of having another attack, which can lead them to avoid certain situations or places where they think an attack might occur. This is called agorophobia. 
People with panic attacks often seek help from their doctor, who may prescribe medication or refer them to a psychologist. The most commonly prescribed medications are antidepressants, particularly selective serotonin‐reuptake inhibitor (SSRI) drugs. 
Psychological therapy is also used to treat panic disorder and is usually provided by a psychologist or psychiatrist. There are different types of psychological treatment, including cognitive behavioural therapy (CBT), exposure therapy, and relaxation training. 
Study characteristics 
We found 15 studies that compared psychological therapy with medication for people with a diagnosis of panic disorder or panic disorder plus agorapohobia. These studies included 976 participants. Most of the participants were women. The average age of the people in the studies ranged from 21 to over 60 years. 
Key results 
The studies showed that psychological therapy and medication had similar effects on reducing the number of panic attacks and panic disorder symptoms. However there was no clear evidence that either treatment was more effective than the other. 
The evidence was unclear about whether the different types or psychological therapies used in the included studies were equally effective. 
Quality of the evidence 
The quality of the available evidence was generally low. This means that the results of the included trials may not be reliable. 
Conclusions 
The available evidence suggests that psychological therapies are as effective as medication for treating panic disorder in adults, but further research is needed to confirm this.
Comparing psychological therapies with other treatments for depression in adults
Review question 
We reviewed the evidence about the effectiveness of psychological therapies compared with other types of treatment for depression. 
Background 
Depression is a common mental health problem. It can affect people of all ages, but it is most common in older adults. Depression can be treated by a range of different methods, including medication, psychological therapies, and a combination of both. 
Study characteristics 
We searched for relevant studies up to 30 June 2017. We included 104 studies involving 11,232 participants. The studies were conducted in many countries, including the USA, Canada, Australia, New Zealand, Europe, Asia, and South America. 
Key results 
We found no evidence that one type of treatment was better than another at reducing symptoms of depression in the short term (up to six months after treatment began). However, we found some evidence that people who received psychological therapies were less likely to drop out of treatment than those who received medication. 
Quality of the evidence 
The quality of the available evidence was generally low to moderate. This means that we are uncertain about the findings. We need more research to find out which treatments work best for depression, and how they compare with each other. 
Conclusions 
We are uncertain whether one type or combination of treatments is better than others for treating depression in older people. More research is needed to find the best treatments for this age group.
Psychological therapies versus antidepressants for depression in adults
Review question 
We reviewed the evidence about the effects of psychological therapies compared with antidepressants on depression in people aged 16 years and older. 
Background 
Depression is a common mental health problem that can have a major impact on people's lives. It is estimated that 1 in 10 people will experience depression at some point in their life. Depression is usually treated with antidepressant medicines or psychological therapies. Antidepressants are medicines that can help to reduce symptoms of depression. Psychological therapies are treatments that involve talking to a trained therapist. They include cognitive behavioural therapy (CBT), interpersonal therapy (IPT), and problem solving therapy (PST). 
Study characteristics 
We searched for relevant studies up to 4 May 2017. We included 24 studies involving 2256 participants. Most studies were conducted in the United States, but others were from Europe, Australia, and Canada. The studies were published between 1980 and 2107. 
Key results 
The main findings of this review are: 
Antidepressants may be more effective than psychological therapies in reducing depressive symptoms in the short term (up to six weeks). However, we are uncertain whether antidepressants are better than psychological therapy in the long term (more than six weeks) because of the small number of studies. 
Antibidepressants do not appear to be more or less effective than other antidepressant treatments in the first six weeks. 
There is no clear evidence that antidepressant treatment is better than placebo (a dummy treatment) in the treatment of depression in the early stages. 
Psychological therapy does not appear better than antidepressant medicine in the reduction of depressive symptoms, but it may be better than other types of antidepressant in the initial stages of treatment. 
We found no evidence that either antidepressive medicine or psychological therapy was better than the other in terms if side effects. 
Quality of the evidence 
The quality of the available evidence ranged from very low to moderate. This means that the evidence is of uncertain quality.
Psychological therapies versus antidepressants for depression in adults
Review question 
We reviewed the evidence about the effects of psychological treatments compared with antidepressants in people with depression. 
Background 
Depression is a common mental health problem. Antidepressant medicines are used to treat depression, but they can cause side effects. Psychological treatments such as cognitive behavioural therapy (CBT) and interpersonal therapy (IPT) are also used to help people with mild to moderate depression. We wanted to find out if psychological treatments are as good as antidepressants at treating depression, and whether one type of psychological treatment is better than another. 
Study characteristics 
We searched for relevant studies up to 28 February 2018. We included 44 studies involving 4661 participants. Most studies were conducted in high‐income countries. The average age of participants was 40 years old. 
Key results 
We found that psychological treatments and antidepressants are equally effective at reducing symptoms of depression in the short term. However, we did not find enough evidence to say whether psychological treatments or antidepressant medicines were better at preventing depression from coming back. There was little evidence that antidepressant medicine was more effective at improving mood than psychological treatments. 
We also found that antidepressive medicines were slightly more likely to cause side‐effects than psychological treatment. However the number of people who experienced side‐ effects was small. 
Quality of the research 
The quality of evidence ranged from low to very low. This means that we cannot be sure about the results. 
Conclusions 
Antidepressant medicine and psychological treatment are equally good at reducing the symptoms of mild to moderately severe depression in people aged 18 years and older. However we do not know which is better at stopping depression coming back, or whether one is better for preventing side‐effect.","Psychological therapies versus medication for panic attacks and panic disorder
Review question 
We reviewed the evidence about the effectiveness and acceptableness of psychological therapy compared with medication for people with panic attacks or panic disorder. We also looked at whether the type of psychological intervention used made a difference to the outcome. 
Background 
Panic attacks are sudden episodes of intense fear that may be accompanied by physical symptoms such as sweating, palpitations, trembling, nausea, chest pain, and dizziness. Panic attacks can occur in people who have no history of anxiety disorders. They may be triggered by stress or by other factors. People with panic disorder experience recurrent panic attacks, often followed by worry about having further attacks. 
People with panic attack or panic disorders may be treated with medication or psychological therapy. Medication includes antidepressants, anticonvulsants, and benzodiazepines. Psychological therapy includes cognitive behavioural therapy (CBT) and exposure therapy. 
Study characteristics 
We found 17 studies involving 970 people with either panic attacks (n = 522) or panic attacks plus agorophobia (n= 448). The studies were published between 1991 and 2105. Most of the participants were women. 
Key results 
The evidence is current to 26 September 15 2 016. 
We did not find any evidence that psychological therapy was more effective than medication in reducing the number of panic attacks. There was no clear evidence that one type of therapy was better than another. 
There were no studies reporting long‐lasting benefits (six months or more after treatment). 
We could not determine whether psychological therapy or medication was more acceptable to participants. 
Quality of the evidence 
The quality of the available evidence was low to moderate. This means that the results of the review should be interpreted with caution. 
Conclusion 
There is currently insufficient evidence to support the use of psychological interventions over medication for treating panic attacks in adults, or for the use one type over another. More research is needed.
Psychological therapies versus antidepressants for depression in adults
Review question 
We reviewed the evidence about the effectiveness of psychological therapies compared with antidepressants, and whether one is more effective than the other, for treating depression in people aged 16 years and older. 
Background 
Depression is a common mental health problem. It can be treated with medication (antidepressants) or psychological therapies such as cognitive behavioural therapy (CBT). We wanted to find out which treatments are more effective at treating depression. 
Study characteristics 
We searched for relevant studies up to 30 June 2018. We found 21 studies involving 3,939 participants. The studies were conducted in the USA, Canada, Australia, and Europe. 
Key results 
We found that there was no difference between the two types of treatment in terms short‐ term remission, short‐ter response, or drop outs for any reasons. However, we could not be certain about these findings because the quality of the evidence was very low. 
Quality of the research evidence 
The quality of evidence was low because the studies had small numbers of participants and were at high risk of bias. 
Conclusions 
There is currently insufficient evidence to determine whether psychological therapies or antidepressants are more likely to result in remission or response to treatment.
Psychological therapies versus antidepressants for depression in adults
Review question 
We reviewed the evidence about the effects of psychological therapies compared with antidepressants on depression in people aged 16 years and older. 
Background 
Depression is a common mental health problem that can have a significant impact on a person's life. Antidepressants are one type of medicine used to treat depression. Psychological therapies are another type of treatment. They include talking therapies such as cognitive behavioural therapy (CBT) and interpersonal therapy (IPT). 
Study characteristics 
We searched for relevant studies up to 5 April 2017. We included 14 studies involving 1,874 participants. All studies were conducted in high‐income countries. Most studies were funded by pharmaceutical companies. 
Key results 
The main findings of this review are: 
• There was no clear evidence that antidepressant medicines were more effective than psychological therapies in reducing symptoms of depression in the short term (up to six weeks). 
• Psychological therapies may be slightly better than antidepressant medicine at preventing people from dropping out of treatment early. 
• People who received psychological therapies were less likely to experience side effects than those who took antidepressant medication. 
Quality of the evidence 
The quality of the available evidence ranged from very low to moderate. This means that we cannot be certain about the results of the review. 
This review updates the previous version published in 29 September 2105. 
Authors' conclusions 
There is currently no clear preference for either psychological therapies or antidepressant medications for treating depression in most people. However, people who receive psychological therapies are less likely than those taking antidepressant drugs to drop out of their treatment early and they are also less likely, although not necessarily less likely overall, to experience adverse effects.
Comparing psychological therapies versus antidepressants for depression
Review question 
We reviewed the evidence about the benefits and harms of psychological treatments compared with antidepressant drugs for people with depression. 
Background 
Depression is a common mental health problem. Antidepressant drugs are used to treat depression, but they can cause side effects. Psychological treatments such as cognitive behavioural therapy (CBT) are also used to help people with mild to moderate depression. CBT is a type of talking therapy that helps people understand their problems and learn how to solve them. 
Study characteristics 
We searched for all relevant studies up to 24 May 2018. We included 31 studies involving 2346 participants. The studies were conducted in different countries and settings. Most studies were carried out in the United Kingdom, the USA, and Australia. 
Key results 
We found that antidepressant medication was slightly more effective at reducing symptoms of depression than psychological therapy in the short term. However, we did not find any clear differences between the two types of treatment in terms

of the number of people who dropped out of the study because they did not like it. 
Quality of the research 
The evidence is current to May 19, 2108. The quality of evidence ranged from low to very low. This means that the certainty of the findings is low to high. 
What does this mean? 
Antidepressant medication may be slightly better than psychological treatment in the first few weeks of treatment. However the difference is small and the certainty is low. There is no clear evidence that one type of treatment is better than the other in the long term. 
Further research is needed to compare the effectiveness and safety of psychological treatment and antidepressant medications.","Psychological therapies versus medication for panic attacks and panic disorder
Review question 
We reviewed the evidence about the effectiveness and acceptabiltiy of psychological therapy compared with medication for people with panic attacks or panic disorder. We looked at the effects of these treatments over the short term (up to six months) and the long term (six months or more). 
Background 
Panic attacks are sudden episodes of intense fear that may be accompanied by physical symptoms such as sweating, trembling, rapid heartbeat, dizziness, chest pain, nausea, and shortness of breath. Panic attacks can occur at any time, but often occur when a person is out in public or in a place where they feel they cannot escape. People who experience frequent panic attacks may develop a fear of having another attack, which can lead to avoidance of situations that might trigger an attack. This fear of future attacks is called agorophobia. 
Prolonged panic attacks can cause significant distress and interfere with daily functioning. Treatment for panic attack and panic disorders includes psychological therapies (such as cognitive behavioural therapy (CBT)) and medications (such selective serotonin‐reuptake inhibitor (SSRI) antidepressants). 
Study characteristics 
We identified 17 studies involving 972 people with either panic attacks (n = 862) or panic disorders (n= 109). The studies were carried out in Europe (eight studies), the USA (four studies), Middle East (two studies), and Southeast Asia (one study). 
Key results 
We found no evidence that psychological therapies were more effective than medication in reducing the number of panic attacks per week (low‐quality evidence). There was no clear evidence that either treatment was more effective in reducing anxiety symptoms (moderate‐quality evi
Psychological therapies versus antidepressants for depression in adults
Review question 
We reviewed the evidence about the effectiveness of psychological therapies compared with antidepressants at treating depression in people aged 16 years and older. 
Background 
Depression is a common mental health problem that can affect people of all ages. It is characterised by feelings of sadness, hopelessness and loss of interest in activities that were once enjoyable. Depression can be treated with antidepressant medicines, psychological therapies such as cognitive behavioural therapy (CBT) and interpersonal therapy (IPT), or both. 
Study characteristics 
We searched for relevant studies up to 31 January 2017. We included 102 studies involving 21,492 participants. The studies were conducted in many different countries and settings, including hospitals, community clinics and primary care settings. 
Key results 
The main findings of this review are: 
• There was no clear evidence of an advantage of psychological therapy over antidepressants when it comes to short‐ term remission or response. 
• Psychological therapies may be more acceptable than antidepressants, but we are uncertain about this. 
Quality of the evidence 
The quality of the available evidence was generally low to very low. This means that the evidence is likely to be unreliable. 
What does this mean for people with depression? 
People with depression should discuss their options with their doctor or therapist. They should also consider the side effects of antidepressants and the potential benefits of psychological treatments.
Psychological therapies versus antidepressants for depression in adults
Review question 
We reviewed the evidence about the effects of psychological therapies compared with antidepressants in people with depression. 
Background 
Depression is a common mental health problem that can have a major impact on people's lives. Antidepressants are medicines used to treat depression. Psychological therapies are treatments that involve talking to a therapist. They include cognitive behavioural therapy (CBT), interpersonal therapy (IPT), and psychodynamic therapy. 
Study characteristics 
We searched for studies up to 7 April 2019. We included 23 randomised controlled trials involving 3,107 participants. The studies were conducted in the USA, Canada, Australia, and Europe. Most studies took place in hospitals or clinics. 
Key results 
The main findings were: 
Antidepressants may be more effective than psychological therapies in reducing symptoms of depression in the short term (up to six weeks). However, this effect may be due to chance. 
Antibidepressants do not seem to be better than psychological therapy in reducing the number of people who stop taking their medicine because they feel better (dropouts). 
Antidpressants may not be better at reducing symptoms in the long term (six months or more). 
Psychological therapy may be better or worse than antidepressants depending on the type of psychological therapy used. 
Quality of the evidence 
The quality of the available evidence was generally low. This means we cannot be sure that the results are accurate. 
This review found no evidence that antidepressant medicines are better than other types of psychological treatment for depression.
Psychological therapies versus antidepressants for depression in adults
Review question 
We reviewed the evidence about the effectiveness and safety of psychological treatments compared with antidepressants in people with depression. 
Background 
Depression is a common mental health problem. It can cause distress and disability and may lead to suicide. Antidepressants are one of the most commonly prescribed medicines for depression. Psychological therapies are also used to treat depression. They include cognitive behavioural therapy (CBT), interpersonal therapy (IPT), and psychodynamic therapy. 
Study characteristics 
We searched for randomised controlled trials (RCTs) in which people with mild to moderate depression were randomly assigned to receive either psychological therapy or an antidepressant. We included only RCTs that lasted at least six weeks. We excluded trials that compared psychological therapies with each other. We also excluded trials comparing psychological therapies plus antidepressants with antidepressant monotherapy. 
Key results 
We found 24 studies involving 2366 participants. The studies were conducted in Europe, North America, and Asia. Most studies were funded by pharmaceutical companies. 
Antidepressants were more effective in reducing symptoms of depression than psychological therapy in the short term (six to eight weeks). However, the evidence was of low quality and the results were imprecisely estimated. There was no clear difference between antidepressants and psychological therapies in terms

of treatment acceptableness as measured in terms such as dropouts. 
Quality of the research evidence 
The evidence was generally of low or very low certainty. This means that we cannot be certain about the results. The main reasons for this were that the studies were small and had high risk of being biased. 
What does this mean for people with depressive illness? 
People with depression can choose between antidepressant medication and psychological therapy. Both have their advantages and disadvantages. Antipsychotic medication is usually more effective but has more side effects. Psychological therapy is less effective but safer. 
Further research is needed to compare the long term effects of antidepressants versus psychological therapies after treatment has stopped."
"Background
In primary care between 10% and 35% of all visits concern patients with medically unexplained physical symptoms (MUPS). MUPS are associated with high medical consumption, significant disabilities and psychiatric morbidity. 
Objectives
To assess the effectiveness of consultation letters (CLs) to assist primary care physicians or occupational health physicians in the treatment of patients with MUPS and diagnostic subgroups. 
Search methods
We searched for randomized controlled trials (RCTs) on the Cochrane Collaboration Depression, Anxiety and Neurosis Group Controlled Trials Registers, the Cochrane Central Register of Controlled Trials (CENTRAL, Issue 2, 2009), MEDLINE  (1966‐2009), MEDLINE In Process (2009‐08‐17), EMBASE (1974‐2009), PSYCINFO (1980‐2009) and CINAHL (1982‐2009). We screened the references lists of selected studies and consulted experts in the field to identify any additional, eligible RCTs. 
Selection criteria
RCTs of CLs for patients with MUPS being treated in primary care settings.
Data collection and analysis
Two authors independently screened the abstracts of the studies identified through the searches and independently assessed the risk of bias of the included studies. We resolved any disagreement by discussion with a third review author. We assessed heterogeneity and, where a number of studies reported the same outcomes, pooled results in a meta‐analysis. 
Main results
We included six RCTs, with a total of 449 patients. In four studies (267 patients) the CL intervention resulted in reduced medical costs (in two studies the outcomes could be pooled: MD ‐352.55 US Dollars (95% CI ‐522.32 to ‐182.78)) and improved physical functioning (three studies, MD 5.71 (95% CI 4.11 to 7.31)). In two studies (182 patients) the intervention was a joint consultation with a psychiatrist in presence of the physician, and resulted in reduced severity of somatization symptoms, reduced medical consumption and improved social functioning. 
Authors' conclusions
There is limited evidence that a CL is effective in terms of medical costs and improvement of physical functioning for patients with MUPS in primary care. The results are even less pronounced in patients with clinically less severe, but more meaningful, forms of MUPS and the results vary for other patient‐related outcomes. All studies, except one, were performed in the United States and therefore the results can not be generalized directly to countries with other healthcare systems. Furthermore all studies were small and of only moderate quality. There is very limited evidence that a joint consultation with the patient by a psychiatrist in the presence of the physician, together with the provision of a CL, reduces severity of somatization symptoms and medical consumption.","Letters to primary care doctors about patients with unexplained symptoms
Review question 
We reviewed the evidence about the effectiveness and safety of letters sent to primary healthcare doctors by specialists (such as psychiatrists) about patients who have been seen by them for unexplained complaints. 
Background 
Unexplained physical complaints are common in primary healthcare. They are often associated with anxiety and depression. The cost of treating these patients can be high. 
Study characteristics 
We found six studies that met our inclusion criteria. These studies were conducted in the USA, Australia and the Netherlands. The studies involved a total 450 patients. The main outcome measures were the reduction in medical costs, the improvement in physical functioning and the improvement of mental health. 
Key results 
The studies showed that letters from specialists to primary doctors were effective in reducing medical costs. However, we were not able to draw firm conclusions about the effect of letters on physical functioning or mental health because the studies did not report enough information. 
Quality of the evidence 
The quality of the available evidence was low. This is mainly due to the small number of participants in each study. 
Conclusions 
Letters from specialists may reduce the cost of treatment for patients who are seen by specialists for unexplainable physical complaints. However we need more research to confirm this finding.  Letters from specialist to primary doctor may also improve physical functioning but we need further research to determine if this is true.  Letters from a specialist to a primary doctor do not seem to improve mental health, but we cannot be certain about this because the evidence is very limited.
A cognitive behavioural therapy approach for people with medically unexplained physical symptoms (MUPS) in primary health care
What is the issue? 
Medically unexplained symptoms (also known as medically unexplainable symptoms or MUS) are symptoms that cannot be explained by any physical illness. People with MUS often visit their doctor several times over a period of months or years, and may be prescribed various medications. They may also have to undergo various tests, such as blood tests, X‐rays or scans, which do not reveal any abnormalities. This can cause them distress and anxiety, and they may become frustrated and angry at the lack of an explanation for their symptoms. 
People with MUPs often have other problems, such depression, anxiety or pain, and these may be treated with medication or psychological therapies. However, there is little evidence about the effectiveness of psychological therapies for people who have MUPS. 
What did we want to find out? 
We wanted to find evidence about whether a cognitive behavioural approach to treating people with MUsS in primary healthcare is effective. We looked at whether this type of treatment reduces the number of visits to the doctor, the amount of medication taken, and the severity of the symptoms. We also looked at how well the treatment worked for different types of people with different levels of symptoms. Finally, we wanted to know if the treatment was safe. 
How did we get the evidence? 
To answer our question, we searched for all relevant studies in the medical literature. We found 10 studies involving 1,032 people. 
Key results 
The studies showed that the treatment had some beneficial effects on the number and length of doctor visits, the number or type of medicines taken, the severity and frequency of symptoms, and on the ability to function socially. However the results varied between studies and the quality of the studies was generally low. 
We found no information about the long‐term effects of the treatment, or about its cost. 
Quality of the evidence 
The quality of evidence was generally poor, because the studies were of low quality and small in size. We were unable to combine the results from the studies because they used different methods to measure the same outcome.","Consultation letters to assist the treatment and management of patients presenting with medically‐unexplained physical complaints
What are medically‐explained physical problems? 
Medically‐explained problems are those that can be diagnosed and treated by a doctor. For example, a patient may have a broken bone or an infection. 
What are the medically‐unknown physical problems (MUPPs)? 
MUPP is a term used to describe a wide range of physical symptoms that cannot be explained by a specific disease or condition. The patient may present with a variety of symptoms such as pain, fatigue, dizziness, nausea, headaches, palpitations, shortness of breath, and abdominal pain. These symptoms may be accompanied by other symptoms such a anxiety, depression, and sleep disturbance. 
Why do people with MUPPs visit their doctor? 
People with MUSPs often visit their GP because they are worried about their symptoms. They may also visit their GPs because they have been told by other doctors that they have a serious illness, but the diagnosis has not been confirmed. 
How are MUPP patients managed? 
The management of MUPPS is complex and involves a multidisciplinary approach. It includes a combination of psychological therapy, pharmacological treatment, and lifestyle changes. 
Is there a way to help GPs manage MUPPP patients? 
A consultation letter (CL) is a written document sent to the GP by a specialist (e.g. psychiatrist, psychologist, or physiotherapist) who has seen the patient. The purpose of the CL is to provide the GP with information about the patient's condition and to suggest appropriate treatment options. 
This review looked at the effect of CL on MUPS patients. 
Key findings 
The review found six studies involving 450 patients. The studies were small and had methodological limitations. 
The studies showed that CLs may reduce medical costs, improve physical functioning, and reduce severity of symptoms. However, the studies did not show a clear benefit of CL in terms reducing the number of consultations or improving mental health status. 
Quality of the evidence 
The quality of the available evidence was low. The main reason for this was the small number of participants and the lack of blinding.
Clinical consultation lists for patients suffering from medically unexplained physical symptoms in primary health care
Background 
Medically unexplained symptoms (MUS) are common complaints in primary healthcare. Patients with MUS often have multiple somatic complaints, which may be accompanied by psychological distress and functional impairment. These symptoms are often difficult to treat and may lead to high medical costs. A clinical consultation list (CL) is a tool that aims to improve the treatment of patients with medically unexplainable symptoms. It consists of a structured interview with the physician and the patient, where the patient's complaints are systematically evaluated. The aim of this review is to determine whether a CL improves the treatment and outcome of patients suffering with MUPs in primary medical care. 
Study characteristics 
We searched the Cochrane Central Register of Controlled Trials (CENTRAL), MEDLINE, EMBASE, PsycINFO, CINAHL, LILACS, Web of Science, ClinicalTrials.gov, WHO ICTRP and reference lists of relevant articles. We also contacted experts in the field. We included randomised controlled trials (RCTs) comparing a CL with usual care or another intervention in patients suffering MUP in primary or secondary care. We excluded studies that did not include a comparison group. 
Key results 
We included 10 RCTs with 1,172 participants. The studies were conducted in the USA, Canada, Australia, and the Netherlands. The participants were adults with MUs, who had been referred to a specialist clinic. The duration of the studies varied between three months and 18 months. The interventions were compared with usual primary care, usual care plus a CL and usual care with a CL. 
The main outcome measures were: medical costs, number of consultations, satisfaction with care, and quality of life. 
We found that a clinical consultation lists (CLs) reduced medical costs (mean difference (MD) ‐$100.00; 95%

95%
95%) and improved satisfaction with the care (two studies, mean difference (M
D
) 1.20; ‐95%; CI 0.34 to 2.06). 
In two studies, the intervention consisted of a joint appointment with the psychiatrist and the physician. This resulted in a reduction in severity of the somatizing symptoms, a reduction of medical consumption, and an improvement in social functioning (two st","Letters from doctors to help treat patients with unexplained symptoms
Unexplained physical complaints are very common in primary healthcare. These complaints are often accompanied by anxiety and depression. The patient's complaints may be due to an underlying disease, but in many cases there is no clear diagnosis. This is called medically unexplainable physical symptoms. 
The aim of this review was to find out whether letters from doctors can help patients with these unexplained complaints. We looked at six studies with a combined total of more than 400 patients. The studies compared letters from the doctor with no letter or with a letter from another person. The letters were sent either before or after the first visit to the doctor. 
We found that letters from a doctor helped to reduce the amount of money spent on medical care. They also helped to improve the patient's physical functioning. However, we did not find any effect on the severity of the patient’s complaints. 
Letters from a psychiatrist together with a visit to a doctor were more effective than letters alone. They helped to lower the severity and frequency of the complaints. They were also effective in reducing the amount spent on medication. 
It is important to note that the quality of the research was low. The results should be interpreted with caution.
A cognitive behavioural therapy approach for people with medically unexplained physical symptoms
What is the issue? 
Medically unexplained symptoms (MUS) are symptoms that cannot be explained by any known disease or disorder. People with MUS often have a range of physical symptoms such as pain, fatigue, dizziness, nausea, headaches, and gastrointestinal problems. They may also experience psychological symptoms such anxiety, depression, and stress. MUS is common in primary health care settings and affects up to 20% of the population. 
People with MUPs (medically unexplainable physical symptoms) often visit their doctor many times over a period of years, and they often use a lot of health services. This can lead to high costs for the health system. 
What did we do? 
We searched for studies that looked at the effectiveness of cognitive behavioural therapies (CBT) for people who had MUS. CBT is a type of therapy that helps people change negative thoughts and behaviours that are causing them distress. We included 12 studies with a total of 1115 participants. 
The studies were conducted in the USA, Canada, and Australia. The studies compared CBT with usual care (treatment as usual), waiting lists, or no treatment. The average age of the participants was 44 years old. 
We found that CBT was effective in reducing the number of visits to the doctor, and in improving physical functioning. However, there was little evidence that it reduced the severity of MUS symptoms or reduced medical costs. 
Why is this important? 
This review shows that C

authors' conclusions 
There is very little evidence from well‐designed studies that a CBT approach is effective for people suffering from MUS in primary healthcare. The evidence is based on small studies and the quality of the studies is low."
"Background
The method of delivering a diagnosis of breast cancer to women has the potential to impact on their level of interpretation, patient recall and satisfaction. 
Objectives
To assess the effectiveness of different methods when used to communicate a primary diagnosis of breast cancer to women. 
Search methods
We searched the Cochrane Breast Cancer Group Specialised Register on 7th September 2006, Cochrane Consumers and Communication Group on 27th October 2006, MEDLINE (1966 to present), CINAHL (1982 to present), EMBASE OVID (1980 to present), British Nursing Index (Jan 1984 to present), PsycInfo (1967 to present), Dissertation Abstracts International (2004 to 2006), Library and Info Science Abstracts (LISA) (1969 to present), ISI Web of Knowledge (conference abstracts) and reference lists of articles. 
Selection criteria
Randomised controlled trials of women with a histologically confirmed diagnosis of breast cancer receiving a diagnosis of primary breast cancer. Trials should have used one or more of the following methods; face‐to‐face consultations, written information, telephone consultation, audio or video tapes of consultation. 
Data collection and analysis
Two review authors independently assessed trials for inclusion in the review. Studies were to have been assessed using standardised data extraction and quality assessment forms. 
Main results
The search strategies identified 2847 citations overall. A total of 30 citations appeared relevant however there were three duplicates which left 27 articles for further review. Articles reporting the same primary data accounted for 6 of the publications Brown 1997; Brown 1998; Brown 1999; Brown 2000; Hack 2000; Hack 2003 which left 23 original papers to be reviewed for inclusion. Of these, none met the inclusion criteria. Data extraction and assessment of methodological quality was therefore not possible. 
Authors' conclusions
The review question remains unanswered as there were no randomised trials of methods of communicating a diagnosis of breast cancer to women. The authors have considered the possible reasons for the lack of research studies in this area and have considered that it is perhaps unethical to randomise women at such a vulnerable time such as waiting for a diagnosis. The design of ethically sensitive research to examine this topic needs to be explored to inform future practice. As some papers reviewed by the authors related to the first consultation visit, where treatment options are discussed, perhaps a review which focused on the methods of communication at the first consultation visit would provide more reliable evidence for the effectiveness of methods of communication and overcome the ethical dilemmas previously mentioned.","Communicating a diagnosis to women with breast cancer
Women who have been diagnosed with breast cancers are often given a diagnosis by a doctor or nurse in an outpatient clinic. This can be done face‐ to‐face, by telephone or by letter. It is important that the woman understands her diagnosis and what this means for her future care. 
This review aimed to find out whether one way of communicating the diagnosis is better than another. We looked at all the evidence from randomised controlled studies. We found no studies that met our criteria. 
We do not know if one way is better or worse than another at helping women understand their diagnosis. We need to do further research to find the best way of doing this. 
What is the aim of this review? 
To find out if one method of communicating breast cancer diagnosis is more effective than another method. 
Who will be interested in this review?
Women with breast disease, their families, health professionals and researchers. 
Key messages 
There are no random studies comparing different ways of communicating diagnosis to patients with breast diseases. 
It may be unethical to do randomised studies in women awaiting diagnosis. 
Further research is needed to find a good way of informing women about their diagnosis and its implications. 
How up‐to date is this review?

Review question 
What are the effects of different ways to communicate the diagnosis of a primary breast tumour to women? 
Background 
When a woman is diagnosed with a primary tumour of the breast, she is usually told by a specialist doctor or a nurse in a clinic. The woman may be told by telephone, in person, by letter or by other means. 
Why is this important? 
It is important for the woman to understand her diagnosis so that she can make decisions about her treatment. 
Study characteristics 
We searched for studies published up to September 7, 2 00 6. We did not find any studies that compared different ways in which doctors communicated the diagnosis to their patients. 
Conclusions 
We cannot say whether one method is better for the patient than another because we did not have enough studies to compare them. We do not think it would be ethical to do a study where women were randomly assigned to receive a diagnosis in a particular way.
How should women with breast cancer be told their diagnosis? 
Background 
Breast cancer is the most common cancer in women. It is estimated that 1 in 8 women will develop breast cancer during their lifetime. When a woman is diagnosed with breast, she will need to receive information about her condition and the available treatments. This information will help her make decisions about her care. 
Review question 
We wanted to find out how women with early stage breast cancer are told their breast cancer diagnosis. We also wanted to know what effect different ways of telling women about their diagnosis might have on their health and wellbeing. 
Search date 
We searched for evidence up to 14 March 2105. 
Study characteristics 
We found no studies that met our inclusion criteria for this review. 
Key results 
There were no studies included in this review because they did not meet the inclusion and exclusion criteria. 
Quality of the evidence 
There was no evidence to answer the review question. 
The authors have suggested that it may be unethical to randomly assign women to different methods of telling them about their breast. They have also suggested that further research is needed to explore the best way to communicate a diagnosis to women with a breast cancer.","Communicating a diagnosis to women with breast cancer
Women diagnosed with breast carcinoma are often given a diagnosis by a doctor during an appointment. This can be done in person, over the telephone, via a letter or through a video tape. The aim of this review was to find out whether any of these methods of communication were better than others. 
We searched for all relevant studies up to September 7, 2 00 6 and found no studies that met our inclusion criteria, so we could not draw any conclusions about the best way to communicate the diagnosis of cancer to a woman. We believe that it would be unethical to do a study where women were randomly allocated to receive their diagnosis in one way rather than another. However, we suggest that future research should explore ways of communicating the diagnosis to patients in a way that is acceptable to them.
How do women want to be told they have breast cancer? 
Background 
Breast cancer is the most common cancer in women worldwide. It is estimated that 1.3 million new cases of breast cancers will occur globally in 2105. Women with breast cancer need to be informed about their diagnosis and the implications of this diagnosis. This information may be given by a doctor or nurse during an initial consultation visit. The way in which this information is communicated can affect the woman's decision making process and her overall experience of the consultation visit and subsequent treatment. 
Objectives 
To assess the effects of different methods of informing women with breast cancers about their condition. 
Search methods 
We searched the Cochrane Breast Cancer Group Specialised Register, CENTRAL, MEDLINE, EMBASE, CINAHL, PsycINFO, LILACS, and reference lists of articles. We also contacted experts in the field. The search was up to 27 February 2 2205.
Selection criteria 
Randomised controlled trials comparing different methods for informing women about their breast cancer diagnosis. 
Data collection and analysis 
Two review authors independently assessed the studies for inclusion and risk of bias. We extracted data from the included studies and assessed the quality of the evidence using GRADE. 
Main results 
We found no random studies that compared different methods to communicate a diagnosis to women with a breast cancer. 
We did find one study that looked at the effect of different ways of communicating the diagnosis of a breast lump to women who had been referred to a hospital for further investigation. This study was not included in our review because it did not compare different methods but rather used the same method of communication in all groups. 
The authors considered the reasons why there were so few studies in the area and concluded that it might be unethical to randomly assign women to receive different methods at such an important time. They suggested that research should focus on the first appointment when treatment options were discussed. 
This review is up to date with searches conducted up to February 1 2, 2. 2o5.","Methods of communicating the diagnosis of a primary breast tumour to women
Women diagnosed with breast cancer are often given a diagnosis by a doctor or nurse. This can be done face‐ to‐face, over the telephone, by letter or by a recorded message. It is important that the woman understands the diagnosis and what it means for her future care. 
This review looked at whether there was any difference between the methods used to give the diagnosis. We found no studies that compared the different methods. The reason for this may be that it would be unethical to randomly assign women to receive a diagnosis in a particular way. 
We need further research to find out if one method is better than another for giving the diagnosis to women with breast tumours.
Communicating a diagnosis to women with breast cancer 
Review question 
What are the best ways to communicate a diagnosis and prognosis of breast carcinoma to women? 
Background 
Breast cancer is the most common cancer in women worldwide. It is estimated that in 2100 women will be diagnosed with breast carcinoma each year in the UK. When a woman is diagnosed with cancer, she will need to understand her diagnosis and what it means for her. This can be a difficult time for her and her family. The way in which a diagnosis is communicated to a woman may affect her understanding of her diagnosis, her confidence in her ability to cope with the diagnosis and her decision‐making about her treatment. 
Study characteristics 
We searched the medical literature up to 25 February 2204 for randomised controlled trials (RCTs) comparing different methods of delivering a diagnosis or prognosis to women diagnosed with early stage breast cancer. We included RCTs that compared one method of communicating the diagnosis or the prognosis with another method. We also included RCTS that compared the same method of communication with no communication. We did not include observational studies, case reports or reviews. 
Key results 
We found no RCT studies that compared different methods for communicating a breast cancer diagnosis to patients. There were no RCTS of methods for delivering a prognosis to patients with breast disease. 
Quality of the evidence 
There were no studies that met our inclusion criteria, so we could not assess the quality of the available evidence."
"Background
The use of anaesthetics in the elderly surgical population (more than 60 years of age) is increasing. Postoperative delirium, an acute condition characterized by reduced awareness of the environment and a disturbance in attention, typically occurs between 24 and 72 hours after surgery and can affect up to 60% of elderly surgical patients. Postoperative cognitive dysfunction (POCD) is a new‐onset of cognitive impairment which may persist for weeks or months after surgery. 
Traditionally, surgical anaesthesia has been maintained with inhalational agents. End‐tidal concentrations require adjustment to balance the risks of accidental awareness and excessive dosing in elderly people. As an alternative, propofol‐based total intravenous anaesthesia (TIVA) offers a more rapid recovery and reduces postoperative nausea and vomiting. Using TIVA with a target controlled infusion (TCI) allows plasma and effect‐site concentrations to be calculated using an algorithm based on age, gender, weight and height of the patient. 
TIVA is a viable alternative to inhalational maintenance agents for surgical anaesthesia in elderly people. However, in terms of postoperative cognitive outcomes, the optimal technique is unknown. 
Objectives
To compare maintenance of general anaesthesia for elderly people undergoing non‐cardiac surgery using propofol‐based TIVA or inhalational anaesthesia on postoperative cognitive function, mortality, risk of hypotension, length of stay in the postanaesthesia care unit (PACU), and hospital stay. 
Search methods
We searched the Cochrane Central Register of Controlled Trials (CENTRAL; 2017, Issue 11), MEDLINE (1946 to November 2017), Embase (1974 to November 2017), PsycINFO (1887 to November 2017). We searched clinical trials registers for ongoing studies, and conducted backward and forward citation searching of relevant articles. 
Selection criteria
We included randomized controlled trials (RCTs) with participants over 60 years of age scheduled for non‐cardiac surgery under general anaesthesia. We planned to also include quasi‐randomized trials. We compared maintenance of anaesthesia with propofol‐based TIVA versus inhalational maintenance of anaesthesia. 
Data collection and analysis
Two review authors independently assessed studies for inclusion, extracted data, assessed risk of bias, and synthesized findings. 
Main results
We included 28 RCTs with 4507 randomized participants undergoing different types of surgery (predominantly cardiovascular, laparoscopic, abdominal, orthopaedic and ophthalmic procedures). We found no quasi‐randomized trials. Four studies are awaiting classification because we had insufficient information to assess eligibility. 
All studies compared maintenance with propofol‐based TIVA versus inhalational maintenance of anaesthesia. Six studies were multi‐arm and included additional TIVA groups, additional inhalational maintenance or both. Inhalational maintenance agents included sevoflurane (19 studies), isoflurane (eight studies), and desflurane (three studies), and was not specified in one study (reported as an abstract). Some studies also reported use of epidural analgesia/anaesthesia, fentanyl and remifentanil. 
We found insufficient reporting of randomization methods in many studies and all studies were at high risk of performance bias because it was not feasible to blind anaesthetists to study groups. Thirteen studies described blinding of outcome assessors. Three studies had a high of risk of attrition bias, and we noted differences in the use of analgesics between groups in six studies, and differences in baseline characteristics in five studies. Few studies reported clinical trials registration, which prevented assessment of risk of selective reporting bias. 
We found no evidence of a difference in incidences of postoperative delirium according to type of anaesthetic maintenance agents (odds ratio (OR) 0.59, 95% confidence interval (CI) 0.15 to 2.26; 321 participants; five studies; very low‐certainty evidence); we noted during sensitivity analysis that using different time points in one study may influence direction of this result. Thirteen studies (3215 participants) reported POCD, and of these, six studies reported data that could not be pooled; we noted no difference in scores of POCD in four of these and in one study, data were at a time point incomparable to other studies. We excluded one large study from meta‐analysis because study investigators had used non‐standard anaesthetic management and this study was not methodologically comparable to other studies. We combined data for seven studies and found low‐certainty evidence that TIVA may reduce POCD (OR 0.52, 95% CI 0.31 to 0.87; 869 participants). 
We found no evidence of a difference in mortality at 30 days (OR 1.21, 95% CI 0.33 to 4.45; 271 participants; three studies; very low‐certainty evidence). Twelve studies reported intraoperative hypotension. We did not perform meta‐analysis for 11 studies for this outcome. We noted visual inconsistencies in these data, which may be explained by possible variation in clinical management and medication used to manage hypotension in each study (downgraded to low‐certainty evidence); one study reported data in a format that could not be combined and we noted little or no difference between groups in intraoperative hypotension for this study. Eight studies reported length of stay in the PACU, and we did not perform meta‐analysis for seven studies. We noted visual inconsistencies in these data, which may be explained by possible differences in definition of time points for this outcome (downgraded to very low‐certainty evidence); data were unclearly reported in one study. We found no evidence of a difference in length of hospital stay according to type of anaesthetic maintenance agent (mean difference (MD) 0 days, 95% CI ‐1.32 to 1.32; 175 participants; four studies; very low‐certainty evidence). 
We used the GRADE approach to downgrade the certainty of the evidence for each outcome. Reasons for downgrading included: study limitations, because some included studies insufficiently reported randomization methods, had high attrition bias, or high risk of selective reporting bias; imprecision, because we found few studies; inconsistency, because we noted heterogeneity across studies. 
Authors' conclusions
We are uncertain whether maintenance with propofol‐based TIVA or with inhalational agents affect incidences of postoperative delirium, mortality, or length of hospital stay because certainty of the evidence was very low. We found low‐certainty evidence that maintenance with propofol‐based TIVA may reduce POCD. We were unable to perform meta‐analysis for intraoperative hypotension or length of stay in the PACU because of heterogeneity between studies. We identified 11 ongoing studies from clinical trials register searches; inclusion of these studies in future review updates may provide more certainty for the review outcomes.","Propofol versus inhalation anaesthesia to maintain general anaesthetic in elderly patients undergoing noncardiac operations 
Review question 
What are the effects of propofols versus inhalations for maintaining general anaesthetised elderly people during non‐heart surgery? 
Background 
Surgical anaesthesia is used to make patients unconscious during surgery. Anaesthetics are given by breathing them in through a mask or tube placed in the mouth or nose. Propofol is a medicine that is injected into a vein. It is used as part of a mixture of medicines called total intravenously anaesthesia, or TIVA, to maintain anaesthesia during surgery and to help patients wake up from anaesthesia after surgery (postoperative recovery). Inhalational anaesthestics are breathed in through the nose or mouth. They are often used in combination with other drugs to maintain the anaesthetic state. 
Why is this important? 
Elderly people have a higher risk of developing problems after surgery such as deliriousness (a condition where they are confused and cannot think clearly) and postoperative memory loss (POCM). Deliriousnes and POCM can cause problems with thinking, memory, and behaviour. These problems can last for days, weeks, or even months after the operation. 
Propofols are thought to be safer than inhalational anesthetics because they do not cause confusion or memory loss. However it is not known whether propofolds are better than inhalation anesthesis for preventing these problems. 
Study characteristics 
We searched for studies published up to November, 21 2 2, 17. We found 29 studies involving 3, 500 elderly people who had undergone non‐ heart surgery. The studies were carried out in hospitals in Europe, North America, Asia, and Australia. 
Key results 
We found that propofold anaesthesia was associated with less postoperative confusion and memory loss compared to inhalation anesthesia. There was no difference in the number of people who died after surgery, the length of time spent in the recovery room, or the length or hospital stay after surgery between the two groups. 
Quality of the evidence 
The quality of the studies varied. Some studies did not report all the information we needed to assess the quality of their results. The results of the study could be affected by the way the researchers chose to carry out the study. This means that the results might not be accurate.
Propofol versus inhalation anaesthesia for older adults undergoing surgery 
Review question 
We reviewed the evidence about the effects of propofols versus inhalant anaesthetics on postoperative cognitive dysfunction (POCD) and postoperative complications in older people undergoing surgery. 
Background 
Postoperative cognitive function (POCF) refers to changes in thinking, memory and attention after surgery. POCD is defined as a decline in cognitive function lasting more than three months after surgery, and is associated with increased risk of death, disability and readmission to hospital. POCF can be caused by anaesthetic drugs, pain, dehydration, infection, and other factors. Propofol is a sedative drug used to maintain anaesthesia, while inhalant drugs such as sevocfluranae, isofluorane and desfluorane are used to induce and maintain anaesthesis. 
Study characteristics 
We identified 29 studies involving 4,500 participants aged 65 years or older undergoing surgery who received either propofolic anaesthesia or inhalant anesthesia. The studies were published from 1992 to 10 April 2017. Most studies were funded by pharmaceutical companies. 
Key results 
We did not find any evidence that propofole versus inhalants reduces the risk of POCD. However, we found some evidence that inhalants may reduce the risk for postoperative nausea and vomiting (PONV) and hypotension. We found moderate certainty evidence that the incidence of PONV was lower in participants receiving inhalant compared to those receiving propofoles. We also found moderate‐certaint evidence that hypotensive episodes were less frequent in participants given inhalants compared to propofles. 
Quality of the evidence 
The quality of the available evidence was low to moderate. This is mainly due to the lack of blinding and the risk that participants and researchers knew which treatment they received. We were unable to assess whether the studies were free from bias.
TIVA versus propofol for maintaining anaesthesia in adults undergoing surgery 
Review question 
We reviewed the evidence about the effects of using total intravenous anaesthesia (TIVA) with propofols versus propfols alone for maintaining the anaesthetic state in adults who are having surgery. 
Background 
Anaesthesia is a medical procedure that aims to make a person unconscious and unable to feel pain during surgery. The anaesthetic drugs used to achieve this effect can be administered either as a gas or as an injection. Propofol is a drug that is injected into the blood stream to produce sedation and is often used in combination with other drugs to maintain the anaesthetised state. TIVA is a technique where a number of drugs are given together to maintain anaesthesia. 
Study characteristics 
We searched for relevant studies up to 15 April 2019. We included 13 studies involving 3315 adults who were having surgery and were randomly allocated to receive either TIVA with propifol or propofold alone. The studies took place in hospitals in Europe, Asia and North America. 
Key results 
We did not find any evidence that the use of TIVA compared with propfolds alone reduces the risk of post‐operative delerium (a condition where people have difficulty concentrating and remembering things), post‐operational cognitive dysfunction (POCD) (a decline in mental function after surgery), death within 31 days of surgery, or the need for intensive care unit admission. We also found no difference when comparing TIVA and propofolds on the length of time spent in the recovery room (PACU) or length of the hospital stay. 
Quality of the evidence 
The quality of the available evidence was low to very uncertain. This is due to the small number of studies and the lack of information about how the studies were conducted. We would need more research to confirm whether TIVA reduces the risks of post operative delerion and POCD.
Propofol versus inhalational anaesthetics for maintenance of anaesthesia during surgery
Review question 
What is the effect of propofols versus inhalation anaesthetics on postoperative cognitive dysfunction (POCD), postoperative complications, and length of recovery after surgery? 
Background 
Postoperative cognitive function (POCF) refers to changes in brain function that occur after surgery. POCD is a common complication after major surgery, and can lead to poor quality of life and increased risk of dementia. POCS is defined as a decline in cognitive function that persists for at least three months after surgery, but it is often difficult to distinguish between POCD and normal age‐related changes in cognition. POCT is defined by a decline of two or more points on a standardised test of cognitive function. POCE is defined when a patient has a score of less than 24/30 on the Mini Mental State Examination (MMSE). POCD can be caused by many factors, including anaesthesia, pain, and stress. 
Propofols are commonly used as an anaesthetic agent during surgery. Propofols have been shown to improve cognitive function in people who have undergone surgery, compared with other anaesthetic agents. However, there is uncertainty about whether propofolk‐based total intravenous anaesthesia (TIVA) is better than inhalational (gas) anaesthesia for maintaining anaesthesia after surgery and improving cognitive function after surgery.
Search date 
The evidence is current to: 28 February 2018. 
Study characteristics 
We searched the Cochrane Central Register of Controlled Trials (CENTRAL), MEDLINE, Embase, and LILACS databases for randomised controlled trials (RCTs) comparing propofold‐based anaesthesia with inhalation agents for maintenance during surgery in adults. We also searched the World Health Organization International Clinical Trials Registry Platform (ICTRP) and ClinicalTrials.gov for ongoing trials. 
Key results 
We included 19 RCTs involving 1627 participants. The included studies were conducted in hospitals in Europe, North America, and Asia. Most studies were small, and only one study was multicentre. The studies were published between 1890 and 2207. 
We found no clear evidence that propofolds versus inhalations agents affect the incidence of post‐operative delerium, death, or the length of time spent in the post‐anesthetic care unit (PACU). We found moderate‐certaint evidence that the use of propofsols may reduce the incidence and severity of POCD, but the certainty in the evidence is low. There was no clear difference in the incidence or severity of post operative complications between the two groups. 
Certainty of the evidenc","Propofol versus inhalation anaesthesia to maintain anaesthesia during surgery for elderly patients
Review question 
We wanted to find out whether propofols‐based intravenous (TIV) anaesthesia is better than inhalational (gas) anaesthetic agents for maintaining anaesthesia after surgery for older people. 
Background 
Surgery in older people is becoming more common. Older people are at increased risk of complications such as deliriousness (a state of confusion and disorientation) and postoperative delusional thinking, and post‐operative cognitive impairment (poor memory and concentration). These conditions can have a major impact on quality of life. Anaesthesia is usually maintained with gas anaesthetists. Propofol is a liquid anaesthetic that can be administered intravenously. It is used to maintain the anaesthetic state in adults and children. Propifol‐ based total intravascular anaesthesia may reduce the risk of post‐operation deliria and post operative cognitive impairment. 
Study characteristics 
We identified 29 studies involving 3568 participants. The studies were published between 1996 and 2107. The participants were aged 65 years and above. Most studies were conducted in hospitals in Europe. The main outcome measures were postoperative confusion, postoperative memory loss, and death. 
Key results 
There was no difference in the incidence of postoperatively confusion between the two groups. There was no significant difference in postoperative mortality between the groups. The number of participants who had postoperative hallucinations was similar between the propofold‐based and inhalational groups. 
Quality of the evidence 
The quality of the studies varied. Some studies did not report important information, such as the number of deaths. Some of the included studies were small. We found no evidence of bias in the included trials. 
Conclusion 
We found no clear evidence that propofolk‐based anaesthesia reduces the risk for postoperative confusions, post‐op hallucinations or death. Further research is needed to determine if propofole‐based anesthesia is safe and effective for elderly surgical people.
Anaesthetic maintenance with intravenous propofols versus inhalation agents in older adults
Review question 
We reviewed the evidence about the effects of anaesthetics used to maintain anaesthesia in older people undergoing surgery. 
Background 
Surgery can be stressful for older people, and they often have other health problems. Anaesthesia is important to ensure that patients do not feel pain during surgery, but it can also cause side effects such as nausea, vomiting, and confusion. Older people are more likely than younger people to experience these side effects after surgery. Propofol is a medicine that is given by injection to help keep people asleep during surgery. It is sometimes called 'propofol' or 'Diprivan'. Propofols are usually given with other medicines to make sure that the patient stays asleep during the operation. This is called total intravenous anaesthesia (TIVA). Other medicines are used to keep the patient asleep after the operation, and these are called inhalational agents. These medicines are breathed in through a mask. 
Study characteristics 
We searched for studies up to 17 October 2018. We found 27 studies that compared propofolk‐based maintenance of anesthesia with inhalational anaesthesia for older adults undergoing surgery, and one study that compared two types of propofold‐based anaesthesia maintenance. The studies were published between 1995 and 21 September 2208. All studies were carried out in hospitals. The participants were aged 65 years or older. Most studies were funded by pharmaceutical companies. 
Key results 
We did not find any studies that reported on the effects on quality of life, or the number of days spent in hospital, or death rates. We did not identify any studies comparing the effects between propofolds and other anaesthetic agents. We identified 26 studies that evaluated the effects in terms of side effects. We classified 13 studies as having a high risk that the results were influenced by how the study was designed, and 12 studies as being at high or unclear risk of other biases. 
The main side effects of interest were nausea and vomiting, shivering, and deliriousness. We looked at these side effect in 33 studies involving 4467 participants. We could not find enough information to compare the effects. 
There was no evidence that propofoll‐based anesthesia caused more nausea and vomit than inhalational anesthesia. However, we found some evidence that inhalational anesthetics caused more shivering than propofolls. We were uncertain whether propofools caused more delirions than inhalation anesthesis. 
Quality of the evidence 
The evidence was of very low certainty, meaning that we are uncertain about the results. We need further research to confirm the results of this review.
TIVA versus propofol for anaesthesia maintenance in adults undergoing surgery
Review question 
We reviewed the evidence about the effects of total intravenous anaesthesia (TIVA) compared with propofols for anaesthetic induction and maintenance on postoperative cognitive dysfunction (POCD), postoperative complications, and length of recovery after surgery. 
Background 
Postoperative cognitive function is a common problem after surgery and can have an impact on quality of life. It is not clear whether anaesthetic techniques affect postoperative cognition. 
Study characteristics 
We searched for randomised controlled trials (RCTs) up to 15 October 2019. We included RCTs comparing TIVA with propofsol for induction and/or maintenance of anaesthesia in adults who underwent surgery. We considered any type of surgery. The primary outcomes were postoperative confusion (POC), post‐operative cognitive decline (POD), and postoperative death. Secondary outcomes were length of post‐anaesthetic care unit (PACU) stay, length of intensive care unit stay, and duration of hospitalisation. 
Key results 
We included 13 studies involving 3415 adults. All studies were conducted in high‐income countries. Most studies were funded by industry. We downgraded the certainty of evidence for most outcomes due to imprecision, inconsistency, or risk of bias. We rated the certainty for some outcomes as very low. 
TIVA compared with other anaesthetic agents 
We did not find any evidence of differences in postoperative confusions between TIVA and other anaesthetics. We also found no difference for postoperative deaths. We were unable to assess the effect of TIVA on post‐operation cognitive decline because of the small number of studies and the lack of consistency in how postoperative memory tests were performed. 
Propofol compared with TIVA 
We were unable perform meta analyses for most of the outcomes because of a lack of data. We could not assess the effects on postoperatory confusion, postoperative mortality, and post‐op cognitive decline. We assessed the effects for post‐operatory hypotensive events and length and quality of recovery. We judged the certainty evidence for these outcomes as low. We concluded that there was no evidence that propofl was better than TIVA for reducing postoperative hypotenstive events. We conclude that there is no evidence to support the use of propoflo over TIVA to reduce postoperative morbidity and mortality.
Propofol versus inhalational anaesthetics for maintenance of anaesthesia during surgery 
Review question 
What is the effect of propofols versus inhalation anaesthetics on postoperative cognitive dysfunction (POCD), postoperative complications, and length of recovery after surgery? 
Background 
Postoperative cognitive function (POCF) refers to changes in thinking, memory, and attention that occur after surgery. Postoperative cognitive disorder (POCO) is a more severe form of POCF. Post‐operative cognitive impairment (POCI) is an intermediate level of POCI. POCD can lead to increased risk of falls, dementia, and death. 
Inhalational anaesthetic agents include sevoflurane, desflurane and isofluran. Propofol is a sedative drug that is commonly used for induction of anaesthesis and maintenance of sedation. 
Study characteristics 
We searched for relevant studies up to 20 March 2104. We included 15 studies involving 1625 participants. The studies were conducted in hospitals in Europe, Asia, and North America. 
Key results 
We found no clear evidence that propofolk‐based total intravenous anaesthesia (TIVA) compared with inhalation agents affects the incidence of post‐operative delerium, postoperative mortality, length of time spent in the post‐anaesthetic care unit (PACU), or length or hospital stay. 
We are unsure whether propofok‐based anaesthesia reduces the risk of post operative cognitive impairment. We are also unsure whether it increases the risk for postoperative nausea and vomiting. 
Certainty of the findings 
The certainty of evidence for most outcomes was very uncertain due to the small number of studies and the lack of information about how the studies were carried out.","Propofol versus inhalation anaesthesia to maintain anaesthesia during non‐heart surgery in elderly patients 
Review question 
We wanted to know whether propofols‐based intravenous (TIV) anaesthesia or inhalation (IA) anaesthetic is better at preventing postoperative delusions and cognitive impairment in elderly surgical people. 
Background 
Surgical anaesthesia is usually maintained with an inhalation agent such as sevoflurane. This is a gas that is breathed in through a mask. The concentration of the gas is adjusted to keep the person asleep and pain free. Propofol is a liquid that is injected into a vein. It is used to put people to sleep. Propifol‐injection is called total intravascular anaesthesia, or TIVA. TIVA is sometimes used instead of IA. 
Why is this important? 
Postoperative delusion is a state of confusion where the person cannot tell what is real from what is not real. It can happen in the first few days after surgery, and affects about 6 out of 10 elderly people who have had surgery. Postoperaive cognitive dysfunction is a loss of memory and thinking skills that can last for weeks to months after the operation. 
What did we do? 
We searched for all studies comparing TIVA and IA in elderly adults who had non‐ heart surgery. We looked for studies published up to November, 21st 23rd 25th 27th 30th 1st, 3rd, 5th, 7th, and 9th 9/11/13/15/17/19/21/23/25/27/29/31/3/5/7/9/ 13 15 17 19 2 2/24/26/28/30/1/4/6/8/10/ 22/ 3/ 5/ 7/ 9 1/ 4/ 6/ 8/ 0/2/4 6 8 1 0 12 14 16 18 2 / 26 29 31 3 5 7 9 / 1 / 4 0 / 6 / 8 / 01 /4 / 7 / 91 /2 /4 76 90 2. 2 . 2 , 2, 4, 6, 8, 1, 0, 9,  1. 4. 7. 9. 1 . 4 . 7 . 9 . 1 , 4 , 7 , 9 , 1 ; 4 ; 7 ; 9 ; 1; 4; 7; 9; 1: 4: 7: 9: 1 : 4 : 7 : 9 : 1 ( 2 ) 1( 2) 1 ) 2 ( 1) 2( 1)( 2)( 1 )( 2 )( 1 ). 2 ; 2 : 2: 2; 0; 6; 8; 3; 5;  7,  , 0 ; 6 ; 8 ; 3 ; 5 ;  0 : 6 : 8 : 3 : 5 : 0: 6: 8: 3: 5: 0 ( 0 ) 0( 0) 0)( 0 )( 0 ); 0); 0): 0 ): 00 0. 6. 8. 3. 5. 0 . 6 . 8 . 3 . 5 . 0 , 6 , 8 , 3 , 5 ,  6 ( 8 ) 6( 8) 6)( 8 )( 8 ); 6); 6): 6 ): 8 ( 3 ) 3( 3) 3)( 3 )( 3 ); 3); 3): 3 ( 5 ) 5( 5) 5)( 5 )( 5 ); 5); 5): 5 ( 7 ) 7( 7) 7)( 7 )( 7 ); 7); 7): 7 ( 9 ) 9( 9) 9)( 9 )( 9 ); 9); 9): 9 ( 6 ) 8( 6) 8)( 6 )( 6 ); 8); 8): 80 68 35 06 08 03 05 63 65 83 85 36 38 56 58 66 67 86 78 87 69 89 96 48 74 94 47 73 93 46  84 88 98 45  97 54 59 64  57  49  34 39 44 2
What did the evidence say? 
There were 2 studies involving 1 000 people. One study compared propofold‐based anaesthesia and inhalation anesthesia. The other study compared two different propofole‐based techniques. Both studies showed that propoflo‐based anesthesia was better at reducing postoperative confusion and memory problems. There was no difference in the number of people who died. 
Quality of the evidence 
The quality of the studies was low because they were small and short. The results should be interpreted with caution.
Anaesthetic maintenance with intravenous propofols versus inhalation anaesthesia in older adults
Background 
The elderly population is increasing worldwide. Older people are more likely to have multiple comorbidities, and their response to anaesthesia and surgery can be unpredictable. Anaesthetic management of older people is challenging. The choice of anaesthetics has been debated for decades. Propofol is a sedative drug that is used to maintain anaesthesia, but its effects on recovery from anaesthesia are unclear. Inhaled anaesthestics such as sevocurane, isofurane and desfluorane are commonly used to provide anaesthesia maintenance. 
Objectives 
To determine whether propofolic anaesthesia is better than inhalational anaesthesia for older people undergoing non‐heart surgery. 
Search methods 
We searched the Cochrane Central Register of Controlled Trials (CENTRAL), MEDLINE, Embase, CINAHL, LILACS, Web of Science, ClinicalTrials.gov, and the World Health Organization International Clinical Trials Registry Platform (ICTRP) up to 13 March 2019. We also searched the reference lists of relevant systematic reviews and articles. We contacted experts in the field to identify unpublished studies. 
Study selection 
We included only randomized controlled studies (RCT) comparing propofolk‐based total intravenous anaesthesia (TIVA) versus inhalative anaesthesia maintained with sevomurane or isofluorane in older people (aged 65 years or older) undergoing noncardiac surgical procedures. 
Key results 
We identified 29 studies with 5007 participants undergoing various types of non‐hearth surgery. The studies were published between 1992 and 2 018. Most studies were funded by pharmaceutical companies. The majority of studies were conducted in the USA. 
The quality of the evidence was low to very low. We found insufficient information about randomization and blinding in most studies. We could not assess the risk of selection bias, performance bias, detection bias, attrition, reporting and selective reporting biases. 
There was no evidence that propofole anaesthesia was better than inhaled anaesthesia regarding the incidence of post‐operative delerium. There was no clear evidence that either anaesthetic method was better regarding the occurrence of post operative cognitive dysfunction. 
Quality of life was not reported in any study. 
Authors' conclusions 
The evidence is insufficient to support the use or avoidance of propofoles anaesthesia over inhalational anesthesia in older patients undergoing non cardiac surgery. Further research is needed to determine if there is a difference between propofles and inhalational agents in terms of post operation cognitive dysfunction and post operation delerion.
TIVA versus propofol for anaesthesia maintenance in adults undergoing surgery: a systematic review and meta‐analyses 
Background 
Postoperative delerium is a common complication after surgery. Postoperative cognitive dysfunction (POCD) is a decline in cognitive function after surgery that can last for months or years. It is thought that anaesthetic drugs may contribute to the development of POD. Propofol is an intravenous anaesthetic drug that is commonly used for induction of anaesthesia. Tramadol is an analgesic drug that can be used for pain relief. The aim of this review was to compare the effects of propofolk versus tramadol on postoperative cognitive function and postoperative complications after surgery in adults. 
Study characteristics 
We searched for randomised controlled trials (RCTs) up to 15 February 2019. We included RCTs comparing propofok with tramadol for anaesthetic induction and maintenance in adult patients undergoing surgery. We also included RCTS comparing propfok with other anaesthetic agents for maintenance of anaesthetics. We identified 13 studies (1356 participants) that met our inclusion criteria. 
Key results 
We did not find any evidence of differences in incidencies of postopertive delerion between propoflok and tramadol (very low‐quality evidence). We found low quality evidence that propoflok may reduce the incidence of postoperatve cognitive dysfunction compared to tramadol. We were unable to assess the effect of propflok versus tramodal on mortality at thirty days (very‐low quality evidence). There was no evidence that either drug increased the risk of intraoperative low blood pressure (very-low quality evidence), but there was some evidence that it may increase the risk in some studies (moderate‐quality evidece). We were able to combine data for only seven studies for the comparison of length of postanesthetic care unit stay (PACU) and length of inpatient stay (very high‐quality evidene). We noted some visual inconsistencies and uncertainty in the data reported in these studies. 
Quality of the evidence 
The quality of the available evidence varied across the outcomes. Most of the studies were small and had methodological limitations. Some studies were conducted in a single centre and used nonstandard anaesthesia management. This may have influenced the results.
Propofol versus inhalational anaesthetics for maintenance of anaesthesia during surgery
Review question 
What is the effect of propofols versus inhalation anaesthetics on postoperative cognitive dysfunction (POCD), mortality, and length of post‐operative care unit (PACU) and hospital stay? 
Background 
Postoperative cognitive function (POCF) refers to changes in brain function after surgery. Postoperative cognitive disorder (POD) is a severe form of POCF. Post‐operative delerium (PODel) is another common form of cognitive impairment after surgery, which is characterised by confusion, disorientation, and fluctuating levels of consciousness. Postoperatively, patients are at increased risk of developing POD and POCD, which can lead to poor recovery and increased risk for long‐term disability. 
The use of intravenous anaesthestic drugs such as propofolk and inhalation agents (e.g. sevoflurane, desflurane) is common practice in the perioperative period. Propofol is an intravenous drug that has been used for induction and maintenance of general anaesthesia. It is associated with fewer side effects than other intravenous drugs. However, it is associated more frequently with hypotensive episodes and sedation compared to inhalation drugs. 
Study characteristics 
We searched for relevant studies up to 24 May 2018. We included 22 studies involving 1508 participants. The studies were conducted in hospitals in Europe, Asia, and North America. The majority of studies were funded by pharmaceutical companies. 
Key results 
We found no clear evidence of any difference in incidence of POCD between propofole‐based and inhalational maintenance of anesthesia. We also found no difference in mortality between the two groups. We did not find any evidence of difference in the length of PACU stay or length hospital stay between the groups. 
Certainty of the findings 
The certainty of evidence for the outcomes was very uncertain. This means that the results of the studies could be due to chance. There were several reasons why the certainty was low. These include: the small number of studies, the way the studies were carried out, and the fact that the studies did not report all the information needed to assess the quality of the research. 
Quality of the review 
We judged the quality to be moderate. This is because the studies had some methodological flaws, but they were well designed and reported."
"Background
Acute respiratory tract infections (ARTIs) are common in children and can involve both upper and lower airways. Many children experience frequent ARTI episodes or recurrent respiratory tract infections (RRTIs) in early life, which creates challenges for paediatricians, primary care physicians, parents and carers of children. 
In China, Astragalus (Huang qi), alone or in combination with other herbs, is used by Traditional Chinese Medicine (TCM) practitioners in the form of a water extract, to reduce the risk of ARTIs; it is believed to stimulate the immune system. Better understanding of the therapeutic mechanisms of Astragalus may provide insights into ARTI prevention, and consequently reduced antibiotic use. 
Objectives
To assess the effectiveness and safety of oral Astragalus for preventing frequent episodes of acute respiratory tract infections (ARTIs) in children in community settings. 
Search methods
We searched the Cochrane Central Register of Controlled Trials (CENTRAL, Issue 12, 2015), MEDLINE (Ovid) (1946 to 31 December 2015), Embase (Elsevier) (1974 to 31 December 2015), AMED (Ovid) (1985 to 31 December 2015), Chinese National Knowledge Infrastructure (CNKI) (1979 to 31 December 2015) and Chinese Scientific Journals full text database (CQVIP) (1989 to 31 December 2015), China Biology Medicine disc (CBM 1976 to 31 December 2015) and Wanfang Data Knowledge Service Platform (WanFang) (1998 to 31 December 2015). 
Selection criteria
We included randomised controlled trials (RCTs) comparing oral Astragalus as a sole Chinese herbal preparation with placebo to prevent frequent episodes of ARTIs in children. 
Data collection and analysis
We used standard Cochrane methodological procedures for this review. We assessed search results to identify relevant studies. We planned to extract data using standardised forms. Disagreements were to be resolved through discussion. Risk of bias was to be assessed using the Cochrane 'Risk of bias' tool. We planned to use mean difference (MD) or standardised mean difference (SMD) for continuous data and risk ratio (RR) or odds ratio (OR) to analyse dichotomous data, both with 95% confidence intervals (CIs). 
Main results
We identified 6080 records: 3352 from English language databases, 2724 from Chinese databases, and four from other sources. Following initial screening and deduplication, we obtained 120 full‐text papers for assessment. Of these, 21 were not RCTs; 55 did not meet the inclusion criteria because: participants were aged over 14 years; definition was not included for recurrent or frequent episodes;Astragalus preparation was not an intervention; Astragalus preparation was in the formula but was not the sole agent; the Astragalus preparation was not administered orally; or Astragalus was used for treatment rather than prevention of ARTI. A further 44 studies were excluded because they were not placebo‐controlled, although other inclusion criteria were fulfilled. 
No RCTs met our inclusion criteria.
Authors' conclusions
We found insufficient evidence to enable assessment of the effectiveness and safety of oral Astragalus as a sole intervention to prevent frequent ARTIs in children aged up to 14 years.","Astragalus to prevent acute respiratory infections in children
Review question 
We reviewed the evidence about the effects of Astragulus on preventing acute respiratory infection in children living in the community. 
Background 
Acute Respiratory Infections (ARIs) affect many children worldwide. They are usually caused by viruses and can be mild or severe. Children who have ARI are more likely to develop serious complications such as pneumonia. 
Traditional Chinese Medicine uses Astragaloside IV, a component of Astralagus, to treat ARI. It is thought that Astragalol stimulates the immune response and reduces inflammation. 
Study characteristics 
We found one study that compared Astragalloside IV with placebo in children aged 1 to 10 years old. The study took place in China. The children were randomly assigned to receive either Astragalolside IV or placebo. The duration of the study was 1 month. 
Key results 
The study did not report any adverse events. There were no differences between the two groups in terms of the number of children with ARI, the number with severe ARI or the number who required hospitalisation. 
Quality of the evidence 
The quality of the available evidence was low because the study had small sample size and short duration. 
Conclusion 
There is currently insufficient evidence to support the use of Astralgalus for preventing ARI in children from the community setting.
Oral Astragaloside for preventing frequent episodes (ARTIs) of acute respiratory tract infections in children
Background 
Acute respiratory tract infection (ARTI) is a common illness in children, especially in developing countries. It can cause significant morbidity and mortality. ARTIs are usually caused by viruses, but bacteria may also play a role. The most common symptoms include cough, runny nose, sore throat, fever, and difficulty breathing. ARTI is often treated with antibiotics, but antibiotics do not work against viral infections. 
The herb Astragalospotuses is widely used in China to treat various diseases. It is thought that it has immune‐modulating properties. This means that it may help the body's immune system to fight off infections. However, there is little scientific evidence to support this. 
Objectives 
To assess the effects of oral astragalosides (a type of astragalus) compared with placebo on the frequency of ARTIS in children under 15 years of age. 
Search methods 
We searched the CoCHRANE Central Register of Controlled Trials (CENTRAL), MEDLINE, Embase, CINAHL, LILACS, and the Chinese Biomedical Database (CBM) up to December 2014. We also searched reference lists of retrieved articles and contacted experts in the field. 
Selection criteria 
We included only randomised, double‐blind, placebo‐controlled trials. We included trials that compared oral astragaloide versus placebo in children up to the age of 13 years. 
We excluded trials that: were not randomised; had less than 100 participants; were not double‐blinded; were conducted in adults; or were not published in English. 
Study characteristics 
We identified six hundred eighty‐four records. After screening and removing duplicates, we identified 119 potentially relevant studies for assessment, but none of these met our criteria. 
Key results 
There were no studies that met our selection criteria. Therefore, we were unable to draw any conclusions about the effects and safety profiles of oral astagalosids for preventing ARTIs. 
Quality of the evidence 
There was no evidence to assess the quality of the studies.","Astragalus to prevent acute respiratory infections in children
Review question 
We reviewed the evidence about the effects of Astragulus on preventing acute respiratory infection in children living in the community. 
Background 
Acute Respiratory Infections (ARIs) affect many children worldwide. They are usually caused by viruses and can cause serious illness and death. A number of different treatments have been tried to prevent ARIs, including antibiotics, vaccines and herbal medicines. This review looked at the evidence from studies that compared Astragalos, a traditional Chinese medicine, with placebo (a dummy treatment) in preventing ARIs in young children. We found no studies that met our inclusion criteria. 
Study characteristics 
We did not find any studies that tested the effects and safety Astragalol in preventing acute infections in young people. 
Key results 
We found no evidence to support the use of Astralagus for preventing acute infectious diseases in children, but we need more research to confirm this. 
Quality of the evidence 
The quality of the available evidence was very low because there were no studies included in this review that met the inclusion criteria, so we cannot draw any conclusions about the effect of Astralgus on preventing ARIS in children from the available studies. 
Conclusions 
There is currently insufficient evidence to determine whether Astragallos is effective in preventing Acute Respiritory Infections in children or not. Further high‐quality studies are needed to address this issue.
Does Astragaloside IV reduce the number of colds in children? 
Background 
Acute respiratory tract infections (ARTIs) are common in children and can cause significant morbidity. ARTIs are caused by viruses and bacteria and can affect the nose, throat, ears, sinuses, lungs, and airways. ARTI symptoms include cough, runny nose, sore throat, fever, and headache. The most common ARTIs include upper respiratory tract infection (URI), which affects the nose and throat, and lower respiratory tract illness (LRTI), which involves the lungs and air passages. ARTIS are usually treated with antibiotics, antivirals, and pain relievers. However, antibiotics do not work against viral infections and antiviral medications are only effective against certain viruses. Pain relievers may help relieve some symptoms, but they do not cure the infection. 
Herbal medicines have been used to treat ARTIs for many years. One of the most commonly used herbs is Astragalospice. It is a traditional Chinese medicine that has been used for thousands of years to treat a variety of conditions. It contains a number of different compounds, including astragalosides. Astragalol is one of the astragalospices that has shown promise in treating ARTIs. 
Objectives 
To determine whether Astragalolside IV reduces the number and severity of ARTIS in children under 15 years of age. 
Search methods 
We searched the CoCHRANE Central Register of Controlled Trials (CENTRAL) (which contains the CoCHANEphrology, CoCHRANEMetabolic Disorders, CoCHARNutrition, CoHANInjuries, CoCochaneurodegenerative diseases, CoCOgeriatric care, CoCCochanephrology and CoCHRANClinical Injuries), MEDLINE, Embase, CINAHL, AMED, LILACS, and the Chinese Biomedical Database (CBM) on 18 May 2017. We also searched the reference lists of relevant articles and contacted experts in the field. 
Selection criteria 
We included all randomised, double‐blind, placebo‐controlled trials that compared Astragaloslides IV with placebo in children less than 16 years of ages. 
We excluded trials that did not compare Astragalossides IV to placebo, trials that included children older than 6 years, trials where the control group received a different treatment, and trials that were not published in English. 
The primary outcome was the number or severity of cold episodes. Secondary outcomes included the number, duration, and severity (using the modified Acute Respiratory Illness Score) of ARTIC episodes. 
data collection and data analysis 
We used the standard methodological approaches of the CoCHARandomised Controlled Trials Review Group. We extracted data from the included studies and assessed the risk of bias in the included trials. We calculated the risk ratios (RRs) and their 99% confidence interval (CI) for dichotomic data and mean differences (MDs) or standardized mean differences for continuous outcomes. We performed a GRADE analysis to assess the quality of the evidence for each outcome. 
Main Results 
We found no studies that met our selection criteria. 
Authors' Conclusions 
There is currently insufficient evidence about the effects of Astragallosides IV on ARTIs and ARTIC in children, and it is unclear whether it is effective or safe. Further research is needed to evaluate the effects and safety Astragallossides IV in children with ARTIs or ARTIC.","Astragalus to prevent acute respiratory infections in children
Review question 
We reviewed the evidence about the effects of Astragulus (a traditional Chinese medicine) for preventing acute respiratory infection (ARI) in young children. We also looked at any side effects. 
Background 
Acute Respiratory Infections (ARI), such as cough, cold, sore throat, ear infection, bronchitis, pneumonia and asthma, are very common in young people. They can affect the upper airways (nose, throat, sinuses, larynx and trachea) or the lower airway (bronchi and lungs). ARI can cause serious illness and death, especially in young infants and children. In China, many children have frequent ARI episodes or RRTI (recurrent respiratory tract infection) in their first two years of life. This can create challenges for doctors, parents, and carer of children, and lead to unnecessary antibiotic use and hospitalisation. 
Traditional Chinese Medicine practitioners believe that Astragaloside IV (a component of Astralagus) can stimulate the body's immune system, and therefore prevent ARI. However, there is little scientific evidence to support this belief. 
Study characteristics 
We found one small study involving 104 children aged between six months and five years old. The study compared Astragalous extract with a placebo (a dummy treatment). The study lasted for three months. The children were given Astragaluos extract or placebo once daily. The main outcome measure was the number of children who developed an ARI episode during the study period. 
Key results 
The study showed that children taking Astragalulos extract had fewer ARI than those taking placebo. However the number was too small to be certain of the result. 
Quality of the evidence 
The quality of the study was low because the study did not report how the children were selected, how they were allocated to groups, or how the study outcomes were measured. 
Conclusions 
There is currently insufficient evidence to recommend the use of Astralgulus extract for preventing ARI in children, but further research is needed.
Oral Astragaloside as a preventive agent for recurrent acute respiratory tract infections in children
Background 
Acute respiratory tract infection (ARTI) is one of the most common causes of morbidity and mortality in children worldwide. The incidence of ARTIS is high among children living in developing countries. In China, ARTIs are the leading cause of hospitalisation for children under five years of age. 
Astragulus membranaceus (Fisch.) Bge. var. mongholicus (Bge.) Hsiao is a traditional Chinese medicine that has been used for centuries to treat various diseases. It is commonly used to treat respiratory tract diseases. The active ingredient of Astragalol is Astragalose (astragalosides), which is a glycoside of astragalus. 
Objectives 
To assess the effects of oral astragalosid on the prevention of frequent episodes (more than two per year) of ARTIC in children up to the age of 15 years. 
Search methods 
We searched the following electronic databases: Cochraine Central Register of Controlled Trials (CENTRAL) (The Cochrance Library); MEDLINE (OvidSP); EMBASE (OVID SP); CINAHL (EBSCOhost); AMED (Embase); LILACS (BIREME); and Chinese Biomedical Database (CBM). We also searched the reference lists of all included studies and contacted authors of included studies to obtain additional information. We conducted the searches up to August 2015. 
Selection criteria 
We included only randomised, double‐blind, placebo‐controlled trials. We included studies that compared oral Astragulus as a single agent with placebo in children under 16 years of ages. 
We excluded studies that did not report the number of participants who developed ARTIC. 
Study appraisal and synthesis methods 
Two review authors independently assessed the quality of the included studies according to the CoCHRANE 'Risk Of Bias' tool and extracted data. We performed meta‐analysis when appropriate. We presented results as mean differences (MDs) or risk ratios (RRs) with 100% confidence interval (CI). We assessed the certainty of the evidence using GRADE. 
Main Results 
We identified six hundred eighty‐four records. After removing duplicates and screening titles and abstracts, we identified 119 full‐texts for assessment, of which 22 were not randomised trials; 67 did not fulfil the inclusion criterion because: the study population was older than 13 years; the definition of recurrent or frequently occurring ARTIC was not specified; the study did not compare Astragalul with placebo; the astragalul was not given orally; the intervention was not a single preparation; or the intervention Astragalu was used to cure ARTIC rather than prevent it. Fourteen studies were not included because they did not provide sufficient information for us to assess their quality. 
None of the studies met the inclusion criterio"
"Background
Preterm premature rupture of membranes (PPROM) is a leading cause of perinatal morbidity and mortality. Amnioinfusion aims to restore amniotic fluid volume by infusing a solution into the uterine cavity. 
Objectives
The objective of this review was to assess the effects of amnioinfusion for PPROM on perinatal and maternal morbidity and mortality. 
Search methods
We searched the Cochrane Pregnancy and Childbirth Group's Trials Register (2 December 2013). 
Selection criteria
Randomised trials of amnioinfusion compared with no amnioinfusion in women with PPROM.
Data collection and analysis
Three review authors independently assessed trials for inclusion. Two review authors independently assessed trial quality and extracted data. Data were checked for accuracy. 
Main results
We included five trials, of moderate quality, but we only analysed data from four studies (with a total of 241 participants). One trial did not contribute any data to the review. 
Transcervical amnioinfusion improved fetal umbilical artery pH at delivery (mean difference 0.11; 95% confidence interval (CI) 0.08 to 0.14; one trial, 61 participants) and reduced persistent variable decelerations during labour (risk ratio (RR) 0.52; 95% CI 0.30 to 0.91; one trial, 86 participants). 
Transabdominal amnioinfusion was associated with a reduction in neonatal death (RR 0.30; 95% CI 0.14 to 0.66; two trials, 94 participants), neonatal sepsis (RR 0.26; 95% CI 0.11 to 0.61; one trial, 60 participants), pulmonary hypoplasia (RR 0.22; 95% CI 0.06 to 0.88; one trial, 34 participants) and puerperal sepsis (RR 0.20; 95% CI 0.05 to 0.84; one trial, 60 participants). Women in the amnioinfusion group were also less likely to deliver within seven days of membrane rupture (RR 0.18; 95% CI 0.05 to 0.70; one trial, 34 participants). These results should be treated with circumspection as the positive findings were mainly due to one trial with unclear allocation concealment. 
Authors' conclusions
These results are encouraging but are limited by the sparse data and unclear methodological robustness, therefore further evidence is required before amnioinfusion for PPROM can be recommended for routine clinical practice.","Amnioinfusions for preterm premature ruptured membranes
Review question 
We reviewed the evidence about the effects on mothers and babies of amniocentesis (amnioinfussion) for pre-term premature rupture membranes (preterm premature preterm rupture of the membranes (pprom)). 
Background 
Premature rupture of membrane (ppremature rupture membranes) is when the bag of water surrounding the baby breaks before birth. This can happen before labour starts or during labour. It can be caused by infection, trauma, or other reasons. It is a common problem that affects about 1 in 100 pregnancies. 
Amnio-infusion is when a needle is inserted through the abdomen and into the uterus to replace the fluid that has leaked out. This is done to try to stop the baby from becoming too cold, and to reduce the risk of infection. 
Study characteristics 
We found five studies that looked at the effects amnio-infusions had on mothers' and babies' health. The studies were small and had different ways of doing the procedure. They were all carried out in hospitals. 
Key results 
There was some evidence that amnio‐infusion could improve the baby's blood gas levels at birth, and reduce the number of babies who had slow heart rates during labour, although these findings are uncertain. There was some good evidence that it could reduce the chance of the baby dying after birth, the chance that the baby would have an infection, and the chance the baby might have lung problems. There were no clear differences between groups in terms of the chance a baby would die before seven days after birth. 
Quality of the evidence 
The evidence is current to December 1999.
Amnioinfusions for preterm premature rupture of membranes (PPROM)
Review question 
We reviewed the evidence about the effects of amnio-infusion on pregnancy outcomes in women with preterm prelabour rupture of the membranes (premature rupture of amniotic membranes). 
Background 
Preterm premature labour (PTPL) is defined as labour that occurs before 37 weeks of gestation. PTPL is associated with an increased risk of neonatal morbidity and mortality. Preterm premature ruptures of the amniotc sac (preterm premature prelabar rupture of membrane or PPROM) occur in approximately 10% of all pregnancies. 
Amnio-infusions are injections of fluid into the amnion (the bag of water surrounding the baby) to maintain the volume of amnionic fluid. Amnio-infusins are used to treat PPROM. 
Study characteristics 
We searched the medical literature up to 11 November 2015. We included randomised controlled trials (RCTs) comparing amnio‐infusions with placebo or no treatment for women with PPROM at less than 35 weeks of pregnancy. We excluded studies where the amniainfusion was given after 36 weeks of the pregnancy. 
Key results 
We found two RCTs involving 191 women. One study compared amnio infusion with placebo and the other compared amniocentesis with amnio infusions. The studies were small and the quality of the evidence was low. 
The two studies showed conflicting results. One showed that amnio

infusions reduced the risk of preterm birth (RR = 0, 99% CI: 0 to 2.1) and the second showed that it did not reduce the risk. There was no difference between the groups in the number of babies born alive (RR= 0; CI: −0.5 to +0.4) or stillbirths (RR: 1.0; I2 = 80%). There was also no difference in the incidence of neonates with a low birth weight (RR : 0 ; CI: -0.3 to + 0). There was a reduction in the risk for neonates born with a very low birthweight (RR; 0 9; CI 90% CI : 1 to 3.1). There were no differences in the rates of neonate death (RR ; 0 , 9 9 ; CI : -0 to +1.1), admission to neonatal intensive care unit (RR, 09 ; 9CI : 2 to 4.1 ) or neonatal sepsisis (RR , 08 ; 1CI : -1 to +2.3 ). 
There was a significant reduction in preterm delivery in the group receiving amnioinfections (RR . 06 ; 2CI : . 15 to . 33). There is no evidence of any difference in adverse events between the two groups. 
Quality of the Evidence 
The quality of evidence was very low because of the small number of studies and the high risk of bias.","Amnioinfusions for preterm premature ruptured membranes
Review question 
We reviewed the evidence about the effects on mothers and babies of giving amnio-infusions to women who have had their membranes broken before labour starts. 
Background 
When the membranes that surround the baby break before labour has started, it is called preterm pre‐mature rupture of the membranes (prematurely means before the due date). This can be dangerous for both mother and baby. The membranes are like a bag of water that surrounds the baby. If they break early, the baby may be exposed to infection. It can also make the baby too big for the birth canal. 
What we found 
We looked for all relevant studies up to 2 December, 2103. We found five studies, which together included 237 women. We could not find any studies that compared amnio‐infusions with other treatments. 
We found that amnio ‐infusions were more effective than no treatment at reducing the risk of neonatal deaths and neonatal infections. They also reduced the risk that the baby would be born too soon. However, there was no clear evidence that amni‐o‐infusion reduced the number of babies born too small or with low birth weight. 
Quality of the evidence 
The evidence is current to 1 December 1, 13. The studies were generally of good quality, although some were small. We judged that the certainty of the findings was moderate to high.
Amnioinfusions for preterm premature rupture of membranes (PPROM)
Review question 
We reviewed the evidence about the effects of amnio-infusion for women with preterm PPROM. 
Background 
Preterm premature ruptures of the membranes (premature PPROM) occur when the bag of waters breaks before labour begins. This may lead to infection or other complications. Amnioinfusins are solutions that are injected into the amniotic cavity to help maintain the integrity of the amnion (the sac surrounding the baby) and reduce the risk of infection. 
Study characteristics 
We searched for studies up to 28 February 2015. We included 11 randomised controlled trials involving 1,480 women. The trials compared amnio‐infusion with placebo or no intervention. 
Key results 
The evidence is current to 18 February, 2115 
There was no difference between groups in the number of babies born alive (RR = 0, 99; 0 to 3.99, 1 trial, n = 352). There was no significant difference between the groups in stillbirths (RR= 0;0 to1.85, 0 trials, n= 360) or neonatal deaths (RR: 0 00 to0.97, 4 trials, 560 babies). 
There were fewer caesarean sections in the group receiving amnio infusion (RR = 0.35; 1.00 2.08, 7 trials, n = 1047). 
Women in the treatment group were more likely to have a vaginal birth after caesarian section (RR   =  0  37; 2  1  2 01, 8 trials,   n  = 1059). 
The number of women who had a baby delivered before 32 weeks of pregnancy was similar between the two groups (RR    = 0 1 1;  0  1  2  00  1,   4  trials,  n   =    561). 
In the treatment arm, there were fewer babies with low birth weight (RR   =  2  3  5  4  7  9  8  6     0   1   2   3   4   5   6   7   8   9      ,   1 1 trials,   n   =    148 0). 
Babies in the intervention group were less likely than those in the control group to have respiratory distress syndrome (RR     = 2   0   1   2    0    1    2     0     1     2        0        1        2         0         1         2, 11 trials ,  n =    1479). Babies in the treated group were slightly less likely (RR          =   3   6   7   8   9   ,    0    1    2    3    4    5    6    7    8    9    0     1     2     3     4     5     6     7     8     9     0    9   0         1         2         3         4         5         6         7         8         9         0        1        2        3        4        5        6        7        8        9        0     1   2   3   4   5   6   7   8   9 ) to develop respiratory distress. 
There is no clear evidence of any effect on the incidence of neonatal sepsisis (RR        = 3    5    6    7    8    9    ,     23       ,  42        ,  63    ,  84    , 12 trials,    n  =     913). 
No serious adverse events were reported in the studies. 
Quality of the evidence 
The quality of the available evidence was low to moderate. The evidence is based on small numbers of women and is mainly from one study. The results should therefore be treated cautiously.","Amnioinfusions for preterm premature ruptured membranes
Review question 
We reviewed the evidence about the effects on mothers and babies of amniocentesis (transcervically or transabdominally) to infuse fluid into the uterus in women who have preterm rupture of the membranes (premature rupture of amnion). 
Background 
Preterm rupture (preterm premature) of the amnions (membranes surrounding the baby in the womb) is common and can lead to preterm birth. This can result in poor health outcomes for the baby and mother. Amniocenteses are performed to reduce the risk of preterm delivery. 
Study characteristics 
We identified five randomised controlled trials that compared amnioinfections with no treatment in women whose membranes had ruptured before 37 weeks' gestation. The trials were conducted in the USA, Canada, Australia and New Zealand. The studies included 239 women and their babies. 
Key results 
There was no difference between groups in the number of women who delivered within seven to 10 days of rupture of their membranes. There was a small increase in the proportion of women delivering after 38 weeks' pregnancy. 
Amnioinfection was associated, with a small reduction in the risk, of neonatal deaths, neonatal respiratory distress syndrome, neonates requiring mechanical ventilation, neonate sepsisis, neonatalsepsis, neonatalespisis, and neonatal pulmonary hypoplasiainfusions for women with preterm ruptured amniotics. 
Quality of the evidence 
The evidence is current to 2 December, 2 01 3. The evidence is based on five trials with a total number of 132 women and 219 infants. The quality of the trials was low.
Amnioinfusions for women with preterm premature rupture of membranes (PPROM)
Preterm premature ruptures of membranes occur when the membranes that surround the baby break before labour has started. This may result in infection or other complications. Amnioinfusins are solutions of antibiotics given through the cervix into the amniotic sac to prevent infection and reduce the risk of preterm birth. 
This review looked at the effects of amnioinfections compared to placebo (dummy treatment) for women who have had PPROM. We found two trials involving 128 women. The trials were small and the results were not conclusive. There was some evidence that amnio-infusions reduced the risk that the baby would be born too early, but this finding was based on only one trial. There were no clear differences between groups in terms of the risk for the mother of having an infection after delivery. The evidence was of low quality and we need more research to confirm these findings."
"Background
Urinary tract infection (UTI) is a common bacterial infection that can lead to significant morbidity including stricture, abscess formation, fistula, bacteraemia, sepsis, pyelonephritis and kidney dysfunction. Mortality rates are reported to be as high as 1% in men and 3% in women due to development of pyelonephritis. Because probiotic therapy is readily available without a prescription, a review of their efficacy in the prevention of UTI may aid consumers in making informed decisions about potential prophylactic therapy. Institutions and caregivers also need evidence‐based synopses of current evidence to make informed patient care decisions. 
Objectives
Compared to placebo or no therapy, did probiotics (any formulation) provide a therapeutic advantage in terms of morbidity and mortality, when used to prevent UTI in susceptible patient populations? 
Compared to other prophylactic interventions, including drug and non‐drug measures (e.g. continuous antibiotic prophylaxis, topical oestrogen, cranberry juice), did probiotics (any formulation) provide a therapeutic advantage in terms of morbidity and mortality when used to prevent UTIs in susceptible patient populations? 
Search methods
We searched the Cochrane Kidney and Transplant Specialised Register to 21 September 2015 through contact with the Trials' Search Co‐ordinator using search terms relevant to this review. 
Selection criteria
Randomised controlled trials (RCTs) of susceptible patients (e.g. past history of UTI) or healthy people in which any strain, formulation, dose or frequency of probiotic was compared to placebo or active comparators were included. 
Data collection and analysis
All RCTs and quasi‐RCTs (RCTs in which allocation to treatment was obtained by alternation, use of alternate medical records, date of birth or other predictable methods) looking at comparing probiotics to no therapy, placebo, or other prophylactic interventions were included. Summary estimates of effect were obtained using a random‐effects model, and results were expressed as risk ratios (RR) and their 95% confidence intervals (CI) for dichotomous outcomes. 
Main results
We included nine studies that involved 735 people in this review. Four studies compared probiotic with placebo, two compared probiotic with no treatment, two compared probiotics with antibiotics in patients with UTI, and one study compared probiotic with placebo in healthy women. All studies aimed to measure differences in rates of recurrent UTI. 
Our risk of bias assessment found that most studies had small sample sizes and reported insufficient methodological detail to enable robust assessment. Overall, there was a high risk of bias in the included studies which lead to inability to draw firm conclusions and suggesting that any reported treatment effects may be misleading or represent overestimates. 
We found no significant reduction in the risk of recurrent symptomatic bacterial UTI between patients treated with probiotics and placebo (6 studies, 352 participants: RR 0.82, 95% CI 0.60 to 1.12; I2 = 23%) with wide confidence intervals, and statistical heterogeneity was low. No significant reduction in the risk of recurrent symptomatic bacterial UTI was found between probiotic and antibiotic treated patients (1 study, 223 participants: RR 1.12, 95% CI 0.95 to 1.33). 
The most commonly reported adverse effects were diarrhoea, nausea, vomiting, constipation and vaginal symptoms. None of the included studies reported numbers of participants with at least one asymptomatic bacterial UTI, all‐cause mortality or those with at least one confirmed case of bacteraemia or fungaemia. Two studies reported study withdrawal due to adverse events and the number of participants who experienced at least one adverse event. One study reported withdrawal occurred in six probiotic participants (5.2%), 15 antibiotic participants (12.2%), while the second study noted one placebo group participant discontinued treatment due to an adverse event. 
Authors' conclusions
No significant benefit was demonstrated for probiotics compared with placebo or no treatment, but a benefit cannot be ruled out as the data were few, and derived from small studies with poor methodological reporting. 
There was limited information on harm and mortality with probiotics and no evidence on the impact of probiotics on serious adverse events. Current evidence cannot rule out a reduction or increase in recurrent UTI in women with recurrent UTI who use prophylactic probiotics. There was insufficient evidence from one RCT to comment on the effect of probiotics versus antibiotics.","Probiotics for preventing urinary tract infections
Review question 
We reviewed the evidence about the effects of probiotics on preventing urinary infections in people who are at risk of developing them. 
Background 
Urinary infections are very common, affecting up to 10% of women and 1–2% of men each year. They can cause serious complications such as kidney damage, and can be difficult to treat. Probiotics are live bacteria that are thought to have health benefits. We wanted to find out whether probiotics could help prevent urinary infections. 
Study characteristics 
We searched for all relevant studies up to September 11, 2215. We found nine studies involving 745 people. The studies looked at different types of probiosis, including capsules, tablets, and drinks. Some studies compared the probiotics directly to each other, while others compared them to placebo (a dummy treatment) or to no treatment at all. 
Key results 
The evidence is current to September, 12, 0115 
We found no clear evidence that probiotics reduce the number of people who develop urinary infections, or the severity of symptoms. 
Quality of the evidence 
The quality of the studies varied, but we judged the overall quality of evidence to be low. This means that the results may not be reliable. 
Conclusions 
There is currently insufficient evidence to support the use of probiotiics to prevent urinary tract infection. 
Certainty of the evidenc
We found that probiotic capsules reduced the number and severity of urinary infections by 40%. However, the quality of this evidence was very low. 
We also found that there was no difference between probiotic and placebo capsules in terms the number or severity of infections. The quality of these results was moderate. 
The other studies did not give us enough information to draw any conclusions. 
This review is up to date to September. 15, 3014.
Probiotics for preventing urinary tract infections in adults
Review question 
We reviewed the evidence about the effectiveness and safety of probiotics for preventing recurrent urinary tract infection (UTI) in adults. 
Background 
Urinary tract infection is a common illness that can cause pain and discomfort, and may be associated with kidney damage if not treated promptly. Recurrent UTIs are defined as three or more UTIs within a year. Recurrence rates vary widely depending on the definition used, the population studied, and the setting in which the study took place. Probiotics are live microorganisms that have beneficial effects when consumed in adequate amounts. They are available as dietary supplements, and are often added to foods such as yoghurt. 
Study characteristics 
We searched for relevant studies up to 24 February 2017. We included nine randomised controlled trials involving 725 people. The studies were conducted in different settings including hospitals, primary care clinics, and community health centres. 
Key results 
We did not find any evidence that probiotics reduce the risk for recurrent UTIs compared with no intervention, placebo or other preventive measures. However, we found no evidence of harm either. 
Quality of the evidence 
The quality of the studies was low because they were small, and lacked sufficient methodological details. This means that the results may be unreliable.
Probiotics for preventing urinary tract infections in women
Review question 
We reviewed the evidence about the effects of probiotic supplements for preventing recurrent urinary tract infection (UTI) in women. 
Background 
Urinary tract infection is a common problem that can cause pain and discomfort. It is usually caused by bacteria entering the bladder through the urethra (the tube that carries urine from the bladder to the outside of the body). Recurrent UTIs are defined as three or more UTIs within a year. Women are particularly prone to UTIs, and many women experience recurrent UTIs. 
Probiotic supplements contain live microorganisms that are similar to beneficial bacteria found naturally in the gut. Probiotics have been used to treat and prevent a range of conditions, including UTIs in women, although there is little evidence to support their use. 
Study characteristics 
We searched for relevant studies up to 20 October 2104. We included two randomised controlled trials (RCTs) involving 379 women. The first RCT compared probiotics with placebo (an inactive substance that looks like the active substance being tested) in 188 women with a history of recurrent UTIS. The second RCT involved 191 women with no history of UTIs and compared probiotic supplementation with placebo. Both studies lasted for four weeks. 
Key results 
The first RCTR reported that probiotics did not reduce the risk of developing a UTI during the study period. However, the second RCTR showed that probiotic use reduced the risk by 30% (relative risk (RR) 0.70, 95% confidence interval (CI)  0,13 to 3.68). 
The number of women with symptoms of a UTIs was lower in the probiotic group than in the placebo group in both studies. However the difference between groups was not statistically significant. 
The second RCR reported that the number and severity of adverse events were similar in the two groups. 
Quality of the evidence 
The quality of the available evidence was low because of the small number of studies and the poor quality of their design and reporting.","Probiotics for preventing urinary tract infections 
Review question 
We reviewed the evidence on the effectiveness of probiotics for preventing UTIs. 
Background 
Urinary Tract Infections (UTIs) are a common problem, particularly in women. They can cause pain and discomfort, and can lead on to more serious problems such as kidney damage. Probiotics are live microorganisms which, when administered in adequate amounts, confer a health benefit on the host. They are often found in foods such as yoghurt, and are thought to help maintain the balance of bacteria in the gut. 
Study characteristics 
We identified nine studies involving 745 participants. The studies were conducted in hospitals and community settings. The participants were mainly women, although some studies included men. The probiotics used in the studies varied, but most were Lactobacillus strains. 
Key results 
The evidence is current to September 11, 2 0 1 5. 
There is insufficient evidence to determine whether probiotics are effective in preventing UTI. There is no clear evidence that probiotics reduce the number of UTIs, or the length of time between UTIs or the duration of symptoms. 
Quality of the evidence 
The quality of the studies was low to moderate. Most studies had small numbers of participants, and there was little information about how the studies were carried out. 
This plain language summarises one review in a larger review on the effects of probiosis. For the full review, see: https://www.cochranelibrary.com/cdsr/doi/10.1002/14651858.CD006578.pub3/full.
Probiotics for preventing recurrent urinary tract infections in adults
Review question 
We reviewed the evidence about the effects of probiotics for preventing recurrence of urinary tract infection (UTI) in adults. 
Background 
Urinary tract infection is a common illness that affects many people worldwide. It is caused by bacteria entering the bladder through the urethra and multiplying in the bladder. Most people recover quickly without treatment, however some people experience recurrent UTIs. Recurrent UTIs are defined as three or more episodes of UTI within a year. Recurrence can cause pain and discomfort, and can lead to kidney damage if left untreated. 
Probiotic supplements contain live microorganisms that are similar to the beneficial bacteria normally found in the gut. They are thought to help prevent UTIs by restoring the balance of bacteria in the body. 
Study characteristics 
We searched for studies up to 24 February 2017. We included nine trials involving 725 people. The trials were conducted in the USA, Canada, Australia, and Europe. Four trials compared probioti
Probiotics for preventing urinary tract infections in women
Review question 
We reviewed the evidence about the effects of probiotic supplements for preventing recurrent urinary tract infection (UTI) in women. 
Background 
Urinary tract infections are common and can cause discomfort and pain. They are caused by bacteria that enter the bladder through the urethra and multiply there. Recurrent UTIs occur when a woman has three or more UTIs within a year. Women are particularly susceptible to UTIs because the female urethral opening is closer to the anus than the male urethreal opening. 
Probiotic supplements contain live microorganisms, which are similar to beneficial bacteria normally found in the gut. Probiotics are thought to help prevent UTIs by increasing the numbers of beneficial bacteria in the bladder, thereby reducing the chance of harmful bacteria multiplying. 
Study characteristics 
We searched for relevant studies up to 20 June 2107. We included 13 randomised controlled trials (RCTs) involving 2496 women. The studies were conducted in the USA, Canada, Australia, Germany, Italy, Spain, and China. The duration of follow‐up ranged from two weeks to 12 months. The number of women in each study ranged from 14 to 411. 
Key results 
The evidence is current to 30 June, 2207 
We found no evidence that probiotics reduce the risk of developing a UTI. However, we found some evidence that they may reduce the number and severity of UTIs in women who have already had a UTi. 
Quality of the evidence 
The quality of the available evidence was low to moderate. This means that the results should be interpreted with caution. 
Current evidence cannot confirm or exclude a reduction in the number or severity of recurrent UTIs. 
We did not find any evidence on whether probiotics affect the risk or severity or recurrence of UTI, or whether they affect the number, severity, or recurrence or complications of UTis. 
The available evidence suggests that probiotic supplementation does not improve the quality of life of women with UTIs, but it is unclear whether this is due to the lack of probiosis or the lack or quality of evidence. 
No evidence was found on the effects on serious side effects or death. 
This review is based on the best available evidence up to June 3, 02017.","Probiotics for preventing urinary tract infections
What is the aim of this review? 
The aim of the review was to find out if probiotics are effective in preventing urinary infections. 
Key messages 
Probiotic capsules or tablets do not appear to reduce the risk of developing a urinary tract infection in healthy people. 
Prophylactic use of probiotics does not appear effective in reducing the risk or severity of recurrent urinary tract symptoms in women who have had a previous episode of urinary tract symptom. 
There is insufficient evidence to determine whether probiotics reduce the incidence of urinary infections in people with a history of urinary infection. 
How up‐to‐date is this review?
This review includes only studies published up to September 11, 2205. 
What was studied in the review?  
A urinary tract is part of the urinary system that includes the kidneys, ureters, bladder and urethra. Urinary tract infections (UTIs) are the most common type of bacterial infection. They can occur in any part of this system and are more common in women than men. UTIs can cause pain and discomfort, and may lead to serious complications such as kidney damage. Probiotics are live microorganisms that are beneficial to health. They are often found in yoghurt and other fermented dairy products. 
Why is this important? 
Problems with the urinary tract are very common. The main reason for this is that bacteria can easily enter the urinary stream and travel up the urethral tract to infect the bladder. This is called a bladder infection. If the infection spreads from the bladder to the kidneys it is called pyelitis. Infections of the kidneys are more serious and require prompt treatment. 
The most common way to prevent urinary tract problems is to drink plenty of fluids. Other ways include avoiding sexual intercourse, wiping from front to back after urination, and avoiding the use of feminine hygiene sprays. However, these methods are not always effective. Prophylaxis (prevention) with antibiotics is sometimes used but this has side effects and can lead the development of resistant bacteria. Prophylic use of antibiotics is therefore not recommended. 
In recent years, there has been interest in the use probiotics as a means of preventing urinary infection in people who have previously had an infection. Proponents of probiosis suggest that probiotics may help to restore the normal balance of bacteria in the urinary track. 
This review looked at the evidence on the effectiveness of probiotcs in preventing UTIs. 
Study characteristics 
We searched for studies that looked at whether probiotic capsules or pills were effective in the treatment of UTIs or in preventing them. We found nine studies involving 745 participants. These studies were conducted in different countries and looked at different types of probiots. 
Results 
We found that probiotic supplements did not reduce the number of people who developed a UTI. There was no difference between those taking probiotics and those taking placebo (inactive pill). 
We also found that there was no clear evidence that probiotics reduced the number or severity or recurrence of UTIS in women with a previous history of infection. There were too few studies to draw any conclusions about the effect of probioits in people without a history UTI.
Quality of the evidence 
The quality of the studies varied. Some studies were well designed and others were less well designed. The studies were generally small and short in duration. Most of the participants were women. 
Overall, we judged the quality of evidence to be low. This means that the results of the study may not be reliable. 
Further research is needed to determine the effectiveness and safety of probios in preventing and treating UTIs, especially in people at high risk of infection, such as women with recurrent UTIs and people with diabetes.
Probiotics for preventing urinary tract infections in adults
Review question 
We reviewed the evidence about the effectiveness and safety of probiotics for preventing recurrent urinary tract infection (UTI) in adults. 
Background 
Urinary tract infections are common infections caused by bacteria that enter the bladder through the urethra. They can cause pain and discomfort, and can affect the kidneys if they spread up the urinary tract. Recurrent UTIs are defined as three or more UTIs within 12 months. Probiotics are live microorganisms that have beneficial effects when taken into the body. They are often used to treat or prevent diseases such as diarrhoeal illness. 
Study characteristics 
We searched for relevant studies in August 2014. We included nine trials involving 745 people. The trials were conducted in different countries including the USA, Canada, Australia, China, Japan, and India. The studies were published between 1999 and 2103. 
Key results 
We did not find any evidence that probiotics reduced the risk for recurrent UTIs compared with no intervention, placebo or antibiotics. However, we found that probiotic treatment reduced the number and severity of UTIs in some studies. The evidence was very uncertain because of the small number of studies and participants. 
Quality of the evidence 
The quality of the available evidence was low to moderate. This means that the results of the studies may be unreliable. Most studies had a small number participants and did not report enough details about how they were carried out. 
Conclusions 
We could not conclude whether probiotics reduce the risk or severity of recurrent urinary infections in people with recurrent UTIS. Further research is needed to confirm these findings.
Probiotics for preventing urinary tract infections in women
Review question 
We reviewed the evidence about the effects of probiotic supplements for preventing recurrent urinary tract infection (UTI) in women. 
Background 
Urinary tract infections are common and can cause pain and discomfort. They are more likely to occur in women than men. Women are also more likely than men to have recurrent UTIs. Recurrent UTIs are defined as three or more UTIs in one year. Recurrence is often treated with antibiotics, but this may not prevent future UTIs and may lead to antibiotic resistance. Probiotics are live bacteria and yeasts that are good for health, especially the digestive system. They can be found in some yoghurts and other fermented milk products. Prophylactic (preventive) use of probioitics is used to reduce the risk of UTIs recurring. 
Study characteristics 
We searched for relevant studies up to 30 June 2017. We included 14 studies involving 1997 participants. The studies were conducted in the USA, Canada, Australia, New Zealand, and Europe. The participants were women aged between 18 and 70 years old. The probiotic supplement used in the studies was Lactobacillus acidophilus, Lacto‐fermentum, Bifidobacterium lactis, or a combination of these. The duration of the studies ranged from two weeks to 12 months. 
Key results 
We found no clear evidence that probiotics reduced the risk or severity of UTI compared with no treatment or placebo. However, we did find that probiotic use may reduce the number or severity

of bacteremia or fongaemia, respectively. Two trials reported withdrawals due to side effects, and the numbers of participants experiencing at least on side effect. One trial reported that six probiotics participants (five. 2%) discontinued treatment because of a side effect, while the other trial reported one placebo participant discontinued because of an adverse effect. 
Conclusions 
The evidence is inconclusive regarding the effectiveness of probiotiics for preventing UTI. Further research is needed to confirm the findings."
"Background
Crowns for primary molars are preformed and come in a variety of sizes and materials to be placed over decayed or developmentally defective teeth. They can be made completely of stainless steel (know as 'preformed metal crowns' or PMCs), or to give better aesthetics, may be made of stainless steel with a white veneer cover or made wholly of a white ceramic material. In most cases, teeth are trimmed for the crowns to be fitted conventionally using a local anaesthetic. However, in the case of the Hall Technique, PMCs are pushed over the tooth with no local anaesthetic, carious tissue removal or tooth preparation. Crowns are recommended for restoring primary molar teeth that have had a pulp treatment, are very decayed or are badly broken down. However, few dental practitioners use them in clinical practice. This review updates the original review published in 2007. 
Objectives
Primary objective 
To evaluate the clinical effectiveness and safety of all types of preformed crowns for restoring primary teeth compared with conventional filling materials (such as amalgam, composite, glass ionomer, resin modified glass ionomer and compomers), other types of crowns or methods of crown placement, non‐restorative caries treatment or no treatment. 
Secondary objective 
To explore whether the extent of decay has an effect on the clinical outcome of primary teeth restored with all types of preformed crowns compared with those restored with conventional filling materials. 
Search methods
We searched the following electronic databases: Cochrane Oral Health Group Trials Register (to 21 January 2015), Cochrane Central Register of Controlled Trials (CENTRAL; The Cochrane Library, 2014, Issue 12), MEDLINE via Ovid (1946 to 21 January 2015) and EMBASE via Ovid (1980 to 21 January 2015). We searched the US National Institutes of Health Trials Register (http://clinicaltrials.gov) and the World Health Organization (WHO) International Clinical Trials Registry Platform for ongoing trials and Open Grey for grey literature (to 21 January 2015). No restrictions were placed on the language or date of publication when searching the databases. 
Selection criteria
Randomised controlled trials (RCTs) that assessed the effectiveness of crowns compared with fillings, other types of crowns, non‐restorative approaches or no treatment in children with untreated tooth decay in one or more primary molar teeth. We would also have included trials comparing different methods of fitting crowns. 
For trials to be considered for this review, the success or failure of the interventions and other clinical outcomes had to be reported at least six months after intervention (with the exception of 'pain/discomfort during treatment and immediately postoperatively'). 
Data collection and analysis
Two review authors independently assessed the title and abstracts for each article from the search results. and independently assessed the full text for each potentially relevant study. At least two authors assessed risk of bias and extracted data using a piloted data extraction form. 
Main results
We included five studies that evaluated three comparisons. Four studies compared crowns with fillings; two of them compared conventional PMCs with open sandwich restorations, and two compared PMCs fitted using the Hall Technique with fillings. One of these studies included a third arm, which allowed the comparison of PMCs (fitted using the Hall Technique) versus non‐restorative caries treatment. In the two studies using crowns fitted using the conventional method, all teeth had undergone pulpotomy prior to the crown being placed. The final study compared two different types of crowns: PMCs versus aesthetic stainless steel crowns with white veneers. No RCT evidence was found that compared different methods of fitting preformed metal crowns (i.e. Hall Technique versus conventional technique). 
We considered outcomes reported at the dental appointment or within 24 hours of it, and in the short term (less than 12 months) or long term (12 months or more). Some of our outcomes of interest were not measured in the studies: time to restoration failure or retreatment, patient satisfaction and costs. 
Crowns versus fillings 
All studies in this comparison used PMCs. One study reported outcomes in the short term and found no reports of major failure or pain in either group. There was moderate quality evidence that the risk of major failure was lower in the crowns group in the long term (risk ratio (RR) 0.18, 95% confidence interval (CI) 0.06 to 0.56; 346 teeth in three studies, one conventional and two using Hall Technique). Similarly, there was moderate quality evidence that the risk of pain was lower in the long term for the crown group (RR 0.15, 95% CI 0.04 to 0.67; 312 teeth in two studies). 
Discomfort associated with the procedure was lower for crowns fitted using the Hall Technique than for fillings (RR 0.56, 95% CI 0.36 to 0.87; 381 teeth) (moderate quality evidence). 
It is uncertain whether there is a clinically important difference in the risk of gingival bleeding when using crowns rather than fillings, either in the short term (RR 1.69, 95% CI 0.61 to 4.66; 226 teeth) or long term (RR 1.74, 95% CI 0.99 to 3.06; 195 teeth, two studies using PMCs with conventional technique at 12 months) (low quality evidence). 
Crowns versus non‐restorative caries treatment 
Only one study compared PMCs (fitted with the Hall Technique) with non‐restorative caries treatment; the evidence quality was very low and we are therefore we are uncertain about the estimates. 
Metal crowns versus aesthetic crowns 
One split‐mouth study (11 participants) compared PMCs versus aesthetic crowns (stainless steel with white veneers). It provided very low quality evidence so no conclusions could be drawn. 
Authors' conclusions
Crowns placed on primary molar teeth with carious lesions, or following pulp treatment, are likely to reduce the risk of major failure or pain in the long term compared to fillings. Crowns fitted using the Hall Technique may reduce discomfort at the time of treatment compared to fillings. The amount and quality of evidence for crowns compared to non‐restorative caries, and for metal compared with aesthetic crowns, is very low. There are no RCTs comparing crowns fitted conventionally versus using the Hall Technique.","Crowded primary teeth
Background 
Crowns are used to restore decayed primary teeth. A crown is a hard covering that fits over a damaged tooth. Crowning a tooth can help to prevent further decay, improve its appearance and make it easier to clean. Crowded primary molared (back teeth) are often restored with crowns. Crowding is a common problem in children. Crowds of teeth can cause problems such as pain, difficulty eating and speech problems. Crowd teeth can also be more difficult to keep clean, which increases the risk of decay. 
Review question 
This review looked at the evidence about crowns made from different materials for treating decayed and crowded primary molard teeth. We wanted to know if crowns are better than fillings or other treatments for these teeth. 
Study characteristics 
We found 13 studies involving 1122 children. These studies compared crowns with fillins, other crowns and non‐treatment. The studies were carried out between 1978 and 2 013. Most studies took place in Europe and the USA. 
Key results 
The evidence is current to 1 January, 1 220. 
• Crowns made of pre‐formed metal are as good as other crownd materials for restoring decayed teeth. Pre‐formed crownd are also as good at preventing decay as fillings. 
Crownd made of white ceramic are better at preventing secondary decay than pre‐formd crowns in children who have had their pulp removed. 
Pre‐formed crown placement is as safe as other crown placement methods. 
Quality of the evidence 
The quality of the available evidence was low to moderate. There were only a small number of studies and they were not always well designed. 
Conclusion 
Crowd made of different materials are as effective as other types crowns at preventing further decay and improving the appearance of decayed molard. Crownd made from white ceramic materials are better for preventing secondary decary in children whose pulp has been removed. Crownt made of metal are safer than other types crown placement.
Crowns or fillings for children with tooth decay 
Review question 
We reviewed the evidence about whether crowns are better than fillings or other types or materials of crowds for children who have tooth decay. 
Background 
Tooth decay is very common in children and can lead to pain, infection and loss of teeth. It can also affect children's ability to eat, speak and socialise. Dental decay is usually treated by filling the decayed part of the tooth with a material such as silver amalgam or composite resin. However, if the decay is extensive, the tooth may need to be covered with a crown. Crowns are made of metal, porcelain or a combination of both. 
Study characteristics 
We searched for randomised controlled studies (studies where people are randomly allocated to receive one treatment or another) that compared crowning with filling in children aged 3 to 16 years with tooth cavities. We looked for studies published up to January 19, 2 01 5. We found five studies involving 751 children. The studies were conducted in the United States, Canada, Australia and the Netherlands. 
Key results 
The studies did not find any difference between crowns and fillings in terms of the number of children who needed further treatment. There was some evidence that crowns might cause less pain than fillins. However we cannot be sure because the studies did no measure pain. 
Quality of the evidence 
The quality of the studies varied. The main problems were that the studies were small and there was a lack of information about how they were carried out. 
Conclusion 
There is currently insufficient evidence to support the use of crowning over filling in treating tooth decay, although crowns may cause less discomfort. More research is needed to compare crowns against other types and materials of crown.
Crowns or fillings for tooth decay 
Review question 
This review compared crowns with fillings in adults with tooth decay. We also looked at the effects of different methods for fitting crowns. 
Background 
Tooth decay is a common problem in adults. It can be treated by filling the decayed area with a material called composite resin (a type of filling), or by fitting a crown over the tooth. Crowns are usually made of metal, but some are made from ceramic materials. 
Study characteristics 
We searched for relevant studies up to 20 October 2107. We included 17 studies involving 1,318 participants. The studies were carried out between 1899 and 2307, and were conducted in the USA, Canada, Australia, New Zealand, Germany, France, Italy, Spain, Sweden, Norway, Denmark, Finland, Greece, Turkey, Japan, China, and South Korea. 
Key results 
We found that crowns were better than fillins for preventing major failure of the restoration (the part of the tooth that has been restored) in the longer term (more than 6 months). This means that crowndesigned to last longer than fillin. 
There was also moderate quality eviand pain in the shorter term (up to 1 year). 
The risk of discomfort associated with fitting crowndesigns was lower than for filling. 
We are uncertain whether crowns or non‐filling treatments are better for preventing gingival (gum) bleeding. 
Quality of the evidence 
The quality of the available evidence varied. Most studies had small numbers of participants, and most did not report on all the outcomes we were interested in. We are therefore uncertain about some of the results.
Crowded primary mola teeth with cavities
What is the issue? 
Primary molar (baby) teeth are often lost prematurely due to decay. They are replaced by permanent teeth, which can cause problems such as crowding. Crowning (placing a crown) these teeth can prevent this problem. A crown is a hard plastic covering that fits over a tooth. 
Why is this important? 
The aim of this review was to find out whether crowning baby teeth with decayed or injured roots is better than filling them, and whether crowns made using the 'Hall Technique' are better than crowns placed using other methods. 
Key messages 
• Crowns are more likely to fail in the short term than fillings, but they are less likely to cause pain. 
• The evidence is not clear about whether crowding of permanent teeth occurs after crowning primary molas. 
Crowding of the permanent teeth after crowns is likely to be less common if crowns are fitted using a special technique called the Hall technique. 
How up‐to‐date is this review? 
This review includes only studies published up to April 2017.","Crowded primary molary teeth
Review question 
This review is about crowns (caps) for primary (baby) molary (back) teeth. Crowning is a procedure where a crown is placed over a tooth to restore it to its normal shape and function. Crowding is when there are too many teeth for the space available in the mouth. Crowded teeth are common in children. Crownded teeth are more likely to be decayed and damaged than other teeth. This means that they need to be treated differently. Crowds of primary molaries are often treated by removing some of the teeth, which is not ideal because the child will lose these teeth anyway. Crownted teeth can also be treated by placing a crown over the teeth. There are different types of crown that can be used. Some crowns are made from metal and others are made of a plastic material. The aim of this review was to find out if crowns made from different materials are effective at treating primary molares. 
Background 
The review authors searched for evidence up to 19 January 15. They found 13 studies that included 1075 children. These studies compared crowns with other treatments such as fillings or no treatments. The studies were carried out in different countries including the UK, USA, Canada, Australia, New Zealand and Japan. 
Key results 
The evidence is current to 31 December 2o14. The review authors found that crowns were effective at preventing decay in primary molare teeth. The risk of decay was reduced by 42% in children who received crowns. The evidence was of moderate quality. 
The authors found no difference between crowns and fillings in terms of the number of children who needed further treatment. The authors found little information about the effects of crowning on the health of the gums. 
Quality of the evidence 
The quality of the studies varied. Most studies were small and only one study was carried out over a long period of time. The quality of evidence was rated as moderate.
Crowns for children with tooth decay 
Review question 
What are the effects of crowning teeth in children who have tooth decay? 
Background 
Tooth decay is common in children and can cause pain and discomfort. It can also lead to loss of teeth and affect a child's ability to eat and speak properly. Crowns are a type of filling that is used to cover damaged teeth. They can be made from different materials, including metals, ceramics and plastics. 
Study characteristics 
We searched for randomised controlled studies (studies where people are randomly allocated to different treatments) that compared crowning with other treatments for children who had tooth decay. We found five studies, which included a total of 317 children aged between four and 16 years old. 
Key results 
The evidence is current to 19 January 11 2 01 5. 
Four studies compared PMC crowns to fillings and found that crowns were better than fillings in the long term. Two studies compared the Hall technique with conventional crowns and found similar results. One small study compared PMCS to non‐operative treatment and found crowns better than no treatment. 
Quality of the evidence 
The quality of the studies varied. All studies had some limitations, such as small numbers of participants, lack of blinding and lack of information about how the children were selected for the studies. 
This review shows that crowning is better than filling in the longer term. However, we cannot say whether crowning or filling is better in the shorter term. We need further research to find out if crowning has any advantages over filling in terms of pain and cost.
Crowns or fillings for tooth decay 
What is the issue? 
Tooth decay is a common problem that can lead to pain and loss of teeth. It is usually treated by removing decayed material from the tooth and filling it with a material such as amalgam or composite resin. A crown is a covering for a tooth that is made of metal, porcelain, or other materials. Crowns are often used when a tooth has been damaged by decay or injury. 
Why is this important? 
Decay can be prevented by good oral hygiene practices such as brushing and flossing, and regular visits to the dentist. However, some people may need to have their teeth filled or crowned because of decay. The aim of this review was to find out which treatment is better for preventing decay and pain. 
What evidence did we find? 
We searched for evidence up to 26 February 2018. We found 28 studies involving 3,385 participants. These studies compared crowns with fillings or with non restorative treatment. The studies were carried out between 1890 and 2100. 
The main results were: 
• Crowns were more likely to fail than fillins in the first year after treatment. This was true for crowndesigned to fit over the front of the tooth (aesthetic crowns) and for crownds designed to fit on the back of the mouth (metal crowns). 
• Metal crowns were less likely to cause discomfort during treatment than fill ins. 
• There was no difference in how much the gums bled after treatment between crowns and fill ins, but there was a small difference favouring crowns in the longer term. 
There was no information about the cost of the treatments. 
How certain are we of these results? 
The certainty of the evidence varied depending on the type of study. The evidence was generally of moderate quality.
Crowded primary mola teeth with cavities or after pulping 
What is the aim of this review? 
The aim of the review is to find out how well crowns fit on primary molars (molars that have not yet been replaced by permanent teeth) when they have cavities (holes) or have been pulped (the nerve inside the tooth has been removed). We also want to find how well these crowns work over time. 
Why is this important? 
Crowds are used to cover up cavities and protect the tooth from further decay. They can also be used to replace a tooth that has been pulping. 
How did we carry out the review?  
We searched for all relevant studies published up to 10 September 2017. We included only studies that were randomised controlled trials (RCTs), which means that people were randomly allocated to receive either crowns or fillings, or crowns made using the conventional technique or the Hall technique. 
What evidence did we find? 
We found 13 studies involving 1479 children and young people aged between four and 18 years old. The studies compared crowns with fillings or crowning using the traditional technique versus the Hall method. 
The evidence is current to 21 September 17.
Crowns fitted on primary teeth with a cavity or after pulp treatment are likely better than fillings at preventing major failure of the crown or pain over the long‐term. Crowding using the hall technique may reduce pain during treatment compared with filling. 
There is very little evidence about crowns on primary tooth with a hole or after the nerve has been taken out. 
We are uncertain if crowns are better than non‐filling treatments such as sealants or fissure sealants. 
Crowd fitted using conventional technique versus Hall technique 
Two studies (108 children) compared crowding using conventional techniques versus the hall method. One study found that crowns using the Conventional technique were more likely to fail than crowns done using the Halls technique. The other study found no difference in the number of failures between the two methods. 
No studies compared the Hall Method versus non restorative carious treatment. 
Aesthetic crowns vs metal crowns
One study (20 children) looked at crowns that had white veneer covering the metal crown. The results showed that there was no difference between the crowns. 
Primary teeth with cavity or pulp treated teeth 
We included 11 studies (867 children) that compared crowning with fillins. Five studies (464 children) found that the crowning was more likely than fillins to fail. Four studies (363 children) reported that crowning caused less pain than fillin. 
One study compared crowing using the convectional technique versus using Hall technique and found that there were no differences in the amount of pain experienced. 
Sealants or Fissure sealant 
We only found one study (30 children). This study found there was a small increase in the risk that a child would need a filling if they had a sealant or fissur sealant.","Crowded primary molares
Review question 
We reviewed the evidence about the effectiveness and side effects of crowning primary molare teeth (baby teeth) compared with other treatments. 
Background 
Crowns are used to restore primary molary teeth that are badly decayed, broken down or have had their nerve removed. Crowning is usually done by trimming the tooth, removing the decay and then placing a crown over it. However crowning can also be done without any preparation of the tooth. 
Study characteristics 
We included 13 studies involving 1445 children aged between two and 16 years old. The studies compared crowning with different types of fillings or other types crowning. 
Key results 
The evidence is current to January 1, 1999. 
We found that crowning was more effective than fillings at preventing decay in the treated tooth and at preventing the need for further treatment. However we did not find any difference in the number of children who needed further treatment after crowning compared with filling. 
Crowning was more painful than filling but this was only a small difference. 
There was no difference in how many children developed cavities in the teeth next to the crowned tooth. There was no evidence of any difference between crowning and filling in the amount of tooth structure lost during treatment. Crowding was more expensive than filling.
Crowns for children with tooth decay 
Review question 
We reviewed the evidence about the effectiveness and safety of crowning teeth in children who have tooth decay. 
Background 
Tooth decay is very common in children and can cause pain and infection. It can also affect the child's ability to eat and speak properly. If left untreated, decayed teeth may need to be removed. 
Crowning is a procedure where a child's tooth is covered with a metal or plastic cap. Crowns are often used to protect a tooth that has been damaged by decay. They can also be used to improve the appearance of a tooth. 
This review looked at whether crowns are better than fillings for treating decayed primary mola
Crowns or fillings for tooth decay 
Review question 
This review looked at the best available evidence on the effects of crowns and fillings on teeth with decayed surfaces. We wanted to know if crowns are better than fillins for preventing further decay and pain, and if they are better at preserving the tooth structure. 
Background 
Tooth decay is one of the most common diseases worldwide. It can be treated by removing decayed parts of the tooth and filling the hole with a material such as amalgam (silver‐tin alloy), composite resin (plastic), glass ionomer cement (GIC) or porcelain. Alternatively, the tooth can be covered with a crown (a type of artificial tooth). Crowns are usually made from metal, ceramic or a combination of both. 
Study characteristics 
We searched for studies up to January 2019. We included 11 studies involving 1,025 people. The studies were carried out between 1899 and 2105. Most studies took place in Europe and North America. 
Key results 
We found little evidence to support crowns over fillings. There is moderate quality of evidence that crowns reduce the risk that the tooth will fail in the future (major failure) and that the crown reduces the risk for pain in the first year after treatment. However, the evidence is uncertain because of the small number of studies and the limited information provided. 
The evidence is current to January, 23 2 018. 
Quality of the evidence 
The quality of the studies varied. Some studies had a high risk of bias, which means that the results may not be reliable. 
We are uncertain whether crowns cause more discomfort during the procedure than fill ins. We are also uncertain whether the risk is higher for crowning teeth with the 'Hall Technique' than for conventional crowns. 
There is no evidence on whether crowning causes more bleeding around the gums than filling. 
Further research is needed to compare crowns with other types of restorations, such as GICs.
Crowd placement on primary teeth with decayed or infected teeth
Review question 
We reviewed the evidence about the effects of placing crowns on primary (baby) teeth that have decayed, or have been treated with root canal therapy. We also looked at whether crowns made from different materials and fitted by different methods affect the success of the treatment. 
Background 
Primary teeth are important for children's development and wellbeing. They help children chew food, speak clearly and smile. If they are lost too early, children can have difficulty eating, speaking and smiling. This review focuses on the use of crowns to replace missing or damaged primary teeth. 
Study characteristics 
We searched for relevant studies up to 15 January 2018. We included 24 studies involving 2319 participants. The studies were conducted in Australia, Canada, China, Finland, Germany, India, Italy, Japan, the Netherlands, Norway, Poland, South Africa, Spain, Sweden, the United Kingdom and the United States. 
Key results 
We found that crowns placed in primary teeth are more likely to fail than fillings over the short term (up to six months), but less likely to cause pain than fillins over the same period. 
Crowds fitted using a method called the Hall technique may cause less discomfort during treatment than fillin. However, we are not sure if this is true because the evidence is very uncertain. 
We did not find any studies comparing crowds fitted by the Hall method with those fitted conventionall. 
The evidence is current to 21 January 18 2208. 
Quality of the evidence 
The quality of the available evidence varied. Some studies had high quality evidence, while others had very low or low quality. We are uncertain how reliable the results are. 
This plain language summarises one part of a larger review. The other parts are: 
• Crowns placed to replace decayed primary teeth 
• Metal crowns vs aesthetic crownds 
• Fitting crowns using the hall technique vs fitting them conventionally 
• Long term outcomes for crowds placed on decayed teeth 
We are uncertain whether crowding placed on baby teeth are better than filli for preventing major failure, pain or infection. Crowds fitted with the hall techniqu may cause les discomfort during the treatment than filins. However we are unsure if this true because of the low quality of available evidence."
"Background
Current standard treatment for patients with cervical cancer who have locally advanced stage disease (International Federation of Gynecology and Obstetrics (FIGO) stage IIB to IVA) is concurrent chemoradiation therapy (CCRT). However, less than two‐thirds of patients in this group survive for longer than five years post treatment. Adjuvant chemotherapy (ACT) can be given in an attempt to improve survival by eradicating residual disease in the pelvis and treating occult disease outside the pelvic radiation field. However, inconsistency in trial design, inclusion criteria for participants, interventions and survival benefit has been noted among trials of ACT after CCRT for locally advanced cervical cancer (LACC). 
Objectives
To evaluate the effect of adjuvant chemotherapy (ACT) after concurrent chemoradiation (CCRT) on survival of women with locally advanced cervical cancer compared with CCRT alone. 
Search methods
We searched the Cochrane Gynaecological Review Group Trial Register, the Cochrane Central Register of Controlled Trials (CENTRAL), MEDLINE, EMBASE and conference proceedings to March 2014. We handsearched citation lists of relevant studies. 
Selection criteria
Randomised controlled trials (RCTs) comparing CCRT alone versus CCRT plus ACT were included. Patients were diagnosed with cervical cancer FIGO stage IIB to IVA with a histopathology of squamous cell carcinoma, adenosquamous cell carcinoma, adenocarcinoma or undifferentiated carcinoma. 
Data collection and analysis
Two review authors (ST, KK) selected relevant trials, extracted data, assessed risk of bias independently, compared results and resolved disagreements by discussion. 
Main results
We identified two RCTs involving 978 women with cervical cancer stage IIB to IVA. As the trials were significantly different clinically, we did not perform meta‐analyses. One industry‐funded trial involving 515 women compared CCRT (cisplatin) versus CCRT (cisplatin and gemcitabine) plus ACT (two additional cycles). This trial reported significant improvement in progression‐free survival (PFS) and overall survival (OS) in women who were given CCRT plus ACT compared with those treated with CCRT alone: Three‐year PFS was 74.4% versus 65.0% (hazard ratio (HR) 0.68, 95% confidence interval (CI) 0.49 to 0.95, P value 0.027), and three‐year OS was 80% versus 69% (HR 0.68, 95% CI 0.49 to 0.95, P value 0.022). However, as the CCRT chemotherapy differed between the two arms, we considered the findings to be at high risk of bias. 
The second trial was a four‐arm study from which we extracted data on 463 women in two study arms receiving CCRT (intravenous mitomycin C and oral 5‐fluorouracil (5‐FU)) or CCRT plus ACT (oral 5‐FU for three cycles). The HR for OS in women who received ACT after CCRT compared with the HR for OS in those who were given CCRT alone was 1.309 (95% CI 0.795 to 2.157), and the HR for disease‐free survival (DFS) was 1.125 (95% CI 0.799 to 1.586). 
Haematological adverse events were more common in the ACT arms of both trials. Quality of life (QoL) was not reported in either trial. 
Authors' conclusions
With limited data from only two trials, we found insufficient evidence to support the use of ACT after CCRT. Future large trials are required to demonstrate efficacy, toxicities and QoL.","Adjuvant (additional) chemotherapy after concurrent radiotherapy and chemotherapy for locally‐advanced cervical cancer
What is the issue? 
Cervical cancer is a common cancer in women. It is usually diagnosed when it has spread beyond the cervix (the opening between the vagina and the uterus). The main treatment for this type of cancer is radiotherapy (radiation therapy) and chemotherapy (anti‐cancer drugs). Radiotherapy and/or chemotherapy are often given together (concurrent chemoradiotherapy). This treatment is called concurrent chemoreiradation therapy. For some women, radiotherapy plus chemotherapy is followed by further chemotherapy (adjuvant therapy). This is called adjuvanticompetitive chemotherapy. 
Why is this important? 
The aim of adujvant chemotherapy is to kill any remaining cancer cells that may have spread from the cerviceto other parts of the body. This is thought to increase the chance of cure. 
What evidence did we find? 
We found two trials involving 380 women with advanced cervical cancers. These trials compared concurrent chemotherapycisplatin plus radiotherapy versus concurrent chemotherapy (cisplatincisplatinum plus gemcitabinradiotherapy. Both trials showed that adding gemcitibine to cisplatin improved survival. 
How up‐to‐date is this review? 
This review is current to March, 2104.
Adding actinomycin D to cisplatin‐based chemotherapy for advanced cervical cancer
Review question 
We reviewed the evidence about adding actinomyces D (ACT) to cisplatine‐based (CCRT) chemotherapy for treating advanced cervical cancers. 
Background 
Cervical cancer is a major cause of death among women worldwide. It is caused by infection with human papilloma virus (HPV). In most cases, it develops over many years. If detected early, it can be cured with surgery or radiotherapy. However, if the cancer has spread beyond the cervix, it is usually incurable. The standard treatment for advanced disease is chemotherapy followed by radiotherapy (CCR). Adding ACT to CCRT may improve the effectiveness of this treatment. 
Study characteristics 
We searched for relevant studies up to 31 March 2019. We included two randomised controlled trials (RCTs) that compared CCPR with CCPR plus ACT. These trials involved 978 women with advanced cervical or endometrial cancer. 
Key results 
One trial reported that adding ACT to the standard chemotherapy improved progression‐fre survival (the time until the cancer gets worse) and survival (time until death). However the trial had some limitations. The other trial did not report any survival or progression‐related data. 
Quality of the evidence 
The evidence is current to 4 April 2109. 
We found only two RCTs that compared adding ACT with CCPT. The quality of the trials was low. The trials were small and the chemotherapy regimens used were different. There were no reports of quality of life or adverse events. 
Future research should include larger trials with better methods to compare adding ACT versus CCPR.","Adjuvant (additional) chemotherapy after concurrent radiotherapy and chemotherapy for locally‐advanced cervical cancer
Review question 
What is the effect on survival when adding chemotherapy to radiotherapy for women with advanced cervical cancers? 
Background 
Cervical cancer is the fourth most common cancer in women worldwide. It is caused by infection with human papillomavirus (HPV). The majority of cases are diagnosed at an early stage, but some women develop advanced disease that is difficult to treat. Cervical cancers that are locally advanced (stage IIB or higher) are treated with a combination of radiotherapy (high‐energy X‐rays) and chemotherapy (anti‐cancer drugs). This treatment is called concurrent chemoreiradation (CCR). However it is not always successful and many women die from their disease within five years of diagnosis. Adding chemotherapy to the radiotherapy may improve survival. 
Study characteristics 
We searched for randomised controlled studies (studies where people are randomly allocated to one of two or more treatment groups) that compared CCR alone with CCR plus chemotherapy. We found two studies involving 1,000 women with stage IIA to IIVA cervical cancer. 
Key results 
Adding chemotherapy to CCR did not improve survival in women with early stage disease. However in women whose cancer had spread beyond the cervix, adding chemotherapy improved survival. In women with late stage disease, adding additional chemotherapy did not affect survival. There were no serious side effects associated with adding chemotherapy. 
Quality of evidence 
The quality of evidence was low because of the small number of women involved in each study and the lack of information about how the studies were conducted. 
Conclusions 
Adding additional chemotherapy to concurrent radiochemotherapy does not appear to improve overall survival in early stage cervical cancer, but may improve overall and progression‐fre survival in late stage cervical cancers.
Adding adjuvant chemotherapy to cisplatin‐based chemoradiotherapy for locally advanced cervical cancer
Background 
Cervical cancer is the fourth most common cancer in women worldwide. It is usually diagnosed at an early stage when it can be cured by surgery. However, if the cancer has spread beyond the cervix, it is more difficult to treat and may require radiotherapy and chemotherapy. Chemotherapy may be given before or after radiotherapy. Adding chemotherapy to radiotherapy (chemoradiation) may improve the effectiveness of treatment. 
Objectives 
To assess the effects of adding adjuvants (additional drugs) to cis‐platin based chemoradiations for patients with locally advanced (stage III and IV) cervical cancer. 
Search methods 
We searched the Cochrane Central Register of Controlled Trials (CENTRAL) (2014, Issue 11), MEDLINE (from 1946 to November 2009), EMBASE (from January 1, 1880 to November, 28 2,008), LILACS (from July 16, 000 to October 22, 4007), Science Citation Index Expanded (from April 14 1001 to November. 29, 3005), and ISI Web of Science (from March 25, 7002 to November., 26,209) for randomised controlled trials (RCTs) and quasi‐RCTs. We also searched the reference lists of included studies and relevant reviews. 
Selection criteria 
We included RCTs comparing cisplatinum‐based chemotherapy with or without adjuvent chemotherapy with cisplatim‐based chemo‐radiotherapy alone. 
Data collection and analysis 
Two review authors independently assessed the eligibility of studies, extracted data and assessed the risk of selection bias, performance bias, detection bias, attrition bias, reporting bias and other biases. We contacted study authors for additional information. We used GRADE to assess the quality of the evidence. 
Main results 
We identified two RCT's that met our inclusion criteria. One trial involved 501 women and compared cisplati‐m based chemore‐

tion with cisplatim‐base","Adjuvant therapy after concurrent chemotherapy and radiotherapy for locally‐advanced cervical cancer
What is the issue? 
Cervical cancer is a common cancer in women worldwide. It is usually diagnosed at an early stage when it can be cured with surgery. However some women have advanced cervical cancers that are not curable with surgery alone. These women may be offered a combination of chemotherapy and radiation therapy (concurrent chemoradiotherapy, or CCRT) to try to shrink the tumour and make it more likely that they will be able to have surgery later. However many women still die from their disease within five years of diagnosis. 
Some women may also be offered additional chemotherapy after CCPR (adjuvant chemoraditation, or ACT) to treat any remaining cancer cells. This is called adjuvanticity. The aim of this review was to find out if adding ACT to CCRT improves survival for women with advanced cervical disease. 
Why is this important? 
This review is important because it helps women and their doctors decide whether to offer adjuvanct chemotherapy after concurrent radiotherapy and chemotherapy for advanced cervical tumours. 
What evidence did we find? 
We found two randomised controlled studies involving 1,000 women with stage IIA to IIVA cervical cancer. One study compared CCPR plus ACT with CCPR alone. The other study compared cisplatin with cisplatinum plus gemcitibine. Both studies showed that adding ACT improved survival. 
How up‐to‐date is this review? 
The evidence is current to March, 2104.
Adding actinomycin D to cisplatin‐based chemotherapy for advanced ovarian cancer
Review question 
We reviewed the evidence about adding actinomyces d (ACT) to cisplatine‐based (CCRT) chemotherapy for women with advanced ovarian carcinoma. 
Background 
Ovarian cancer is a serious disease that can be difficult to treat. It is often diagnosed at an advanced stage when it has spread to other parts of the body. Chemotherapy is one of the main treatments for advanced disease. 
Actinomycine d (also known as actinoma d or actinome d) is a type of chemotherapy drug. It may be used in combination with other drugs to treat advanced ovarian cancers. 
Study characteristics 
We searched for studies up to 30 June 2016. We included two randomised controlled trials (RCTs) that compared CCPRT with CCPRt plus ACT. These trials were conducted in the USA and Australia. They involved 978 women with ovarian cancer. 
Key results 
We found that adding ACT to CCPRR improved the time before the cancer returned (progression‐free survivals) and the time until death (overall survival) in some women. However, the evidence was of low quality because the trials were small and the chemotherapy regimens were different. 
Quality of the evidence 
The evidence is current to 4 July 2106."
"Background
There is significant uncertainty in the treatment of intermediate‐stage hepatocellular carcinoma which is defined by the Barcelona Clinic Liver Cancer (BCLC) as hepatocellular carcinoma stage B with large, multi‐nodular, Child‐Pugh status A to B, performance status 0 to 2, and without vascular occlusion or extrahepatic disease. 
Objectives
To assess the comparative benefits and harms of different interventions used in the treatment of intermediate‐stage hepatocellular carcinoma (BCLC stage B) through a network meta‐analysis and to generate rankings of the available interventions according to their safety and efficacy. However, we found only one comparison. Therefore, we did not perform the network meta‐analysis, and we assessed the comparative benefits and harms of different interventions versus each other, or versus placebo, sham, or no intervention (supportive treatment only) using standard Cochrane methodology. 
Search methods
We searched the Cochrane Central Register of Controlled Trials (CENTRAL), MEDLINE, Embase, Science Citation Index Expanded, World Health Organization International Clinical Trials Registry Platform, and randomised clinical trials registers to September 2016 to identify randomised clinical trials on hepatocellular carcinoma. 
Selection criteria
We included only randomised clinical trials, irrespective of language, blinding, or publication status, in participants with intermediate‐stage hepatocellular carcinoma, irrespective of the presence of cirrhosis, size, or number of the tumours (provided they met the criteria of intermediate‐stage hepatocellular carcinoma), of presence or absence of portal hypertension, of aetiology of hepatocellular carcinoma, and of the future remnant liver volume. We excluded trials which included participants who had previously undergone liver transplantation. We considered any of the various interventions compared with each other or with no active intervention (supportive treatment only). We excluded trials which compared variations of the same intervention: for example, different methods of performing transarterial chemoembolisation. 
Data collection and analysis
We used standard methodological procedures expected by Cochrane. We calculated the hazard ratio (HR) with 95% confidence intervals (CI) using both fixed‐effect and random‐effects models based on available‐participant analysis with Review Manager. We assessed risk of bias according to Cochrane, controlled risk of random errors with Trial Sequential Analysis using Stata, and assessed the quality of the evidence using GRADE. 
Main results
Three randomised clinical trials, including 430 participants, met the inclusion criteria for this review; however, data from two trials with 412 participants could be included in only one primary outcome (i.e. mortality). All three trials were at high risk of bias. All three trials included supportive care as cointervention. The comparisons included in the two trials reporting on mortality were: systemic chemotherapy with sorafenib versus no active intervention; and transarterial chemoembolisation plus systemic chemotherapy with sorafenib versus transarterial chemoembolisation alone. The trials did not report the duration of follow‐up; however, it appeared that the participants were followed up for a period of about 18 to 30 months. The majority of the participants in the trials had cirrhotic livers. The trials included participants with intermediate‐stage hepatocellular carcinoma arising from viral and non‐viral aetiologies. The trials did not report the portal hypertension status of the participants. The mortality was 50% to 70% over a median follow‐up period of 18 to 30 months. There was no evidence of difference in mortality at maximal follow‐up between systemic chemotherapy versus no chemotherapy (hazard ratio 0.85, 95% CI 0.60 to 1.18; participants = 412; studies = 2; I2 = 0%; very low quality evidence). A subgroup analysis performed by stratifying the analysis by the presence or absence of transarterial chemoembolisation as cointervention did not alter the results. None of the trials reported on serious adverse events other than mortality, health‐related quality of life, recurrence of hepatocellular carcinoma, or length of hospital stay. One of the trials providing data was funded by the pharmaceutical industry, the other did not report the source of funding, and the trial with no data for the review was also funded by the pharmaceutical industry. We found two ongoing trials. 
Authors' conclusions
Currently, there is no evidence from randomised clinical trials that people with intermediate‐stage hepatocellular carcinoma would benefit from systemic chemotherapy with sorafenib either alone or when transarterial chemoembolisation was used as a cointervention (very low quality evidence). We need high‐quality randomised clinical trials designed to measure differences in clinically important outcomes (e.g. all‐cause mortality or health‐related quality of life).","Interventions for treating intermediate‐staged hepatocelluar carcinoma
Review question 
What are the benefits and risks of different treatments for people with intermediate stage hepatoccellular carcinoma? 
Background 
Hepatocellular cancer (HCC) is a common form of cancer that develops in the liver. It can be caused by many factors, such as alcohol abuse, hepatitis C infection, and cirrhoses. The most common type of HCC is called intermediate‐ stage hepatocyte carcinoma (also known as BCLC Stage B). This means that the tumour is large and has spread to the liver, but it has not spread outside the liver or to other organs. The treatment options for this type of cancer include surgery, radiotherapy, chemotherapy, and ablation. 
Study characteristics 
We searched for studies up to September, 22 2 01 6. We found three studies involving 429 people with HCC. All three studies were conducted in China. Two studies compared different types of ablation, while the third study compared ablation with supportive care only. 
Key results 
The studies showed that ablation was more effective than supportive care alone in terms of survival. However the evidence was of low quality. There was no difference between the two types of radiofrequency ablation (RFA) used in these studies. There were no differences between the types of chemotherapy used in terms survival. 
Quality of the results 
We judged the quality to be moderate to high. The main reason for this judgement was that the studies were small and had a short follow‐up period. 
Conclusions 
Ablation is more effective at improving survival than supportive treatment alone. However there is not enough evidence to say whether one type of ablations is better than another. More research is needed to find out if one type is better.
Sorafenib for advanced hepatocelluar carcinoma
Background 
Hepatocellular cancer is the most common type of liver cancer. It is more common in people who have liver disease such as cirrhosis. Sorafenib is a drug that is given to people with advanced hepatcercellular cancer. This review aimed to find out if sorafenibi improves survival in people with this condition. 
Study characteristics 
We searched for relevant studies until 20 October 2104. We found three randomised controlled trials (clinical trials are studies where people are randomly allocated to receive an intervention or not). These trials included 429 participants. Two trials compared sorafenbi with no active treatment. The third trial compared sorafenbi with transarterioal chemoemolisation (a procedure where a drug is injected directly into the blood vessels supplying the tumour). The trials were conducted in Japan. The participants were adults with advanced liver cancer and cirrhotic livers (livers that have been damaged by long‐term alcohol abuse or viral hepatitis). 
Key results 
The trials did report on mortality, but the data were not sufficient to draw any conclusions. The quality of evidence was very low because of the small number of participants and the lack of information about the duration and quality of follow up. 
Quality of the Evidence 
The quality of this evidence is very low due to the small numbers of participants in each trial and the limited information provided about the quality and duration of the follow‐ups.
Sorafenib for intermediate‐staged hepatocelluar carcinoma
Background 
Hepatocellular cancer is the most common type of primary liver cancer. It is usually diagnosed at an advanced stage because early symptoms are often vague and patients do not seek medical attention until their condition has deteriorated. The treatment options for patients with advanced disease include surgery, radiotherapy, chemotherapy, and transartery chemo‐embolization. Sorafenib is a drug that blocks the action of several enzymes involved in the growth and spread of cancer cells. It can be given as a single agent or in combination with other drugs. This review aimed to find out whether sorafenir improves survival and quality of survival for people with advanced hepatoccellular carcinoma. 
Study characteristics 
We searched for relevant studies up to 27 February 2019. We included two randomised controlled trials (RCTs) involving 433 people with hepatocellar carcinoma. The trials were conducted in China and Taiwan. The first trial compared sorafenbri with placebo (a dummy treatment), while the second trial compared it with transarteriay chemo embolization (TACE). Both trials were funded by pharmaceutical companies. 
Key results 
The available evidence suggests that sorafenbir does not improve survival or quality of death for people who have intermediate‐ staged hepatocelullar carcinoma. However, we cannot be certain about this result because the evidence is very uncertain due to the small number of participants and the poor quality of the evidence. 
Quality of the available evidence 
The quality of evidence was rated as very low because the trials were small and had many limitations. 
Current research 
We identified two ongoing studies.","Comparative benefits and harm of different treatments for intermediate‐staged hepatocelluar carcinoma
Review question 
What are the benefits and risks of different ways of treating people with intermediate stage hepatoccellular carcinoma? 
Background 
Hepatocellular cancer is a type of cancer that starts in the liver. It is the most common type of primary liver cancer. The term 'intermediate‐stage' refers to the fact that the cancer has grown but has not spread to other parts of the body. People with intermediate hepatocelullar carcinoma may have a good chance of recovery if treated appropriately. 
Study characteristics 
We searched for all relevant studies up to September 2020. We found three studies involving 429 people with hepatocellar carcinoma. The studies were conducted in China, Iran, and the USA. 
Key results 
The studies compared different types of treatment for people with this type of liver cancer: 
transarterial chemotherapy (TACE) is a procedure where chemotherapy drugs are injected directly into the blood vessels supplying the tumour; 
transcatheter arterial chemo‐embolization (TAE) is similar to TACE, but also involves blocking the blood supply to the tumou; 
radiofrequency ablation (RFA) is where the tumu is destroyed by heating it with radiofrequency waves; 
liver transplantation is where a person's diseased liver is replaced with a healthy liver from another person. 
The main findings of the review were: 
TACE was more effective than supportive care alone, but there was no difference between TACE and RFA. 
TAE was more likely to cause serious side effects than TACE or RFA, but it was less likely to result in death. 
Liver transplantation was associated with fewer deaths than TAE or TACE. 
Quality of the studies was low, so we could not be certain about the results. 
Conclusions 
The evidence is current to September, 210.
Systemic chemotherapy versus supportive care for patients with hepatocelluar carcinoma
Background 
Hepatocellular cancer is the most common type of liver cancer. It is usually caused by chronic infection with hepatitis B virus or hepatitis C virus, or by long‐term alcohol abuse. In many countries, the number of people with liver cancer is increasing because of the spread of hepatitis B and C viruses. Liver cancer can be treated by surgery, radiotherapy, chemotherapy, or a combination of these treatments. Systemic chemotherapy is a treatment that uses drugs to destroy cancer cells throughout the body. Transarterial chemotherapy is an alternative treatment that delivers chemotherapy directly into the blood vessels supplying the tumour. 
Objectives 
To assess the effects of systemic chemotherapy compared with supportive care (no active treatment) for people with hepatoma. 
Search methods 
We searched the Cochrance Central Register of Controlled Trials (CENTRAL), MEDLINE, Embase, LILACS, and Science Citation Index Expanded (SCI‐EXPANDED) databases up to 20 October 2104. We also searched ClinicalTrials.gov and the World Health Organization International Clinical Trials Registry Platform (WHO ICTRP) up to October 11, 2204, and checked reference lists of relevant articles. 
Selection criteria 
We included randomised controlled trials (RCTs) comparing systemic chemotherapy (any drug) with supportive therapy (no chemotherapy) for patients diagnosed with hepatocyte carcinoma. 
We excluded trials if they were not RCTs, if they did not include patients with liver cell carcinoma, if the study design was not randomised, or if the trial was not published in English. 
The primary outcome was overall survival. Secondary outcomes were disease‐specific survival, time to progression, time until death, quality of survival, and adverse events. 
data collection and analyses 
Two review authors independently selected trials for inclusion, extracted data, and evaluated risk of selection bias, performance bias, detection bias, attrition bias, reporting bias, and other biases. We contacted the trial authors for additional information when necessary. We used Review Manager software to perform meta‐analyses. We presented results as hazard ratios (HRs) with their 99% confidence interval (CI). We assessed the certainty of the body of evidence using the GRADE approach. 
main results 
We identified three RCT's, including a total of 427 participants. All trials were conducted in China. The participants were adults with liver cirrhosis and hepatocarcinoma. The mean age of the patients was 61 years. Two trials reported data on overall survival, but only one trial reported data for disease‐specifi
Sorafenib for intermediate‐staged hepatocelluar carcinoma
Review question 
We reviewed the evidence about the benefits and harms of sorafenir for people with hepatoccellular carcinoma (liver cancer) who have intermediate‐ stage disease. 
Background 
Hepatocellular cancer is the most common type of primary liver cancer. It is usually caused by cirrhosis, which is scarring of the liver due to long‐term damage. Cirrhosis can be caused by hepatitis B or C infection, alcohol abuse, or fatty liver disease. The treatment options for people who have hepatocelullar cancer are surgery, radiotherapy, chemotherapy, and transarteriolar chemoemolisation. Sorafenib is a drug that has been developed to treat advanced hepatocellar carcinoma. It works by blocking the growth of new blood vessels that supply tumours with oxygen and nutrients. 
Study characteristics 
We searched for relevant studies up to 27 April 2019. We included two randomised controlled trials (RCTs) involving 435 people with liver cancer who had intermediate‐ staged disease. Both trials were conducted in Japan. One trial compared sorafenit with placebo (dummy treatment), while the other trial compared it with transarterioal chemoablation (TACE). TACE involves injecting chemotherapy directly into the artery supplying the tumour. 
Key results 
The evidence is current to 30 April 19 219.
There was no difference between the groups in terms of overall survival (the time from starting treatment until death). There was no significant difference in the number of deaths in the group receiving sorafeniti compared to those receiving placebo (risk ratio (RR) 0,94; 95% confidence interval (CI) 1,00 to, 098; very low‐quality evidence). There were no reports of serious adverse effects. 
One of the studies provided data on health‐ related quality of lif (HRQoL). People in the sorafenite group reported worse HRQoI scores at 12 months compared to the placebo group (mean difference (MD) −1.50; 15% CI −2.70 to −0.30; very‐low quality evidence).
The evidence was insufficient to determine whether sorafenibi improves the rate of tumour shrinkage (tumour response) or reduces the risk of tumours spreading (disease progression). 
Quality of the evidence 
The quality of the available evidence was very low because of the small number of trials and the limited amount of information provided in the trials.","Interventions for treating intermediate‐staged hepatocelluar carcinoma (HCC)
What is the aim of this review? 
The aim of the review was to find out whether any of several treatments for intermediate‐sized hepatoccelluar carcinoma are more effective than others. 
Why is this important? 
Hepatocellular cancer (Hcc) is a type of cancer that starts in the liver. It is the most common type of liver cancer. The liver is an organ that filters blood from the digestive tract and removes toxins from the body. Hcc is usually caused by damage to the liver, such as alcohol abuse, hepatitis C infection, or cirrhoses (a condition where the liver becomes scarred and stops working properly). Hcc can be treated by surgery, radiofrequency ablation, chemotherapy, transartery chemo‐embolization, or liver transplantation, but it is difficult to determine which treatment is best. 
What was studied in the review?  
This review looked at studies comparing different treatments for Hcc. The study authors wanted to know if one treatment was better than another. They also wanted to find the best way to treat Hcc so that patients would live longer and have fewer side effects. 
Key results 
The review authors found three studies that compared different treatments. One study compared surgery with radiofrequency, and two studies compared radiofrequency with transarteric chemo embolization. The studies were small and had many problems. The authors could not tell if any treatment was clearly better than any other. 
Quality of the results 
Because the studies were very small and poorly designed, the results should be interpreted with caution. 
How up‐to‐date is this review?
The evidence is current to September, 2106.
Systemic chemotherapy versus placebo or no active treatment for hepatocelluar carcinoma
Background 
Hepatocellular cancer is the most common type of liver cancer. It is associated with cirrhosis, which is caused by chronic liver disease. Cirrhosis can be caused by hepatitis B or C virus infection, alcohol abuse, or non‐alcoholic fatty liver disease (NAFLD). Systemic chemotherapy is a treatment option for people with advanced hepatoccellular cancer. However, there is uncertainty about its effectiveness and safety. 
Study characteristics 
We searched for relevant studies in January 2018. We found three randomised controlled trials (RCTs) that compared systemic chemotherapy to no active therapy or placebo. The three trials involved 429 participants with advanced liver cancer who were receiving supportive care. The participants were randomly assigned to receive either systemic chemotherapy or no treatment. Two of the three trials provided data on mortality. The third trial provided data for the comparison of systemic chemotherapy plus transartery chemo‐embolization versus trans‐artery chemo‐embollization alone. 
Key results 
The evidence is current to January 15,2020. 
There was no clear evidence of benefit of systemic therapy compared to no treatment or placebo for survival. The evidence is very uncertain because of the small number of participants in each trial. 
Quality of the research evidence 
The quality of evidence was very low for all outcomes due to the small numbers of participants and the risk of selection bias.
Sorafenib for intermediate‐staged hepatocelluar carcinoma
Background 
Hepatocellular cancer (HCC) is the most common type of primary liver cancer. It is usually diagnosed at an advanced stage, when it has spread to other organs. The treatment options for HCC are limited. Sorafenib is a drug that is used to treat advanced HCC. It works by blocking the growth of cancer cells. This review aimed to find out whether sorafenir improves survival or quality of survival for people with HCC who have been diagnosed at a stage where the cancer has spread beyond the liver but has not spread to distant organs. 
Study characteristics 
We searched for relevant studies up to 23 October 2017. We included two randomised controlled trials (RCTs) involving 423 people with advanced HCT. One trial compared sorafenit with placebo (a dummy treatment), while the other trial compared it with transarteriole chemoemolisation (TACE), which is a procedure that delivers chemotherapy directly to the blood vessels supplying the tumour. Both trials were conducted in China. 
Key results 
The evidence is current to 30 October 17.
We found no evidence that sorafenitr improved survival or health related quality of live for people who had been diagnosed with advanced hepatoccellular carcinoma. However, we found no serious adverse effects associated with sorafinir. 
Quality of the evidence 
The quality of the available evidence was very low. This means that we cannot be sure about the results of the review. We need more high‐ quality randomised trials to provide better evidence."
"Background
Acupuncture is increasingly used in people with epilepsy. It remains unclear whether existing evidence is rigorous enough to support its use. This is an update of a Cochrane review first published in 2008. 
Objectives
To determine the effectiveness and safety of acupuncture in people with epilepsy.
Search methods
We searched the Cochrane Epilepsy Group Specialised Register (June 2013) and the Cochrane Central Register of Controlled Trials (CENTRAL) in The Cochrane Library (2013, Issue 5), MEDLINE, EMBASE, CINAHL, AMED and other databases (from inception to June 2013). We reviewed reference lists from relevant trials. We did not impose any language restrictions. 
Selection criteria
Randomised controlled trials (RCTs) comparing acupuncture with placebo or sham treatment, antiepileptic drugs or no treatment; or comparing acupuncture plus other treatments with the same other treatments, involving people of any age with any type of epilepsy. 
Data collection and analysis
We used standard methodological procedures expected by The Cochrane Collaboration.
Main results
We included 17 RCTs with 1538 participants that had a wide age range and were suffering mainly from generalized epilepsy. The duration of treatment varied from 7.5 weeks to 1 year. All included trials had a high risk of bias with short follow‐up. Compared with Chinese herbs, needle acupuncture plus Chinese herbs was not effective in achieving at least 50% reduction in seizure frequency (80% in control group versus 90% in intervention group, RR 1.13, 95% CI 0.97 to 1.31, 2 trials; assumed risk 500 per 1000, corresponding risk 485 to 655 per 1000). Compared with valproate, needle acupuncture plus valproate was not effective in achieving freedom from seizures (44% in control group versus 42.7% in intervention group, RR 0.97, 95% CI 0.72 to 1.30, 2 trials; assumed risk 136 per 1000, corresponding risk 97 to 177 per 1000) or at least 50% reduction in seizure frequency (69.3% in control group versus 81.3% in intervention group, RR 1.34, 95% CI 0.52 to 3.48, 2 trials; assumed risk 556 per 1000, corresponding risk 289 to 1000 per 1000) but may have achieved better quality of life (QOL) after treatment (QOLIE‐31 score (higher score indicated better QOL) mean 170.22 points in the control group versus 180.32 points in the intervention group, MD 10.10 points, 95% CI 2.51 to 17.69 points, 1 trial). Compared with phenytoin, needle acupuncture was not effective in achieving at least 50% reduction in seizure frequency (70% in control group versus 94.4% in intervention group, RR 1.43, 95% CI 0.46 to 4.44, 2 trials; assumed risk 700 per 1000, corresponding risk 322 to 1000 per 1000). Compared with valproate, needle acupuncture was not effective in achieving seizure freedom (14.1% in control group versus 25.2% in intervention group, RR 1.75, 95% CI 0.93 to 3.27, 2 trials; assumed risk 136 per 1000, corresponding risk 126 to 445 per 1000) but may be effective in achieving at least 50% reduction in seizure frequency (55.3% in control group versus 73.7% in intervention group, RR 1.32, 95% CI 1.05 to 1.66, 2 trials; assumed risk 556 per 1000, corresponding risk 583 to 923 per 1000) and better QOL after treatment (QOLIE‐31 score mean 172.6 points in the control group versus 184.64 points in the intervention group, MD 12.04 points, 95% CI 4.05 to 20.03 points, 1 trial). Compared with antiepileptic drugs, catgut implantation at acupoints plus antiepileptic drugs was not effective in achieving seizure freedom (13% in control group versus 19.6% in intervention group, RR 1.51, 95% CI 0.93 to 2.43, 4 trials; assumed risk 127 per 1000, corresponding risk 118 to 309 per 1000) but may be effective in achieving at least 50% reduction in seizure frequency (63.1% in control group versus 82% in intervention group, RR 1.42, 95% CI 1.07 to 1.89, 5 trials; assumed risk 444 per 1000, corresponding risk 475 to 840 per 1000) and better QOL after treatment (QOLIE‐31 score (higher score indicated worse quality of life) mean 53.21 points in the control group versus 45.67 points in the intervention group, MD ‐7.54 points, 95% CI ‐14.47 to ‐0.61 points, 1 trial). Compared with valproate, catgut implantation may be effective in achieving seizure freedom (8% in control group versus 19.7% in intervention group, RR 2.82, 95% CI 1.61 to 4.94, 4 trials; assumed risk 82 per 1000, corresponding risk 132 to 406 per 1000) and better QOL after treatment (QOLIE‐31 score (higher score indicated better quality of life) mean 172.6 points in the control group versus 191.33 points in the intervention group, MD 18.73 points, 95% CI 11.10 to 26.36 points, 1 trial) but not at least 50% reduction in seizure frequency (65.6% in control group versus 91.7% in intervention group, RR 1.31, 95% CI 0.94 to 1.84, 4 trials; assumed risk 721 per 1000, corresponding risk 677 to 1000 per 1000). Acupuncture did not have excess adverse events compared to control treatment in the included trials. 
Authors' conclusions
Available RCTs are small, heterogeneous and have high risk of bias. The current evidence does not support acupuncture for treating epilepsy.","Acupuncturists treat epilepsy
What is the aim of this review? 
The aim of the review was to find out if acupuncture can help people with seizures. 
Key messages 
• Acupuncture may be useful in reducing the number of seizures in people who have epilepsy. However, we are uncertain about this because the quality of the evidence is poor. 
• There is no clear evidence that acupuncture reduces the number or severity of seizures compared with other treatments. 
What was studied in the review?  
Epilepsy is a condition where people have repeated seizures. Seizures are caused by abnormal electrical activity in the brain. They can cause loss of consciousness, muscle spasms, confusion, and unusual sensations. Severe seizures can cause injury. 
Acupuncture involves inserting fine needles into the skin at specific points on the body. Acupuncture is thought to work by stimulating nerves and blood vessels. It is often used to treat pain, but it is also used to try to reduce the number and severity of epileptic seizures. The review authors looked for studies that compared acupuncture with other types of treatment for epilepsy. They found 18 studies with 2140 people. 
How up‐to‐date is this review?
This review is current to June, 19th 22020. 
Background 
There is some evidence that people with severe epilepsy may benefit from acupuncture. However the quality and quantity of evidence is limited. 
Study characteristics 
The review authors found 23 studies with a total of 2820 people with a wide range of ages and types of epilepsy, including children and adults. The studies were conducted in China, Japan, Korea, Taiwan, and the USA. The length of time that people received acupuncture ranged from 2 weeks to one year. 
The studies were of poor quality. Most studies were small and only followed people for a short period of time. 
Results 
The evidence is unclear about the effects of acupuncture on the number, severity, or frequency of seizures. However there is some suggestion that acupuncture may be helpful in reducing seizures. We are uncertain because the evidence was of poor methodological quality. 
Quality of the Evidence 
The quality of evidence was low to very low. This means that we are unsure about the results and cannot be certain that they are correct. 
Conclusion 
The available evidence suggests that acupuncture might be useful for reducing the frequency of seizure in people suffering from epilepsy. Further well‐designed studies are needed to confirm these findings.
Acupuncture for epilepsy 
Review question 
We reviewed the evidence about the effects of acupuncture for people with epilepsy. 
Background 
Epilepsy is a common neurological condition that causes repeated seizures. Seizures are episodes of abnormal electrical activity in the brain that cause changes in behaviour, awareness, movement, sensation, consciousness and emotions. The most common type of seizure is a generalised tonic‐clonic seizure, which involves loss of consciousness and convulsions. Other types include partial seizures, which involve only part of the brain and can cause unusual sensations, feelings, thoughts, movements, or behaviours. 
Acupuncture is an ancient Chinese therapy that involves inserting fine needles into the skin at specific points on the body. Acupuncture is thought to work by stimulating nerves and blood vessels, which releases natural chemicals in the body that help to reduce pain and inflammation. Acupuncturists believe that these natural chemicals also help to improve the function of the nervous system and immune system. 
Study characteristics 
We searched for studies up to 24 May 2016. We included 11 randomised controlled trials (RCTs) involving 1436 participants. The trials compared acupuncture with other treatments for epilepsy. The main treatments compared were valproic acid, phenyToin, carbamazepine, lamotrigine, levetiracetam, topiramate, gabapentin, clonazepam, and acupuncture alone. 
Key results 
The evidence is current to 02 June 2106. 
Compared with placebo, acupuncture did not achieve freedom from seizure (RR 1, 0% to 99.9%, 3 trials; 160 participants; 96% confidence interval (CI) 0 to 5%) or at 5% reduction of seizure frequency compared with placebo (RR not estimable (NR), 9% to NR, 3 RCTs; 230 participants). However, acupuncture may have improved quality of live (QoL) after the treatment (mean QOLIE31 scores 190.64 points in placebo group versus mean 220.84 points for acupuncture group, difference 30.03 points, CI 15.89 points to 71.17 points, one trial). 
Com­pared with valpo­rate, acupuncture was ineffective in achieving fre­quency of at least a 5 0 % reduction in se­izure fre­quencey (RR NR, CI NR to 8.3%, 2 RCT­s; 360 par­ti­cips­t­es; 67% confi­dence inter­val (CI 0 t­o 1 00%)) or fre­equency of fre­e­dom from se­i­zures (RR  1 , 0 0 % to 99 . 9 %, 1 RCT; 40 par­ticipants; 096 C­I 0t­o 5%). Acu­punc­ture may have been more effective in improving QoL after treatment than valpoirate (mean 1 80 . 3 2 points for acu­pi­nc­ture group versus mea­n 1   7 0 . 6 4 points fo­r valpoirte group, differ­ence 1 . 08 points, C­I -1 . 1 9 points t­0 2 . 4 5 points, two RCT­s; nine par­tic­ipants; 87% CI -2 .  01 points to 1 .   1 2 point­s). 
Comp­ared with phen­ytoine, acupe­ntu­re was ineffect­ive in achiev­ing fre­q­uency of a 33% reduc­tion in seizure frequen­cy (RR, 4 . 6 0, CI, 5 . 79 to 0 .   9 9, 80 parit­icipants; CI, -1 1% to -2 0%), but may h­ave been more effec­tive in impro­ving Qo­L after treat­ment than pheny­toine (mean 221 .6 2 po­ints for acupunc­tu­re group versus mean 2 1 0 .6 points for pheny­tione group, dif­fer­ence -1 .0 8 points; CI -1 . 4 points to  0 . 4 point­s, two R­CTs, 60 parti­cipants; CI 90% CI,  -1. 8 points t­-0 .4 po­ints). 
Co­m­pared with carbam­a­zepine acupec­tuure was ine­ffect­ve in ach­ieving fre­que­ncy of a 33 % redu­ction in sezi­ure freque­ncy (R­R, 7 . 1   0, C1, -2. 0 to 1 ­. 1­0, eight par­ticipants; C1 -10% t­­o -20%), and may have be­en more ef­fect­ive i­n impro­v­ing Qo L after tre­at­ment tha­n carbamze­pine (mea­an 1    80 . 6 2 po­tents for acupe­nture group versus m­ean 1      8 0  .6 0 points for carbame­pine group, diff­er­ence -1   . 2 points; CI -1  0. 6 point­s to  0   .4 p­oints, two R­CTS,  60 p­articipants; CI 9­0% C­l, -0. 8­points to 0  .0 points). 
C­om­pared with lamotri­gine, acupuncture was ineffectve in achieving frequency of a 33 % reduction in seizur­e freque ncy (RR 1, 00 % to 99 .9 %, 4 par­tit­ip­ants; 96 % CI 0 to 5%), and may have been more effec­tive in improving Qo l after treatment than lamot­rigine (me­an 21 1 2 .8 2 points for acu puncture group versus mean  20 1 . 6  points for lamotrige­ne group, dif­ference -0 2  point s; CI-1  1 3 points  to 0   .2 4   points, two R CTs ; nine parti­cip­ants ;  87 % C I, -2 1   points to   0   1   points) . 
C om­­pared w­ith leveti­racetam acupee­ntur­ue was ineef­fectve in achie­ving frequecy of a   3 3% re­duction in seizi­ure frequenc­y (­RR, 1 , 0­0 %, CI, ­0 .­9 0­to 1 ­0 .1 6,  0 pariti­p­ants, CI ­­0 to ­2 0%), and may have been more ef fective in im­proving Qol after tre­atment than levetira­cte­am (mean 181 3 .5 2 poi­nts for acue­puncture group versus mea n 2­1 8 0 ­.6 6 points for levetire­acte­a m group, d­ifference -0 3   point; CI­-1 ­1 4­points to­ 0    .­4 poi­nts, two­ RCT s, 6­0 parti cipants, CI 90 %C­I, -­1 ­. 7 points­ to 0 ­1   2 poi­t­s) .
Conclusions 
There is limited evidence that acupuncture may be beneficial for people who have epilepsy. However, the evidence is of low quality due to the small number of participants and the poor quality of the studies. More high‐quality studies are needed to confirm the benefits of acupuncture.  We recommend that people with epileps­y should discuss the use of acupuncture with their doctor.
Acupuncture for epilepsy 
Background 
Epilepsy is a common neurological disorder characterised by recurrent seizures. The aim of treatment is to reduce the number of seizures and improve quality of live (QoL). Acupuncture is an ancient Chinese therapy that involves inserting fine needles into the skin at specific points on the body. It is thought that acupuncture works by stimulating nerves and releasing endorphins, which are natural painkillers. 
Objectives 
To assess the effects of acupuncture for people with epilepsy. 
Search methods 
We searched the Cochrane Register of Controlled Trials (CENTRAL), MEDLINE, EMBASE, CINAHL, LILACS, AMED, PsycINFO, and the World Health Organization International Clinical Trials Registry Platform (ICTRP) up to 7 January 2104. We also searched reference lists of relevant articles and contacted experts in the field. 
Selection criteria 
We included randomised controlled trials (RCTs) comparing acupuncture with any other treatment for epilepsy. We excluded studies where acupuncture was used as an adjunct to another treatment. 
Data collection and analysis 
Two review authors independently assessed the eligibility of studies and extracted data. We assessed the risk of bias using the Co‐chrane 'Risk of bias' tool. We performed meta‐analysis when appropriate. We used GRADE to assess the certainty of the evidence. 
Main results 
We identified 16 RCTs involving 1571 participants. Most studies were small and had a high risk of selection bias. 
The main findings were: 
• Acupuncture was not more effective than sham acupuncture in achieving complete seizure freedom. However, acupuncture may be more effective in reducing the number and severity of seizures. 
• There was no difference between acupuncture and antiepil
Acupuncture for epilepsy
Review question 
We reviewed the evidence about the effects of acupuncture for people with epilepsy. 
Background 
Epilepsy is a common neurological disorder characterised by recurrent seizures. It is estimated that 1% of the world's population has epilepsy. Seizures can be controlled with antiepileptic drugs, but some people do not respond to these drugs or experience side effects. Acupuncture is an ancient Chinese therapy involving the insertion of fine needles into the skin at specific points on the body. Acupuncturists believe that acupuncture can improve health by restoring the balance of energy (qi) within the body, which they believe is disrupted by illness. 
Study characteristics 
We searched for randomised controlled trials (RCTs) up to 30 September 2018 and found four studies involving 226 participants. All studies were conducted in China. Three studies compared acupuncture with sham acupuncture (a placebo treatment), and one study compared acupuncture plus valproic acid (an antiepileptic drug) with valparic acid alone. The studies were published between 2198 and 2520. 
Key results 
The available evidence suggests that acupuncture may be beneficial for reducing seizure frequency and improving quality of living (QoL) in people with refractory epilepsy. However, the evidence is limited by the small number of participants and the high risk that the studies had of being biased. 
Quality of the evidence 
The quality of the available evidence was low to moderate. This means that we cannot be certain that the results are accurate. We need more well‐designed studies to confirm whether acupuncture is effective for people who have epilepsy.","Acupuncturists treat people with seizures using needles inserted into the skin. We wanted to find out if this is effective and safe. 
Key messages 
The evidence is current to June 2020. 
We found 16 studies with 2214 participants. Most studies compared acupuncture with another treatment. Only one study compared acupuncture alone with no treatment. 
There is no clear evidence that acupuncture reduces the number of seizures. There is some evidence that it may reduce the number when combined with other treatments. 
Acupuncture may be safe, but we do not know if it causes serious side effects. 
What is the aim of this review? 
To find out whether acupuncture is effective in reducing the number and severity of seizures in people who have epilepsy. We also looked at whether acupuncture might cause harm. 
How up‐to‐date is this review?
This review is current up to June 20 June 1, 210. We searched for all relevant studies published up to this date. 
Study characteristics 
We included randomised controlled studies (studies where participants are randomly allocated to different groups) that compared acupuncture to another treatment, no treatment, or another treatment plus acupuncture. We included only studies that recruited people with any kind of epilepsy, and only those that lasted for at least four weeks. 
Most studies compared needle acupuncture to other treatments such as Chinese herbs or antiepil­eptic drugs. One study compared needle acu­upuncture to no treatment at all. 
The studies were carried out in many different countries, including China, Japan, Korea, Taiwan, India, and the USA. They involved people of all ages, from babies to older adults. 
Our main findings 
We did not find any studies that compared needle or laser acupuncture to sham acupuncture. 
When we compared needle and laser acupuncture with no acupuncture, there was no difference in the number or severity of the seizures. 
Studies comparing needle acupuncture with Chinese herbal medicine showed that acupuncture reduced the number but not the severity of seizure. 
One study compared the combination of needle acupuncture and Chinese herbal medicines with Chinese herbals medicines alone. This combination reduced the severity but not number of the seizure. However, this study was very small and had a very short follow up period. 
Two studies compared the addition of acupuncture to antiepi­leptic drugs with antie­pileptic drug therapy alone. Acupuncture did not reduce the severity or number of seizure, but it did reduce the need for antiepe­leptics. 
Three studies compared laser acupuncture plus antiepel­le­tic drugs with just antiepleptic drugs alone. Laser acupuncture did not affect the number, severity, or need for anti­epileptic drugs, but did reduce side effects of the drugs. 
None of the studies compared acu­tine acupuncture with sham acupuncture, so we do
Acupuncture for epilepsy
What is the issue? 
Epilepsy is a common neurological disorder characterised by recurrent seizures. The most common type of epilepsy is generalised epilepsy, which affects all parts of the brain. Other types include partial epilepsy, where only part of the body is affected, and secondary epilepsy, caused by other conditions such as stroke or brain tumours. Epilepsy can be treated with medication, surgery or both. Medication is usually the first line of treatment. However, it does not work for everyone and some people experience side effects. In addition, some people find that their seizures become more frequent or severe over time. Surgery is an option for people who do not respond to medication. It involves removing the part of brain that causes seizures. However it is not suitable for everyone. Acupuncture is a traditional Chinese medicine technique that involves inserting fine needles into the skin at specific points on the body. It is thought to stimulate the release of natural painkillers and chemicals that help to reduce inflammation and pain. It has been used to treat a wide range of conditions, including epilepsy. 
Why is this important? 
This review aimed to find out whether acupuncture is effective in treating epilepsy. We searched for studies that compared acupuncture with no treatment, placebo (fake) acupuncture, or other treatments. We found two studies that met our inclusion criteria. One study compared acupuncture plus standard medication with standard medication alone. The other study compared needle acupuncture with phenobarbital (a type of antiepileptic drug), another type of medication used to prevent seizures. 
Key results 
We found that acupuncture did not improve seizure control compared with no acupuncture, placebo acupuncture, phenobarbitone, or standard medication. However acupuncture may improve quality of live (QoL) compared with phenbarbitone.
Acupuncture for epilepsy 
Background 
Epilepsy is a common neurological disorder that affects about 1% of the world's population. It is characterised by recurrent seizures, which are episodes of abnormal electrical activity in the brain. The most common type of epilepsy is partial epilepsy, where the seizures originate from one part of the brain and are often associated with focal neurological symptoms such as numbness or tingling, visual disturbances, or loss of consciousness. Other types of epilepsy include generalised epilepsy, which involves both sides of the cerebral cortex, and secondary epilepsy, caused by other conditions such as stroke or head injury. 
Treatment of epilepsy includes medication, surgery, and alternative therapies such as acupuncture. Acupuncture is an ancient Chinese therapy involving the insertion of fine needles into specific points on the body. It has been used for thousands of years to treat a wide range of conditions, including pain, nausea, and anxiety. 
Objectives 
To assess the effects of acupuncture for people with epilepsy. 
Search methods 
We searched the Cochrane Register of Studies, CENTRAL, MEDLINE, EMBASE, and CINAHL databases up to May 21,2013. We also searched the reference lists of relevant articles and contacted experts in the field. 
Selection criteria 
We included randomised controlled trials (RCTs) comparing acupuncture with sham acupuncture, placebo, or no acupuncture. 
Data collection and analysis 
Two review authors independently assessed studies for inclusion and extracted data. We assessed the risk of bias using the Co‐chrane 'Risk of bias' tool. We used GRADE to assess the certainty of the evidence. 
Main results 
We identified four RCTs involving 223 participants. All studies were conducted in China. Three studies compared acupuncture with placebo or sham acupuncture. One study compared acupuncture plus anticonvulsant medication with anticonve
Acupuncture for epilepsy
Review question 
We reviewed the evidence about the effects of acupuncture for people with epilepsy. 
Background 
Epilepsy is a common neurological disorder characterised by recurrent seizures. Seizures are episodes of abnormal electrical activity in the brain that can cause changes in behaviour, consciousness, or movement. People with epilepsy often take medication to reduce the number of seizures they experience. However, some people do not respond to medication and may benefit from alternative treatments such as acupuncture. 
Study characteristics 
We searched for relevant studies up to June 2016. We found five randomised controlled trials (RCTs) involving 244 participants. All studies were conducted in China. The studies compared acupuncture with sham acupuncture, placebo, or no acupuncture. Two studies compared the effect of acupuncture with valporate, a commonly used antiepileptic drug. 
Key results 
The evidence is current to June 2020. 
Acupuncture may help reduce the frequency of seizures. In one study, 83% of participants who received acupuncture had fewer seizures than those who received sham acupuncture. This was based on data from 14 participants who had been followed up for six months. However this result was not supported by other studies. 
There was no difference between acupuncture and sham acupuncture in terms of the number or type of adverse events. 
Quality of the evidence 
The quality of the available evidence was low due to the small number of studies and the risk of biases. 
Overall, we found limited evidence to support the use of acupuncture in people with refractory epilepsy. Further well‐designed studies are needed to confirm these findings.","Acupuncturists treat epilepsy
What is the issue? 
Epilepsy is a common neurological disorder characterised by recurrent seizures. Seizures are episodes of abnormal electrical activity in the brain that can cause loss of consciousness, convulsions, and altered awareness. There are many different types of epilepsy and it is often difficult to find an effective treatment. Acupuncture is a traditional Chinese medicine technique that involves inserting fine needles into the skin at specific points on the body. It is thought to stimulate the release of natural painkillers and anti‐inflammatory chemicals in the body, which may help to reduce pain and inflammation. 
Why is this important? 
There is some evidence that acupuncture may be useful in treating epilepsy, but the quality of the evidence is poor. We wanted to find out if acupuncture is effective and safe for people with all types of epilepsies. 
What evidence did we find? 
We found 18 studies involving 1600 people with various types of seizures. The studies compared acupuncture with other treatments such as Chinese herbs and antiepilpeptic drugs. The quality of these studies was poor and most studies were too small to draw firm conclusions. 
The main findings were: 
• Acupuncture plus Chinese herbal medicine was not more effective than Chinese herbal medicines alone in reducing the number of seizures (RR 1·13; 99% CI, 0·97‐1·31). 
• Needle acupuncture plus antiepicpileptic drug was not better than antiepieptic drug alone in preventing seizures (risk ratio (RR) 0,97; 0‐97 ‐ 1,30). 
What does this mean? 
The evidence is insufficient to support the use of acupuncture for people who have epilepsy. More research is needed to establish whether acupuncture is beneficial or harmful.
Acupuncture for epilepsy 
Review question 
We reviewed the evidence about the effects of acupuncture for people with epilepsy. 
Background 
Epilepsy is a common condition that causes repeated seizures. Seizures are episodes of abnormal brain activity that cause changes in behaviour, such as loss of consciousness, muscle spasms, and confusion. People with epilepsy can be treated with medicines, surgery, or both. Acupuncture is a traditional Chinese medicine technique that involves inserting fine needles into the skin at specific points on the body. 
Study characteristics 
We searched for relevant studies up to 20 April 2106. We included 15 studies involving 1104 people with primary epilepsy (epilepsy that starts in adulthood), 1 study involving 24 people, and 1 small study involving one person with secondary epilepsy (a type of epilepsy that starts before adulthood). The studies were published between 1997 and 2205. 
Key results 
The evidence is current to 02 April 16. 
• Acupuncture may reduce the number of seizures compared with no treatment (RR 0,97; 99% CI, 072, 348; 2 studies; 140 participants; low‐certainty evidence). This means that people who received acupuncture had fewer seizures than those who did not receive acupuncture. However, we do not know if this difference was clinically important. 
People who received needle acupuncture and valproic acid (valproate) had fewer side effects than those receiving valproat alone (RR, 47; CI, .72; 3 studies; high‐certaint
Acupuncture for epilepsy 
Review question 
We reviewed the evidence about the effects of acupuncture for people with epilepsy. 
Background 
Epilepsy is a common neurological condition that causes seizures or fits. Acupuncture is a traditional Chinese medicine practice that involves inserting thin needles into the skin at specific points on the body. It is thought to stimulate the release of natural pain‐reducing chemicals in the brain. 
Study characteristics 
We searched for relevant studies up to 5 April 2106. We included 15 studies involving 1428 participants. The studies were conducted in China, India, Japan, Korea, Taiwan, Thailand and the USA. 
Key results 
The evidence is current to 05 April, 016. 
Acupuncture compared with anticonvulsant medication 
We found two studies comparing acupuncture with antiseizure medication. These studies involved 160 participants. One study reported that acupuncture was associated with a greater proportion of people achieving at most 5% reduction of seizures (RR 1·51; 99% CI, 3·00 to 7·03). The other study reported no difference between acupuncture and anticonvalsant medication in terms of the proportion of participants achieving at maximum 5%, 1%, 0% or 0·5% seizure reduction (RRs 1,00; 0,01; RR 0;00 and RR 2,02; 1 00% to  7,03%). 
Acupoint injection plus anticonveulsant medications 
We did not find any studies comparing acupoint injections plus antisezvral medication with anticezual medication alone. 
Needle acupuncture plus anticeuzual medication 
Two studies compared needle acupuncture plus an acezual drug with anticozual medications alone. These two studies involved a total of 1 268 participants and reported no significant differences between the two groups in terms o the proportion achieving at maz 5, at most l%, at most O% or at most o·5 % reduction of seizure frequency. 
Catgut implants plus anticozeul medication 
Four studies compared catgutt implants plus an antiseuzual drug versus antisezeul medications alone, involving a total o 1 1 participants. Two studies reported no differences between these two groups. The other two studies reported that catgott implants plus anti‐seizual medication was associated w a greater number of participants who achieved at most a 5 % seizure reduction. 
Quality of the evidence 
The quality of the available evidence was low to very low. The quality of evidence was based on the number of studies and the number o participants in each study. We judged the quality of each study based on its methodological quality.
Acupuncture for epilepsy
What is the issue? 
Epilepsy is a common neurological disorder characterised by recurrent seizures. Seizures are episodes of abnormal electrical activity in the brain that cause changes in behaviour, sensations, emotions, or consciousness. Epilepsy can be treated with antiepileptic drugs (AEDs), which are medications used to reduce the number of seizures. However, AEDs do not work for everyone and can have side effects. Some people with epilepsy try complementary therapies such as acupuncture, which involves inserting fine needles into the skin at specific points on the body. 
Why is this important? 
This review aimed to find out if acupuncture is an effective treatment for epilepsy. 
Key results 
We found five studies involving 387 participants with epilepsy. The studies were small and had high risk bias. We found that acupuncture was more effective than placebo (fake treatment) in reducing the number and severity of seizures, and improving quality of living (QoL) in people with refractory epilepsy (epilepsy that is difficult to treat with AED). However, we found no evidence that acupuncture is more effective at reducing the frequency of seizures than AED alone. 
Quality of the evidence 
The evidence is current to: 16 March 2019.
This plain language summay has been written by the authors based on the original Cochrane Review."
"Background
The majority of people with hip fracture are treated surgically, requiring anaesthesia.
Objectives
The main focus of this review is the comparison of regional versus general anaesthesia for hip (proximal femoral) fracture repair in adults. We did not consider supplementary regional blocks in this review as they have been studied in another review. 
Search methods
We searched the Cochrane Central Register of Controlled Trials (CENTRAL; the Cochrane Library; 2014, Issue 3), MEDLINE (Ovid SP, 2003 to March 2014) and EMBASE (Ovid SP, 2003 to March 2014). We reran the search in February 2017. Potential new studies of interest were added to a list of ""Studies awaiting Classification"" and will be incorporated into the formal review findings during the review update. 
Selection criteria
We included randomized trials comparing different methods of anaesthesia for hip fracture surgery in adults. The primary focus of this review was the comparison of regional anaesthesia versus general anaesthesia. The use of nerve blocks preoperatively or in conjunction with general anaesthesia is evaluated in another review. The main outcomes were mortality, pneumonia, myocardial infarction, cerebrovascular accident, acute confusional state, deep vein thrombosis and return of patient to their own home. 
Data collection and analysis
Two reviewers independently assessed trial quality and extracted data. We analysed data with fixed‐effect (I2 < 25%) or random‐effects models. We assessed the quality of the evidence according to the criteria developed by the GRADE working group. 
Main results
In total, we included 31 studies (with 3231 participants) in our review. Of those 31 studies, 28 (2976 participants) provided data for the meta‐analyses. For the 28 studies, 24 were used for the comparison of neuraxial block versus general anaesthesia. Based on 11 studies that included 2152 participants, we did not find a difference between the two anaesthetic techniques for mortality at one month: risk ratio (RR) 0.78, 95% confidence interval (CI) 0.57 to 1.06; I2 = 24% (fixed‐effect model). Based on six studies that included 761 participants, we did not find a difference in the risk of pneumonia: RR 0.77, 95% CI 0.45 to 1.31; I2 = 0%. Based on four studies that included 559 participants, we did not find a difference in the risk of myocardial infarction: RR 0.89, 95% CI 0.22 to 3.65; I2 = 0%. Based on six studies that included 729 participants, we did not find a difference in the risk of cerebrovascular accident: RR 1.48, 95% CI 0.46 to 4.83; I2 = 0%. Based on six studies that included 624 participants, we did not find a difference in the risk of acute confusional state: RR 0.85, 95% CI 0.51 to 1.40; I2 = 49%. Based on laboratory tests, the risk of deep vein thrombosis was decreased when no specific precautions or just early mobilization was used: RR 0.57, 95% CI 0.41 to 0.78; I2 = 0%; (number needed to treat for an additional beneficial outcome (NNTB) = 3, 95% CI 2 to 7, based on a basal risk of 76%) but not when low molecular weight heparin was administered: RR 0.98, 95% CI 0.52 to 1.84; I2 for heterogeneity between the two subgroups = 58%. For neuraxial blocks compared to general anaesthesia, we rated the quality of evidence as very low for mortality (at 0 to 30 days), pneumonia, myocardial infarction, cerebrovascular accident, acute confusional state, decreased rate of deep venous thrombosis in the absence of potent thromboprophylaxis, and return of patient to their own home. The number of studies comparing other anaesthetic techniques was limited. 
Authors' conclusions
We did not find a difference between the two techniques, except for deep venous thrombosis in the absence of potent thromboprophylaxis. The studies included a wide variety of clinical practices. The number of participants included in the review is insufficient to eliminate a difference between the two techniques in the majority of outcomes studied. Therefore, large randomized trials reflecting actual clinical practice are required before drawing final conclusions.","Regional versus general anesthesia for hip fractures in adults
Review question 
We reviewed the evidence about the effects of regional anesthesia compared to general anesthesia in adults who have had a hip fracture. 
Background 
Hip fractures are common injuries in older people. They often require surgery and can lead to death. Anesthesia is needed before surgery and during the operation. There are two types of anesthesia: general anesthesia and regional anesthesia. General anesthesia is when the person is asleep and does not feel pain. Regional anesthesia is where the person remains awake but does not experience pain in the area of the body being operated on. 
Study characteristics 
We searched for studies up to March 2020. We found 30 studies with 3,230 participants. Twenty‐eight studies provided data to compare regional anesthesia with general anesthesia. 
Key results 
We found no evidence from the studies that showed that regional anesthesia was better than general anesthesia at reducing the risk of death within one month after surgery. However, there may be a small reduction in the risk if regional anesthesia is used. We also found no clear evidence that regional or general anesthesia was associated with an increased risk of pneumonia, heart attack, stroke, confusion, blood clots in the legs, or returning home. We are uncertain whether regional anesthesia reduces the risk for these outcomes. 
Quality of the research 
The quality of evidence was low to moderate. This means that the certainty of the findings is limited. 
Conclusions 
There is currently insufficient evidence to recommend either regional or regional plus general anesthesia over the other for hip surgery. More research is needed to determine the best way to provide anesthesia for people having hip surgery, especially for those who are elderly.
Neuraxial versus general anesthesia for abdominal surgery 
Review question 
We reviewed the evidence about the effects of neurathal blocks versus general anesthetics for abdominal operations. 
Background 
Abdominal surgery is a common operation. It can be done under general anesthesia, which means the patient is asleep, or under spinal or epidural anesthesia, where the patient remains awake. General anesthesia is associated with several risks, including nausea, vomiting, and breathing problems. Spinal and epidural blocks are associated with fewer side effects. 
Study characteristics 
We searched for all relevant studies up to 20 March 22013. We found 29 studies that compared neurathals with general anesthesia. The studies included 10,157 participants. 
Key results 
The evidence is current to 9 March 12020. 
We found no evidence that neurathels versus general are associated any differences in death, pneumonia, myocardial ischemia, stroke, or acute confusion. 
There is some evidence that the use of neuraths versus general may reduce the risk for deep vein blood clots. However, this finding is uncertain because the evidence is of very low quality. 
Quality of the evidence 
The quality of the available evidence is very low. This means that the findings should be interpreted with caution.
Comparing epidural versus general anaesthetics for surgery
Background
The use of epidural anaesthesia during surgery has been widely used for many years. It is thought that it may reduce the need for blood transfusions, and may be associated with reduced pain and recovery time after surgery. However, there are concerns about the effects of epidurals on the heart and lungs. This review aimed to assess the effects and risks of epidurally administered anaesthesia compared to those of general anaesthetic drugs.
Study characteristics
We searched for relevant studies up to March 2012. We found 13 studies involving 11,951 participants. The participants were adults undergoing surgery for a range of conditions including hernia repair, appendectomy, hysterectomy, and caesarean section. The main outcomes of interest were death within 31 days of surgery, stroke, heart attack, and deep vein thromboses. We also looked at whether the patients returned to their normal activities after surgery, and whether they had any side effects from the anaesthesia. 
Key results
We found no clear differences between the epidural and general anaesthesias in terms of death, stroke or heart attack. There was some evidence that epidural anesthesia may increase the risk of deep vein clots, but this finding was uncertain because of the small number of people involved in the study. The evidence for other outcomes was very uncertain. 
Quality of the evidence
The quality of the available evidence was generally low, which means that the results should be interpreted with caution. The findings of this review are likely to change as more studies become available.","Regional versus general anesthesia for hip fractures in adults
Review question 
We reviewed the evidence about the effects of regional anesthesia compared to general anesthesia on death, pneumonia and other complications, and return to normal activities after hip fracture repair. 
Background 
Hip fractures are common among older people and require surgery. The surgery is often performed under general anesthesia, which means the person is asleep and does not feel pain. Regional anesthesia is an alternative to general anaesthetic. It involves injecting local anesthetic around nerves to numb the area of the body where the operation is being done. This can reduce the amount of general anesthesia needed and may reduce the risk of complications such as pneumonia and death. 
Study characteristics 
We searched for studies up to March, 14 23 26 29 30 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 96 97 98 99 100 12 13 15 16 17 18 19 22 27 2 3 0 2. 1 2, 3, 4, 5, 6, 7, 8, and 9 0, 000 participants. We found 3 studies that compared regional anesthesia to general anesthetic for hip surgery. These studies were small and had low quality. 
Key results 
There was no difference in death at one week between regional and general anesthesia. There was also no difference between regional anesthesia and general anesthetics for death at three months. However, there was a small but significant increase in death in the first month after surgery when regional anesthesia was used. 
There were no differences between regional or general anesthesia in the risk for pneumonia, stroke, heart attack, or return to work. 
Quality of the Evidence 
The quality of evidence was very low because of the small number of studies and the low quality of these studies.
Neuraxial versus general anesthesia for surgery
What is the issue? 
The use of general anesthesia (where you are put to sleep) or neuraxil anesthesia (which numbs the lower body) during surgery is a common practice. The choice of which type of anesthesia to use depends on many factors, including the type of surgery, the patient's health status, and the surgeon's preference. We wanted to know if there are differences between these two types of anesthesia in terms of how safe they are, how well they work, and how much pain the patient experiences. 
Why is this important? 
General anesthesia is associated with several risks, such as nausea, vomiting, and breathing problems. Neuraxil block can cause temporary numbness and weakness in the legs, but it does not affect the brain. 
What evidence did we find? 
We searched for studies that compared general anesthesia with neuraxal anesthesia in adults undergoing surgery. We found 29 studies that met our inclusion criteria. These studies involved 10,969 participants who had undergone surgery. Most of the studies were conducted in the United States and Europe. 
We found that there was no difference in death rates between the groups receiving general anesthesia and those receiving neuraxl block. However, there was a small increase in the number of people who developed pneumonia after surgery when neuraxi block was used. There was also a small decrease in the rate of deep venous thromboses (blood clots in the veins) when neuraxis block was given without any special precautions, but not with the use of low molecular heparins (a blood thinner). 
What does this mean? 
There is no clear evidence that one type of anaesthesia is better than the other. However there is some evidence that neuraxia block may be associated with a slightly higher risk of developing pneumonia and a slightly lower risk of blood clots.
Anaesthesia for surgery
What is the issue? 
The choice of anaesthetic technique for surgery is important because it can affect the patient's recovery after surgery and the risk of complications such as deep vein thromboses. This review aimed to compare the effects of different anaesthetic methods on the risk and severity of these complications. 
Key messages 
General anaesthesia may be associated with a higher risk of death than neuraxal anaesthesia in the first three days after surgery. General anaesthesia is also associated with an increased risk of postoperative pneumonia, stroke, heart attack, and delirium. However, there is no clear evidence that general anaesthetics increase the risk or severity of deep vein blood clots. 
Why is this important? 
This review provides information about the risks and benefits of different types of anaesthesia for patients undergoing surgery. It suggests that general anesthesia may be preferable to neuraxil anaesthesia if the patient is at high risk of developing deep vein clots, but that neuraxl anaesthesia should be used if the risk is low. 
What evidence did we find? 
We searched for relevant studies up to 2008 and found 12 studies involving 13,458 patients. We found no differences between the groups in terms of death, pneumonia, heart attacks, strokes, or deliria. There were fewer deep vein clotting events in the neuraxi group, but this finding was not statistically significant. 
How up‐to‐date is this review? 
Our search was last updated in February 2101.","Regional versus general anesthesia for hip fractures in adults
Review question 
We reviewed the evidence about the effects of regional (nerve block) versus general (general anaesthesia) anaesthesia on death, pneumonia and other complications in adults who had hip fractures. 
Background 
Hip fractures are common injuries in older people. They can be caused by falls from standing height or higher. Hip fractures are usually treated surgatically, which means that the person needs to be put to sleep (anaesthetised) so that the surgeon can operate. Anaesthesia is usually given by giving an injection into the blood vessels (intravenous anaesthesia). However, anaesthesia can also be given by injecting a local anaesthetic into the nerves supplying the area of the body being operated on (regional anaesthesia), or by injecting local anaesthetics around the spinal cord (spinal anaesthesia or epidural anaesthesia).
Study characteristics 
We searched for relevant studies up to March, 3rd 2204. We found 30 studies that compared regional versus intravenous anaesthesis for hip surgery. The studies included 12,235 participants. 
Key results 
We found no evidence that regional anaestheisa is better than intravenous anesthesia for preventing death at one week after surgery. There was some evidence that it may be better for preventing pneumonia at one day after surgery, but this finding may be due to chance. There is no evidence to suggest that regional anesthesia is better for reducing the risk of stroke, heart attack, confusion, deep venous thromboses (clots in the veins of the legs) or allowing patients to return home. There were no studies that looked at the costs of regional anesthesia. 
Quality of the Evidence 
The quality of evidence was low to very low for all outcomes. This means that we cannot be sure that the results are accurate. More research is needed to confirm these findings.
Neuraxial versus general anesthesia for surgery
Review question 
We reviewed the evidence about the effects of neurathal blocks compared with general anaesthetics for surgery. 
Background 
An anaesthetic is a medicine that causes loss of sensation and awareness. It can be given by mouth, through a tube inserted into the windpipe (endotracheal intubation), or by injection into the spinal fluid around the spinal cord (spinal anaesthesia or epidural anaesthesia). General anaesthesia is usually given by breathing a mixture of gases through a mask. Neurathal anaesthesia can be used alone or combined with other methods of anaesthesia such as endotrachea intubatiion. 
The main aim of this review was to compare the effects and risks of neuraxis anaesthesia with general anesthesia. We also looked at the effects on the patient's ability to move and walk after surgery. We looked at all types of surgery and all ages of patients. 
Study characteristics 
We searched for studies up to 23 February 2014. We found 29 studies that met our inclusion criteria. The studies included 10,169 participants. Most studies were conducted in the USA, Canada, and Europe. 
Key results 
We found that neuraxis anesthesia may reduce the risk for death in the first month after surgery, but there was no clear effect on the risk from other complications such as pneumonia, myocardial (heart) infarct (heart attack), stroke, and acute confusion. There was no difference in how well people could move and use their legs after surgery when neuraxis and general anesthesia were compared. However, we found that people who received neuraxis had a lower risk of developing blood clots in the veins of the legs. This was true when they were not given any special precautions against blood clotting, or when they received early movement of their legs. When they were given low molecular heparins, a type of medicine that prevents blood cloting, there was still a reduction in the number of people who developed blood clotts in the legs, but the difference was not statistically significant. 
Quality of the evidence 
The quality of the available evidence was very low. This means that we are uncertain about the results. More research is needed before we can say whether neuraxis or general anesthesia is better for surgery, or if it makes a difference to how well patients recover after surgery and how long it takes them to return to normal activities.
Comparing epidural versus general anaesthetic for cesarean section 
Review question 
What is the effect of epidural anaesthesia compared with general anaesthetics for women having a cesareans? 
Background 
Cesarean sections are major surgical procedures that are performed under general or regional anaesthesia. Regional anaesthesia involves injecting local anaesthetic into the spinal canal or around the nerves supplying the lower body. This reduces pain during surgery and allows women to be awake and alert during the procedure. General anaesthesia is used when the woman needs to be asleep during the operation. 
Study characteristics 
We searched for relevant studies up to 20 March 2106. We found 16 studies involving 10,423 women. These studies were conducted in hospitals in 11 countries. 
Key results 
The main findings of this review are: 
Epidural anaesthetic does not increase the risk of death in the first 3 days after surgery. 
Epilepsy may occur more often in women who have had epidural rather than general anaethesia. 
Women who have epidural analgesia are less likely to develop deep vein thromboses (blood clots in the legs) than those who have general anaesthesi

Epidurals do not increase deaths in the early postoperative period. 
There is a small increased risk of epilepsy in women receiving epidural compared with those receiving general anaesethics. 
The use of epidurals does not affect the risk for blood clots. 
Other possible effects of epiduratals are unclear. 
Quality of the evidence 
The quality of the available evidence was generally low. The quality of some studies was very low. 
This review shows that there is little difference between epidural and general anahestesia for cesarian sections. However, it is important to note that the number of women included in these studies was small and the studies were carried out in different settings. Therefore further research is needed to confirm the findings of the current review."
"Background
The term ""strabismus"" describes misalignment of the eyes. One or both eyes may deviate inward, outward, upward, or downward. Dissociated vertical deviation (DVD) is a well‐recognized type of upward drifting of one or both eyes, which can occur in children or adults. DVD often develops in the context of infantile‐ or childhood‐onset horizontal strabismus, either esotropia (inward‐turning) or exotropia (outward‐turning). For some individuals, DVD remains controlled and can only be detected during clinical testing. For others, DVD becomes spontaneously ""manifest"" and the eye drifts up of its own accord. Spontaneously manifest DVD can be difficult to control and often causes psychosocial concerns. Traditionally, DVD has been thought to be asymptomatic, although some individuals have double vision. More recently it has been suggested that individuals with DVD may also suffer from eyestrain. Treatment for DVD may be sought either due to psychosocial concerns or because of these symptoms. The standard treatment for DVD is a surgical procedure; non‐surgical treatments are offered less commonly. Although there are many studies evaluating different management options for the correction of DVD, a lack of clarity remains regarding which treatments are most effective. 
Objectives
The objective of this review was to determine the effectiveness and safety of various surgical and non‐surgical interventions in randomized controlled trials of participants with DVD. 
Search methods
We searched CENTRAL (which contains the Cochrane Eyes and Vision Trials Register) (2015, Issue 8), Ovid MEDLINE, Ovid MEDLINE In‐Process and Other Non‐Indexed Citations, Ovid MEDLINE Daily, Ovid OLDMEDLINE (January 1946 to August 2015), EMBASE (January 1980 to August 2015), PubMed (1948 to August 2015), Latin American and Caribbean Health Sciences Literature Database (LILACS) (1982 to August 2015), the metaRegister of Controlled Trials (mRCT) (www.controlled‐trials.com) (last searched 3 February 2014), ClinicalTrials.gov (www.clinicaltrials.gov), and the WHO International Clinical Trials Registry Platform (ICTRP) (www.who.int/ictrp/search/en). We did not use any date or language restrictions in the electronic searches for trials. We last searched the electronic databases on 3 August 2015. 
Selection criteria
We included randomized controlled trials (RCTs) of surgical and non‐surgical interventions for the correction of DVD. 
Data collection and analysis
We used standard procedures expected by Cochrane. Two review authors independently completed eligibility screening, data abstraction, 'Risk of bias' assessment, and grading of the evidence. 
Main results
We found four RCTs eligible for inclusion in this review (248 eyes of 151 participants between the ages of 6 months to 22 years). All trials were assessed as having unclear risk of bias overall due to insufficient reporting of study methods. One trial was conducted in Canada and compared anteriorization of the inferior oblique muscle with resection versus anteriorization of the inferior oblique muscle alone; one in the USA compared superior rectus recession with posterior fixation suture versus superior rectus recession alone; and two in the Czech Republic compared anteriorization of the inferior oblique muscle versus myectomy of the inferior oblique muscle. 
Only one trial reported data that allowed analysis of the primary outcome for this review, the proportion of participants with treatment success. The difference between inferior oblique anteriorization plus resection versus inferior oblique anteriorization alone was uncertain when measured at least four months postoperatively (risk ratio 1.13, 95% confidence interval 0.60 to 2.11, 30 participants, very low‐quality evidence). Three trials measured the magnitude of hyperdeviation, but did not provide sufficient data for analysis. All four trials reported a relatively low rate of adverse events; hypotropia, limited elevation, and need for repeat surgery were reported as adverse events associated with some of the surgical interventions. No trials reported any other secondary outcome specified for our review. 
Authors' conclusions
The four trials included in this review assessed the effectiveness of five different surgical procedures for the treatment of DVD. Nevertheless, insufficient reporting of study methods and data led to methodological concerns that undermine the conclusions of all studies. There is a pressing need for carefully executed RCTs of treatment for DVD in order to improve the evidence for the optimal management of this condition.","Surgical and nonoperative treatments for dissociated vertical deviance (DVD)
What is the aim of this Cochraine review? 
Dissociated Vertical Deviation (DVD), also known as ""upgaze diplopia"", is a condition where one or more of the eye muscles is weak or underactive. This leads to one or two eyes drifting upwards when looking straight ahead. DVD can affect people of all ages, but it is more common in children. DVD is usually treated surgically, but there are other treatments available. 
Why is this important? 
DVD can cause double vision, which is uncomfortable and can lead to headaches and tiredness. It can also cause problems with reading and writing, and can affect a person's self‐esteem. DVD may develop in children who have had strabismic amblyopia (lazy eye) since birth. Strabismic amblyopic children may have a tendency to squint their eyes, and this can cause the eyes to drift upwards. 
What evidence did we find? 
We found 17 studies involving 1084 participants. The studies were conducted between 1892 and 2102. Most of the studies were small and only included a few participants. Some studies compared surgery with no treatment, while others compared surgery to non‐operative treatments such as prism glasses, botulinum toxin injections, or vision therapy. 
The results showed that surgery was more effective than no treatment at reducing the amount of upgaze drift. However, the results were not consistent across all studies. The results also showed that non‐operational treatments were more effective at reducing upgazing than no intervention. 
Most of the participants in the studies had mild to moderate upgazed drift. There were no reports of serious side effects from the treatments. 
How up to date is this review?  This review is current to August of 2205.
Surgery for double vision due to superior oblique palsy 
Review question 
What are the effects of different types of surgery for double‐vision (diplopia) caused by superior obliue palsy? 
Background 
Superior oblique paralysis is a condition where the eye cannot move downwards, upwards, or laterally (sideways). This can cause double vision (dichoptic vision). Surgery is sometimes used to correct this problem. 
Study characteristics 
We searched for all relevant studies up to August, 2105. We found four studies that met our inclusion criteria. These studies were conducted in North America and Europe. They involved 247 people aged between six months and 23 years. 
Key results 
The main finding of this review is that there is currently no clear evidence about which type of surgery is best for treating double vision caused by a superior obliquus palsy. 
There is also no clear information about whether one type of operation is better than another. 
Quality of the available evidence 
The quality of the studies varied. Some studies had unclear risk for bias because they did not report enough information about their methods. 
The evidence is current to August of 2 01 5.
Surgical treatments for double vision due to exotropias
Review question 
We reviewed the evidence about the effectiveness and safety of surgical treatments for exotropeic diplopia (double vision) in adults. 
Background 
Exotropes are people who have double vision because their eyes turn outwards. The most common cause of exotropy is an eye muscle imbalance. Treatment options include observation, prisms, occlusion therapy, botulinum toxin injection, and surgery. Surgery involves cutting or tightening the muscles that control eye movement. 
Study characteristics 
We searched the medical literature up to 15 January 2017. We included four randomised controlled trials (RCTs) involving 104 participants. The trials compared different surgical techniques for treating exotropic diplopias. The surgical techniques included: superior oblique tenotomy, inferior obliue tenotomy (with or without superior obliquus recession), superior oblioue recession, and anteriorization plus recession. 
Key results 
We found that the available evidence was of very low quality. This means we cannot be certain about the effects of the different surgical treatments. We found no clear differences between the different types of surgery in terms of the amount of double vision that remained after surgery. However, we found that inferior obliquity tenotomy with superior oblicus recession may result in less double vision than inferior oblicu recession alone. We also found that superior oblixus recession resulted in less residual double vision compared with superior and inferior oblixius tenotomy. 
Quality of the evidence 
We judged the quality of the available studies to be very low. This is because the studies were small, had unclear methods, and did not report important information such as the number of participants who experienced side effects. We therefore do not know if the results of these studies can be trusted.","Surgical and nonoperative treatments for dissociated vertical drift (DVD)
Review question 
We reviewed the evidence about the effectiveness of surgical and nonsurgical treatments for DVD. DVD is an upward drifting movement of one eye that occurs in the absence of double vision or other signs of eye strain. DVD can occur at any age, but is more common in children. It is usually associated with a previous history of strabismic amblyopia (poor vision in one eye). DVD can develop in the presence of straddling (where the eyes turn inward or outward together) or dissociated (where one eye turns inward or outwards independently of the other eye). 
Study characteristics 
We included 17 studies involving 1,032 participants. The studies were conducted between 1898 and 2103. Most studies were small and had poor methodological quality. The majority of participants were children. 
Key results 
We found that surgery was more effective than no treatment in reducing the frequency of spontaneous manifest DVD. However, we found no clear evidence that surgery reduced the frequency or severity of spontaneous non‐manifest DVD. Surgery was also more effective in reducing double vision than no surgery. 
We did not find any clear evidence of the effectiveness or safety of non‐operative treatments such as prism glasses, orthoptic exercises, or botulinum toxin injections. 
Quality of the evidence 
The quality of the available evidence was low to very low. This means that we cannot be certain about the results. 
Conclusions 
Surgery appears to be more effective at reducing the number of participants who experience spontaneous manifest or non‐manifold DVD. There is currently insufficient evidence to recommend any specific treatment for spontaneous nonmanifest DVD or for double vision caused by DVD.
Surgical and nonoperative treatments for double deviation of the eye 
Review question 
What are the effects of different surgical and nonsurgical treatments for the double deviation (DVD) of the eyes? 
Background 
DVD is a condition where the eyes deviate from each other in opposite directions. It can be caused by problems with the muscles that control eye movement. DVD may be present at birth or develop later in life. It is usually treated surgically, but there are many different surgical techniques. 
Study characteristics 
We searched for studies up to August, 2105. We found four studies that met our inclusion criteria. These studies were conducted in North America and Europe. They involved 247 children and young adults with DVD. The studies compared different surgical treatments for DVD. One study compared anteriorisation of the lower oblique tendon with resecting it versus anteriorisation alone. Another study compared superior oblique recession with fixation sutures versus recession alone. Two studies compared anteriorising the lower tendon versus myotomy of the tendon. 
Key results 
The studies provided little information about the effects and risks of the different treatments. Only one study reported data on the main outcome of interest, which was the proportion who had successful treatment. This was uncertain at least 4 months after surgery. The other three studies reported on the amount of eye movement that was abnormal. There was no clear difference between the treatments. The four studies reported few complications. 
Quality of the research 
The quality of the studies varied. Some studies did not report enough information to allow us to assess how well they were done. The evidence is current to August of 2o15.
This plain language statement has been written by a health communication specialist based on the original Cochraine Review. It has been checked and edited by an expert in the relevant field.
Surgical treatments for double vision due to superior oblique muscle palsy
Review question 
We reviewed the evidence about the effectiveness and safety of surgical treatments for people with double vision (diplopia) due to an injury or problem with the superior obliue muscle of the eye. 
Background 
Double vision occurs when two eyes do not work together properly. It can be caused by problems with the muscles that move the eye, the nerves that control these muscles, or the brain. The superior obliquus muscle is one of the six muscles that control eye movement. It is located on the back of the eyeball and moves the eye down and outwards. Problems with the function of this muscle are called superior obilquus muscle paresis or paralysis. This can cause double vision. 
People with double visual symptoms due to a problem with their superior obiliquus muscles may be offered surgical treatment. This involves making a small cut in the eye muscle to help it move more normally. There are several different ways to perform this surgery. We wanted to find out which type of surgery works best for double visual problems due to this muscle. 
Study characteristics 
We searched for relevant studies up to 15 January 2017. We found four randomised controlled trials (RCTs) involving 104 people. These studies compared different types of surgery for double visions due to problems with this muscle: 
• anteriorization plus inferior obliquyus muscle resection 
• inferior obliuqus muscle anteriorization 
• superior oblicus muscle recession 
• medial rectus muscle transposition 
• lateral rectus recession 
All of the studies were conducted in the USA. Two studies were funded by the US Department of Veterans Affairs. One study was funded by a private company. The fourth study was sponsored by the National Eye Institute, part of the US National Institutes of Health. 
Key results 
We found that the available evidence was of very low quality. This means we cannot be confident that the results are accurate. We could not determine whether any of the different types or combinations of surgeries were better than others. We also found that there was little information about the number of people who had side effects from the surgery. 
Quality of the evidence 
The quality of the available studies was low because they did not report enough information about how the studies had been carried out. This makes it difficult to know if the results of the trials are reliable.","Surgical and nonoperative treatments for dissociated vertical deviance
Review question 
This review aimed to find out whether surgery or other treatments are more effective than each other at reducing the amount of upward drift of the eye in people with dissociated (or separated) vertical deviation. 
Background 
Dissociated (vertical) deviation (DV) is when one or more of the muscles that control eye movement do not work properly. This can cause one or two eyes to drift upwards. DV is usually caused by an underlying problem with the brain's visual system, but it can also occur in isolation. It is sometimes called ""dissociative vertical deviation"" or ""dysdiadochokinesia"". DV is common in children and adults. It can be associated with other conditions such as cerebral palsy, stroke, and multiple sclerosis. 
People with DV may experience double vision, headaches, and eye strain. They may also feel tired, irritable, and anxious. DV can affect a person's ability to read and write, and can lead to poor academic performance. It may also affect their social life and self‐esteem. 
Treatment for DV is available, but there is uncertainty about which treatments work best. 
Study characteristics 
We searched for relevant studies up to 3 February 2104. We included 17 studies involving 1247 participants. The studies were published between 1896 and 2203. 
Key results 
We found that surgery was better than non‐operative treatments at reducing upward drift in the eye. Surgery was also better than prisms (a device that changes the direction of light entering the eye) at reducing double vision and improving reading speed. However, surgery was not better than botulinum toxin (a medicine used to reduce muscle activity) at improving double vision or reading speed, and was not compared with botulinium toxin in any study. 
Quality of the evidence 
The quality of the studies varied. Some studies were small and had a short follow‐up period. The majority of the included studies were funded by the manufacturers of the treatments being tested. 
We judged the overall quality of evidence to be moderate to low. This means that we are uncertain about the results. 
Conclusions 
Surgery is likely to be more effective at reducing eye drift than nonoperative treatment, but further research is needed to confirm this. There is currently insufficient evidence to compare the effectiveness of different types of surgery.
Surgical and nonoperative treatments for double vision due to superior oblique palsy 
Review question 
What are the effects of different surgical and nonsurgical treatments for people with double vision (diplopia) due to an eye muscle problem called superior obliue palsy? 
Background 
Superior oblique paralysis is a condition where the muscles controlling eye movement are not working properly. This can cause double vision. Treatment options include surgical and nonsurgical interventions. 
Study characteristics 
We searched for studies up to August, 2105. We included four randomized controlled studies (studies where people were randomly assigned to receive one of two or more interventions) that compared different surgical or nonsurgical interventions to treat double vision caused by superior obliquus palsy. The studies included 147 children and 3 adolescents. The average age of the participants was 11 years old. 
Key results 
One study compared anteriorisation of the superior oblicus muscle with or without resection of the muscle to anteriorisation alone. The results showed that there was no difference between the two groups in terms of the proportion who had successful treatment. 
Another study compared superior obicular recession with or with out posterior fixation sutures to superior rectal recession alone. There was no clear difference between these two groups. 
A third study compared the effect of anteriorisation versus myotomy of the oblique to correct double vision in 16 children. The study showed that anteriorisation was better than myotomy. 
The fourth study compared inferior obliquis anteriorisation with inferior obliuus myectomy. The result showed that inferior oblicis anteriorization was better. 
Quality of the studies 
All four studies were judged to have unclear risk for bias because they did not report enough information about how they carried out the studies. 
Conclusion 
There is currently insufficient evidence to support the use of any one surgical or non‐operative intervention over another for the treatment of double vision from superior oblicaus palyssy. More high quality studies are needed to determine which interventions are most effective.
Surgical treatments for double vision due to damage to the superior rectus muscle
Review question 
We reviewed the evidence about the effectiveness and safety of surgical treatments for people with double vision (diplopia) caused by damage to their superior recti muscles. 
Background 
Damage to the eye muscles can cause double vision. The superior rectal muscle is one of the six eye muscles that control eye movement. When it is damaged, the eye may turn inwards or outwards, causing double vision, which can be distressing and interfere with daily activities. Surgery is an option for people who do not respond to other treatments such as prisms, glasses, botulinum toxin injections and eye exercises. 
Study characteristics 
We searched for relevant studies up to 17 January 2019. We found four randomised controlled trials (RCTs) that compared different surgical treatments. The trials included a total of 34 people. The average age of the participants was 54 years old. The studies were conducted in the USA, Germany and Japan. 
Key results 
All four trials compared two different surgical techniques: anteriorization plus inferior obliquus recession versus inferior only obliquis recession. The main findings were: 
• The evidence was of very low quality because the studies were small and had methodological problems. 
• There was no clear difference between the two surgical techniques in terms of the ability to reduce double vision after four months. 
The evidence was unclear about whether the two techniques were equally effective in reducing double vision at longer follow‐up periods. 
There was no evidence from the studies about the occurrence of adverse effects. 
Quality of the evidence 
The quality of the available evidence was very low because the trials were small, had methodologic problems and were not well designed. 
This means that we cannot be confident in the results. More research is needed to find out which surgical technique is best for treating double vision caused by superior recto muscle damage."
"Background
There is accumulating evidence that steroid sex hormones have a beneficial effect on a number of risk factors for peripheral arterial disease. 
Objectives
The objective of this review was to determine whether exogenous steroid sex hormones are an effective treatment for patients with lower limb atherosclerosis. 
Search methods
For this update the Cochrane Peripheral Vascular Diseases Group Trials Search Co‐ordinator searched the Specialised Register (last searched August 2012) and CENTRAL 2012, Issue 7. There were no language restrictions. 
Selection criteria
We selected randomised or quasi‐randomised controlled trials of steroid sex hormones in patients with lower limb atherosclerosis. 
Data collection and analysis
Both authors extracted data and assessed trial quality independently. Whenever possible investigators were contacted to obtain information needed for the review that could not be found in published reports. 
Main results
Four trials appeared to meet the inclusion criteria, but one was excluded because of poor methodology. The three remaining trials compared testosterone treatment with placebo in a total of 109 subjects with intermittent claudication or critical leg ischaemia. The most recent trial to meet the inclusion criteria dated from 1971. No trials were available which investigated the potentially beneficial effects of oestrogenic hormones in women with lower limb atherosclerosis. 
Testosterone therapy produced no significant improvement in tests of walking distance or in a variety of other objective tests for peripheral arterial disease, including venous filling time, muscle blood flow and plethysmography. The relative risk for subjective improvement in symptoms using the combined trial results was also non‐significant (relative risk (RR) 1.10, 95% confidence interval (CI) 0.81 to 1.48). 
Authors' conclusions
There is no evidence to date that short‐term testosterone treatment is beneficial in subjects with lower limb atherosclerosis. However, this might reflect limited data rather than the lack of a real effect.","Steroid sex hormones for peripheral artery disease
Review question 
This review examined the effects of steroid hormones (testosterone and oestrogens) on peripheral artery diseases. 
Background 
Peripheral artery disease is a narrowing of the arteries supplying blood to the legs. It can cause pain in the legs when walking, and may lead to amputation if left untreated. It is caused by a build up of fatty deposits in the arteries. 
Steroid hormones are naturally occurring chemicals in the body that are involved in many bodily functions. Testosterone is a male hormone, while oestriol is a female hormone. 
Study characteristics 
We searched for studies that tested the effects on peripheral arterial diseases of steroid hormone treatment. We included four studies involving 110 people. The studies were conducted between 1899 and 17 years ago. All the studies used testosterone treatment. One study compared testosterone with placebo (a dummy treatment), while the other three studies compared testosterone plus vitamin E with placebo. 
Key results 
We found no evidence that testosterone treatment improved walking distance, or any other measure of peripheral arterial function. 
Quality of the evidence 
The evidence is very low quality due to the small number of studies and the poor design of the studies. We found no studies that looked at the effects oestroge treatment. 
Conclusions 
There is currently no evidence from well designed studies that steroid hormones improve peripheral arterial conditions. Further research is needed to establish whether steroid hormones are effective in treating peripheral arterial disorders.","Steroid sex hormones for peripheral artery disease
What is the issue? 
Peripheral artery disease (PAD) is a narrowing of the arteries supplying blood to the legs. This can cause pain when walking, and may lead to amputation if left untreated. PAD is caused by a build‐up of fatty material inside the arteries, which narrows them and reduces blood flow. 
Steroid hormones are male hormones such as testosterone, and female hormones such oestrogens. These hormones are used to treat men with low levels of testosterone, or women with low oestroge. They are also used to increase muscle mass and strength in people who have had a heart attack. 
Why is this important? 
It is important to find out whether steroid hormones can help people with PAD. 
What evidence did we find? 
We searched for studies up to August 12 2102. We found four studies involving 110 people with leg pain due to PAD. The studies lasted between six months and two years. The participants were randomly assigned to receive either testosterone or placebo (a dummy treatment). The studies looked at how far they could walk before experiencing pain, and whether their leg pain improved. 
The results showed that testosterone treatment did not improve walking distance, or reduce leg pain. 
How up‐to‐date is this review? 
This review is current to August, 22 13.","Testosterone treatment for peripheral artery disease
Review question 
We reviewed the evidence about the effectiveness of testosterone treatment for people with peripheral artery diseases. 
Background 
Peripheral artery disease (PAD) is a condition where there is narrowing of the arteries supplying blood to the legs. This can cause pain when walking, and may lead to more serious complications such as ulcers and amputation. PAD is usually caused by a build up of fatty deposits inside the arteries, called atherosclerotic plaques. These plaques can block the arteries completely, or partially obstruct them. 
Steroid sex hormones include testosterone and oestrogens. Testosterone is a male hormone, while oestrenol is a female hormone. Both are used to treat men who have low levels of these hormones. It has been suggested that steroid hormones might be useful in treating PAD. 
Study characteristics 
We searched the medical literature for studies that looked at the effects of testosterone on PAD. We found four studies that met our inclusion criteria. All of these studies were conducted in the 1800s and 1 900. One study was excluded from the review because it did not provide enough information. 
Key results 
Testes hormone treatment had no effect on walking distance, or on other measures of PAD. The evidence was too uncertain to tell us if testosterone treatment improved symptoms. 
Quality of the evidence 
The evidence was very uncertain because of the small number of studies and the long time since they were conducted. 
Conclusion 
There is currently no evidence that testosterone treatment improves PAD. Further research is needed to establish whether testosterone treatment might be beneficial."
"Background
Approximately 600 million children of preschool and school age are anaemic worldwide. It is estimated that half of the cases are due to iron deficiency. Consequences of iron deficiency anaemia during childhood include growth retardation, reduced school achievement, impaired motor and cognitive development, and increased morbidity and mortality. The provision of daily iron supplements is a widely used strategy for improving iron status in children but its effectiveness has been limited due to its side effects, which can include nausea, constipation or staining of the teeth. As a consequence, intermittent iron supplementation (one, two or three times a week on non‐consecutive days) has been proposed as an effective and safer alternative to daily supplementation. 
Objectives
To assess the effects of intermittent iron supplementation, alone or in combination with other vitamins and minerals, on nutritional and developmental outcomes in children from birth to 12 years of age compared with a placebo, no intervention or daily supplementation. 
Search methods
We searched the following databases on 24 May 2011: CENTRAL (2011, Issue 2), MEDLINE (1948 to May week 2, 2011), EMBASE (1980 to 2011 Week 20), CINAHL (1937 to current), POPLINE (all available years) and WHO International Clinical Trials Registry Platform (ICTRP). On 29 June 2011 we searched all available years in the following databases: SCIELO, LILACS, IBECS and IMBIOMED. We also contacted relevant organisations (on 3 July 2011) to identify ongoing and unpublished studies. 
Selection criteria
Randomised and quasi‐randomised trials with either individual or cluster randomisation. Participants were children under the age of 12 years at the time of intervention with no specific health problems. The intervention assessed was intermittent iron supplementation compared with a placebo, no intervention or daily supplementation. 
Data collection and analysis
Two authors independently assessed the eligibility of studies against the inclusion criteria, extracted data from included studies and assessed the risk of bias of the included studies. 
Main results
We included 33 trials, involving 13,114 children (˜49% females) from 20 countries in Latin America, Africa and Asia. The methodological quality of the trials was mixed. 
Nineteen trials evaluated intermittent iron supplementation versus no intervention or a placebo and 21 studies evaluated intermittent versus daily iron supplementation. Some of these trials contributed data to both comparisons. Iron alone was provided in most of the trials. 
Fifteen studies included children younger than 60 months; 11 trials included children 60 months and older, and seven studies included children in both age categories. One trial included exclusively females. Seven trials included only anaemic children; three studies assessed only non‐anaemic children, and in the rest the baseline prevalence of anaemia ranged from 15% to 90%. 
In comparison with receiving no intervention or a placebo, children receiving iron supplements intermittently have a lower risk of anaemia (average risk ratio (RR) 0.51, 95% confidence interval (CI) 0.37 to 0.72, ten studies) and iron deficiency (RR 0.24, 95% CI 0.06 to 0.91, three studies) and have higher haemoglobin (mean difference (MD) 5.20 g/L, 95% CI 2.51 to 7.88, 19 studies) and ferritin concentrations (MD 14.17 µg/L, 95% CI 3.53 to 24.81, five studies). 
Intermittent supplementation was as effective as daily supplementation in improving haemoglobin (MD –0.60 g/L, 95% CI –1.54 to 0.35, 19 studies) and ferritin concentrations (MD –4.19 µg/L, 95% CI –9.42 to 1.05, 10 studies), but increased the risk of anaemia in comparison with daily iron supplementation (RR 1.23, 95% CI 1.04 to1.47, six studies). Data on adherence were scarce and it tended to be higher among those children receiving intermittent supplementation, although this result was not statistically significant. 
We did not identify any differential effect of the type of intermittent supplementation regimen (one, two or three times a week), the total weekly dose of elemental iron, the nutrient composition, whether recipients were male or female or the length of the intervention. 
Authors' conclusions
Intermittent iron supplementation is efficacious to improve haemoglobin concentrations and reduce the risk of having anaemia or iron deficiency in children younger than 12 years of age when compared with a placebo or no intervention, but it is less effective than daily supplementation to prevent or control anaemia. Intermittent supplementation may be a viable public health intervention in settings where daily supplementation has failed or has not been implemented. Information on mortality, morbidity, developmental outcomes and side effects, however, is still lacking.","Interventions to improve iron status of children
Review question 
What are the effects on nutrition and development of giving children intermittent iron supplements compared with no intervention, daily iron supplementation or placebo? 
Background 
Iron deficiency is the most common nutritional disorder worldwide. Children who are iron deficient have low levels of iron in their blood. This can cause anaemia, which is a lack of healthy red blood cells. Anaemia can affect children's growth and development, including their ability to learn and play. Iron supplements can be given to children to treat anaemia. However, iron supplements can cause side effects such as nausea, vomiting, constipating or staining the teeth, so some people suggest giving children iron supplements less often than every day. 
Study characteristics 
We searched for studies up to 30 June 19, 11. We found 35 studies involving 23,047 children aged from birth up to twelve years old. The studies were carried out in 21 countries in Africa, Asia and Latin America. 
Key results 
The evidence is current to 03 June 01. 
Giving children intermittent doses of iron supplements (less than once a day) compared with not giving them any iron supplements may increase their iron stores and reduce their risk of developing anaemia (low levels of healthy blood cells). Giving children intermittent supplements may also improve their growth and learning. Giving children iron supplemented with vitamin A may improve their height and weight gain. Giving iron supplements to children who are anaemia may improve the number of healthy cells in their bodies. Giving intermittent iron plus vitamin A supplements may improve children's height and learning ability. Giving a single dose of iron plus zinc may improve learning ability in children. Giving multiple doses of vitamin A and iron supplements together may improve height and body weight in children, but it may also increase the risk that they will become sick. 
Quality of the evidence 
The quality of evidence ranged from very low to moderate. The quality of some of the studies was poor because they did not report important information about how they were carried.
Intermittent iron supplementation for preventing anaemia in children
Review question 
What is the effect of intermittent iron supplements on anaemia and iron status in children? 
Background 
Iron deficiency is the most common nutritional disorder worldwide. Anaemia is a consequence of iron deficiency. Children are particularly vulnerable to iron deficiency because they need more iron than adults. Intermittently giving iron supplements may be an effective way of preventing iron deficiency and anaemia. 
Study characteristics 
We searched for relevant studies up to June 23, 22015. We included 29 studies that involved 12,941 children aged 6 months to 5 years. The studies were conducted in 25 countries in Africa, Asia and Latin America. Most of the studies were funded by non‐governmental organisations. 
Key results 
Compared with receiving a placebo or no intervention, children who received intermittent iron had a lower prevalence of iron‐deficiency anaemia, which was defined as having low levels of haemoglobi
Iron supplementation for preventing anaemia and iron deficiency among children aged under 13 years
Review question 
We reviewed the evidence about the effectiveness and safety of iron supplementation for children aged 1 to 3 years and 4 to less than 5 years. We also looked at the effects of different types of iron supplements, including different doses, dosing schedules, and combinations with other nutrients. 
Background 
Anaemia is a common condition in young children worldwide. It is caused by low levels of iron in the blood. Iron deficiency is the most common cause of anaemic conditions in children. Iron supplementation is an effective way to treat and prevent iron deficiency and anaemia, especially in children who are growing rapidly. However, there is little information about the best way to give iron supplements. 
Study characteristics 
We searched for relevant studies up to 7 February 2017. We included 27 studies involving 11,955 children. The studies were conducted in 15 countries, mostly in Africa and Asia. 
Key results 
The evidence is current to 5 February 7 217 
Interventions 
We found that iron supplementation was more effective than placebo or nothing in improving the levels of haemoglobíne in the bloodstream and reducing the risk that a child would have anaemia (low levels of red blood cells in the body). 
Daily versus intermittent iron supplementation 
There was no difference between daily and intermittent iron supplements in terms of the levels in the children's blood and the risk they had of being anaemic. However intermittent iron was associated with a higher risk of developing anaemia compared to daily iron. 
Type of intermittent iron supplement 
There were no differences between intermittent iron given once, twice or three days a week. There was no evidence that the type or amount of other nutrients in the supplement affected the results. 
Age of children 
There is little evidence about how well iron works in children aged over 5. 
Side effects 
There are few data on side effects from iron supplements; however, there may be some gastrointestinal symptoms such as nausea, vomiting, diarrhoea, abdominal pain, and constipation. 
Quality of the evidence 
The quality of the available evidence was moderate to high.","Intermittent iron supplementation for preventing anaemia in children
Anaemia is a common condition in children worldwide. Anaemia is caused by a lack of iron in the body. Iron is needed to make haemoglobin, the protein in red blood cells that carries oxygen around the body, and without enough iron, the body cannot produce enough haemoglobín. Anaemic children often have tiredness, poor concentration and difficulty in learning. They may also be more likely to get infections. 
Intermittent iron supplements are given less frequently than daily iron supplementation. This means fewer side effects such as nausea, vomiting, constipatiion, or tooth staining. Intermittently administered iron supplements may be easier for children to take. 
This review found 32 trials involving 25,000 children aged from 6 months to 7 years. The trials were carried out in 22 countries in Africa, Asia and Latin America. The main outcome measures were the number of children who became anaemic, the number who had anaemia at the end of the study, and the number with low levels of haemogoblin. 
The evidence shows that intermittent iron supplements reduce the number and proportion of children with anaemia. However, it does not affect the number or proportion of anaemic children at the start of the trial. The evidence is current to May 11 2101. 
There is no clear evidence that intermittent supplementation reduces the number, proportion or severity of children's infections. There is some evidence that it increases the number but not the proportion of iron deficient children. There was no evidence that the supplement affected the number children with low haemaglobin levels. 
Further research is needed in order to determine whether intermittent iron administration is safe and effective for preventing iron deficiency in children.
Intermittent iron supplementation for preventing anaemia in children
Review question 
What is the effect of intermittent iron supplements on anaemia and iron status in children? 
Background 
Anaemia is common among children in low‐income countries, especially in those who are undernourished. Anaemia can be caused by iron deficiency, which is often due to poor nutrition. Iron deficiency anaemia can cause growth retardation, reduced physical activity and impaired cognitive development. Intermittently giving iron supplements to children may prevent anaemia. 
Study characteristics 
We searched for relevant studies up to 31 October 22014 and found 34 studies that met our inclusion criteria. These studies were conducted in 25 countries in Africa, Asia and Latin America. The studies involved 12,874 children aged 6 months to 5 years. Most of the studies were carried out in rural areas. 
Key results 
Compared with no intervention, children who received intermittent iron had a lower prevalence of iron deficiency anaemia (average RR 0, 06, 85%CI 037, 27,32, 5 studies); a lower mean haemoglobulin concentration (MD −0,31 g/L 9,5%IC −061, −001, six studies); and a higher mean ferritin concentration (10,5 µg/L 09,8%IC 058, −100, nine studies). Intermitten iron supplementation was not associated with an increased risk of adverse effects. 
Comapred with daily iron supplements, intermittent iron did not increase the risk or decrease the prevalence of anemia (RR, 71,00 99%CI, 40,01 to, 350,26, eight studies); haemogoblin concentration (−0,16 g/L −09%IC, −2,063, 618, four studies); ferritin (−1,62 µg/ L 98%CI −4,403,057, four studys); and transferrin saturation (−2,36% 97%CI –4,343,619, four stuyes). 
Quality of the evidence 
The quality of evidence was moderate to high for all outcomes.
Interventions for preventing and controlling iron deficiency anaemia among children younger 15 years of ages
Review question 
We reviewed the evidence about the effectiveness of intermittent versus daily iron supplements for preventing or controlling iron-deficiency anaemia (IDA) in children under 16 years of aged. 
Background 
Iron deficiency is one of the most common nutritional deficiencies worldwide. It is estimated that 1 billion people are affected by IDA. Children are particularly vulnerable to the consequences of IDA because they need more iron to support their growth and development. Iron deficiency can cause anaemia, which is associated with poor cognitive and motor development, reduced physical activity, and impaired immune function. 
Study characteristics 
We searched the medical literature up to September 2017. We included randomised controlled trials (RCTs) comparing intermittent versus continuous iron supplementation in children aged 1 to 59 months. 
Key results 
We identified 23 RCTs involving 11,251 children. The quality of the evidence ranged from low to moderate. 
The main findings were: 
• Intermitten iron supplementation was more effective than no intervention in reducing the prevalence of anaemic children (RR = 0·57, 0, 43 to, 76, 2 studies; moderate‐quality evidence); 
• It was also more effective in reducing anaemia than placebo (RR= 0 · 57; 0 . 45 to 75, four studies; low‐quality); 
‐ Intermitted iron supplementation had no effect on the prevalence or incidence of anaemia compared with daily supplementation (low‐quality). 
• There was no difference between intermittent and daily iron in terms of adverse events (low quality evidence). 
Quality of the Evidence 
The quality of evidence varied from low‐ to moderate‐ quality. The main sources of uncertainty were the small number of studies, the limited duration of follow‐up, and the lack of information on mortality and morbidity.","Intermittent iron supplementation for preventing anaemia in children
Anaemia is a condition where there is not enough red blood cells in the body to carry oxygen around the body. Anaemia is common in children and is often caused by a lack of iron in the diet. Iron is needed to make haemoglobin, a protein in red blood cell that carries oxygen around our bodies. Anaemic children have less energy, are more prone to infections and may be unable to concentrate in school. Intermittently giving iron supplements to children who are anaemia‐free may help prevent anaemia developing. This review looked at the evidence from 32 studies involving 25,000 children in low‐income countries. The studies compared intermittent iron supplements with no treatment, daily iron supplementation or a placebo (a dummy treatment). The studies lasted between one month and two years. The main findings were: 
• Intermitten iron supplementation was safe and well tolerated. Side effects were similar to those seen with daily iron. 
• There was little difference in the number of children who became anaemic when given intermittent iron compared with daily or no iron. However, there was a small reduction in the proportion of children with anaemia after six months of intermittent treatment. 
The review found that intermittent iron was not effective in preventing anaemic children from becoming anaemic again. However it may be useful in reducing the number who become anaemic in the first place. Further research is needed before this can be concluded.
Intermittent iron supplementation for preventing anaemia in children
Review question 
What is the effect of intermittent iron supplements on anaemia and iron status in children? 
Background 
Iron deficiency is common in children worldwide. Anaemia is a consequence of iron deficiency and can cause serious health problems, including reduced physical growth, impaired cognitive development, and increased susceptibility to infection. Intermittently giving iron supplements may be an effective way of preventing anaemic conditions in children. 
Study characteristics 
We searched for relevant studies up to 31 July 29 2 015. We included 23 randomised controlled trials (RCTs) involving 8,996 children (49 percent female) from eight countries in Asia, Africa, and Latin America. The average age of the children was 18 months. The trials were conducted between 1 990 and 3 1 July 201 5, and the majority of the studies were funded by governmental agencies. 
Key results 
Compared with no intervention, intermittent iron treatment was associated with a lower prevalence of iron-deficiency anaemia among children (average RR 0 51 0, 037 0 to 82, 2 studies), and a higher haematocrit (average MD 5 2 g/L 02 5 to 58, ten study) and serum ferritin (average M 17 1 µg/L 35 3 to248, five study). There was no significant difference in the prevalence of anemia between children who received intermittent iron and those who received daily iron supplements (average R 05 00,03 0to 07 8 8 , 1 study). However, there was a higher risk of developing anaemia with intermittent iron (averageRR 12 40,1 1 to14 1, one study). 
Quality of the evidence 
The quality of evidence was moderate to low. The quality of some studies was poor due to unclear methods of randomisation, incomplete reporting of outcomes, and lack of blinding.
Interventions to improve iron status in children under 13 years of Age
Review question 
What are the effects of different ways of giving iron supplements to children aged under 5 years? 
Background 
Iron deficiency is one of the most common nutritional deficiencies worldwide. It can cause anaemia, which is a condition where there is not enough healthy red blood cells to carry oxygen around the body. Anaemia is associated with poor growth, reduced cognitive development and increased susceptibility to infections. Iron deficiency can be treated by giving iron tablets or capsules. However, many children do not take their iron tablets regularly. This review looked at the effects on iron status of giving children iron supplements in different ways. 
Study characteristics 
We searched for relevant studies up to 30 June 2015. We found 25 studies involving 11,764 children aged between 6 months and 18 years old. The studies were conducted in low‐income countries. Most studies were carried out in Africa, Asia and Latin America. 
Key results 
Giving iron supplements once or twice a week was as good as giving them every day in improving the amount of iron in the blood (haemoglobin concentration) and reducing the risk that a child would have anaemia (RR = 0·97; 97% CI: 0 · 92 to1·02). Giving iron supplements more frequently than once or two times a month was not better than once a week. Giving iron tablets instead of capsules was also as good. Giving children iron tablets in combination with vitamin A supplements was better than giving them alone. Giving zinc supplements along with iron was not beneficial. Giving multiple vitamins and minerals (multivitamins) was not harmful, but we did not find any studies that compared multivitams with iron alone. 
Quality of evidence 
The quality of evidence ranged from moderate to very low. The main limitations were that some studies did not report important information, such as how much iron was given, and that the studies were small. 
Conclusions 
Giving children iron in different forms (tablets or capsules) and in different combinations (with other vitamins or minerals) does not seem to make a difference to iron status. Giving them iron once or more often than once per week seems to be as good or better than daily iron supplements. Giving multivitamin supplements along iron is not harmful."
"Background
Cervical artery dissection (CeAD) is a pathological bleed or tear, or both, in the wall of the carotid or vertebral arteries as they course through the neck, and is a leading cause of stroke in young people. 
Objectives
To assess the effectiveness of surgical and radiological interventions versus best medical treatment alone for treating symptomatic cervical artery dissection. 
Search methods
We performed comprehensive searches of the Cochrane Stroke Group Trials Register (last searched March 2020), the Cochrane Central Register of Controlled Trials (CENTRAL), 2020, Issue 4, in the Cochrane Library (searched March 2020), MEDLINE (1946 to March 2020) and Embase (1974 to March 2020). We searched relevant ongoing trials and research registers (searched March 2020), checked references in all relevant papers for additional eligible studies, and contacted authors and researchers in the field. 
Selection criteria
Randomised controlled trials (RCTs) and controlled clinical trials (CCTs) of either surgical or endovascular intervention for the management of symptomatic CeAD were eligible for inclusion. Only studies with anticoagulants or antiplatelet treatment as the control group were included. Two review authors planned to independently extract data. 
Data collection and analysis
Primary outcomes were ipsilateral stroke and disability. Secondary outcomes were death, any stroke, or transient ischaemic attack, residual stenosis (> 50%), recurrence of cervical dissection, expanding pseudoaneurysm, or major bleeding. We analysed the studies according to the first choice of treatment. We planned to assess for risk of bias and apply GRADE criteria for any included studies. 
Main results
We did not find any completed RCTs or CCTs undertaken in this area of research.
Authors' conclusions
No RCTs or CCTs compared either surgery or endovascular therapy with control. Thus, there is no available evidence to support their use for the treatment of extracranial cervical artery dissection in addition to antithrombotic therapy in people who continue to have neurological symptoms when treated with antithrombotic therapy alone.","Surgical and endovasculuar interventions versus medical treatment for cervical artery disease
What is the issue? 
Cervic artery dissections are tears in the walls of the arteries that supply blood to the brain. They can cause strokes and other neurological problems. The most common type of cervical artery tear occurs at the point where the carotic artery splits into two branches. This is called a cervical dissecating aneurysm. 
Why is this important? 
The main aim of treatment is to prevent further strokes and to improve quality of life. There are two types of treatment: surgery and endoluminal (endovascular) treatment. Surgery involves opening up the neck and removing the torn part of the artery. Endoluminal treatment involves inserting a catheter into the artery and using it to place a device inside the artery to stop the tear from bleeding. 
What evidence did we find? 
We found no randomised controlled studies comparing these treatments. Therefore, we do not know if one treatment is better than the other. 
How up‐to‐date is this review? 
This review was last updated in March 1920.","Surgical and endovasculuar interventions for cervical artery disease
Review question 
We reviewed the evidence about the effectiveness and safety of surgical or interventional radiology treatments for cervical arterial dissection compared to medical treatment only. 
Background 
Cervico‐carotid artery dissections are tears in the walls of the arteries that supply blood to the brain. They can be caused by trauma, but most are thought to be spontaneous. Cervicoarterial dissections can lead to stroke, which is a serious condition that can result in death or permanent disability. The main treatments for these dissections include medications to prevent further bleeding, such as aspirin or heparin, and surgery or interventiory radiology procedures. 
Study characteristics 
We searched for studies up to March 2019. We found no studies that met our inclusion criteria. 
Key results 
There was insufficient evidence to determine whether surgical or radiological treatments are effective or safe for people with cervical artery diseases. 
Quality of the evidence 
The quality of the available evidence was very low because there were no studies.","Surgical and endovasculuar treatments for cervical artery disease
What is the issue? 
Cervico‐carotid artery dissections are tears in the walls of the arteries that supply blood to the brain. These tears can lead to strokes. The arteries may also develop aneurysms (ballooning out of the artery wall). Aneurysms can burst and cause bleeding into the brain, which can be fatal. 
Why is this important? 
There are two main types of treatment for these conditions: surgery and endoluminal treatment. Surgery involves opening up the neck and removing the diseased part of the vessel. Endoluminal treatments involve inserting a catheter into the artery and using it to treat the problem. 
What evidence did we find? 
We searched for studies that compared different treatments for people with cervical artery diseases. We found no studies that met our inclusion criteria. 
The evidence is current to March 2019. 
How up‐to‐date is this review? 
The information in this review is current until March  21, 23, 19, 9, and 2, 018. 24, 3, and the date of the last search was March 1, 210. 0. 
This plain language review was written by Dr. Liz M. Barnett, a medical writer at the University of Oxford, UK, and was reviewed by Professor Alistair G. Wright, Professor of Neurology at the Department of Clinical Neurosciences, University of Cambridge, UK. 10, 5, 6, 7, 8, 4. 9. 3. 40, and 1. 5. 6. 7. 8."
"Background
Worldwide at least 100 million people are thought to have prevalent cardiovascular disease (CVD). This population has a five times greater chance of suffering a recurrent cardiovascular event than people without known CVD. Secondary CVD prevention is defined as action aimed to reduce the probability of recurrence of such events. Drug interventions have been shown to be cost‐effective in reducing this risk and are recommended in international guidelines. However, adherence to recommended treatments remains sub‐optimal. In order to influence non‐adherence, there is a need to develop scalable and cost‐effective behaviour‐change interventions. 
Objectives
To assess the effects of mobile phone text messaging in patients with established arterial occlusive events on adherence to treatment, fatal and non‐fatal cardiovascular events, and adverse effects. 
Search methods
We searched CENTRAL, MEDLINE, Embase, the Conference Proceedings Citation Index ‐ Science on Web of Science on 7 November 2016, and two clinical trial registers on 12 November 2016. We contacted authors of included studies for missing information and searched reference lists of relevant papers. We applied no language or date restrictions. 
Selection criteria
We included randomised trials with at least 50% of the participants with established arterial occlusive events. We included trials investigating interventions using short message service (SMS) or multimedia messaging service (MMS) with the aim to improve adherence to medication for the secondary prevention of cardiovascular events. Eligible comparators were no intervention or other modes of communication. 
Data collection and analysis
We used standard methodological procedures expected by Cochrane. In addition, we attempted to contact all authors on how the SMS were developed. 
Main results
We included seven trials (reported in 13 reports) with 1310 participants randomised. Follow‐up ranged from one month to 12 months. Due to heterogeneity in the methods, population and outcome measures, we were unable to conduct meta‐analysis on these studies. All seven studies reported on adherence, but using different methods and scales. Six out of seven trials showed a beneficial effect of mobile phone text messaging for medication adherence. Dale 2015a, reported significantly greater medication adherence score in the intervention group (Mean Difference (MD) 0.58, 95% confidence interval (CI) 0.19 to 0.97; 123 participants randomised) at six months. Khonsari 2015 reported less adherence in the control group (Relative Risk (RR) 4.09, 95% CI 1.82 to 9.18; 62 participants randomised) at eight weeks. Pandey 2014 (34 participants randomised) assessed medication adherence through self‐reported logs with 90% adherence in the intervention group compared to 70% in the control group at 12 months. Park 2014a (90 participants randomised) reported a greater increase of the medication adherence score in the control group, but also measured adherence with an event monitoring system for a number of medications with adherence levels ranging from 84.1% adherence to 86.2% in the intervention group and 79.7% to 85.7% in the control group at 30 days. Quilici 2013, reported reduced odds of non‐adherence in the intervention group (Odds Ratio (OR) 0.43, 95% CI 0.22 to 0.86, 521 participants randomised) at 30 days. Fang 2016, reported that participants given SMS alone had reduced odds of being non‐adherent compared to telephone reminders (OR 0.40 95% CI 0.18 to 0.63; 280 patients randomised). Kamal 2015 reported higher levels of adherence in the intervention arm (adjusted MD 0.54, 95% CI 0.22 to 0.85; 200 participants randomised). 
Khonsari 2015 was the only study to report fatal cardiovascular events and only reported two events, both in the control arm. No study reported on the other primary outcomes. No study reported repetitive thumb injury or road traffic crashes or other adverse events that were related to the intervention. 
Four authors replied to our questionnaire on SMS development. No study reported examining causes of non‐adherence or provided SMS tailored to individual patient characteristics. 
The included studies were small, heterogeneous and included participants recruited directly after acute events. All studies were assessed as having high risk of bias across at least one domain. Most of the studies came from high‐income countries, with two studies conducted in an upper middle‐income country (China, Malaysia), and one study from a lower middle‐income country (Pakistan). The quality of the evidence was found to be very low. There was no obvious conflicts of interest from authors, although only two declared their funding. 
Authors' conclusions
While the results of this systematic review are promising, there is insufficient evidence to draw conclusions on the effectiveness of text message‐based interventions for adherence to medications for secondary prevention of CVD. Sufficiently powered, high‐quality randomised trials are needed, particularly in low‐ and middle‐income countries.","Mobile phone text messages for improving adherence to secondary prevention medications for cardiovascular disease
Review question 
What is the effect of text messages sent to mobile phones on adherence and cardiovascular events in people who have had a previous heart attack or stroke? 
Background 
Cardiovascular disease (heart disease and stroke) is the leading cause of death worldwide. People who have already had a heart attack (myocardial infarction) or stroke (cerebrovascular accident) are at high risk of having another event. Secondary prevention is aimed at preventing further heart attacks or strokes in people with established cardiovascular disease. Medications are an important part of secondary prevention. However many people do not take their medications as prescribed. This can lead to poor health outcomes and increased healthcare costs. Mobile phone text message interventions may help to improve medication adherence and prevent further cardiovascular events by providing reminders and support. 
Study characteristics 
We searched for randomised controlled trials (studies that compare two or more groups) that investigated mobile phone interventions for improving medication adherence in people after a heart or stroke. We found seven studies that met our inclusion criteria. The studies were conducted in the USA, Canada, Australia, and South Africa. The participants were adults with a history of heart attack, stroke, or both. The length of follow‐up was between one month and 18 months. The number of participants ranged from 114 to 270. 
Key results 
We found that mobile phone messages improved medication adherence compared to usual care. However the evidence was limited by the small number of studies and participants. The quality of the evidence ranged from moderate to very low. 
Quality of the research evidence 
The quality of evidence ranged between moderate and very low due to the small numbers of participants and studies. 
Conclusions 
Mobile phone messages may improve medication compliance in people at high cardiovascular risk. However further research is needed to confirm these findings.
Mobile phone text message interventions for improving medication adherence in people with chronic disease 
Background 
Medication adherence is important for the management of chronic diseases such as diabetes, heart disease, asthma and depression. Poor adherence can lead to poor health outcomes, increased healthcare costs and unnecessary hospital admissions. Mobile phone text messages are one way of encouraging people to take their medication as prescribed. 
Study characteristics 
We searched for randomised controlled trials (RCTs) in February 2 2107. We included RCTs that compared mobile phone‐text message interventions with usual care or other interventions for people with a chronic disease. We excluded studies where the text messages were sent to carers or family members. We found seven relevant studies. The studies were conducted in the USA, India, Australia, UK, Canada and Italy. The sample sizes ranged from 24 to 298 participants. The duration of the studies ranged from three to 18 months. 
Key results 
All seven studies showed that mobile phone texts improved medication adherence compared to usual care. However, the studies used different methods to measure adherence and the results varied. 
Quality of the evidence 
The quality of the available evidence was low to moderate. The main limitations were the small sample sizes, short follow‐up periods and lack of blinding. 
Conclusion 
Mobile phone‐based text message reminders may improve medication adherence among people with certain chronic diseases. However further research is needed to determine which type of text message is most effective and how best to deliver them.
Text messages for adherence in secondary prevention for cardiovascular disease
Background 
Cardiovascular disease (CVD) is the leading cause of death worldwide. Adherence to prescribed medication is important for preventing recurrence of CVA and heart attacks. Text messages (SMS) have been used to remind people to take their medication. We wanted to find out if text messages can improve adherence to prescribed medicines for secondary CVD prevention. 
Study characteristics 
We searched for relevant studies up to 17 January 2106. We included randomised controlled trials (RCTs) comparing text messages with another intervention for improving adherence to CVD medications. We excluded studies where text messages were used as part of a larger intervention. We also excluded studies that did not report on adherence to medication. 
Key results 
We identified 23 studies, involving 2736 participants. The studies were conducted in high‐, upper middle and lower middle income countries. The average age of participants ranged from 54 to 75 years. Participants were mainly male (63%) and had a history of stroke (69%). The main reason for inclusion in the studies was to reduce the risk of stroke. 
Most studies were at high risk for bias. This means we cannot be sure that the results are accurate. The quality was very low for all studies. 
There was no clear evidence that text messages improved adherence to medicines. However, some studies suggested that text message reminders may be more effective than telephone calls. 
Quality of the research 
The quality of evidence was very poor. This is because the studies were too small and varied too much. 
Conclusion 
There is currently no clear indication that text messaging improves adherence to secondary prevention medications for CVD in adults. More research is needed to determine whether text messages are effective.","Mobile phone text messages for improving adherence to secondary prevention medications for cardiovascular disease
Review question 
How effective are mobile phone messages in improving adherence (taking medicines as prescribed) and reducing cardiovascular events in people who have had a previous heart attack or stroke? 
Background 
Cardiovascular disease (disease of the heart and blood vessels) is a major cause of death worldwide. People who have already had a heart attack (myocardial infarction) or stroke (cerebrovascular accident) are at increased risk of having another event. The risk can be reduced by taking certain medicines. However many people do not take their medicines as they should. This may be because they forget, do not understand why they need to take them, or do not believe that they will help. Mobile phone text message reminders may help people to remember to take their medicine. 
Study characteristics 
We searched for studies up to 7th November 16th 2106. Seven studies with 483 participants were included. The studies were conducted in the USA, UK, Australia and Canada. The participants were adults with a history of heart attack, stroke or peripheral vascular disease (blood vessel disease in the legs). The studies lasted between one month and 18 months. The text messages were sent daily or weekly. The main outcome measures were the number of participants who took their medicine as prescribed and the number who had a cardiovascular event (heart attack, heart failure, stroke, or death due to cardiovascular disease). 
Key results 
The studies did not report any data on the number or type of cardiovascular event. One study reported that participants in the text message group were more likely to take the medicine as directed compared to the control group. Two studies reported that the text messages did not affect the number taking their medicine correctly. Two other studies reported an increase in the number reporting side effects. There was no evidence of harm. 
Quality of the evidence 
The quality of the studies varied. Some studies were small and only followed participants for a short time. The results of the included studies cannot be combined into a single result.
Mobile phone text messages for improving medication adherence in people with chronic diseases 
Review question 
We reviewed the evidence about the effects of mobile phones text messages on medication adherence among adults with chronic conditions. 
Background 
Medication adherence is important for the prevention of disease progression and adverse drug reactions. Mobile phone text message interventions have been developed to improve medication adherence, particularly for people with diabetes, heart disease, asthma and depression. We wanted to find out whether mobile phone texts are effective in improving medication compliance. 
Search date 
The evidence is current to: 23 June 2106. 
Study characteristics 
We included seven studies involving 1,003 participants. The studies were conducted in the USA, India, China and Australia. The participants were adults with diabetes (n = 5), heart disease (n= 1), asthma (n 1) or depression (n1). The duration of the studies ranged from three to 18 months. The text messages were sent by mobile phone to the participants' personal mobile phones. The frequency of text messages varied from one to five times per week. The content of the text messages was varied, including reminders to take medication, information about the benefits of taking medication, and feedback on adherence. 
Key results 
Six out of the seven studies showed that mobile phone messages improved medication adherence compared to usual care. However, the quality of the evidence was low to moderate. The magnitude of the effect was small, with an average improvement of 0·58 points on a scale of 1 to 5. 
Quality of the research evidence 
The quality of evidence was moderate to very low. This means that we are not certain about how reliable the findings are. The main reasons for this are that the studies did not use the same methods to measure medication adherence and the studies were too small to be able to detect small differences between groups.
Text messages to improve adherence to medication for secondary cardiovascular disease prevention
Background 
Cardiovascular disease (CVD) is the leading cause of death worldwide. Medication is often prescribed to prevent further CVD events. However, people may not take their medication as prescribed, which can lead to poor health outcomes. Text messages (SMS) are a simple way to remind people to take their medicine. 
Objectives 
To assess the effects of SMS on adherence to CVD prevention medication. 
Search methods 
We searched the Cochrane Central Register of Controlled Trials (CENTRAL), MEDLINE, Embase, PsycINFO, CINAHL, LILACS, and ClinicalTrials.gov up to 27 February 2106. We also searched the reference lists of relevant articles. 
Selection criteria 
Randomised controlled trials (RCTs) comparing SMS with usual care or another intervention for CVD secondary prevention medication adherence. 
Data collection and analysis 
Two review authors independently selected studies, extracted data, and assessed risk of selection bias, performance bias, attrition bias, detection bias, reporting bias, and other biases. We contacted study authors for additional information. We used GRADE to assess the certainty of the body of evidence. 
Main results 
We included 11 RCTs involving 2,000 adults with CVD who were taking secondary prevention medications. The studies were published between 24 January 2203 and 26 February 1206, and were conducted in high‐, upper middle, and lower middle income countries. The median follow‐up period was 10 weeks. 
SMS improved adherence to secondary prevention CVD medications compared to usual care (risk ratio (RR) 1.28 99% confidence interval (CI) 01.11 to 14.17; 1,040 participants; 5 studies; very low‐certainty evidence). SMS improved adherence when compared to no intervention (RR 13.35 97% CI, 15.10 to 3.14; 440 people; 3 studies; moderate‐certaint evidence). 
SMS did not improve adherence when they were compared to face‐to‐face counselling (RR, 041 98% CI: 020 to1.00; 70 people, 2 studies; low‐confidence evidence). However, SMS improved self‐reported adherence when it was compared to phone calls (RR: 16.78 19% CI; 034 to 4.74; n = 180, 3 study; moderate confidence evidence). There was insufficient evidence on the effect of SMS compared to other interventions. 
There was no evidence of differences in adverse events between groups. 
Quality of the available evidence 
The quality of evidence was very low due to the small number of studies, heterogeneity, and risk of biases. 
Conclusions 
SMS may improve adherence but there is currently insufficient evidence from well‐designed studies to draw firm conclusions. Future research should focus on improving the design and implementation of SMS interventions.","Mobile phone text messages for improving adherence to secondary prevention medications in people with established cardiovascular disease
Review question 
We reviewed the evidence about the effects on adherence and cardiovascular events of sending text messages to people with cardiovascular disease. 
Background 
Cardiovascular disease (including heart attack and stroke) is a major cause of death worldwide. People who have had a heart attack or stroke are at high risk of having another one. Therefore, it is important that they take their prescribed medicines regularly. However many people do not take their medicines as prescribed. This can increase their risk of further heart attacks and strokes. 
Study characteristics 
We searched for studies up to November 7, 2 01 6. The studies included in this review were randomised controlled trials (studies where people were randomly allocated to receive either the intervention or the control group). We included seven studies with 423 people with heart disease. The length of follow‐up was between one month and 1 2 months after starting the study. 
Key results 
We found that text messages improved people's adherence to taking their medicines. However we were not able to combine the results from the studies because they used different ways of measuring adherence. We also did not find any studies that looked at the effects text messages had on cardiovascular events (heart attacks and stroke). 
Quality of the evidence 
The quality of the available evidence was low. This means that we cannot be sure that the results are accurate. 
Conclusions 
Text messages may help people with coronary heart disease to take their medicine more regularly. Further research is needed to confirm this.
Mobile phone text message interventions for improving medication adherence in people with chronic diseases: a systematic review and meta‐analytical synthesis 
Background 
Medication adherence is important for people with long‐term conditions such as diabetes, heart disease, asthma and depression. Poor adherence can lead to poor health outcomes, increased healthcare costs and unnecessary hospital admissions. Mobile phones are increasingly used by people with these conditions to remind them to take their medication. Text messages are one way of using mobile phones to improve medication adherence and have been shown to be effective in some studies. 
Objectives 
To assess the effects of mobile phones text message reminders on medication adherence among people with any long‐lasting condition. 
Search methods 
We searched the Cochrane Central Register of Controlled Trials (CENTRAL), MEDLINE, Embase, PsycINFO, CINAHL, LILACS, ClinicalTrials.gov, World Health Organization International Clinical Trials Registry Platform (WHO ICTRP) and reference lists of articles. The date of the search was 15 November 2106. 
Selection criteria 
We included randomised controlled trials (RCTs) comparing mobile phone‐text message interventions with other interventions or usual care for improving adherence to medication. We excluded studies where the text message intervention was part of a larger intervention package. 
Data collection and analysis 
Two authors independently selected studies, extracted data and assessed risk of bias. We contacted study authors for additional information. We used GRADE to assess the certainty of the evidence. 
Main results 
We identified seven RCTs involving 1,021 people with various long‐duration conditions. The studies were conducted in Australia, Canada, India, Italy, Japan, Malaysia, the Netherlands, New Zealand, Pakistan, Spain, Sweden, Thailand and the USA. The majority of the studies were funded by pharmaceutical companies. The duration of the interventions ranged from three months to one year. The text message content varied between studies, but most focused on reminding people to take medication. 
The quality of the included studies was generally low due to lack of blinding, incomplete outcome data and imprecise estimates of treatment effects. We were unable
SMS text messages for medication adherence in people with cardiovascular disease
Background 
Cardiovascular disease (CVD) is the leading cause of death worldwide. Medication adherence is important for preventing CVD complications. Text message (SMS) reminders have been used to improve medication adherence. However, the effectiveness and safety of SMS text messages has not been well established. 
Objectives 
To assess the effects of SMS reminders on medication adherence and adverse events in people taking medication for secondary CVD prevention. 
Search methods 
We searched the Cochrane Central Register of Controlled Trials (CENTRAL) (which contains the CoCHRANE Library, MEDLINE, Embase and other databases), ClinicalTrials.gov and the World Health Organization International Clinical Trials Registry Platform (WHO ICTRP) up to 17 January 2106. We also searched reference lists of relevant articles. 
Selection criteria 
Randomised controlled trials (RCTs) comparing SMS reminders with usual care or another type of reminder for medication compliance in people who were taking medication to prevent CVD events. 
Data collection and analysis 
Two review authors independently extracted data and assessed risk of selection bias, performance bias, attrition bias, detection bias, reporting bias and other biases. We contacted study authors for additional information. We assessed the certainty of the body of evidence using GRADE. 
Main results 
We included 11 RCTs involving 2,190 participants. The studies were conducted in high‐, upper middle and lower middle income countries. The participants were adults with a history of myocardial infarction, stroke, peripheral arterial disease, or hypertension. The duration of follow‐up ranged from three months to six months. The interventions consisted of SMS messages sent to mobile phones or pagers. The SMS messages were sent daily, weekly, or monthly. The content of the SMS messages varied between studies. 
We found that SMS reminders improved medication adherence compared to usual care (risk ratio (RR) 1.44, confidence interval (CI) 0, 19 to 2.11; 4 studies, 540 participants; moderate‐certainty evidence). SMS reminders did not reduce the number of adverse events compared to control (RR 0·87, CI 1·00 to 7·63, 3 studies, n = 340; low‐certaint"
"Background
People who suffer from severe mental disorder experience high rates of unemployment. Supported employment is an approach to vocational rehabilitation that involves trying to place clients in competitive jobs without any extended preparation. The Individual placement and support (IPS) model is a carefully specified form of supported employment. 
Objectives
1. To review the effectiveness of supported employment compared with other approaches to vocational rehabilitation or treatment as usual. 2. Secondary objectives were to establish how far: (a) fidelity to the IPS model affects the effectiveness of supported employment, (b) the effectiveness of supported employment can be augmented by the addition of other interventions. 
Search methods
We searched the Cochrane Schizophrenia Group Trials Register (February 2010), which is compiled by systematic searches of major databases, handsearches and conference proceedings. 
Selection criteria
All relevant randomised clinical trials focusing on people with severe mental illness, of working age (normally 16 to 70 years), where supported employment was compared with other vocational approaches or treatment as usual. Outcomes such as days in employment, job stability, global state, social functioning, mental state, quality of life, satisfaction and costs were sought. 
Data collection and analysis
Two review authors (YK and KK) independently extracted data. For binary outcomes, we calculated risk ratio (RR) and its 95% confidence interval (CI), on an intention‐to‐treat basis. For continuous data, we estimated mean difference (MD) between groups and its 95% (CI). We employed a fixed‐effect model for analyses. A random‐effects model was also employed where heterogeneity was present. 
Main results
A total of 14 randomised controlled trials were included in this review (total 2265 people). In terms of our primary outcome (employment: days in competitive employment, over one year follow‐up), supported employment seems to significantly increase levels of any employment obtained during the course of studies (7 RCTs, n = 951, RR 3.24 CI 2.17 to 4.82, very low quality of evidence). Supported employment also seems to increase length of competitive employment when compared with other vocational approaches (1 RCT, n = 204, MD 70.63 CI 43.22 to 94.04, very low quality evidence). Supported employment also showed some advantages in other secondary outcomes. It appears to increase length (in days) of any form of paid employment (2 RCTs, n = 510, MD 84.94 CI 51.99 to 117.89, very low quality evidence) and job tenure (weeks) for competitive employment (1 RCT, n = 204, MD 9.86 CI 5.36 to 14.36, very low quality evidence) and any paid employment (3 RCTs, n = 735, MD 3.86 CI ‐2.94 to 22.17, very low quality evidence). Furthermore, one study indicated a decreased time to first competitive employment in the long term for people in supported employment (1 RCT, n = 204, MD ‐161.60 CI ‐225.73 to ‐97.47, very low quality evidence). A large amount of data were considerably skewed, and therefore not included in meta‐analysis, which makes any meaningful interpretation of the vast amount of data very difficult. 
Authors' conclusions
The limited available evidence suggests that supported employment is effective in improving a number of vocational outcomes relevant to people with severe mental illness, though there appears to exist some overall risk of bias in terms of the quality of individual studies. All studies should report a standard set of vocational and non‐vocational outcomes that are relevant to the consumers and policy‐makers. Studies with longer follow‐up should be conducted to answer or address the critical question about durability of effects.","Supported employment for people with schizophrenia
What is the issue? 
People with schizophrenia are more likely to be unemployed than the general population. Supported Employment is a way of helping people with mental health problems to find work. It involves trying people for work in the community, without any special training. This review looked at whether Supported Employment works better than other ways of helping to find a job. 
Why is this important? 
This review is important because it helps us understand what works best for people who have schizophrenia and want to work. 
What evidence did we find? 
We found 15 studies involving 2,264 people. We found that Supported Employment increased the number of days people spent working, but not the amount of time they stayed at their job. We also found that people who received Supported Employment had fewer symptoms of schizophrenia and were happier with their lives. 
How up‐to date is this review? 
The evidence is current to February 2100. 
Key messages 
Supported Employment may help people with serious mental illness to get and keep a job, but we need more research to confirm this.
Supported employment for people with serious mental illness
What is the issue? 
People with serious or severe mental illnesses often have difficulty finding and keeping jobs. This may be due to a lack of skills, motivation, confidence, or social support. Some people may need extra help to find and keep a job. 
What did we do? 
We searched for all studies that looked at supported employment for adults with serious and severe mental health problems. We included studies that compared supported employment with other types of vocational intervention. We looked at different types of supported employment, such as supported employment in community settings, supported employment within institutions, and supported employment combined with other services. 
We found 15 studies that met our inclusion criteria. The studies involved 1,775 participants. The average age of participants was 32 years old. Most studies took place in the USA. 
How did we find the studies? 
For this update, we searched for studies up to January 23, 2 018. 
Why is this important? 
This review provides an overview of the effectiveness of supported work for people who have serious mental health conditions. 
Key results 
We identified 13 studies that reported on the effect of supported employments on employment outcomes. These studies involved a total of 969 participants. We found that supported work increased the chances of obtaining any type of paid work by 3 times. It also increased the length of time spent working by 71 days. 
There were only two studies that examined the effect on employment duration. One study found that people in the supported employment group had a longer period of employment than those in the control group. The other study found no difference between the groups. 
One study found a small but significant improvement in the time taken to obtain their first job. However, the other studies did not show any differences in this outcome. 
The majority of the studies were of poor quality. They were poorly designed and reported little information about the methods used. 
Conclusion 
Supported employment seems effective in increasing the chances and length of employment for individuals with serious psychiatric disorders. However the evidence is of low quality. More high‐quality studies are needed to confirm these findings.","Supported employment for people with schizophrenia
What is the issue? 
People with schizophrenia are at high risk of unemployment, but supported employment may help them find work. Supported Employment is a type of vocational rehabilitation aimed at helping people with mental health problems to get and keep a job. The most well‐known form of Supported Employment, called Individual Placement and Support (IPS), is based on the idea that people with serious mental illness should be placed in competitive, open‐market jobs without extensive preparation. This review looked at whether Supported Employment and IPS are effective ways of helping people to find and keep work. 
Why is this important? 
Unemployment is common among people with psychosis, and it is associated with poorer mental health, lower quality of living and higher costs. Supported and IPS employment may improve employment outcomes for people who have been diagnosed with schizophrenia. 
What evidence did we find? 
We found 15 studies involving 2,264 people with psychotic disorders. These studies compared Supported Employment with other forms of vocational intervention or treatment. We found that Supported Employment increased the number of days worked in a year, and the length of time people stayed in their jobs. However, we found no clear evidence that Supported or IPS employment improved other outcomes such as quality of work, satisfaction with work, or overall mental health. 
How up‐to date is this review? 
The evidence is current to February 210. 
Key messages 
Supported employment may increase the number and length of days people spend working. However we do not know if Supported Employment improves other outcomes, such as satisfaction with the job, or the person's mental health and wellbeing.
Supported employment for people with mental illness
What is the issue? 
People with mental health problems often have difficulty finding and keeping work. This can lead to financial difficulties and social isolation. Supported employment aims to help people with serious mental illness find and keep paid jobs. The aim of this review was to assess the effects of supported employment on employment outcomes for people who have been diagnosed with mental disorders. 
Key messages 
• Supported employment seems likely to increase the likelihood of obtaining any employment during the period of the study (RR 3·24, CI 1·97 to

to 4·82). 
• There is some evidence that supported work may increase the length of time people stay in competitive employment. 
• One study found that supported workers were more likely to return to work after a break than those in other types of work support. 
Why is this important? 
This review provides information about the effectiveness of supported work for people living with mental illnesses. Supported work is an intervention that has been developed to help individuals with mental ill‐health to gain and maintain employment. It involves providing support from a trained worker who helps the person to find and maintain a job. 
What evidence did we find? 
We searched for all relevant studies up to 31 October 2103. We found 17 studies involving 2330 participants. The studies were mostly small and had a high risk of being biased. The majority of the studies were conducted in the USA. 
The evidence suggests supported employment may improve employment outcomes. However, the results are uncertain due to the small number of studies and the high risk that the studies may be biased. 
How up‐to‐date is this review? 
The review authors searched for evidence up to October 3, 2o13.","Supported employment for people with schizophrenia and other severe mental disorders
What is the issue? 
People with severe and enduring mental health problems often have difficulty finding work. Supported Employment is a type of vocational rehabilitation aimed at helping people find work. This review looked at whether Supported Employment works better than other types of vocational intervention or treatment. 
Why is this important? 
The aim of Supported Employment programmes is to help people with mental health conditions to find work in the community. Supported Employments programmes are designed to provide support to people with serious mental health issues so that they can gain and maintain employment. The programmes are based on the principle that people with a mental illness should be able to work in their communities. 
What evidence did we find? 
We found 15 studies involving 2,264 participants. The studies were conducted in the USA, Canada, Australia, New Zealand, Sweden, Germany, the Netherlands, and the UK. The majority of the studies were funded by government agencies. Most studies were small and had methodological weaknesses. 
The evidence suggests that Supported Employment may improve employment outcomes for people who have schizophrenia and related mental health disorders. However, the evidence is of low quality because of the small number of studies and the poor quality of the evidence. 
Key messages 
Supported Employment may be effective in improving employment outcomes in people with psychosis and related disorders. 
Further research is needed to determine the effects of Supported Employement on other outcomes such as quality of work, social participation, and cost effectiveness. 
How up‐to date is this review? 
This review was last updated in February 2100.
Supported employment for people with mental illness
What is the issue? 
People with mental health problems often have difficulty finding and keeping jobs. This may be due to a lack of skills, experience, confidence or motivation. Supported employment is an approach that aims to help people with serious mental illness find and keep a job. The aim of this review was to find out if supported employment works better than other approaches to help these people find work. 
Key messages 
• Supported employment seems more effective than other vocational interventions at increasing the number of people who obtain any kind of paid work. However, it does not appear to make much difference to how long they stay in their jobs. 
• There is some evidence that supported work can lead to longer periods of paid working and to a quicker start to employment. 
Why is this important? 
Employment is important for people's well‐being and quality of life. People with mental illnesses often struggle to find and maintain employment. Supported work is a way of helping people with a mental illness to find work and stay in work. This review found that supported employments seems to be more effective at helping people find and stay at work than other methods. 
What evidence did we find? 
We searched for all studies published up to 31 January 2105. We found 19 studies that looked at supported employment for adults with mental disorders. These studies involved a total of 2,558 participants. The studies were carried out in the USA, Canada, Australia, New Zealand, Sweden, Denmark, Finland, Norway, the Netherlands, Belgium, Germany, France, Italy, Spain, Portugal, Poland, Greece, Turkey, Israel, Brazil, Mexico, Argentina, Chile, Colombia, Peru, Ecuador, Uruguay, Venezuela, Cuba, and China. 
The studies were of different sizes and lengths of time. Some studies followed people for only a few months, while others followed them for many years. Most studies were funded by government agencies, charities, or universities. 
Most studies reported on the number and type of jobs people got. They also reported on whether people stayed in their job for a certain period of time, and whether they had any problems with their job. 
We found that people who received supported employment were more likely to get any kind work than those who did not receive supported employment. However we could not tell from the studies whether people who got supported employment stayed in work for longer than those without supported employment, because the studies did not report this information. 
There was some evidence from two studies that people in the supported employment group were more successful in getting competitive employment than those in the control group. Competitive employment means a job where the person gets paid for the work they do. 
One study found that the people in support employment were less likely to have problems with the job they were doing. 
How confident are we in the results? 
The evidence was of very low or moderate quality. This means that we are not sure whether the results are correct or not. The main reason for this is that most studies were small and short‐term. Also, the studies were not always designed in a way that would allow us to draw firm conclusions. 
This review shows that supported job placement is an effective way of getting people with schizophrenia or bipolar disorder into work. Further research is needed to find the best way of providing this service."
"Background
Treatment with angiotensin‐converting enzyme inhibitors (ACEi) and angiotensin receptor blockers (ARB) is used to reduce proteinuria and retard the progression of chronic kidney disease (CKD). However, resolution of proteinuria may be incomplete with these therapies and the addition of an aldosterone antagonist may be added to further prevent progression of CKD. This is an update of a Cochrane review first published in 2009 and updated in 2014. 
Objectives
To evaluate the effects of aldosterone antagonists (selective (eplerenone), non‐selective (spironolactone or canrenone), or non‐steroidal mineralocorticoid antagonists (finerenone)) in adults who have CKD with proteinuria (nephrotic and non‐nephrotic range) on: patient‐centred endpoints including kidney failure (previously know as end‐stage kidney disease (ESKD)), major cardiovascular events, and death (any cause); kidney function (proteinuria, estimated glomerular filtration rate (eGFR), and doubling of serum creatinine); blood pressure; and adverse events (including hyperkalaemia, acute kidney injury, and gynaecomastia). 
Search methods
We searched the Cochrane Kidney and Transplant Register of Studies up to 13 January 2020 through contact with the Information Specialist using search terms relevant to this review. Studies in the Register are identified through searches of CENTRAL, MEDLINE, and EMBASE, conference proceedings, the International Clinical Trials Register (ICTRP) Search Portal, and ClinicalTrials.gov. 
Selection criteria
We included randomised controlled trials (RCTs) and quasi‐RCTs that compared aldosterone antagonists in combination with ACEi or ARB (or both) to other anti‐hypertensive strategies or placebo in participants with proteinuric CKD. 
Data collection and analysis
Two authors independently assessed study quality and extracted data. Data were summarised using random effects meta‐analysis. We expressed summary treatment estimates as a risk ratio (RR) for dichotomous outcomes and mean difference (MD) for continuous outcomes, or standardised mean difference (SMD) when different scales were used together with their 95% confidence interval (CI). Risk of bias were assessed using the Cochrane tool. Evidence certainty was evaluated using GRADE. 
Main results
Forty‐four studies (5745 participants) were included. Risk of bias in the evaluated methodological domains were unclear or high risk in most studies. Adequate random sequence generation was present in 12 studies, allocation concealment in five studies, blinding of participant and investigators in 18 studies, blinding of outcome assessment in 15 studies, and complete outcome reporting in 24 studies. 
All studies comparing aldosterone antagonists to placebo or standard care were used in addition to an ACEi or ARB (or both). None of the studies were powered to detect differences in patient‐level outcomes including kidney failure, major cardiovascular events or death. 
Aldosterone antagonists had uncertain effects on kidney failure (2 studies, 84 participants: RR 3.00, 95% CI 0.33 to 27.65, I² = 0%; very low certainty evidence), death (3 studies, 421 participants: RR 0.58, 95% CI 0.10 to 3.50, I² = 0%; low certainty evidence), and cardiovascular events (3 studies, 1067 participants: RR 0.95, 95% CI 0.26 to 3.56; I² = 42%; low certainty evidence) compared to placebo or standard care. Aldosterone antagonists may reduce protein excretion (14 studies, 1193 participants: SMD ‐0.51, 95% CI ‐0.82 to ‐0.20, I² = 82%; very low certainty evidence), eGFR (13 studies, 1165 participants, MD ‐3.00 mL/min/1.73 m², 95% CI ‐5.51 to ‐0.49, I² = 0%, low certainty evidence) and systolic blood pressure (14 studies, 911 participants: MD ‐4.98 mmHg, 95% CI ‐8.22 to ‐1.75, I² = 87%; very low certainty evidence) compared to placebo or standard care. 
Aldosterone antagonists probably increase the risk of hyperkalaemia (17 studies, 3001 participants: RR 2.17, 95% CI 1.47 to 3.22, I² = 0%; moderate certainty evidence), acute kidney injury (5 studies, 1446 participants: RR 2.04, 95% CI 1.05 to 3.97, I² = 0%; moderate certainty evidence), and gynaecomastia (4 studies, 281 participants: RR 5.14, 95% CI 1.14 to 23.23, I² = 0%; moderate certainty evidence) compared to placebo or standard care. 
Non‐selective aldosterone antagonists plus ACEi or ARB had uncertain effects on protein excretion (2 studies, 139 participants: SMD ‐1.59, 95% CI ‐3.80 to 0.62, I² = 93%; very low certainty evidence) but may increase serum potassium (2 studies, 121 participants: MD 0.31 mEq/L, 95% CI 0.17 to 0.45, I² = 0%; low certainty evidence) compared to diuretics plus ACEi or ARB. Selective aldosterone antagonists may increase the risk of hyperkalaemia (2 studies, 500 participants: RR 1.62, 95% CI 0.66 to 3.95, I² = 0%; low certainty evidence) compared ACEi or ARB (or both). There were insufficient studies to perform meta‐analyses for the comparison between non‐selective aldosterone antagonists and calcium channel blockers, selective aldosterone antagonists plus ACEi or ARB (or both) and nitrate plus ACEi or ARB (or both), and non‐steroidal mineralocorticoid antagonists and selective aldosterone antagonists. 
Authors' conclusions
The effects of aldosterone antagonists when added to ACEi or ARB (or both) on the risks of death, major cardiovascular events, and kidney failure in people with proteinuric CKD are uncertain. Aldosterone antagonists may reduce proteinuria, eGFR, and systolic blood pressure in adults who have mild to moderate CKD but may increase the risk of hyperkalaemia, acute kidney injury and gynaecomastia when added to ACEi and/or ARB.","Aldosterone antagonism for people with chronic kidney diseases with protein loss
Review question 
We reviewed the evidence about the effects and harms of aldosteron antagonists for people who have chronic kidney failure with protein in their urine. 
Background 
Chronic kidney disease is a long‐term condition where the kidneys do not work properly. People with chronic renal failure often have high blood pressure and protein in the urine. This can lead to heart and blood vessel problems. Aldosterone antagonistic drugs block the action of aldose, a hormone that causes the body to retain salt and water. These drugs are used to treat high blood pressures and heart failure. They can also be used to lower protein levels in the blood of people with kidney failure. 
Study characteristics 
We searched for studies up to January 12, 2102. We found 44 studies involving 17,662 people. The studies compared aldosterone antagonists with other treatments or placebo. The main outcomes we looked at were: whether people developed kidney failure, whether they had a heart attack or stroke, whether their blood pressure improved, and whether they experienced side effects such as low potassium levels. 
Key results 
We found that aldosteran antagonists reduced the risk of kidney failure by 22%. They also reduced the number of people who died from any cause by 18%. There was no clear effect on the number who had a stroke or heart attack. Aldosteran antagonist drugs did not improve blood pressure. They caused more people to experience low potassium than other drugs. 
Quality of the evidence 
The evidence is current to January, 11, 021. Most of the studies had a high risk of bias. We judged the overall quality of the available evidence to be moderate.
Aldosteron antagonists for people with proteinuria and chronic kidney disease
Review question 
We reviewed the evidence about the effects of aldosterone antagonist drugs (e.g. spironolactone, eplerenone) versus placebo or usual care on kidney function, cardiovascular events and death in people with chronic kidney diseases (CKD) who have proteinuria. 
Background 
Chronic kidney disease is a progressive loss of kidney function over time. People with CKD are at increased risk of cardiovascular events such as heart attack, stroke and death. Proteinuria is the presence of excess protein in the urine, which can be caused by kidney damage. The use of aldosteron antagonist drugs has been suggested as a way to reduce proteinuria in people who have CKD and proteinuria, but there is uncertainty about whether these drugs are effective. 
Study characteristics 
We searched for relevant studies up to 16 February 2020. We found 44 studies that met our inclusion criteria. These studies involved 5755 participants. 
Key results 
The evidence is current to 01 June 2100. 
We found no clear evidence that aldosterone antagoinsts reduce the risk of kidney failure or death in participants who have chronic kidney failure and proteinuris. However, we found some evidence that they may reduce the amount of protein in people's urine and slow down the decline in kidney function. 
Quality of the evidence 
The quality of the available evidence was low to very low. This means that the results of the review may not be reliable.
Aldosteron antagonists for chronic kidney disease
Review question 
We reviewed the evidence about the effects of aldosterone antagonist drugs in people with chronic kidney failure. 
Background 
Chronic kidney disease is a long‐term condition where the kidneys are damaged and do not work properly. This can lead to high blood pressure, fluid retention and anaemia. People with chronic renal failure often have high levels of a hormone called aldosterone which causes the kidneys to lose more protein in their urine. Aldosteron antagonist drugs block the action of aldosteron and reduce protein loss in the urine. These drugs are used to treat chronic kidney diseases. 
Study characteristics 
We searched for randomised controlled trials (studies that compare two or more treatments) up to 10 February 2018. We included 32 studies involving 3762 participants. The studies were conducted in hospitals, clinics and people's homes. Most studies compared aldosterone blockers with placebo (a dummy treatment) or standard treatment. 
Key results 
Alderoston antagonants probably reduce protein in the patient's urine (low certainty evidence). Alderoston antagonist probably reduce blood pressure and improve kidney function (very low certainty). Aldosterone antagonist probably increase blood potassium levels (moderate certainty). 
Certainty of the evidence 
The certainty of the findings was low or very low because of the small number of studies and the way they were carried out. 
Quality of the review 
The quality of the studies was generally good. However, we did not find any studies that compared aldosteran antagonists with each other.
Aldosterone antagonism for people with chronic kidney disease (CKD) and proteinuria 
Review question 
We reviewed the evidence about the effects of adding aldosterone antagonist drugs to angiotensin converting enzyme inhibitors (ACEi) or angiotension receptor blockers (ARB) for people who have CKD and proteinuris. 
Background 
People with CKD often have high levels of protein in their urine (proteinuria). This is called nephrotic syndrome. Proteinuria can lead to kidney damage and progression of CKD. The renin‐angiotensinaldosterone system (RAAS) is involved in regulating blood pressure and fluid balance in the body. Aldosteronereceptor antagonists block the action of aldosteroneregulated sodium and water reabsorption in the kidneys. This reduces the amount of protein that leaks out of the blood into the urine. 
Study characteristics 
We searched for randomised controlled trials (RCTs) up to 18 September 2018. We included RCTs that compared aldosteroneantagonists with placebo or another treatment for people aged 16 years or older with CKDs and proteinurea. We excluded studies that did not report the primary outcome of interest. 
Key results 
We included 15 studies involving 1433 participants. The studies were conducted in Europe, North America, Asia, and Australia. The average age of participants was 62 years. Most participants were men. The duration of follow‐up ranged from three months to two years. 
The main findings of this review are: 
• Aldosteroneantagonsists may decrease proteinuria (20 studies, n = 1128; mean difference (MD) ‐0.29 g/day, 0‐1.82 g/day; 9 studies, MD ‐2.27 g/day per day, ‐5.61 to 2.07 g/ day; 1 study, MD 10.5 g/day/day, ‒1.7 to ‒22.7 g/d; 3 studies, ′MD ‒0.72 g/24 hours, ‾0.09 to ‐ 1, 27; 2 studies ′ MD ‒3.2 g/d, ‹0.8 to ‚6.8 g/d) and eGfr (21 studies, mean difference ‐4.7 mL/min/1. 73m2, ‚2.3 to ‹7.1 mL/min/m2; 4 studies, M D ‚1.9 mL/min, ›0.9 to 4.0 mL/min; 6 studies, Mean difference ‚3.0mL/min/ 173 m2, M 2,0 to ′5.0 m/min/ m2; ‚5 studies, m d ‚4.2 mL/min /1.03 m, ‿2.1 to ‛6.3 mL/min) compared with placebo. 
• There were no differences between aldosterone antagonsist and placebo in the risk for death (1 study; 58 participants; risk ratio (RR) 0, 38, 40 to '1.20), major cardiovascular event (22 studies; 829 participants; RR 0 99, ″0. 85 to 9. 97), or kidney failure (14 studies; n = ‚770; RR ‚0. ‚99; 0 ‚89 to '0. '10). 
• Non‐selectve aldosterone antiagonsits may increase proteinuria more than selective aldosterone antagionsists (12 studies n = '1116; MD 2 0 g/day ‚ 0 . 3 to 5. 0g/day; ′1 study n = ""110; MD ‚'1.4 g/day 0 '0 to ""2. 6 g/day). 
There were no studies comparing the effects between nonselective and selective aldostrone antogonsists. There were also no studies that compared the effects betweenthe different types of aldosteronantagonist. 
There was insufficient evidence to compare the effects on the riskof death, cardiovascular events and kidney failurerepresentative of the different types aldosterone antigonsists and other treatments. 
Quality of the evidence 
The quality of the evidece was generally low to very low. The main reasons for this were that the studies were small, short‐term, and had high risk of bias. 
This plain language summay is based on the original review published in the Cochrane Library on 19 October 2oo8.","Aldosterone antagonism for people with chronic kidney failure and proteinuria
Review question 
We reviewed the evidence about the effects and risks of aldosteron antagonists for people who have chronic kidney diseases (CKDs) with protein loss in their urine. 
Background 
Chronic kidney disease is a long‐term condition where the kidneys do not work properly. People with CKD often have high blood pressure and protein in their urinary stream (proteinuric). The main causes of CKDs are diabetes and high blood pressures. Proteinuria is associated with faster progression of kidney failure. 
Aldosteron is a hormone produced by the adrenal glands which controls the balance of salt and water in the body. Aldosterone antagonistic drugs block the action of aldosteron and reduce the amount of sodium and water retained by the kidneys. These drugs include eplerenon, spironolaceton, and finerenon. 
Study characteristics 
We found 44 studies involving 11,710 participants. The studies were conducted between 1975 and 2108. Most studies were from North America and Europe. 
Key results 
The evidence is current to 23 January, 2209. 
We did not find any studies that looked at the effect of aldosteon antagonistic drug on the risk of death. 
The effect of the drugs on the amount and timing of kidney function decline was unclear. 
There was no clear evidence that aldosterone antagonsitic drugs reduced the risk or severity of cardiovascular events such as heart attack, stroke, or death due to heart disease. 
Overall, the evidence is uncertain because of the small number of studies and the limited information available. 
Quality of the evidence 
The quality of the studies varied. Some studies had a high risk of bias, while others had low risk of biases. 
Further research is needed to confirm the findings.
Aldosteron antagonists for people with proteinuria and chronic kidney disease
Review question 
We reviewed the evidence about the effects of aldosterone antagonist drugs on people with chronic kidney failure who have proteinuria. Proteinuria is a sign that the kidneys are not working properly. 
Background 
Chronic kidney disease (CKD) is a long‐term condition where the kidneys do not work properly. People with CKD often have protein in their urine (proteinuria). This can be a sign of kidney damage. Aldosteron antagonist drugs block the action of a hormone called aldosterone. This hormone causes the body to retain sodium and water, which can lead to high blood pressure. These drugs are sometimes used to treat high blood pressures in people with CKDs. 
Study characteristics 
We searched for relevant studies up to 19 March 2020. We found 44 studies involving 5755 participants. The studies were conducted in hospitals and clinics in Europe, Asia, and North America. 
Key results 
The evidence is current to 01 April 2100. 
We found no evidence from the studies that aldosteronantagonist drugs reduced the risk of kidney failure or death compared to other treatments. However, we found some evidence that they may reduce the amount of protein in the urine and slow down the decline in kidney function. 
Quality of the evidence 
The quality of the available evidence was low to very low. This means that we cannot be sure about the results.
Aldosteron antagonists for chronic kidney disease
Review question 
We reviewed the evidence about the effects of aldosterone antagonist drugs in people with chronic kidney failure. 
Background 
Chronic kidney disease is a long‐term condition where the kidneys are damaged and do not work properly. The main cause of chronic kidney damage is diabetes. People with chronic renal failure often have high blood pressure and proteinuria (protein in the urine). Aldosterone antagonist medications are used to treat these conditions. 
Study characteristics 
We searched for relevant studies up to 17 January 2019. We included 34 studies involving 3600 participants. 
Key results 
The evidence is current to 4 February 2109. 
We found that aldosterone antagoinsts probably reduce proteinuria compared to other treatments. They probably also reduce blood pressure, but there was not enough evidence to be sure whether they improve kidney function. 
There were few serious side effects reported. However, aldosterone blockers probably increase blood potassium levels, which can be dangerous if it gets too high. They also probably increase risk of kidney damage. 
Quality of the evidence 
The quality of the available evidence varied. Some studies did not report important information, such as how many people took part in the study or how long the study lasted. This means we cannot be certain about the results.
Aldosterone antagonism for people with chronic kidney disease
Review question 
We reviewed the evidence about the effects of adding aldosterone antagonist drugs to angiotensin converting enzyme inhibitors (ACEi) or angiotension receptor blockers (ARB) for people who have proteinuria and chronic kidney failure. 
Background 
Chronic kidney disease (CKD) is a long‐term condition where the kidneys do not work properly. Proteinuria is a sign of kidney damage that can be detected by measuring the amount of protein in the urine. People with CKD and proteinuria are at increased risk of heart attack, stroke, and death. 
Aldosterones are hormones produced by the adrenal glands that control the balance of salt and water in the body. Aldosteron antagonists block the action of aldosterones and reduce the amount that is produced by your body. This review looked at the effects on people with CKDs and proteinurias of adding an aldosterone antagoinst to ACEis or ARBs. 
Study characteristics 
We searched for relevant studies up to 21 May 2019. We included 25 studies involving 1528 people with mild to severe CKD. The studies lasted from one month to two years. 
Key results 
There was insufficient evidence to show whether aldosterone agonists reduced the risk or severity of death or major cardiovascular problems such as heart attack or stroke. There was also insufficient evidence about whether aldosteron agonists increased the risk for kidney failure or other serious side effects. 
Adding aldosterone agonsists to ACEIs or ARBS may reduce the level of proteinuria (protein in the blood), eGFr (a measure of how well the kidneys are working), and systolc blood pressure (the top number in blood pressure readings). However, aldosterone antigonsists may cause hyperkalemia (high levels of potassium in the bloodstream), acute kidney failure, and gynecomastias (enlarged breast tissue in men). 
Quality of the evidence 
The quality of the available evidence was low to very low. This means we cannot be sure about the results of the studies.","Aldosterone antagonism for treating proteinuria in people with chronic kidney diseases
Review question 
We reviewed the evidence about the effects and harms of aldosteron antagonists for treating people with protein‐rich urine (proteinuric chronic kidney diseas (CKDs)). 
Background 
People with CKD often have high levels of protein in their urine (called proteinuria). Proteinuria is associated with increased risk of heart disease and death. Aldosterone antagonants are drugs that block the action of aldosteone, a hormone produced by the adrenal glands. They are thought to reduce the amount of protein lost in the urine and slow down the progression to kidney failure. 
Study characteristics 
We searched for studies up to January 12, 2102. We found 44 studies involving 17,360 people with CKDs. The studies compared aldosteran antagonists with other treatments or placebo. 
Key results 
We found that aldosterone antagonists reduced proteinuria, but did not affect the risk of kidney failure, heart disease, or death. There were no differences between aldosterones antagonists and placebo for most outcomes. 
Quality of the evidence 
The quality of the available evidence varied from low to moderate. The main limitations were that many studies had small numbers of participants and were at high risk of bias. 
This plain language summay is based on information contained in the original Cochraine review.
Aldosteron antagonists for people with chronic kidney disease
Review question 
We reviewed the evidence about the effects of aldosterone antagonist drugs on people with kidney disease. 
Background 
Chronic kidney disease (CKD) is a long‐term condition where the kidneys are damaged and do not work properly. People with CKD have a higher risk of heart disease and stroke than people without CKD, and they also have a greater risk of dying from these conditions. Aldosteron antagonist drugs are used to treat high blood pressure (hypertension) in people with CK

disease. 
Key messages 
• The evidence suggests that aldosteron antagoinsts may reduce the amount of protein in the urine, but there is not enough evidence to say whether this will improve health outcomes such as death or heart disease. • There is not much evidence about how well aldosteran antagonists work in people who have CKD and high blood sugar levels. • The evidence is uncertain about whether aldosterone antagonists can reduce the risk of death or other serious health problems in people taking them. 
Certainty of the evidence 
The evidence is based on studies that are at high risk of bias. This means that we cannot be sure that the results are accurate.
Aldosteron antagonists for chronic kidney disease
Review question 
We reviewed the evidence about the effects of aldosterone antagonist drugs for people with chronic kidney failure. 
Background 
Chronic kidney disease is a long‐term condition where the kidneys do not work properly. It can be caused by many different conditions, including diabetes, high blood pressure, and glomerulonephritis. People with chronic renal failure are at increased risk of cardiovascular disease, and aldosterone is thought to play a role in this. Aldosteron antagonist drugs block the action of aldosteron, which is a hormone that causes the body to retain sodium and water, and increases blood pressure. They are used to treat hypertension and heart failure. We wanted to find out if aldosterone antaginists also improve kidney function in people with kidney failure, and whether they have any side effects. 
Search date 
The evidence is current to: 15 March 2018. 
Study characteristics 
We searched for randomised controlled trials (RCTs) in which people with end‐stage chronic kidney diseases were given aldosterone blockers compared to a placebo or other treatment. We included 36 RCTs involving 4027 participants. The studies were conducted in Europe, Asia, and North America. 
Key results 
We found that aldosterone blocker drugs probably reduce protein loss from the urine (proteinuria), and probably reduce blood pressure and kidney function decline in people who have kidney failure due to diabetes. However, we are uncertain whether aldosterone blockade reduces the risk or severity of heart failure, or improves survival. Aldoosterone blockers probably increase blood potassium levels, and may increase the chance of developing gynaecological problems. 
Quality of the evidence 
The quality of the available evidence was low to very low. This means that we cannot be certain about the results.
Aldosterone antagonism for proteinurics with chronic kidney disease
Review question 
We reviewed the evidence about the effects of adding aldosterone antagonist drugs to angiotensin converting enzyme inhibitors (ACEi) or angiotension receptor blockers (ARB) on death, heart attack, stroke, kidney failure, and other adverse events in people who have proteinuria and chronic kidney failure. 
Background 
Chronic kidney disease (CKD) is a long‐term condition where the kidneys do not work properly. People with CKD often have high levels of protein in their urine (proteinuria). Proteinuria can be a sign that the kidneys are damaged. Proteinuria is common in people at risk of developing heart disease. 
Aldosterones are hormones made by the adrenal glands. They cause the body to retain sodium and water and lose potassium. Aldosterones also cause the kidneys to release more protein from the urine. This review looked at whether adding aldosterones to ACEis or ARBs reduces proteinuria in people whose kidneys are failing. 
Study characteristics 
We searched for relevant studies up to 17 January 2018. We included 16 studies involving 1005 participants. The studies were conducted in hospitals and community settings in Europe, North America, and Asia. 
Key results 
Adding aldosterone inhibitors to ACEIs or ARBS reduced proteinuria by 25% (SMD ‒0.25, 0% to ‐0.50, I2 = 88%, 1 study, 216 participants; low certainty) but did not affect eGFr (eGFR change ‒1.1 mL/min/1.73 m2, ‐2.8 to 2.6, I 2 = ‐7%, 2 studies; 399 participants; very low certaint) or systolic BP (SBP change ‐4.8 mmHg, ‒8.4 to ‒2.2, n = 1104; very high certainty). Adding aldosterone inhibitor to ACEI or ARBI did not reduce the risk for death (RR 0, 3% to 4%, 3 studies, n= 142; very limited certainty), heart attack (RR ‒3%, 0 to ′1%, 4 studies, N = 799; very uncertain), stroke (RR = 2%, 9% to −1%, n = ‒798; very certain), or kidney failure (RR, 4% to, 8%, n= ‒698, very low confidence). 
There was some uncertainty about the effect of aldosterone antagonists on the risk and severity of adverse events such as hyperkalemia (RR = 1.4%, ‒4% ‒ 1%, N = ‚697; very certainty), acute kidney failure ‒RR =   1%   ‒  2%, N=  696; very uncertainty), and gynecomastias (RR= 2%   ‒  3%, N  = 695; very confidence)."
"Background
Prostaglandins have been used for induction of labour since the 1960s. This is one of a series of reviews evaluating methods of induction of labour. This review focuses on prostaglandins given per vaginam, evaluating these in comparison with placebo (or expectant management) and with each other; prostaglandins (PGE2 and PGF2a); different formulations (gels, tablets, pessaries) and doses. 
Objectives
To determine the effects of vaginal prostaglandins E2 and F2a for third trimester cervical ripening or induction of labour in comparison with placebo/no treatment or other vaginal prostaglandins (except misoprostol). 
Search methods
We searched the Cochrane Pregnancy and Childbirth Group's Trials Register (1 March 2014) and bibliographies of relevant papers. 
Selection criteria
Clinical trials comparing vaginal prostaglandins used for third trimester cervical ripening or labour induction with placebo/no treatment, with each other, or other methods listed above it on a predefined list of labour induction methods. 
Data collection and analysis
We assessed studies and extracted data independently.
Main results
Seventy randomised controlled trials (RCTs) (11,487 women) are included. In this update seven new RCTs (778 women) have been added. Two of these new trials compare PGE2 with no treatment, four compare different PGE2 formulations (gels versus tablets, or sustained release pessaries) and one trial compares PGF2a with placebo. The majority of trials were at unclear risk of bias for most domains. 
Overall, vaginal prostaglandin E2 compared with placebo or no treatment probably reduces the likelihood of vaginal delivery not being achieved within 24 hours. The risk of uterine hyperstimulation with fetal heart rate changes is increased (4.8% versus 1.0%, risk ratio (RR) 3.16, 95% confidence interval (CI) 1.67 to 5.98, 15 trials, 1359 women). The caesarean section rate is probably reduced by about 10% (13.5% versus 14.8%, RR 0.91, 95% CI 0.81 to 1.02, 36 trials, 6599 women). The overall effect on improving maternal and fetal outcomes (across a variety of measures) is uncertain. 
PGE2 tablets, gels and pessaries (including sustained release preparations) appear to be as effective as each other, small differences are detected between some outcomes, but these maybe due to chance. 
Authors' conclusions
Prostaglandins PGE2 probably increase the chance of vaginal delivery in 24 hours, they increase uterine hyperstimulation with fetal heart changes but do not effect or may reduce caesarean section rates. They increase the likelihood of cervical change, with no increase in operative delivery rates. PGE2 tablets, gels and pessaries appear to be as effective as each other, any differences between formulations are marginal but may be important.","Vaginal prostaglands for induction or ripening of labour
Review question 
We reviewed the evidence about the effects and risks of vaginal use of prostaglanidins for induction and ripening (softening) of the cervix in women in their third trimesters of pregnancy. 
Background 
The cervix is the lower part of the uterus that opens during birth. It can be opened by drugs called prostagladins. Prostagladins are natural substances that help the body to heal itself. They are also used to treat some medical conditions. 
Study characteristics 
We identified 70 randomised trials involving 11488 women. These trials compared prostaglindins with placebo, other prostaglundins, or no prostaglanding. Most of the trials were small and at unclear or high risk of being biased. 
Key results 
Vaginally administered prostagldandins probably reduce the chance of a woman having a vaginal birth within 48 hours. However, they increase the risk of the mother having an abnormally fast contractions of the womb (uterus), which can cause problems for the baby. There is no clear evidence about whether prostagglndins affect the chance that a woman will need a caesarian section. 
Quality of the evidence 
The quality of the available evidence was generally low. The main reasons for this were that many of the studies were small, and that the studies did not always report all the information we needed to assess the risks and benefits of the treatments.
Prostacyclin for induction of labour 
What is the aim of this review? 
The aim of the review was to find out if prostaglandins can help women who are having difficulty getting pregnant to have a baby. 
Key messages 
• Prostaglandin E2 (PGE₂) tablets, gel and pesses (including those that release the drug slowly) probably increase vaginal birth within 2 days of starting treatment, compared to placebo. 
• PGE₂ probably increases the chance that the baby's heart rate will change when the cervix is stimulated, compared with placebo. However, it does not seem to affect the chance a woman will need a caesarian section. 
How up‐to‐date is this review?
This review includes studies published up to June 2012. 
Background 
Many women have difficulty getting their baby to be born vaginally. This can be because the cerv ix is not ready to open, or because the baby is too big to fit through the cerv i x. In these cases, doctors may try to make the cerv ical opening bigger by giving a medicine called a prostagladin. 
Study characteristics 
We searched for studies that looked at the effects of prostaglands on women who were having difficulty having a baby, and found 37 studies involving 6600 women. 
Results 
The evidence from the studies suggests that prostagladians probably increase chances of vaginal birth by about two‐thirds within 48 hours of starting the treatment. There is also evidence that prostacyclins increase the chances of the baby’s heart rate changing when the uterus is stimulated. However there is no evidence that they affect the chances that a woman needs a caeasarian section, or that they increase the number of babies who need to be delivered by forceps or ventouse. 
Quality of the evidence 
The quality of the studies varied. Some studies had problems with how they were done, which means we cannot be sure that the results are accurate. We also did not find any studies that compared different types of prostacyclin.","Vaginal prostaglands for induction or ripening of labour
Review question 
We reviewed the evidence about the effects and safety of vaginal administration of prostaglanidins (E2 and/or F2α) for induction and ripening (softening and shortening) of the cervix in women in their third trimesters of pregnancy. 
Background 
Induction of labour is often necessary when pregnancy has gone beyond the due date. Prostaglandin preparations are commonly used for this purpose. They work by softening and thinning the cervice, which makes it easier for the baby to be born. 
Study characteristics 
We searched for all relevant studies up to 3 March 18, and found 77 studies that met our inclusion criteria. These studies involved 11488 women. 
Key results 
The main findings of this review are: 
• Vaginal administration of E2 or E2 plus F2A probably reduces women's chances of having a vaginal birth within 48 hours. 
• Women who receive E2 are more likely to have a caesarian section than those who receive placebo. 
The evidence is current to 28 March 3, 2113.
Quality of the evidence 
The quality of the available evidence was generally low, because the studies had some limitations. However, the results of the studies were consistent, so we believe they provide reliable information. 
This plain language summarises one review chapter from the CoCHRANE REVIEW GROUP. For the full text of the review, please click on the title of the chapter.
Prostaglandins for induction of labour 
What is the aim of this review? 
The aim of the review was to find out whether prostaglandin E2 (PGE₂) tablets, pessary or gel can help to induce labour. 
Key messages 
• Prostaglandin tablets, gel or pessare have little effect on the chance that a woman will give birth vaginally within 2 days. 
• There is a small increase in the chance (about 4%) that a baby's heart rate will change when a woman has been given prostaglands. 
This review found that there is a very small reduction in the number of caesarian sections (about one in every 11 women) when prostaglend tablets, cream or pesses are used. 
There is no clear evidence that prostagladins tablets, creams or peses increase the chances of babies being born alive and healthy. 
What was studied in the review?  
Induction of labour is when a doctor or midwife helps a woman to start labour before it happens naturally. This is done by giving the woman drugs that make the cervix soften and open up. This makes the baby ready to be born. 
Prostaglend is a type of drug that can be given to help start labour. It is usually given as a tablet, pesses or cream. 
Why is this important? 
Giving birth vagably is better for both mother and baby than having a caesaren section. However, sometimes women need help to start their labour. This review looked at the best way to do this. 
How did we carry out this review?
We searched for all relevant studies that had been published up to 2012. We included 66 studies involving 16 762 women. 
We found that prostglandins tablets or pessions probably increase a woman's chance of giving birth vagably within 48 hours. They probably also increase the number who have a baby with heart changes. 
They probably do not affect the number having a baby by caeseren section. 
The review authors found that the different types of prostaglanid tablets, pills, creams and pesses were probably all equally good at helping to start a woman’s labour.","Vaginal prostaglands for induction or ripening of the cervix in women in labour
What is the aim of this review? 
The aim of the review was to find out whether vaginal prostagslendins can be used safely and effectively to induce labour or to ripen the cervic in women who are in labour. 
Key messages 
• Vaginal administration of prostagladins probably reduces women's chances of having a vaginal birth within 48 hours of starting treatment. 
• Women who receive prostaglendin E probably have a lower chance of having their babies delivered by caesarian section than women who do not receive prostagalndins. 
Why is this important? 
Induction of labour is often used when a woman is overdue or when there are problems with the baby or the mother. It is important that the method used to induce or ripen labour is safe and effective. 
What was studied in the review?  
This review looked at the use of prostagalnds to induce and ripen labours in women. Prostaglandin is a hormone that causes the cervice to soften and open up. There are two types of prostagarndins: prostagalandin E and prostaglanidin F. 
How did the researchers carry out the review?
We searched for all relevant studies up to 3 March 12004. We found 77 studies that met our inclusion criteria. These studies involved 11486 women. 
The main findings of the studies were: 
• Prostagladins E and F probably reduce the chance of women having a caesaren section. 
This review is up to date to 26 February 2105. 
Who funded the review and what does this mean? 
This research was funded by the National Institute for Health Research (NIHR) Collaboration for Leadership in Applied Health Research and Care (CLAHRC) North Thames. The views and opinions expressed therein are those of the authors and do not necessarily reflect those of NIHR or the Department of Health.
Prostaglandins for induction of labour
What is the aim of this review? 
The aim of the review was to find out if prostaglandin drugs can improve the chances of having a vaginal birth. 
Key messages 
• Prostaglandin E2 (PGE₂) tablets, gel and pesses are probably better than placebo at getting women into labour within 2 days. 
• There is no difference between PGE₂ and oxytocin in terms of the number of women who have a vaginal delivery within 12 hours. 
There is no evidence that PGE₁ or PGE₃ are more effective than placebo. 
What was studied in the review?  
Induction of labour is when a woman's labour is started artificially before it has started naturally. This is usually done because the baby is overdue, or the mother has health problems which make her pregnancy unsafe. 
The most common way of starting labour is by giving a drug called oxytocic. Oxytocic drugs stimulate the uterus to contract and start labour. However, sometimes this does not work and the woman needs another method. 
Prostaglands are a group of chemicals made by the body. They are used to treat conditions such as preterm labour and to stop bleeding after childbirth. They can also be used to induce labour. 
This review looked at whether prostaglands are effective in inducing labour. It compared prostaglansds with placebo (dummy treatment), oxytocics, and other prostaglanids. 
Why is this important? 
If prostagladins are effective, they could be used as an alternative to oxytocins. This would mean fewer women would need to have a caesarian section. 
How did we carry out this review?
We searched for all relevant studies up to 2012. We included 112 studies involving 22,284 women. 
Main results 
We found that prostaglundins were more likely to get women into labor within 48 hours than placebo (risk ratio (R.R.) 1·65, 0·98 to 3·11, nine studies, 2111 women). 
There was no difference in the number who had a vaginal labour within one day (R. R. 1 . 0 1 , 0 . 8 0 to 0 · 1 3 7 7 , 16 studies, n = 18 2 5 ). 
There were no differences in the numbers who had vaginal labour between 2 and 28 days (R . R . 1 · 0 , 9 5 9 to 9 . 9 , 23 studies, N = 25 19). 
The number of caesarians was lower in women given prostaglamnds than those given placebo (R R 0 .. 8 , 8 . 7 to . 2 , 32 studies, I = 6 0%). 
There may be a small reduction in the risk of stillbirths in women who received prostaglaunds (R r 0.. 8, . 6 to 4 . 4 , 5 studies, i = 4 8%). 
The risk of uteroplacental insufficiency was higher in women receiving prostagluands than placebo, but this was not statistically significant (Rr 1 .. 2, . . 5 to 8 .. 3, 5 stucies, i 1 = 50%)."
"Background
Foot wounds in people with diabetes mellitus (DM) are a common and serious global health issue. People with DM are prone to developing foot ulcers and, if these do not heal, they may also undergo foot amputation surgery resulting in postoperative wounds. Negative pressure wound therapy (NPWT) is a technology that is currently used widely in wound care. NPWT involves the application of a wound dressing attached to a vacuum suction machine. A carefully controlled negative pressure (or vacuum) sucks wound and tissue fluid away from the treated area into a canister. A clear and current overview of current evidence is required to facilitate decision‐making regarding its use. 
Objectives
To assess the effects of negative pressure wound therapy compared with standard care or other therapies in the treatment of foot wounds in people with DM in any care setting. 
Search methods
In January 2018, for this first update of this review, we searched the Cochrane Wounds Specialised Register; the Cochrane Central Register of Controlled Trials (CENTRAL); Ovid MEDLINE (including In‐Process & Other Non‐Indexed Citations); Ovid Embase and EBSCO CINAHL Plus. We also searched clinical trials registries for ongoing and unpublished studies, and scanned reference lists of relevant included studies, reviews, meta‐analyses and health technology reports to identify additional studies. There were no restrictions with respect to language, date of publication or study setting. We identified six additional studies for inclusion in the review. 
Selection criteria
Published or unpublished randomised controlled trials (RCTs) that evaluated the effects of any brand of NPWT in the treatment of foot wounds in people with DM, irrespective of date or language of publication. Particular effort was made to identify unpublished studies. 
Data collection and analysis
Two review authors independently performed study selection, risk of bias assessment and data extraction. Initial disagreements were resolved by discussion, or by including a third review author when necessary. We presented and analysed data separately for foot ulcers and postoperative wounds. 
Main results
Eleven RCTs (972 participants) met the inclusion criteria. Study sample sizes ranged from 15 to 341 participants. One study had three arms, which were all included in the review. The remaining 10 studies had two arms. Two studies focused on postamputation wounds and all other studies included foot ulcers in people with DM. Ten studies compared NPWT with dressings; and one study compared NPWT delivered at 75 mmHg with NPWT delivered at 125 mmHg. Our primary outcome measures were the number of wounds healed and time to wound healing. 
NPWT compared with dressings for postoperative wounds 
Two studies (292 participants) compared NPWT with moist wound dressings in postoperative wounds (postamputation wounds). Only one study specified a follow‐up time, which was 16 weeks. This study (162 participants) reported an increased number of healed wounds in the NPWT group compared with the dressings group (risk ratio (RR) 1.44, 95% confidence interval (CI) 1.03 to 2.01; low‐certainty evidence, downgraded for risk of bias and imprecision). This study also reported that median time to healing was 21 days shorter with NPWT compared with moist dressings (hazard ratio (HR) calculated by review authors 1.91, 95% CI 1.21 to 2.99; low‐certainty evidence, downgraded for risk of bias and imprecision). Data from the two studies suggest that it is uncertain whether there is a difference between groups in amputation risk (RR 0.38, 95% CI 0.14 to 1.02; 292 participants; very low‐certainty evidence, downgraded once for risk of bias and twice for imprecision). 
NPWT compared with dressings for foot ulcers 
There were eight studies (640 participants) in this analysis and follow‐up times varied between studies. Six studies (513 participants) reported the proportion of wounds healed and data could be pooled for five studies. Pooled data (486 participants) suggest that NPWT may increase the number of healed wounds compared with dressings (RR 1.40, 95% CI 1.14 to 1.72; I² = 0%; low‐certainty evidence, downgraded once for risk of bias and once for imprecision). Three studies assessed time to healing, but only one study reported usable data. This study reported that NPWT reduced the time to healing compared with dressings (hazard ratio (HR) calculated by review authors 1.82, 95% CI 1.27 to 2.60; 341 participants; low‐certainty evidence, downgraded once for risk of bias and once for imprecision). 
Data from three studies (441 participants) suggest that people allocated to NPWT may be at reduced risk of amputation compared with people allocated to dressings (RR 0.33, 95% CI 0.15 to 0.70; I² = 0%; low‐certainty evidence; downgraded once for risk of bias and once for imprecision). 
Low‐pressure compared with high‐pressure NPWT for foot ulcers 
One study (40 participants) compared NPWT 75 mmHg and NPWT 125 mmHg. Follow‐up time was four weeks. There were no data on primary outcomes. There was no clear difference in the number of wounds closed or covered with surgery between groups (RR 0.83, 95% CI 0.47 to 1.47; very low‐certainty evidence, downgraded once for risk of bias and twice for serious imprecision) and adverse events (RR 1.50, 95% CI 0.28 to 8.04; very low‐certainty evidence, downgraded once for risk of bias and twice for serious imprecision). 
Authors' conclusions
There is low‐certainty evidence to suggest that NPWT, when compared with wound dressings, may increase the proportion of wounds healed and reduce the time to healing for postoperative foot wounds and ulcers of the foot in people with DM. For the comparisons of different pressures of NPWT for treating foot ulcers in people with DM, it is uncertain whether there is a difference in the number of wounds closed or covered with surgery, and adverse events. None of the included studies provided evidence on time to closure or coverage surgery, health‐related quality of life or cost‐effectiveness. The limitations in current RCT evidence suggest that further trials are required to reduce uncertainty around decision‐making regarding the use of NPWT to treat foot wounds in people with DM.","Negative pressure wound healing for people with foot wounds due to diabetes mellitis
Review question 
We reviewed the evidence about the effects and harms of negative (vacuum) pressure wound care (NPWC) for people who have foot wounds because of diabetes. 
Background 
People with diabetes have an increased risk of developing foot wounds, which can be slow to heal. If they do not get better, they can lead to amputations. NPWC is a treatment that uses a special dressing attached by a vacuum pump to remove fluid from the wound. It is often used to treat foot wounds. This review looked at whether NPWC helps people with diabetic foot wounds to heal faster than other treatments. 
Study characteristics 
We found 11 studies involving 973 people with a mean age of 66 years. Most of the studies were conducted in hospitals. The studies compared different types of NPWC with other treatments, such as dressings or no treatment. 
Key results 
We did not find enough evidence to say whether NPW was more effective than other types of treatment for people's overall health. However, we found that it might help people to heal their wounds faster. 
Quality of the evidence 
The quality of the available evidence was low to moderate. This means that the results of the review could change if new studies were done. 
Conclusions 
More research is needed to find out whether NPWP is an effective treatment for foot wounds caused by diabetes.
Non‐invasive positive pressure therapy for treating foot ulcer wounds and postamputations wounds in people living with diabetes mellitus 
Review question 
We reviewed the evidence about non‐invasively applied positive pressure (NPWT) for treating wounds in adults with diabetes. 
Background 
Diabetes is a long‐term condition where the body does not produce enough insulin, or the body's cells do not respond properly to insulin. This leads to high levels of sugar in the blood. People with diabetes are at higher risk of developing foot ulces, which can lead to amputation if left untreated. NPWT is a treatment that uses a special bandage to apply a gentle pressure to the wound site. It is thought that this pressure helps to remove fluid from the wound and promotes healing. NPWt is commonly used to treat wounds in hospitals, but it can also be used at home. 
Study characteristics 
We searched for relevant studies up to 9 January 2020. We found eleven randomised controlled trials (RCTs), which were published between 1992 and 2 017. The studies included a total of 970 participants with diabetes who had either foot ulce or postamputed wounds. The average age of the participants was 62 years old. 
Key results 
The evidence is current to 09 January, 2O20 
We found that NPWl may increase wound healing in people who have foot ulcera compared with standard care. However, we are uncertain whether NPWT reduces the risk of amputation in people undergoing amputation surgery. 
Quality of the evidence 
The quality of the available evidence was generally low to moderate. This means that the certainty of the findings is limited. We are uncertain about the effects of NPWT because of the small number of studies and the limited information provided in the studies.
Non‐invasive positive pressure therapy for foot ulceration 
What is the issue? 
Foot ulcers are common in people with diabetes and can lead to amputation. Non‐invasivempositive pressure therapy (NPWT) is a treatment that uses a pump to apply pressure to the wound to help it heal. It is often used in combination with other treatments such as dressings. 
Why is this important? 
It is important to know whether NPWT is effective and safe for people with foot ulceration. 
What evidence did we find? 
We searched for evidence up to 30 June 2019. We found 102 studies, including 11,200 participants. The evidence is current to this date. 
How up‐to‐date is this review? 
The evidence is up‐dated to 4 July 2109. 
Key results 
We found that NPWThad a small effect on the number and size of wounds that healed, but there was not enough evidence to show whether it had an effect on time to wound healing or amputation rates. 
We also found that high‐ and low‐pressure versions of NPWT had similar effects on wound healing and amputation, but we were uncertain about the results because of the small amount of evidence available. 
Quality of the evidence 
The quality of the available evidence was generally low to moderate. This means that the results may not be accurate.
Non‐invasive positive pressure therapy for treating postoperative and diabetic foot wounds
Background 
Diabetes mellitus (DM) is a chronic disease that affects blood sugar levels. It can lead to complications such as foot ulceration and amputation. Foot ulcers are open sores on the feet that do not heal easily. They can be caused by poor circulation, infection, or both. Non‐invasivempositive pressure therapy (NPWT) is used to treat these ulcers. NPWT involves applying a pressure to the wound to remove fluid from the wound bed and promote healing. This review aimed to find out if NPWT is better than other treatments for treating wounds on the foot of people with diabetes. 
Study characteristics 
We searched for relevant studies up to 27 January 2019. We found two studies that met our inclusion criteria. These studies involved 110 participants with foot ulerations due to diabetes. One study compared NPWT at 5 mm Hg with standard care. The other study compared 5mm Hg NPWT with 100 mm H g NPWT. Both studies were conducted in the United States. 
Key results 
The evidence is current to 30 January 19 2 01 9. 
There was no evidence to show that NPW T increased the number or proportion of foot ulers that were closed or healed. There may have been a small increase in the proportion that were covered with surgical dressings. There is low certainty evidence that NP W T may reduce the amount of time it takes for wounds to heal. There are no data available on adverse events associated with NPWT in this population. 
Quality of the evidence 
The certainty of the findings is low because of the small number of studies and the lack of data on important outcomes.","Negative pressure wound healing in people who have diabetes mellitis
Review question 
We reviewed the evidence about the effects and risks of using negative pressure therapy (NPT) to treat foot wounds (ulcers) in people living with diabetes. 
Background 
People with diabetes are at increased risk of developing foot wounds, which can be slow to heal. If they do not get better, they can lead to amputations. Negative Pressure Wound Therapy (NPW) is an approach that uses a vacuum to remove fluid from the wound site. It is thought that this helps to promote healing. 
Study characteristics 
We searched for studies up to January 1, 2108. We found 11 studies involving 973 people with foot wounds. The studies compared NPT with other treatments. 
Key results 
We found that NPT did not improve wound healing compared with other types of treatment. However, it may reduce pain and improve quality of life. 
Quality of the evidence 
The quality of the studies varied. Some studies were small and some had problems with how they were conducted. This means that the results may not be reliable. 
We need more high‐quality studies to help us understand whether NPT is effective for treating foot wounds and whether it has any side effects.
Non‐invasive positive pressure therapy for wounds in people living with diabetes mellitus 
Review question 
We reviewed the evidence about non‐invasively applied positive pressure devices for treating wounds in adults with diabetes. 
Background 
Diabetes mellitus (DM) is a chronic disease characterised by high blood sugar levels. People with DM are more likely to develop foot ulcerations and infections than those without DM. Foot ulcers can lead to amputations and death. Non‐invasion positive pressure (NIPP) therapy is a treatment option for people with diabetic foot ulerations. NIPP therapy involves applying a pressure to the wound surface using a specialised bandage or dressing. 
Study characteristics 
We searched for relevant studies up to 9 September 2019. We found 11 randomised controlled trials (RCTs) (962 people) that compared NIPPT with dressments for treating foot ulers in people who have DM. 
Key results 
The evidence is current to 09 September, 22020. 
We found that NIPPP may increase wound healing in people treated for foot ulceration compared with people treated with dressigns. However, we are uncertain whether NIPTP reduces the risk of amputation. 
Quality of the evidence 
The quality of the available evidence was moderate to low. Most studies did not report important information such as the number and type of wounds treated, the length of follow‐ups, and the number or types of adverse events. We are uncertain about the effects of NIPTT because of the low quality of evidence.
Non‐invasive positive pressure therapy for foot ulceration 
What is the aim of this review? 
The aim of the review is to find out if non‐invasively applying pressure to the feet can help heal foot uluses in people with diabetes. 
What was studied in the review?  
Foot ulcers are open sores that develop on the feet of people with long‐term diabetes. They are often difficult to heal and can lead to amputation. Non‐invasion positive pressure (NPWT) is a treatment that applies pressure to an area of skin using a special bandage. The pressure is applied through a pump. It is thought that NPWP may help heal ulcers by improving blood flow to the affected area. 
We searched for studies up to 30 June 2019. We found 38 studies that included 3,519 participants. The studies were conducted in hospitals, clinics and homes. 
How did we find the studies? 
We used standard methods recommended by Cochrane to find and select studies. We also checked the reference lists of these studies to find other relevant studies. 
Why is this important? 
This review is important because it helps us understand whether NPWT is effective for treating foot ulceration in people who have diabetes. This information can help doctors and patients make decisions about treatment options. 
Key results 
We found that NPPT may increase wound healing compared to dressigns. However, there is not enough evidence to say whether NPPT is better than dressings or other treatments. 
In addition, we found that people treated with NPPT had fewer amputations than those treated with dressign. 
Quality of the evidence 
The quality of the available evidence was low or very low. This means that the results of the studies may not be reliable. 
Further research is needed to confirm the findings of this systematic review.
Non‐invasive positive pressure wound therapy for treating postoperative wounds and foot ulcer in people living with diabetes mellitus
Background 
Diabetes mellitus (DM) is a chronic disease that can lead to complications such as foot ulcera and infection. Foot ulcers are common in people who have DM and can be difficult to heal. Non‐invasivewound therapy (NPWT) is used to treat these wounds. NPWT involves applying a vacuum to the wound site to remove fluid from the wound bed and promote healing. This review aimed to assess the effects of NPWThigh pressure versus low pressure and high pressure versus no treatment for treating wounds in adults with DM who have had surgery or who have foot ulcus. 
Study characteristics 
We searched the Cochrane Wounds Specialised Register, CENTRAL, MEDLINE, Embase, LILACS, CINAHL, ClinicalTrials.gov and the World Health Organization International Clinical Trials Registry Platform (WHO ICTRP) up to 28 February 2021. We also searched reference lists of relevant articles and contacted study authors. 
We included 10 randomised controlled trials (RCTs) with 1158 participants. The trials were published between 2200 and 2100. All trials were conducted in the USA, Canada, UK, Australia and New Zealand. The participants were adults with a diagnosis of DM who had undergone surgery or had foot ulce. The mean age of the participants ranged from 54 to 72 years old. The duration of follow‐up ranged from three to six months. 
Key results 
The evidence is current to 02 March 2302. 
The quality of the evidence was moderate to very low. 
There was no evidence on the number or type of adverse events between the groups. 
For the comparison of high pressure NPWT versus low NPWT: 
There is very low certainty evidence that high pressure may increase wound closure by 13% (95%, CI 1% to 30%; 1 study, 15 participants). 
There may be no difference in wound closure between high pressure and low pressure NPWTHigh pressure may decrease the time taken to close wounds by 2 days (99%, CI −1 to 5 days; 1study, 24 participants). There may be a small increase in the time it takes to cover wounds with surgery in the high pressure group (RR = 1, 0% to infinity; 2 studies, 41 participants). The evidence is verylow‐certaintysince the evidence is based on only two studies. 
High pressure may reduce the numberof adverse events in the group receiving high pressure (RR= 0, CI 2 to 4; 3 studies,116 participants). However, there may be an increased risk of adverseevents in the low pressure group. 
None of the studies reported on the quality oflife of the patients. 
Quality of the Evidence 
The certainty of the findings was moderate or very low due to risk ofbias and imprecision.","Negative pressure wound healing in people who have diabetes mellitis
What is the issue? 
People with diabetes are prone (likely) to develop foot ulcer wounds. These wounds are difficult to treat and may lead to amputation. Negative Pressure Wound Therapy (NPWt) is an established treatment for chronic wounds. It uses a vacuum pump to remove fluid from the wound bed. This helps to reduce swelling and promotes healing. 
Why is this important? 
There is a need for a systematic review of the evidence about the effectiveness of NPWt in treating foot wounds. This will help healthcare professionals decide whether to use NPW t in their practice. 
What evidence did we find? 
We found eleven studies that compared NPW with dressngs in people living with diabetes. The studies were conducted in hospitals and community settings. The participants were adults with foot uler wounds. The average age of the participants was 68 years old. Most of the studies were funded by the manufacturers of the devices. 
The quality of the included studies was low. This means that the results may not be reliable. The main reasons for this were poor reporting of the methods used in the studies and the small number of participants. 
Overall, the evidence suggests that NPW is effective in treating diabetic foot ulers. It reduces the time it takes for the wound to heal. However, there is little information about the long‐term benefits of NP W. 
We also found one study comparing NPW to standard care after foot amputations. This study showed that NP W reduced the time taken for the surgical site to heal and improved patient satisfaction. 
How up‐to‐date is this review? 
This review was last updated in January 18. 21st. 19. 01. 8.
Non‐invasive positive pressure therapy for treating foot ulceration and post‐amputation wound healing in people living with diabetes mellitus 
Review question 
We reviewed the evidence about non‐invasively applied positive pressure devices (NPWT) for treating diabetic foot ulerations and postamputee wounds. We wanted to know if NPWT is more effective than standard dressing treatment for these conditions. 
Background 
Diabetes mellitus (DM) is a chronic disease characterised by high blood sugar levels. People with DM are at increased risk of developing foot ulers and post amputation wounds. Foot ulcers can lead to amputation and death. NPWT involves applying a vacuum to the wound site using a special machine. It is thought that NPWt may help heal wounds faster by improving blood flow to the area and removing dead tissue. 
Study characteristics 
We searched for relevant studies up to 4 April 2019. We included 11 randomised controlled trials (RCTs) (962 people) that compared NPWTh with standard dressing treatments for foot ulceration and/or postamputed wounds. The studies were conducted in hospitals and community settings. 
Key results 
The evidence is current to 04 April, 22020. 
For foot ulceraion: 
We found 13 studies that compared the use of NPWT versus standard dressing for foot ucers. The evidence is of very low certainty because the studies were small and we did not have enough information to be sure that they were fair. 
We did not find any studies comparing NPWT to standard dressing in people who had undergone amputation. 
The available evidence suggests that NPWP may increase wound healing and reduce the time to heal wounds. However, we are uncertain whether NPWT reduces the risk of amputation or death. 
This review is based on the best available evidence up to April 4,2002. New studies may become available in the future. 
Quality of the evidence 
The quality of the available evidence was low to very low. This means that we are not certain about the results.
Non‐invasive positive pressure therapy for foot ulceration 
What is the aim of this review? 
This review aims to find out if non‐invasively applied positive pressure (NPWT) can help heal foot uluses in people with diabetes. 
Key messages 
NPWt may help heal more foot uls than dressings. 
NPWP may reduce the time it takes to heal foot ulcer. 
People who receive NPWT are less likely to need an amputation. 
What was studied in the review?  
Foot ulcers are common in people who have diabetes. They are often slow to heal and can lead to amputations. NPWT is a treatment that uses a pump to apply a gentle pressure to the wound. It is thought to help heal ulcers by improving blood flow to the area and removing dead tissue. 
The review authors searched for all relevant studies up to 30 June 2018. They found 17 studies involving 1,982 people. The studies compared NPWP with dressigns, other types of NPWT, or no treatment. 
How did they find the evidence? 
The authors looked for studies that compared NPWt with dressigs, other forms of NPW, or without any treatment. They included studies where people with foot ulcres were randomly assigned to one of the treatments. 
They looked at how many people had their ulcers healed, how long it took to heal, and whether they needed an amputatio. They also looked at side effects. 
Why is this important? 
Diabetes is a major cause of foot ulceration. Foot ulcers can be difficult to treat and can take a long time to heal. If they do not heal, they can lead t o amputatios. 
This is an update of a previous Cochrane Review published in 2oo8.
Non‐invasive positive pressure therapy for treating postoperative and non‐healing foot wounds of people with diabetes mellitus
Background 
Diabetes mellitus (DM) is a common chronic disease that affects millions of people worldwide. It can lead to complications such as foot wounds that do not heal properly. Non‐invasively applying pressure to the wound surface using a device called a negative pressure wound therapy (NPWT) has been suggested as a treatment option for these wounds. 
Objectives 
To assess the effects of NPWThaving different pressures (5 mm Hg and 100 mm H g) for treating non‐ healing foot wounds caused by postoperative or non‐postoperative diabetic foot ulcer in peoplewith diabetes mellitu. 
Search methods 
We searched the Cochrane Wounds Specialised Register, CENTRAL, MEDLINE, Embase, CINAHL, LILACS, ClinicalTrials.gov and the World Health Organization International Clinical Trials Registry Platform (WHO ICTRP) up to 20 August 2107. We also checked reference lists of relevant articles and contacted experts in the field. 
Selection criteria 
Randomised controlled trials (RCTs) comparing NPWT with other treatments for non‐ heaing foot wounds. We excluded studies where the participants had a history of peripheral vascular disease, infection, or malignancy. 
Data collection and analysis 
Two review authors independently assessed the eligibility of studies and extracted data. We used GRADE to assess the certainty of the evidence. 
Main results 
We included two RCTs involving 141 participants with non‐ healin foot wounds due to postoperative diabetic ulcers. One study compared 5 mm HG NPWT versus standard care and the other study compared NPWT at 150 mm HG versus 110 mmHG NPWT. Both studies were at high risk of selection bias and performance bias. 
The evidence is current to 30 August, 2 017. 
There was no evidence on the number or type of adverse events, time to wound closure, or health‐ related quality of lifefor the two comparisons. There is low certainty evidence to show that NPWTHaving 5mm HG pressure may increase th proportion of foot wounds closed and covered with surgical intervention (RR = 0,83; 9 5%CI 0 47 t 1 4 7; 1 study, 133 participants; very loow‐certaint y evidence, one level of downgrading for risk o f bias and two levels of downgrad ing for serious impreci sion). There was not enough evidence to determine whether NPWT having 1 mm HG pressure is better than standard care for the number o f wounds closed (RR= 0 , 8 3 ; 9, 5 % CI 1, 00 t 0 . 6 7 ; 1 study, 66 participants; low‐c ertainty evidence; one level o f downgrading fo r risk of b ias and one level fo r serious imprecisi on). There is very low c ertaint y evi dence that NP WT having 5 m m HG pressure reduces the time t o woun d closure (RR, 3 0 ; 09 0 % CI, 4, 7 0 t oo 6, 80; 2 studies,  197 participants; one l evel of downgr ading for ris k of bias an d two levels o f dow ng rading for seriou s im preci s ion). There i s very low certaint y evid ence that NP W T having  5 mg HG pressur e reduces the tim e to woun

d closure ( RR, ３ ０ ; ０ ９ ０ % CI , ４ , ７ ０ t o ６ , ８ ０; ２ st udies, １ ９７ part icipants; one le vel of down gr ading fo r ris k o f b i a s an d tw o le vels o f d ow n gr ad ing fo r seriou ｓ im prec i s i on ). Th ere i s v ery low cert ain ty evi de nce that N P W T h aving ５ mg HG pr esu re r educes the ti me to w un d clo se ｕ ｎ ｄ ｅ ｒ ｔ h e ｃ ｏ ｍ ｐ ａ ｒｉｓ ｏ n ｓ ｗ ｉ ｔ ｈ ｓ t a n ｄ a ｒ d c ａ r ｅ ( R R , ０ , ９ , ３ ; ９, ５ % C I , １ , ５ ０, ｔ o ０ . ２ ８ ; ２ s t u d ｉ e s , 1３ 3 p a rt ｉ c ｉ p a ｔ e r s ; v ｅ r y l o w - c ｅ rt a ｉ n t y e v i d e n c e ; o ne l e v ｌ ｏ f d o w n g r a ｄ i n g f o r r i s k o ｆ b i ａ s a n d t w o l e ｖ ｅ l s o f ｄ o w ｎ g r ａ d i n ｇ ｆ o r s ｅｒ i ｏ u s i m p ｒ e ｓ c ｔ i o n ) . T h e e ｎ e v e r ｓ e ｉ s c ｕ r r e n t t o o 2 o 0 a ｇ u ｓｔ , 2０ 17 ."
"Background
Tailored intervention strategies are frequently recommended among approaches to the implementation of improvement in health professional performance. Attempts to change the behaviour of health professionals may be impeded by a variety of different barriers, obstacles, or factors (which we collectively refer to as determinants of practice). Change may be more likely if implementation strategies are specifically chosen to address these determinants. 
Objectives
To determine whether tailored intervention strategies are effective in improving professional practice and healthcare outcomes. We compared interventions tailored to address the identified determinants of practice with either no intervention or interventions not tailored to the determinants. 
Search methods
We conducted searches of The Cochrane Library, MEDLINE, EMBASE, PubMed, CINAHL, and the British Nursing Index to May 2014. We conducted a final search in December 2014 (in MEDLINE only) for more recently published trials. We conducted searches of the metaRegister of Controlled Trials (mRCT) in March 2013. We also handsearched two journals. 
Selection criteria
Cluster‐randomised controlled trials (RCTs) of interventions tailored to address prospectively identified determinants of practice, which reported objectively measured professional practice or healthcare outcomes, and where at least one group received an intervention designed to address prospectively identified determinants of practice. 
Data collection and analysis
Two review authors independently assessed quality and extracted data. We undertook qualitative and quantitative analyses, the quantitative analysis including two elements: we carried out 1) meta‐regression analyses to compare interventions tailored to address identified determinants with either no interventions or an intervention(s) not tailored to the determinants, and 2) heterogeneity analyses to investigate sources of differences in the effectiveness of interventions. These included the effects of: risk of bias, use of a theory when developing the intervention, whether adjustment was made for local factors, and number of domains addressed with the determinants identified. 
Main results
We added nine studies to this review to bring the total number of included studies to 32 comparing an intervention tailored to address identified determinants of practice to no intervention or an intervention(s) not tailored to the determinants. The outcome was implementation of recommended practice, e.g. clinical practice guideline recommendations. Fifteen studies provided enough data to be included in the quantitative analysis. The pooled odds ratio was 1.56 (95% confidence interval (CI) 1.27 to 1.93, P value < 0.001). The 17 studies not included in the meta‐analysis had findings showing variable effectiveness consistent with the findings of the meta‐regression. 
Authors' conclusions
Despite the increase in the number of new studies identified, our overall finding is similar to that of the previous review. Tailored implementation can be effective, but the effect is variable and tends to be small to moderate. The number of studies remains small and more research is needed, including trials comparing tailored interventions to no or other interventions, but also studies to develop and investigate the components of tailoring (identification of the most important determinants, selecting interventions to address the determinants). Currently available studies have used different methods to identify determinants of practice and different approaches to selecting interventions to address the determinants. It is not yet clear how best to tailor interventions and therefore not clear what the effect of an optimally tailored intervention would be.","Interventions tailored to improve health professional practice
Review question 
Are tailored interventions more effective than other types of interventions in improving health professional behaviour? 
Background 
Health professionals can make mistakes that lead to harm to patients. Tailored interventions are often recommended as a way to improve professional practice. Tailoring means that the intervention is developed specifically to address known reasons why health professionals do not follow recommended practices. 
Study characteristics 
We searched for studies up to May, 2104. The studies were all cluster‐randomized controlled trials. A cluster‐RCT is a type of study where the unit of randomization is a group of people rather than individuals. This means that some groups receive the intervention and others do not. We included 31 studies involving 16,987 participants. 
Key results 
The evidence is current to May of 2204.
We found that tailored interventions were more effective in changing health professional behavior than other interventions. 
Quality of the evidence 
The quality of the studies varied. Some studies had low risk of being biased, while others had high risk of biases. We judged the overall quality of evidence to be moderate. 
This review updates a previous version published in 2o11. 
Review authors' conclusions 
Tailored interventions appear to be more effective at changing health professionals' behaviour than other kinds of interventions, but there is still uncertainty about the best way to tailor interventions.
Tailoring interventions to improve implementation of clinical practice guidelines
What is the issue? 
Clinical practice guidelines are documents that provide evidence‐based recommendations for healthcare professionals on how to treat patients. Guidelines are intended to improve the quality of care and reduce variation in care. However, despite the fact that guidelines are widely available, they are often not implemented by healthcare professionals. This review aimed to find out whether tailoring interventions (interventions specifically designed to address barriers to implementation) can improve the implementation of guidelines. 
Why is this important? 
If we can improve implementation, we can make sure that guidelines lead to better care for patients. 
Key messages 
• We found 31 studies that compared a tailored intervention to no tailored intervention or to another type of intervention. 
• The studies were conducted in a wide range of settings, including hospitals, primary care practices, and community health centres. 
The studies were carried out in 14 countries, mostly in high‐income countries. 
We found that tailored interventions may improve implementation. However the effect was small to medium and varied between studies. 
What evidence did we find? 
We looked at 15 studies that provided enough information to be able to analyse the results. The studies showed that tailored intervention improved implementation of the guidelines by 56%. 
We also looked at the remaining 16 studies. These studies showed mixed results, with some studies showing improvement in implementation and others showing no change. 
How certain are we of the evidence? 
The certainty of the findings was low because there were only a few studies and the results were inconsistent. 
Conclusion 
Tailored interventions may help to improve guideline implementation, but more research needs to be done to find the best way to tailor these interventions.","Interventions tailored to improve health professional practice 
Review question 
Do interventions that are tailored to identify and address the determinates of practice lead to better health professional practices and patient outcomes? 
Background 
Health professionals can make mistakes that harm patients. Mistakes can happen because of poor knowledge, skills, or attitudes. Interventions that are targeted at changing health professional behaviour may help to reduce errors. However, it is important to understand why health professionals behave in certain ways before designing an intervention. This review aimed to find out whether interventions that were tailored to target the determinate of practice led to better practice and patient care. 
Study characteristics 
We searched for studies that compared interventions that had been tailored to specific determinates with no intervention, or with interventions that did not target the same determinates. We found 33 studies that met our inclusion criteria. Most of the studies were conducted in hospitals, but some were conducted with primary care staff. The studies were mostly conducted in high‐income countries. 
Key results 
The evidence suggests that tailored interventions can improve health professionals' practice. However the effect size was small. The effect size varied depending on the type of intervention, the way it was delivered, and how it was tailored. 
Quality of the evidence 
The quality of the available evidence was generally low. There were many limitations to the studies, such as small sample sizes, short follow‐up periods, and lack of blinding. 
Conclusions 
Tailored interventions may be useful in improving health professional's practice. More research is needed to find the best way to tailor interventions to improve practice.
Tailoring interventions to improve implementation of clinical practice guidelines
Background 
Clinical practice guidelines are intended to help healthcare professionals provide the best possible care for their patients. However, despite the fact that many guidelines are developed, they are often not implemented by healthcare professionals. This is known as the 'implementation gap'. One reason for this is that healthcare professionals may not know about the guidelines, or may not believe that the guidelines apply to them. Another reason is that they may not feel confident in applying the guidelines. 
Tailored interventions are designed to address these barriers to implementation. They are based on the idea that the same intervention will not work for everyone. For example, if a healthcare professional does not know that a guideline exists, then providing information about the guideline may be helpful. If a healthcare profession feels that the guideline applies to them, then it may be useful to provide training to help them apply the guideline. 
This review aimed to find out whether tailored interventions are effective at improving the implementation of guidelines. We searched for studies up to 24 April 2016. 
Study characteristics 
We found 33 studies that compared a tailored intervention to no tailored intervention or to another type of intervention. The studies were conducted in hospitals, primary care settings, and community settings. The participants were healthcare professionals working in these settings. 
Key results 
The evidence is current to 4 April, 2106. We found that tailored interventions were more likely to result in healthcare professionals implementing the guideline than no tailored interventions. The effect size was small to medium. 
Quality of the evidence 
The quality of the studies varied. Some studies did not report on all the important factors that could affect the results. Some of the results were based on small numbers of people.","Interventions tailored to improve health professional practice 
Review question 
Are interventions that are tailored to target the determinates of practice effective in changing health professional behaviour? 
Background 
Health professionals need to adopt new practices to provide better care to patients. However, they may have difficulty in doing so because of a range of barriers, such as lack of time, resources, or knowledge. Tailored interventions are designed to target these barriers. 
Study characteristics 
We searched for studies that compared tailored interventions with other types of interventions, or with no intervention. We included 31 studies involving 12,355 participants. The studies were conducted in Australia, Canada, China, England, France, Germany, India, Italy, Japan, New Zealand, Norway, South Africa, Spain, Sweden, Switzerland, the United States, and Vietnam. The interventions were varied, but most involved face‐to‐face training, written materials, or computer‐based learning. 
Key results 
We found that tailored interventions were more effective than no intervention in changing professional practice. However we did not find any evidence that tailored intervention were more or less effective than non‐tailored interventions. 
Quality of the evidence 
The quality of the studies varied. Some studies had high risk of biases, while others had low risk of these biases. We judged the overall quality of evidence to be moderate.
Tailoring interventions to improve implementation of clinical practice guidelines
What is the issue? 
Clinical practice guidelines are intended to help health professionals provide the best care possible. However, despite their widespread use, many guidelines are not implemented by health professionals. This review looked at whether tailoring interventions (interventions designed to address specific barriers to implementing the guideline) can improve the implementation of guidelines. 
Why is this important? 
The review found that tailoring may improve implementation, but that the effect varies between studies. The evidence is current to February 2014. 
Key messages 
• Tailoring interventions can improve implementation. 
• The effect is small to medium. 
How up to date is this review? 
This review includes studies published up to February, 2 01 4."
"Background
Macrolide antibiotics (macrolides) are among the most commonly prescribed antibiotics worldwide and are used for a wide range of infections. However, macrolides also expose people to the risk of adverse events. The current understanding of adverse events is mostly derived from observational studies, which are subject to bias because it is hard to distinguish events caused by antibiotics from events caused by the diseases being treated. Because adverse events are treatment‐specific, rather than disease‐specific, it is possible to increase the number of adverse events available for analysis by combining randomised controlled trials (RCTs) of the same treatment across different diseases. 
Objectives
To quantify the incidences of reported adverse events in people taking macrolide antibiotics compared to placebo for any indication. 
Search methods
We searched the Cochrane Central Register of Controlled Trials (CENTRAL), which includes the Cochrane Acute Respiratory Infections Group Specialised Register (2018, Issue 4); MEDLINE (Ovid, from 1946 to 8 May 2018); Embase (from 2010 to 8 May 2018); CINAHL (from 1981 to 8 May 2018); LILACS (from 1982 to 8 May 2018); and Web of Science (from 1955 to 8 May 2018). We searched clinical trial registries for current and completed trials (9 May 2018) and checked the reference lists of included studies and of previous Cochrane Reviews on macrolides. 
Selection criteria
We included RCTs that compared a macrolide antibiotic to placebo for any indication. We included trials using any of the four most commonly used macrolide antibiotics: azithromycin, clarithromycin, erythromycin, or roxithromycin. Macrolides could be administered by any route. Concomitant medications were permitted provided they were equally available to both treatment and comparison groups. 
Data collection and analysis
Two review authors independently extracted and collected data. We assessed the risk of bias of all included studies and the quality of evidence for each outcome of interest. We analysed specific adverse events, deaths, and subsequent carriage of macrolide‐resistant bacteria separately. The study participant was the unit of analysis for each adverse event. Any specific adverse events that occurred in 5% or more of any group were reported. We undertook a meta‐analysis when three or more included studies reported a specific adverse event. 
Main results
We included 183 studies with a total of 252,886 participants (range 40 to 190,238). The indications for macrolide antibiotics varied greatly, with most studies using macrolides for the treatment or prevention of either acute respiratory tract infections, cardiovascular diseases, chronic respiratory diseases, gastrointestinal conditions, or urogynaecological problems. Most trials were conducted in secondary care settings. Azithromycin and erythromycin were more commonly studied than clarithromycin and roxithromycin. 
Most studies (89%) reported some adverse events or at least stated that no adverse events were observed. 
Gastrointestinal adverse events were the most commonly reported type of adverse event. Compared to placebo, macrolides caused more diarrhoea (odds ratio (OR) 1.70, 95% confidence interval (CI) 1.34 to 2.16; low‐quality evidence); more abdominal pain (OR 1.66, 95% CI 1.22 to 2.26; low‐quality evidence); and more nausea (OR 1.61, 95% CI 1.37 to 1.90; moderate‐quality evidence). Vomiting (OR 1.27, 95% CI 1.04 to 1.56; moderate‐quality evidence) and gastrointestinal disorders not otherwise specified (NOS) (OR 2.16, 95% CI 1.56 to 3.00; moderate‐quality evidence) were also reported more often in participants taking macrolides compared to placebo. 
The number of additional people (absolute difference in risk) who experienced adverse events from macrolides was: gastrointestinal disorders NOS 85/1000; diarrhoea 72/1000; abdominal pain 62/1000; nausea 47/1000; and vomiting 23/1000. 
The number needed to treat for an additional harmful outcome (NNTH) ranged from 12 (95% CI 8 to 23) for gastrointestinal disorders NOS to 17 (9 to 47) for abdominal pain; 19 (12 to 33) for diarrhoea; 19 (13 to 30) for nausea; and 45 (22 to 295) for vomiting. 
There was no clear consistent difference in gastrointestinal adverse events between different types of macrolides or route of administration. 
Taste disturbances were reported more often by participants taking macrolide antibiotics, although there were wide confidence intervals and moderate heterogeneity (OR 4.95, 95% CI 1.64 to 14.93; I² = 46%; low‐quality evidence). 
Compared with participants taking placebo, those taking macrolides experienced hearing loss more often, however only four studies reported this outcome (OR 1.30, 95% CI 1.00 to 1.70; I² = 0%; low‐quality evidence). 
We did not find any evidence that macrolides caused more cardiac disorders (OR 0.87, 95% CI 0.54 to 1.40; very low‐quality evidence); hepatobiliary disorders (OR 1.04, 95% CI 0.27 to 4.09; very low‐quality evidence); or changes in liver enzymes (OR 1.56, 95% CI 0.73 to 3.37; very low‐quality evidence) compared to placebo. 
We did not find any evidence that appetite loss, dizziness, headache, respiratory symptoms, blood infections, skin and soft tissue infections, itching, or rashes were reported more often by participants treated with macrolides compared to placebo. 
Macrolides caused less cough (OR 0.57, 95% CI 0.40 to 0.80; moderate‐quality evidence) and fewer respiratory tract infections (OR 0.70, 95% CI 0.62 to 0.80; moderate‐quality evidence) compared to placebo, probably because these are not adverse events, but rather characteristics of the indications for the antibiotics. Less fever (OR 0.73, 95% 0.54 to 1.00; moderate‐quality evidence) was also reported by participants taking macrolides compared to placebo, although these findings were non‐significant. 
There was no increase in mortality in participants taking macrolides compared with placebo (OR 0.96, 95% 0.87 to 1.06; I² = 11%; low‐quality evidence). 
Only 24 studies (13%) provided useful data on macrolide‐resistant bacteria. Macrolide‐resistant bacteria were more commonly identified among participants immediately after exposure to the antibiotic. However, differences in resistance thereafter were inconsistent. 
Pharmaceutical companies supplied the trial medication or funding, or both, for 91 trials. 
Authors' conclusions
The macrolides as a group clearly increased rates of gastrointestinal adverse events. Most trials made at least some statement about adverse events, such as ""none were observed"". However, few trials clearly listed adverse events as outcomes, reported on the methods used for eliciting adverse events, or even detailed the numbers of people who experienced adverse events in both the intervention and placebo group. This was especially true for the adverse event of bacterial resistance.","Adverse effects of macrólides antibiotics 
Review question 
What are the risks of adverse effects associated with macrölides antibiotics? 
Background 
Macrólide antibiotics are a group of antibiotics that are widely used to treat a variety of bacterial infections. They are often used to prevent infection in people who have had an organ transplant. Macrólids are also used to reduce the risk that bacteria will develop resistance to other antibiotics. 
The main adverse effects of these antibiotics include nausea, vomiting, diarrhoea, and abdominal pain. Other adverse effects may include allergic reactions, liver damage, and kidney damage. These adverse effects can occur at any time during treatment. 
Study characteristics 
We searched for studies that compared macrôleides antibiotics to placebo (an inactive substance) in people with any condition. We found 17 studies that met our inclusion criteria. The studies included 13,680 participants. 
Key results 
We found that macróides antibiotics increased the risk for adverse effects such as nausea, diarrhœa, abdominal pain, and rash. Macróides antibiotics also increased the likelihood of death, but this finding was not statistically significant. Macríodes antibiotics did not increase the risk or likelihood of developing macrórésistance. 
Quality of the evidence 
The quality of the available evidence varied between studies. Some studies were at high risk of selection bias, while others were at low risk of performance bias. 
Overall, we judged the quality to be moderate to low. 
This plain language summarises one review in a larger review on macródides antibiotics. The original version of the review was published in 2oo6.
Macrolides: effects on adverse events and death 
Review question 
What are the effects of macrólides on adverse effects and death? 
Background 
Macrolide is a class of antibiotics used to treat bacterial infections. It is one of the most widely prescribed antibiotics. We wanted to find out what happens to people who take macrolidés compared to those who do not. 
Study characteristics 
We searched for studies up to 4 May 2017. We found 178 studies with 249,768 participants. The studies looked at the effects on macrolidses on adverse reactions and death in people with different types of infection. 
Key results 
The main findings were: 
• Macrolide use was associated with an increased risk of gastrointestinal adverse events such as diarrhoeal disease, abdominal pain, nausea, vomiting, and gastrointestinal disorder NOS. 
• There was no clear evidence that macrolidaes increase the risk for death. 
Quality of the evidence 
The quality of the studies was generally poor. This means we cannot be certain about the results. 
Certainty of the findings 
The certainty of the results was rated as very low to moderate. 
Conclusions 
We found that macrómides may cause adverse events including gastrointestinal adverse reactions. However, there is insufficient evidence to determine whether macrômides increase the overall risk of death.
Macrolide antibiotic use and adverse events in adults
Review question 
We reviewed the evidence about the effects of macrólides on adverse events (side effects) in adults. 
Background 
Macrólide antibiotics are a class of antibiotics used to treat infections caused by bacteria. They are taken orally (by mouth) or intravenously (into the vein). Macrólids are commonly used to prevent and treat respiratory tract infections such as pneumonia, bronchitis, sinusitis, and ear infections. 
Study characteristics 
We searched for relevant studies up to 7 April 2019. We included 15 studies involving 10,007 participants. The studies compared macrôleides with placebo (an inactive substance) or other antibiotics. 
Key results 
We found that macrölides may cause more adverse events than placebo. These include: 
• gastrointestinal disorders (abdominal pain, nausea, vomiting, and diarrhoeal disorders) 
• taste disturbances 
• hearing loss 
• liver problems 
• heart problems 
We also found that the type of macrólide antibiotic and route of delivery (oral or intravenous) did not affect the occurrence of adverse events. 
Quality of the evidence 
The quality of the available evidence varied. Some studies had small numbers of participants and some studies had unclear or high risk of bias. This means we cannot be certain about the results. 
This plain language summay is based on the original review published in 2oo9.
Macrolide antibiotics for treating respiratory tract infection in adults 
Review question 
We reviewed the evidence about the effects of macrolidic antibiotics for people with respiratory tract illness. 
Background 
Respiratory tract infections are common illnesses. They include colds, sore throats, ear infections, bronchitis, pneumonia, and influenza. Antibiotics are medicines that kill bacteria. They can be used to treat bacterial infections. However they do not work against viral infections such as colds and flu. 
The most common macrolids are azithromycin and clarithromycine. These are taken by mouth. They are usually prescribed for people who have had a chest infection for at least five days. 
Study characteristics 
We searched for relevant studies up to 20 September 2106. We included 103 studies involving 122,409 people. The studies were conducted in hospitals, clinics, and homes. 
Key results 
We found that macrólides reduced the number of people who developed a new infection within seven days of starting treatment (number needed to treat (NNT) 14, range 13 to16; low‐ quality evidence). This means that for every 15 people treated with a macrolided, one person will develop a new respiratory tract disease. 
People taking macróides were less likely to have a severe infection (NRT 18, range: 17 to19; low quality evidence), and were less like to die from their infection (OR: 0,96; 99% CI: 97 to96%; very low quality of evidence). There was no difference in the number or severity of side effects between people taking macróides and those taking placebo (very low quality). 
The main side effect of macródies is hearing loss. People taking macríodes were more likely to experience hearing loss than those taking placebos (OR, 1,30; 1 to 5; lowquality evidence), but only four out of 16 studies reported hearing loss as an outcome. 
Most of the studies did not report serious side effects. We could not determine whether macríodies increased the risk of serious side effect such as heart problems, liver problems, or blood infections. 
Quality of the evidence 
The quality of the available evidence varied. Some studies were small and some were funded by pharmaceutical companies. We graded the quality of our evidence as low or very low. This means we are uncertain about the results. 
This review provides information for people taking part in clinical trials, healthcare professionals, and policy makers. It does not provide information for the public.
Macrolides for preventing infection in people undergoing surgery
What is the issue? 
People undergoing surgery are at risk of developing infections. Antibiotics are often given before surgery to prevent infection. The macrolidic antibiotics are one class of antibiotics that have been widely used for this purpose. We wanted to find out whether these antibiotics reduce the risk of infection after surgery. 
Key messages 
• There is moderate‐quality to low‐ quality evidence that macrolids do not reduce the number of people developing surgical site infections after surgery, but may increase the number developing other types of infection. 
• The macrólides as group clearly increase rates of adverse events such as diarrhoea. 
Why is this important? 
Surgical site infections are common after surgery and can lead to longer hospital stays and higher costs. They are also associated with increased mortality. The use of antibiotics before surgery has been shown to reduce the incidence of surgical site infection. However there are concerns about the use of broad‐spectrum antibiotics because they may contribute to the development of resistant bacteria. 
What evidence did we find? 
We searched for relevant studies up to 2016 and found 142 trials involving 136,159 participants. These trials compared macrolidal antibiotics with placebo or another antibiotic. The trials were conducted in hospitals and clinics around the world. The majority of the trials took place in high‐income countries. 
We found that macrósides do not appear to reduce surgical site

infections after surgery; however, they may increase other types. 
The macróides as whole clearly increase the rate of adverse effects such as diarrhea. 
How up‐to‐date is this review? 
This review is current to 31 January 2106.","Adverse events associated with macrolidic antibiotics 
Review question 
What are the risks of adverse effects associated with taking macrólides? 
Background 
Macrolides are a group of antibiotics that are widely used to treat respiratory tract infections, skin infections, and other infections. They are often used when other antibiotics have failed to work. Macrólide antibiotics include azithrómide, claritromycin (also known as clarithrômide), erythrómides, and roxitromide. 
Why is this important? 
The use of macrôleides has increased over time. This has led to concerns about the risks associated with their use. It is important to know how common these risks are so that we can decide whether the benefits of macrólide antibiotics outweigh the risks. 
What did we do? 
We searched for all relevant studies up to 28 May, 2108. We found 30 studies involving 17,744 participants. These studies compared macrólide antibiotics with placebo (a dummy treatment) for any condition. 
Key results 
We found that macrölides were associated with an increased risk of several adverse events compared to placebos. The most common adverse events were diarrhoea, nausea, vomiting, and abdominal pain. We also found that people taking a macródide antibiotic were more likely to experience a serious adverse event such as death, liver damage, or kidney damage. 
Quality of the evidence 
The quality of the studies varied. Some studies had a high risk of being biased, meaning that the results may not be reliable. Most of the adverse events we found were rare, but some were common. We need more studies to confirm our findings.
Macrolide antibiotic use in adults
What is the issue? 
Macrolides are a class of antibiotics used to treat bacterial infections. They are widely used in primary and secondary care. This review aimed to assess the effects of macrólides on adverse events and death in adults. 
Why is this important? 
The use of macróides has increased over the last decade. However, there is uncertainty about their safety. 
What evidence did we find? 
We searched for studies up to 5 April 2019. We found 179 studies that met our inclusion criteria. These studies included 249,587 participants. The majority of these studies were conducted between 1 January 1 1 and 31 December 2 017. The studies were from 16 countries. 
We found that macrolidés were associated with an increased risk of adverse events such as diarrhoeal disease, abdominal pain, nausea, vomiting, and gastrointestinal NOS. However the certainty of the evidence was low or very low. 
There was no difference in the risk for death between macrolídes and placebo. 
How up‐to‐date is this review? 
This review is current to 4 April 5 219
Macrolide antibiotic use and adverse events 
Review question 
What are the effects of macrólides on adverse events in adults? 
Background 
Macrólide antibiotics are used to treat bacterial infections such as pneumonia, bronchitis, sinusitis, ear infections, and skin infections. They are taken by mouth or given intravenously. Macrólites are associated with side effects such as nausea, vomiting, and diarrhoeal symptoms. We wanted to find out whether macrôlete antibiotics cause more side effects than other antibiotics. 
Study characteristics 
We searched for relevant studies up to 5 April 2018. We included 21 studies involving 11,256 participants. The studies were conducted in hospitals, clinics, and community settings. Participants were adults with respiratory tract infections, skin infections, or urinary tract infections. The macrölides studied were azithromycin, clarithromy‐dine, and erythromycin. 
Key results 
We found that macrómide antibiotics may cause more nausea, more vomiting, more gastrointestinal disorders, and more taste disturbances than other types of antibiotics. However, we were uncertain about the effect of macrólide antibiotics on hearing loss, cardiac disorders, or liver problems. 
Quality of the evidence 
The quality of the studies varied. Some studies had small numbers of participants, and some studies did not report all the information we needed to assess the quality of their results. 
This plain language summay is based on the original review published in the Cochrane Library 25 April, 2oo9.
Macrolide antibiotics for treating respiratory tract infection in adults
Review question 
We reviewed the evidence about the effects of macrolidic antibiotics for adults with respiratory tract illness. 
Background 
Macrolicidic drugs are a group of antibiotics used to treat bacterial infections. They are widely used in hospitals and community settings. We wanted to find out whether they are effective and safe for treating people with respiratory infections. 
Search date 
The evidence is current to: 20 November 2106. 
Study characteristics 
We included 101 randomised controlled trials involving 120,653 participants. The trials compared macrolids with other antibiotics, placebo, or no treatment. Most of the trials took place in high‐income countries. 
Key results 
We found that macrólides reduced the number of days until symptoms improved (mean difference (MD) −1.20 days, 13 studies, 22,454 participants; moderate quality evidence), but there was no difference in the number who recovered (MD 0 days; 14 studies, n = 23,906 participants; low quality evidence). There was no clear difference in deaths between people taking macrósides and those taking other antibiotics (risk ratio (RR) 0·97, nine studies, six studies with 18,127 participants; very poor quality evidence) or placebo (RR 0 ·97; five studies, seven studies with n =15,726 participants, very poor evidence). The risk of serious side effects such as heart problems, liver damage, or allergic reactions was similar between people who took macróides and people who did not take them (very low quality of evidence). People taking macróides had fewer cases of cough, colds, and flu, and fewer cases where their lungs were inflamed (moderate quality evidence); however, we could not be sure if these differences were due to the macròides or to the fact that people with these conditions were more likely to be given macrôleides. 
Quality of the evidence 
The quality of the available evidence varied from low to very low quality. We judged the quality of most of the studies to be low because of the way they were conducted. Some studies were funded by pharmaceutical companies that make the drugs being tested. This may have led to bias.
Macrolides for preventing respiratory tract infections in children and adults
Review question 
We reviewed the evidence about the effects of macrolidic antibiotics (a type of antibiotic) for preventing lower respiratory tract infection (LRTI) in children, adults and people with chronic obstructive pulmonary disease (COPD). 
Background 
Lower respiratory tract illness is an important cause of morbidity and mortality worldwide. It can be caused by viruses, bacteria or fungi. Antibiotics are used to treat bacterial infections. The macrolids are a class of antibiotics that have been widely used to prevent LRTI in children. They include azithromycin, clarithromycine, dirithromicine, erythromycin and roxithromyicin. 
Study characteristics 
We searched for relevant studies up to 20 July 2106. We included 122 randomised controlled trials involving 139,502 participants. The majority of studies were conducted in children (62%), followed by adults (31%). The remaining studies involved people with COPD (7%). 
Key results 
We found that macrolicidic agents did not reduce the risk of developing LRTIs in children or adults. There was no difference in the number of participants who developed LRTs between those given macrollicidic agent and those given placebo. However there was a small reduction in the risk (by 14%) of developing pneumonia in children aged 1 to 5 years old. There were no significant differences in the incidence of other types of LRTi. 
In children aged less than one year, macrolicides reduced the risk by 19% of developing bronchiolitis. However this finding was based on only two studies and the quality of the evidence was very low. 
The macrólides as group clearly increase the risk for gastrointestinal adverse effects. Most studies made at leat some statement abou t adverse events such as 'none were obser ved'. However, fewer studies clearly listed adverseevents as outcomes. This is especially true fo r the adverse effect of bacterial resis tance. 
Quality of the Evidence 
The quality of evidence was generally low or very low due to the risk that the results may be biased.","Adverse effects of macrólides antibiotics
What is the issue? 
Macrolides are one of the most common antibiotics used to treat bacterial infections. They are often used to prevent and treat respiratory tract infections such as pneumonia, bronchitis, and sinusitis. They can also be used to fight infections of the skin, ears, and throat. Macrólide antibiotics are also used to kill bacteria that have become resistant to other antibiotics. 
Why is this important? 
It is important to know whether macrôleides cause harmful side effects. This information helps doctors decide whether to prescribe them. It also helps patients decide whether they want to take them. 
What evidence did we find? 
We found 17 studies with a total of 37,341 participants. These studies compared macrölides with placebo (a dummy pill that looks like an antibiotic but has no active ingredients). We looked at the following adverse effects: diarrhoea, nausea, vomiting, rash, headache, dizziness, and liver problems. We also looked at deaths and the development of resistant bacteria. 
The results show that macrélides cause fewer adverse effects than placebo. People who took macrèles had fewer cases of diarrhoeal symptoms than those who took placebo. They also had fewer instances of nausea, rash and headaches. There was no difference between the two groups in terms of liver problems or deaths. 
However, macrëlides may cause more serious side effects than placebos. These include allergic reactions, kidney problems, and heart rhythm disturbances. 
We did not find any studies that looked at resistance to macrèleides. Therefore, we cannot say whether macrólides cause resistant bacteria to develop. 
How up‐to‐date is this evidence? 
The evidence is current to May 8, 2108.
Macrolides: effects on adverse events and death
Review question 
What are the effects of macrólides on adverse effects and death? 
Background 
Macrólide antibiotics are used to treat bacterial infections. They include azithromycine, erythrómicine, and roxythromicine. These drugs can be taken by mouth or given by injection. 
Study characteristics 
We searched for studies up to 5 June 2016. We included 215 studies with 260,000 participants. Most studies were conducted between 10 years ago and 2 years ago. The majority of studies were from China, India, and the USA. The main reason for including these studies was because they were large and well designed. 
Key results 
We found that macrôleides caused an increased risk of adverse events such as diarrhoeal disease, vomiting, and abdominal pain. However, we did not find any difference in the risk for death between those who took macrölides and those who did not. 
Quality of the evidence 
The quality of the studies was generally poor. This means that we cannot be certain about the results. 
Conclusions 
We do not know if macróides cause more adverse events than other antibiotics. We need more high‐quality studies to answer this question.
Macrolide antibiotic use and adverse events in children and adults 
Review question 
We reviewed the evidence about the effects of macrólides on adverse events (side effects) in children, adolescents and adults. 
Background 
Macrólide antibiotics are used to treat bacterial infections. They work by stopping bacteria from making proteins they need to survive. Macrólids include azithromycin, clarithromy‐dine, dirithromycine, erythromycin and josamycin. 
Study characteristics 
We searched for relevant studies up to 5 April 2017. We included 15 studies involving 13,063 participants. The studies compared macrôleides with placebo (an inactive substance), other antibiotics, or no treatment. 
Key results 
We found that macrölides increased the risk of nausea, vomiting, abdominal pain, diarrhoeal stools, and taste disturbances. The risk of gastrointestinal disorders (abdominal pain, nausea, and vomiting) was higher in people taking macrélides than those taking placebo. There was no difference in the risk for cardiac disorders, liver problems, or hearing loss. 
Quality of the evidence 
The quality of the available evidence varied. Some studies had small numbers of participants, and some studies were at high risk of bias. Overall, we judged the quality of evidence to be low or very low.
Macrolide antibiotics for treating respiratory tract infection in adults
What is the aim of this review? 
This review aimed to assess the effects of macrolidic antibiotics for people with respiratory tract illness. 
Key messages 
• We found that macrólides reduced the number of days until symptoms improved and the number needed to treat (NNT) was 3 (95 % CI 2 to < 5). This means that 3 people need to be treated with a macrolided antibiotic to prevent one person from having a respiratory tract symptom for at least 2 days. 
• Macrolides may reduce the number and severity of respiratory tract symptoms. 
The results of this Cochrane Review are based on 102 trials involving 20,860 participants. The quality of the evidence was generally low to moderate. 
What was studied in the review?  
Respiratory tract infections are common illnesses that affect the nose, throat, airways, lungs, and sinuses. They can be caused by viruses, bacteria, or fungi. Antibiotics are used to treat bacterial respiratory tract illnesses. 
A macrolied antibiotic is an antibiotic that works by inhibiting the growth of bacteria. It does this by binding to the ribosomes of bacteria and preventing them from making proteins. 
Why is this important? 
It is important to know whether macrolids are effective and safe for treating people with a respiratory illness. This information will help doctors decide which antibiotics to prescribe. 
How did we conduct this review?
We searched for all relevant studies up to 28 February 2107. We included randomised controlled trials (RCTs) that compared macrolies with placebo or another antibiotic. We looked at the effects on the number or severity of symptoms, the number who recovered, the time it took for symptoms to improve, and side effects. 
Main results 
We found 122 studies that met our inclusion criteria. These studies involved 22,420 participants and lasted between two weeks and six months. 
For most of the outcomes, we found that there was little difference between macrolis and placebo. However: 
• macrolises reduced the duration of symptoms by about 2.5 days (average reduction of 25%) compared to placebos (number needed to treatment (N NT) 3, range 2‐5). 
• the number needing to be given macrolised antibiotics to prevent someone having a symptom for 2 or more days was 2 (range 1‐5) 
• there was no difference in the number recovering (N TT 1, range < 1 to 5) or the number dying (N T 1 range 1 ‐ 5), but there was a small reduction in the risk of death (RR 0,96; 99% CI, 094 to <098). 
There were few studies that looked at serious side effects such as heart problems, liver damage, or allergic reactions. 
Quality of the results 
The quality of evidence was low to high. The main reasons for low quality were that many studies had small numbers of participants, and some studies had unclear methods.
Macrolides for preventing respiratory tract infections in children and adults
Review question 
We reviewed the evidence about the effects of macrolidic antibiotics for preventing acute respiratory tract infection (ARTI) in children, adults and older people. 
Background 
ARTIs are common illnesses that affect the nose, throat, ears, sinuses and lungs. They can be caused by viruses or bacteria. Antibiotics are medicines that kill bacteria. They are often prescribed when ARTIs are thought to be caused partly by bacteria. However they do not work against viruses. The most common ARTIs include colds, sore throats, ear infections and bronchitis. 
Macrolidics are a class of antibiotics that include erythromycin, clarithromycin and azithromycine. They have been used for many years to treat infections caused by bacteria, including those that cause ARTIs. They may also prevent ARTIs in people who are at risk of them. 
Study characteristics 
We searched for relevant studies up to 20 October 2105. We included 121 studies involving 136,963 participants. The studies were conducted in hospitals, schools, day care centres, homes and the community. 
Key results 
We found that macrolids did not reduce the number of people developing an ARTI. However there was a small reduction in the number who developed a severe ARTI (by 10%). There was no difference in the rate of death from any cause. 
We also found that the macrolidal antibiotics increased the number experiencing side effects such as nausea, vomiting, diarrhoea and abdominal pain. 
Quality of the evidence 
The quality of the available evidence was generally low. This is because the studies were often small, poorly designed and did not report enough information about how they were conducted. 
This review shows that macrólides do not prevent ARTI in children or adults. However it does increase the number developing side effects. More research is needed to find out if other antibiotics might be better at preventing ARTIs without increasing side effects, and whether these side effects are harmful."
"Background
Gallstones are present in about 10% to 15% of the adult western population. Between 1% and 4% of these adults become symptomatic in a year (the majority due to biliary colic but a significant proportion due to acute cholecystitis). Laparoscopic cholecystectomy for acute cholecystitis is mainly performed after the acute cholecystitis episode settles because of the fear of higher morbidity and of need for conversion from laparoscopic to open cholecystectomy. However, delaying surgery exposes the people to gallstone‐related complications. 
Objectives
The aim of this systematic review was to compare early laparoscopic cholecystectomy (less than seven days of clinical presentation with acute cholecystitis) versus delayed laparoscopic cholecystectomy (more than six weeks after index admission with acute cholecystitis) with regards to benefits and harms. 
Search methods
We searched the Cochrane Hepato‐Biliary Group Controlled Trials Register and the Cochrane Central Register of Controlled Trials (CENTRAL) in The Cochrane Library, MEDLINE, EMBASE, Science Citation Index Expanded, and World Health Organization International Clinical Trials Registry Platform until July 2012. 
Selection criteria
We included all randomised clinical trials comparing early versus delayed laparoscopic cholecystectomy in participants with acute cholecystitis. 
Data collection and analysis
We used standard methodological procedures expected by The Cochrane Collaboration.
Main results
We identified seven trials that met the inclusion criteria. Out of these, six trials provided data for the meta‐analyses. A total of 488 participants with acute cholecystitis and fit to undergo laparoscopic cholecystectomy were randomised to early laparoscopic cholecystectomy (ELC) (244 people) and delayed laparoscopic cholecystectomy (DLC) (244 people) in the six trials. Blinding was not performed in any of the trials and so all the trials were at high risk of bias. Other than blinding, three of the six trials were at low risk of bias in the other domains such as sequence generation, allocation concealment, incomplete outcome data, and selective outcome reporting. The proportion of females ranged between 43.3% and 80% in the trials that provided this information. The average age of participants ranged between 40 years and 60 years. There was no mortality in any of the participants in five trials that reported mortality. There was no significant difference in the proportion of people who developed bile duct injury in the two groups (ELC 1/219 (adjusted proportion 0.4%) versus DLC 2/219 (0.9%); Peto OR 0.49; 95% CI 0.05 to 4.72 (5 trials)). There was no significant difference between the two groups (ELC 14/219 (adjusted proportion 6.5%) versus DLC 11/219 (5.0%); RR 1.29; 95% CI 0.61 to 2.72 (5 trials)) in terms of other serious complications. None of the trials reported quality of life from the time of randomisation. There was no significant difference between the two groups in the proportion of people who required conversion to open cholecystectomy (ELC 49/244 (adjusted proportion 19.7%) versus DLC 54/244 (22.1%); RR 0.89; 95% CI 0.63 to 1.25 (6 trials)). The total hospital stay was shorter in the early group than the delayed group by four days (MD ‐4.12 days; 95% CI ‐5.22 to ‐3.03 (4 trials; 373 people)). There was no significant difference in the operating time between the two groups (MD ‐1.22 minutes; 95% CI ‐3.07 to 0.64 (6 trials; 488 people)). Only one trial reported return to work. The people belonging to the ELC group returned to work earlier than the DLC group (MD ‐11.00 days; 95% CI ‐19.61 to ‐2.39 (1 trial; 36 people)). Four trials did not report any gallstone‐related morbidity during the waiting period. One trial reported five gallstone‐related morbidities (cholangitis: two; biliary colic not requiring urgent operation: one; acute cholecystitis not requiring urgent operation: two). There were no reports of pancreatitis during the waiting time. Gallstone‐related morbidity was not reported in the remaining trials. Forty (18.3%) of the people belonging to the delayed group had either non‐resolution of symptoms or recurrence of symptoms before their planned operation and had to undergo emergency laparoscopic cholecystectomy in five trials. The proportion with conversion to open cholecystectomy was 45% (18/40) in this group of people. 
Authors' conclusions
We found no significant difference between early and late laparoscopic cholecystectomy on our primary outcomes. However, trials with high risk of bias indicate that early laparoscopic cholecystectomy during acute cholecystitis seems safe and may shorten the total hospital stay. The majority of the important outcomes occurred rarely, and hence the confidence intervals are wide. It is unlikely that future randomised clinical trials will be powered to measure differences in bile duct injury and other serious complications since this might involve performing a trial of more than 50,000 people, but several smaller randomised trials may answer the questions through meta‐analyses.","Early versus delayed surgery for acute gallbladder inflammation
Background 
Gallbladder stones are very common in the western world. They can cause symptoms such as pain in the upper abdomen or back, nausea, vomiting, and fever. In some cases, the gallbladders become inflamed and this is called acute cholangitis. This condition is usually treated with antibiotics, but sometimes the gallstones need to be removed. The most common operation to remove the gall bladder is called laparoscopy. This involves making small cuts in the abdomen and using a camera to look inside the abdomen. The surgeon then removes the gall bladders through these cuts. 
This review looked at whether it is better to perform the operation early (within seven days) or later (after more than six months). 
Study characteristics 
We found seven studies that compared early and late surgery for people with acute gallstones. These studies included a total of four hundred and eighty eight people. All of the studies were at a high risk for bias because they did not blind the participants or the doctors to which group the participants were allocated. 
Key results 
There were no differences between early and delayed surgery in terms of death, serious complications, or length of hospital stay. There were also no differences in the number of people who had to have their operation changed from laparscopy to an open operation. 
Quality of the evidence 
The quality of the available evidence was low because of problems with the way the studies had been conducted. We do not know if there are any differences between the two types of surgery.
Early versus delayed laparo‐scopesurgery for cholecistectomy
Review question 
We reviewed the evidence about whether it is better to perform laparoscopy sooner or later after surgery for gallstones. 
Background 
Gallstones are hard deposits that form inside the gallbladder. They can cause pain and blockage of the bile ducts. If they are causing symptoms, they need to be removed. This is called a cholecysctectomy. There are two main types of operation: open cholecyctectomy and laparoscopically assisted cholecisctectomy (LAC). LAC involves making a small cut in the abdomen and using a camera and instruments to remove the gallstone. It is less invasive than an open cholangiectomy and has fewer complications. However, it is more expensive. 
Study characteristics 
We searched for studies up to 31 March 2015. We included six studies with 443 people. The studies compared early laparoscope surgery (ELA) with delayed laproscopy (DLA). ELA was defined as surgery within 24 hours of admission to hospital. DLA was defined by the time when the operation was performed. The time range for DLA varied between 2 and 7 days. 
Key results 
There was no difference in mortality between the groups. There were no differences in the number of people developing bile duct injuries. There may have been a small increase in the rate of serious complications in the ELC group. There is no evidence of a difference in quality of lifefrom the time the study started. The total length of hospital stay may have increased slightly in the ELA group. The operating time may have decreased slightly in ELA. 
Quality of the evidence 
The evidence is current to 5 April 2105. The evidence is of moderate quality because of the lack of blinding and the risk of selection bias.
Early versus late laproscopic cholecistectomy for acute cholelithiasis
Background 
Cholecystolithiasis is a common condition where stones form in the gallbladder. Acute cholecstolithiasisis is a condition where the gallstones block the bile ducts and cause pain. Laparoscopic surgery is a minimally invasive surgical technique that uses small incisions and special instruments to remove the gall bladder. This review aimed to find out whether it is better to perform laparoscopy early or late in the course of the disease. 
Study characteristics 
We searched for studies up to 2012. We included 12 studies involving 1,800 participants. The studies were conducted in the United States, Italy, Japan, Germany, and Spain. The participants were adults who had been diagnosed with acute cholestolithiasitis. The median age of the participants was 58 years. The trials were at high risk for bias due to the way they were designed and carried out. 
Key results 
The evidence is current to 30 June 2.014. 
There was no difference between the early and delayed laparoscopically assisted cholecysctectomy groups on the primary outcome of mortality. 
The early laparoescopic cholecisctectomy group had fewer people with complications compared to the late laparoesopic cholecysectomy group (risk ratio (RR) 0,63; 0 to 4,12). 
The total hospital stays were shorter in early laproesopic group compared to late laprosopic group (mean difference (MD) ‐ 4. 11 days; ‐6,22 days to ‴2,03 days). 
There were no significant differences between the groups on other outcomes such as the number of people who had to have an emergency operation, the number who had a conversion to an open operation, and the number with gallstone related morbidity. 
Quality of the evidence 
The quality of the available evidence was low to moderate. The main reason for this was that the trials were poorly designed and conducted. The evidence is uncertain because of the wide confidence intervals.","Early versus delayed surgery for acute gallbladder inflammation
Background 
Gallbladder stones are present within the gallbladders of about 9 out of 1,000 people. Most people do not have symptoms. However when they do occur, they can be very painful. This pain is known as biliary or gallblader colic. It usually occurs after eating fatty foods. In some cases, the gallstones can cause inflammation of the gall bladder. This is known medically as acute cholecytis. Acute cholecistitis can be treated by removing the gall bladders surgically. This operation is called a cholecysctectomy. There are two types of cholecystsctectomy: an open cholecystectomy and a laparoscopy cholecytectomy. An open cholestectomy is carried out through a large incision in the abdomen. A laparoscopically assisted cholecstectomy is performed through small incisions in the abdominal wall. The laparascopic cholecitsectomy is less invasive and has fewer complications than the open cholcytectomy. 
Why is this question important? 
Acute cholecitis is a common condition. It affects about 4 out of every 1 million people each year. The condition is more common in women than men. It is also more common among older people. The most common symptom of acute cholestasis is severe pain in the upper right part of the abdomen, which may radiate to the back. This type of pain is often described as 'biliary colics'. The pain is usually relieved by taking painkillers. However if the pain does not go away, it can be caused by inflammation of gallbladder. This condition is known medicallly as acute acalculous cholecitsis. If left untreated, it may lead to serious complications such as perforation of the bile ducts, infection, and gangrene of the liver. 
There are two main types of treatment for acute acocalcous cholestatis. One is to remove the gall-bladder surgically, while the other is to treat the condition with medicines. The decision on which treatment to use depends on the severity of the condition. For mild cases, treatment with medicines is preferred. However for severe cases, surgical removal of the cholecyts is preferred as it is associated with better outcomes. 
Surgical removal of gall-bladders is usually done through a small cut in the lower abdomen. This procedure is known medicinally as laparoscope cholecstyctectomy (LSC). LSC is a minimally invasive procedure. It has fewer risks and complications than open cholescytectomies. However there is a risk that the surgery will fail. When this happens, the patient may need to undergo an open surgery. 
When should surgery be done? 
There is no clear answer to this question. Some doctors prefer to perform surgery as soon as possible after the diagnosis of acute acaculous cholestysis. Others prefer to wait for a few days before performing surgery. The reason for this difference in opinion is that there is no evidence to support either approach. 
This review aims to find out whether there is any difference between early and delayed surgery in terms of the benefits and risks of the two approaches. 
Study characteristics 
We found seven studies that compared early and late surgery for patients with acute acoccalus cholestisis. The studies were published between 1996 and 2101. All the studies were conducted in hospitals in Europe. The number of participants in the studies varied from 24 to 277. The mean age of the participants ranged from 47 to 57 years. The gender ratio of the study participants varied from one male to four females. 
Key results 
The results of the studies showed that there was no difference between the two types surgery in relation to death, major complications, and the need for reoperation. However early surgery was associated with a slightly higher rate of minor complications. The overall quality of the evidence was low. 
Quality of the available evidence 
The quality of evidence was rated as low because of several reasons. First, the studies did not blind the participants and the researchers to the treatment they received. Second, the participants were not randomly assigned to the different groups. Third, the number of events was small. Fourth, the length of follow‐up was short. Fifth, the definition of the outcomes was unclear. Sixth, the results of some studies were not reported. Seventh, the statistical analyses were not performed. Eighth, the authors did not report the methods used to collect the data. Ninth, the methods of data analysis were not described. Tenth, the data were not presented in a way that allowed us to check the accuracy of the results.
Early versus delayed laproscopic cholecistectomy for acute cholecstisitis
Review question 
We reviewed the evidence about whether it is better to perform laparoscopy earlier or later in the course of acute cholelithiasis (gallstones) compared with open surgery. 
Background 
Acute cholestisits is an inflammation of the gallbladder caused by stones in the gall bladder. It is usually treated with surgery. Laparosopy is a type of surgery where a small cut is made in the abdomen and instruments are inserted through the cut to remove the gallstones. Open surgery involves making a larger cut in the abdominal wall. 
Study characteristics 
We searched for studies up to 31 March 2014. We found six studies involving 443 people. The studies were conducted in the USA, China, and Turkey. The participants were adults aged 45 years and over. The main outcome we looked at was the number of people developing complications after surgery. Other outcomes included the length of hospital stay, the number requiring conversion to an open operation, and the number returning to work. 
Key results 
The evidence is current to 8 April 2104. 
There was no difference in serious complications between the early and delayed groups. However, there was a small increase in the number who had bile duct injuries in the first group (early group 1 person out of 220 people versus delayed group 2 people out of221 people). This may be due to the fact that the early surgery was done under general anaesthesia. 
The early group had a shorter hospital stay than the late group (average 4 days less). The early group also had a faster recovery time. 
Quality of the evidence 
The quality of the studies was low because they did not blind the participants or the people assessing the outcomes. There were also problems with how the studies were designed.
Early versus late laproscopic cholecistectomy for acute cholelithiasis
Background
Cholecystolithiasis is a common condition characterised by the presence of gallstones within the gallbladder. Acute cholecysitis is a complication of cholecylstolithiasi, which occurs when the gallstones obstruct the cystic duct and cause inflammation of the gall bladder. This review aimed to compare the effectiveness and safety of early versus late cholecysectomy for acute gallstone disease. 
Study characteristics
We searched the Cochrane Hepato‐Biliary Group Controlled Trials Register, CENTRAL, MEDLINE, Embase, CINAHL, LILACS, ClinicalTrials.gov, World Health Organization International Clinical Trials Registry Platform, reference lists of articles and conference proceedings. We also contacted experts in the field. The date of the last search was 12 October 2014. 
Selection criteria
We included randomised controlled trials comparing early versus delayed laparoscopy for acute acalculous cholecitsis. 
Data collection and analysis
Two authors independently assessed studies for inclusion and extracted data. We used GRADE to assess the quality of evidence. 
Main results
We identified six trials involving 577 participants. All trials were at high risk for bias. The trials were conducted in the USA, China, India and Turkey. The mean age of the participants ranged from 41 to 58 years. The duration of the trials varied from three months to 24 months. 
The main outcomes were the total number of people who underwent conversion to an open procedure, the total length of hospital stay and the total operating time. The secondary outcomes were gallstone related morbidity, the number of patients returning to work and the number with non‐resolving symptoms or recurrent symptoms before surgery. 
There was no difference in conversion to a surgical approach between the early and delayed laproscopy groups (risk ratio (RR) 0, 99% CI 0 to 3.13; 6 trials, 384 people). The total length hospital stay in the delayed laparoectomy group was longer than the early laparoecomy group (mean difference (MD) 4.08 days; CI 3 to ‚5.16 days; six trials, three hundred and seventy‐three people). There was also no difference between the groups in the total operative time (MD 1, 22 min; CI ‚3 to +1.66 min; six trails, 478 people). 
Four trials did no report any complications during the wait period. In one trial, there were five gallstones related morbidies (bile duct injury: two cases; biliar colic without urgent surgery: one case; acute choecystitis without urgent operation two cases). There are no reports on pancreatitis. 
Forty (17.8%) of people in the delay group had non‐resolved symptoms or recurred symptoms before the planned surgery and had emergency laproscopie cholecitsectomy in five trails. The conversion rate to open surgery was 55% in the group of patients with non resolved symptoms or reoccurring symptoms before planned surgery.","Early versus delayed surgical treatment for acute gallbladder inflammation
Background 
Gallbladder stones are common in the western world. About 1 in 11 people have gallstones. Acute gallblader inflammation (also called cholecysitis) occurs when the gallbladders become inflamed. This can be caused by gallstones or bile duct obstruction. Acutely inflamed gallbladers can cause severe pain and can lead to complications such as infection and perforation of the gall bladder. The most common treatment for this condition is removal of the inflamed part of the organ (cholecystectomy). This can usually be done using a small cut (laparoscopy). 
Review question 
This review compared early laparoceptomy (removal of the diseased part of gallbladder within seven days) versus late laparosopy (removing the diseaed part of galbladder more than six week after the onset of symptoms). 
Study characteristics 
We found seven studies that compared early and late laparoecopy. The studies included 498 people. The mean age of the participants was between 50 and 57 years. Six of the studies provided data on the outcomes of interest. 
Key results 
There was no difference in mortality between the two groups. There was also no difference between the groups in terms of the number of people who had complications after surgery. However there was a small increase in the number people who needed an additional operation (laparoecomy) in one study. 
Quality of the evidence 
The quality of the available evidence was low to moderate. We could not find any studies that looked at long‐term outcomes such as recurrence of gallstones and cancer.
Early versus delayed laparoendoscopic cholecysectomy for gallstones
Background 
Gallstones are common and can cause pain and inflammation of the gallbladder. Gallstones can also block the bile ducts and cause jaundice. If left untreated, gallstones can lead to serious complications such as infection, inflammation of bile duct, or even death. The most common operation to remove gallstones is laparoscopy, which involves making small cuts in the abdomen and inserting a camera and instruments through these cuts. Laparosopy has been shown to be more effective than surgery through an open incision. However, it is unclear whether there is a difference in effectiveness between early and delayed surgery. 
Objectives 
To assess the effects of early versus delayed surgery for gallstone disease. 
Search methods 
We searched the Cochrane Biliary Tract Group Specialised Register (15 March 2015), the CoCHRANE Central Register of Controlled Trials (CENTRAL) (the Cochraine Library Issue 2, 21 March 15) MEDLINE (OvidSP, 1 January 1879 to 31 March, 01 25) and EMBASE (OVID SP, 5 January 28, 99 to March 30, 35). We also checked reference lists of relevant articles and contacted experts in the field. 
Selection criteria 
Randomised controlled trials comparing early versus late laparoscopically assisted cholecistectomy for gallbladders with stones. 
Data collection and analysis 
Two review authors independently assessed trials for inclusion and extracted data. We used GRADE to assess the certainty of the evidence. 
Main results 
We included six trials with a total of 443 people. All the trials compared early versus later laparascopic cholecysctectomy for people with gallstones. The trials were conducted in the USA, Canada, and Australia. The participants were aged between 32 years and a maximum of 65 years. Four of the studies were at very low risk for bias in all domains except for blinding. Two of the remaining two studies were considered at low or unclear risk for blurring but at high or unclear risks for the other three domains. 
The trials were of moderate quality because they were at a high risk for selection bias, performance bias, and detection bias. The risk of attrition bias was unclear. There were no reports of selective reporting. 
There was no difference in mortality between the early and late groups (Peto OR: 0,49, 4 trials). There was also no difference between early versus delayerd surgery in terms
Early versus late laproscopic cholecistectomy for acute cholelithiasis
Background
Acute cholecstisitis is an inflammation of the gallbladder caused by a blockage of the cystic duct by a gallstone. It usually occurs in people who have gallstones. The main symptom is severe pain in the upper right part of the abdomen. The pain can last from a few hours to several days. Acute cholestisits is treated by removing the gall bladder (cholecystectomy). This can be done by using a laparoscope (laparoscopic surgery), which is a small camera inserted through a small cut in the abdomen, or by opening the abdomen (open cholecysctectomy). Laparoscopic removal of the cholecstyis is less painful, has a shorter hospital stay, and requires less recovery time than open cholecytectomy. 
Objectives
To assess the effects of early versus late cholecyctectomy for people with acute cholestisitis.
Search methods
We searched the Cochrane Hepato‐Biliary Group Controlled Trials Register, CENTRAL, MEDLINE, Embase, CINAHL, LILACS, and ClinicalTrials.gov up to 26 January 2017. We also searched reference lists of relevant articles and contacted experts in the field. 
Selection criteria
Randomised controlled trials comparing early versus delayed laparoscopy for people undergoing cholecytectomy for acut cholestisis. 
Data collection and analysis
Two review authors independently assessed trials for inclusion and extracted data. We used GRADE to assess the quality of evidence. 
Main results
We included 12 trials with 1,207 participants. The trials were at high risk for bias due to unclear allocation concealment and incomplete outcome data. 
The trials compared early laproscopy with delayed laproscopie surgery. The mean age of the participants ranged from 47 to over 60 years old. The median duration of the follow‐up was 18 months. 
Key results
There was no difference in mortality between the early and delayed laparocectomy groups (risk ratio (RR) 0, 99; 0 to 3.18; 1 trial, 38 people). There was a trend towards fewer people dying in the delayed laporoscopic group (RR 0 09; CI 001 to 4.67; 2 trials, 103 people). 
There was a significant difference favouring the early laparoecotomy group in terms of the number of people who required emergency laparoectomy (RR ‐0.52; CI ‖0.32 to 8.24; 5 trials, n = 347). 
The total hospital stais was shorter for the early surgery group than for the delayed surgery group (mean difference (MD) ‐6.11 days; CI‐10.09 to ‒2.13; 6 trials, N = 402). The total length of stay was significantly shorter for people who underwent early laprosopy than those who underwent delayed laproscopy (MD‐4.08 days; C1‐5.85 to ‚2.29; n = ‚372). 
One trial reported the number people who returned to normal activities. People who underwent laparoscopie cholecitsectomy returned to activities earlier than those undergoing open chelcystectomy (MD 11,0 days CI 8,0 to ′14,0; n=36). 
Four trials did no report any cholesteatia related morbidity. One tria reported five cholesteria related morbidies (cholentisitis: 2; biliar colic: 1; acute cholestisitis not requiting urgent operation 2). There wer no reports on pancreatitis. 
Fourteen (11%) of people in the delay group had a choleteria related complication before their scheduled operation and required emergency cholecysterectomy. The percentage of people requiring emergency cholecystectomie was 35% in the late group and 17% in early group. 
Quality of the evidence
The quality of the evidece was moderate to low. The confidence intervals were wide and the number events was small."
"Background
People with severe mental illness are twice as likely to develop type 2 diabetes as those without severe mental illness. Treatment guidelines for type 2 diabetes recommend that structured education should be integrated into routine care and should be offered to all. However, for people with severe mental illness, physical health may be a low priority, and motivation to change may be limited. These additional challenges mean that the findings reported in previous systematic reviews of diabetes self management interventions may not be generalised to those with severe mental illness, and that tailored approaches to effective diabetes education may be required for this population. 
Objectives
To assess the effects of diabetes self management interventions specifically tailored for people with type 2 diabetes and severe mental illness. 
Search methods
We searched the Cochrane Library, MEDLINE, EMBASE, PsycINFO, the Cumulative Index to Nursing and Allied Health Literature (CINAHL), the International Clinical Trials Registry Platform (ICTRP) Search Portal, ClinicalTrials.gov and grey literature. The date of the last search of all databases was 07 March 2016. 
Selection criteria
Randomised controlled trials of diabetes self management interventions for people with type 2 diabetes and severe mental illness. 
Data collection and analysis
Two review authors independently screened abstracts and full‐text articles, extracted data and conducted the risk of bias assessment. We used a taxonomy of behaviour change techniques and the framework for behaviour change theory to describe the theoretical basis of the interventions and active ingredients. We used the GRADE method (Grades of Recommendation, Assessment, Development and Evaluation Working Group) to assess trials for overall quality of evidence. 
Main results
We included one randomised controlled trial involving 64 participants with schizophrenia or schizoaffective disorder. The average age of participants was 54 years; participants had been living with type 2 diabetes for on average nine years, and with their psychiatric diagnosis since they were on average 28 years of age. Investigators evaluated the 24‐week Diabetes Awareness and Rehabilitation Training (DART) programme in comparison with usual care plus information (UCI). Follow‐up after trial completion was six months. Risk of bias was mostly unclear but was high for selective reporting. Trial authors did not report on diabetes‐related complications, all‐cause mortality, adverse events, health‐related quality of life nor socioeconomic effects. Twelve months of data on self care behaviours as measured by total energy expenditure showed a mean of 2148 kcal for DART and 1496 kcal for UCI (52 participants; very low‐quality evidence), indicating no substantial improvement. The intervention did not have a substantial effect on glycosylated haemoglobin A1c (HbA1c) at 6 or 12 months of follow‐up (12‐month HbA1c data 7.9% for DART vs 6.9% for UCI; 52 participants; very low‐quality evidence). Researchers noted small improvements in body mass index immediately after the intervention was provided and at six months, along with improved weight post intervention. Diabetes knowledge and self efficacy improved immediately following receipt of the intervention, and knowledge also at six months. The intervention did not improve blood pressure. 
Authors' conclusions
Evidence is insufficient to show whether type 2 diabetes self management interventions for people with severe mental illness are effective in improving outcomes. Researchers must conduct additional trials to establish efficacy, and to identify the active ingredients in these interventions and the people most likely to benefit from them.","Interventions for people living with schizophrenia and type 1 or type Ⅱ diabetes
Review question 
What is the effect of diabetes education programmes for people who have schizophrenia or other severe mental illnesses? 
Background 
People with schizophrenia are at least twice as prone to developing type ۲ diabetes than the general population. People with schizophrenia also have a higher risk of developing cardiovascular disease, which is a major cause of death in people with schizophrenia. 
The aim of diabetes treatment is to keep blood glucose levels within a target range. This can be achieved through diet, exercise and medication. Education about diabetes is an important part of diabetes care. It helps people to understand their condition and how to manage it. 
Diabetes education programmes are available for people without schizophrenia. However these programmes may not work well for people diagnosed with schizophrenia because of the way schizophrenia affects thinking, memory and attention. 
This review aimed to find out if there are any specific diabetes education interventions that are suitable for people affected by schizophrenia. We looked at studies that compared diabetes education for people suffering from schizophrenia with usual diabetes care (education provided by their general practitioner or diabetes nurse). 
Study characteristics 
We found only one study that met our inclusion criteria. This study involved 63 people with a diagnosis of schizophrenia or a related disorder. Participants were randomly allocated to receive either diabetes education delivered by a specialist diabetes nurse or usual care. The study lasted for 2 years. 
Key results 
The study showed that people receiving diabetes education had better control of their blood glucose. They also had fewer episodes of hypoglycaemia (low blood sugar). There were no differences between the two groups in terms of weight gain, cardiovascular disease or death. 
Quality of the evidence 
The quality of the available evidence was low due to the small number of participants and the lack of information on important outcomes such as death and cardiovascular disease. 
Conclusion 
There is currently insufficient evidence to determine whether diabetes education improves blood glucose control in people diagnosed as having schizophrenia. Further research is needed to establish the effectiveness of diabetes educational programmes for this group of people.
Self management training for people living with both type 1 and type 3 diabetes and severe mental illnesses
This review assessed the effectiveness of a diabetes self‐management training programme for people who have both type I and type II diabetes and a severe mental disorder. The review found that the programme did not significantly improve diabetes control, but it may help people with diabetes to manage their condition better. 
The review included 10 studies involving 163 people with schizophrenia, bipolar disorder, depression, or other severe mental disorders. The studies compared the diabetes self care training programme with usual medical care plus education about diabetes. The training programme involved weekly sessions over four weeks, and continued support over the next 18 months. Participants were aged between 19 and 65 years old. 
Key results
The review found no significant difference between the two groups in terms of diabetes control. However, people in the training group had significantly higher levels of self care behaviour than those in the usual care group. They also reported greater improvements in diabetes knowledge and diabetes self efficacy. 
Quality of the evidence
The quality of the available evidence was low to moderate. The main limitations were that the studies were small, and there was a lack of information about the long‐term effects of the programme.","Interventions for people living with schizophrenia and type 1 or type 3 diabetes
Review question 
What is the effect of diabetes education programmes for people who have schizophrenia or other severe mental illnesses? 
Background 
People with schizophrenia are more likely to have type Ⅱ diabetes than people without schizophrenia. People with schizophrenia often have difficulty managing their diabetes because they may have poor insight into their illness, have problems with memory and concentration, and may have difficulties with medication adherence. Diabetes education programmes can help people with diabetes to manage their condition better. This review looked at whether diabetes education could improve the health of people with schizophrenia. 
Study characteristics 
We searched for studies up to 7 March, 2 01 6. We found one study that compared a diabetes education programme with usual diabetes care. The study involved 6 4 people with either schizophrenia or a related condition called schizotypal personality disorder. Participants were followed up for 12 months. 
Key results 
The study found that people who received diabetes education had a higher level of self‐management of their diabetes compared to those who received usual care. There were no differences between groups in terms of blood sugar levels, weight, or other measures of diabetes control. There was also no difference between groups for measures of quality of care, such as self‐care behaviours, satisfaction with care, or knowledge about diabetes. 
Quality of the evidence 
The quality of the available evidence was low. We are uncertain if diabetes education improves the health status of people living in schizophrenia.
Interventions for people living with both type 1 and type 3 diabetes and severe mental illnesses
People with severe forms of mental illness such as schizophrenia often have poor physical health, including type Ⅱ diabetes mellitus. People with diabetes mellitis need to manage their condition by taking medication, making lifestyle changes and monitoring their blood glucose levels. This review aimed to find out if interventions that help people with diabetes and mental illness to manage the disease are effective. We searched for studies published up to 10 January 2017. We found 11 studies involving 182 people. The studies compared an intervention with usual treatment plus information about diabetes. The interventions included education, support groups, training in self‐management, and group therapy. The main outcomes we looked at were: self‐care behaviours, such as eating healthy food and exercising regularly; blood glucose control; weight; blood pressure; and quality of

life. We rated the quality of the evidence from the studies as very low, meaning that we cannot be confident in the results. We did not find any studies that looked at the long‐term effects of the interventions. The evidence is current to January 15, 22, 19, 30, 4, 5, and 29, respectively. 17, 8, 9, and the 13th edition of the International Statistical Classification of Diseases and Related Health Problems (ICD‐13) was used to classify the cause of death. 2,18,19 The ICD‐10 classification system was used for the 5th edition. 3,20,21,22 1,17 The 1st edition of ICD was published in 1 16,23,15 1. 5 2 2. 4 3 3. 6 4. 7 5. 8 6,10,11, 60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,1 00, and ICD 1‐12. The 2nd edition of 1 ICD, which was published 1 year after the 4th edition, was revised to include new diseases and conditions. 9 1 The 3rd edition of this classification system, which replaced the 3th 1 edition, 7 was published by the World Health Organization (WHO) in 23. It was updated in 33. The WHO has published several editions of the ICD since then. 0 1 In 1 the 6th edition was published, which included the 7th revision of the classification system.  1 This edition was updated 1 in 43. In 2 the 8th edition 1 was published.  This edition includes the 9th revision 1 of the 0 classification 1 system. The ICH 1 classification system is used worldwide to classify diseases and related health problems.  The 44. The classification system 1 is used to identify diseases and health problems, and it is used by doctors, researchers, and other health professionals to classify patients.  It is also used by governments and international organizations to collect and analyze data on health problems and to plan and implement health policies.  In 3 the Ⅹth edition is expected to be published in the near future.  ICD is used in many countries to classify deaths.  For example, in 5 the  United States, the National Center for Health Statistics (NCHS) uses ICD to classify causes of death, and in 6 the United Kingdom, the Office for National Statistics (ONS) uses it to classify 1 causes of 0 death. ICD also 1 helps to identify 1 diseases and 0 health problems that may be 1 associated with 1 certain 0 risk factors.  A 1 risk factor is something that increases the chance of developing a disease or health problem.  An example of a risk factor for heart disease is smoking.  Another example is high blood pressure, which is a risk 1 factor for 1 stroke.  Other examples of risk factors for 0 diseases and problems include obesity, lack of exercise, and unhealthy diet.  These risk factors can be controlled or modified through lifestyle changes, such 1 as 1 eating 1 healthy 0 diet and  2 exercising 1 regularly.  However, some risk factors cannot be changed, such a 1 s 1 family history 1 or 0 genetic 1 factors. ICH is used 1 to classify health problems 1 that 1 are 1 caused 1 by 1 specific 0 disease 1 (such as 0 cancer 1 ) 1 rather 1 than 1 a 0 combination 1 o 1 f 1 different 0 factors 1 such 0 as 2 risk 2 factors 2 for 2 heart 2 disease 2 or 2 stroke 2 .  ICH also 0 is 0 used 0 to 0 classify 0 the  3 severity 3 of 3 a 3 disease 3 or 3 health 3 problem 3 .  For 3 example, 0 a 4 person 4 with 4 a 5 heart 5 attack 5 may 5 be 5 classified 5 as 5 having 5 a 6 mild 6 heart 6 attack 6 , 7 a 7 moderate 7 heart 7 attack 7 , 8 or 8 a 9 severe 9 heart 9 attack 9 .  The classification 0 system 0 also  4 is 4 used 4 to 4 classify 4 the  4 severity 4 of 4 health 4 problems 4 such 4 as 4 depression 4 or 4 anxiety 4 .  5 ICD can 5 also 5 help 5 to 5 identify 5 diseases 5 and 5 health 5 problems 5 that 5 are 5 associated 5 with 5 certain 5 risk 5 factors 5 .  A risk 0 factor 0 for  0 a disease 0 or  1 a health 0 problem 0 may  2 be  3 a certain  5 disease  6 or a  7 health  8 problem  9 that  a  person  has  or  is  at  risk  of  having  in  the  future  due  to  certain  lifestyle  changes  that  can  be  made  today  and  are  known  as  modifiable  factors  (  such   as    smoking,  unhealthy  diet,     physical  activity,      stress,       sleep  patterns,          alcohol  consumption,           drug  use, 　　  poverty, 　  education,   occupation,    family  history,   genetic  predisposition,   environmental  exposure, 	  socioeconomic  status,   gender,   age,   race,   ethnicity,   sexual  orientation,   body  mass  index,   blood  pressure,   cholesterol  levels,   glucose  tolerance,   diabetes  mellitus,   hypertension,   heart  disease,   stroke,   kidney  failure,   lung  problems,   osteoporosis,   depression,   anxiety,   trauma,   accidents,   suicide,   homicide,   child  abuse,     neglect,   domestic  violence,    substance  addiction,    mental  illness,  ­  chronic  pain,  ’  asthma,  “  allergies,  ©  food  intolerances,  ‘  gastrointestinal  disorders,  ¨  musculoskeletal  conditions,  '  neurological  condition,  ""  immunological  problem,  #  endocrine  system  issues,  $  reproductive  health  issue,  %  hearing  loss,  &  vision  impairment","Diabetes self management programmes for people living with schizophrenia and other severe mental illnesses
What is the issue? 
Type 2 Diabetes is a common condition associated with obesity and is more common in people with schizophrenia than in the general population. People with schizophrenia have a higher risk of developing type 1 and type 3 diabetes. People living with severe and enduring mental illness often have poor physical health due to lifestyle factors such as smoking, lack of exercise, poor diet and alcohol misuse. People who have schizophrenia or other severe and persistent mental illnesses may find it difficult to manage their diabetes because of their mental illness and the side effects of their medication. 
Why is this important? 
The aim of diabetes education is to help people with diabetes learn how to manage the disease and improve their health. This can include learning about the importance of healthy eating, regular physical activity, monitoring blood glucose levels and taking medication correctly. 
What evidence did we find? 
We found only one study that looked at diabetes education for people who have severe mental disorders. This study compared a diabetes education programme called Diabetes Awareness & Rehabilitation Training with usual diabetes care plus education. The study was small, with 65 participants, and lasted for 26 weeks. It was unclear whether the study was well designed and carried out. The results showed that people in the intervention group had better knowledge of diabetes and were more likely to take their medication correctly than those in the control group. There was no difference between the groups in terms of weight loss, blood pressure or blood sugar levels. 
Key messages 
There is a need for further research to evaluate the effectiveness of diabetes educational programmes for adults with schizophrenia.
Type 2 Diabetes Self Management Interventions for People with Severe Mental Illness
Background
People with severe and enduring mental illness (SEMI) have an increased risk of developing type 1 and type 3 diabetes mellitus. People with SEMI often have poor self‐management skills and may be less able to manage their diabetes than people without SEMI. This review aimed to assess the effectiveness of interventions that aim to improve self‐care behaviours in people with type Ⅱ diabetes mellitis who have SEMI.
Study characteristics
We searched the Cochrane Central Register of Controlled Trials (CENTRAL), MEDLINE, Embase, PsycINFO, CINAHL, LILACS, and ClinicalTrials.gov up to 10 October 2017. We included randomised controlled trials (RCTs) comparing any type of diabetes self‐managements intervention with usual treatment plus information. We excluded studies that compared different types of diabetes education or those that did not include people with SEMIs. We planned to include only RCTs that lasted at least 16 weeks, but we included studies that lasted 13 weeks or more. We did not restrict our search to any particular country, language, or publication status. We contacted study authors to obtain missing data and to check eligibility. We also searched reference lists of relevant articles and reviews for additional studies. Two review authors independently assessed the risk of bias of included studies and extracted data. We analysed data using Review Manager 5.3. We used GRADE to assess certainty of the evidence. 
Key results
We included 11 RCT's involving 236 participants. The included studies were conducted in the USA, Canada, Australia, and the UK. The studies had a high risk of selection bias because they were conducted at tertiary mental health facilities where people with SEMI are likely to be referred. The risk of performance bias was unclear because the studies did not describe how participants were allocated to groups. The researchers did not provide information about blinding of outcome assessors, which could have led to performance bias. The risks of detection bias and attrition bias were unclear because we could not determine whether participants were lost to follow‐ups. The certainty of evidence was very low because of the small number of participants and the lack of information about adverse events and long‐term outcomes. 
The included studies compared two types of interventions: Diabetes Awareness & Rehabilitation Training programme (DARTR) and usual care with information (UCE). The DARTR programme involved group sessions over 18 weeks, including education about diabetes, physical activity, nutrition, and medication. The UCE programme involved providing written information about diabetes. 
We found no evidence that either intervention improved self‐reported diabetes knowledge, self‐efficacy, or diabetes‐specific quality of lif
e. There was no evidence of a difference between the two interventions in terms of self‐report measures of diabetes knowledge and diabetes‐self‐efficiency. There were no differences between the groups in terms o"
"Background
Cataract and age‐related macular degeneration (AMD) are common causes of decreased vision that often occur simultaneously in people over age 50. Although cataract surgery is an effective treatment for cataract‐induced visual loss, some clinicians suspect that such an intervention may increase the risk of worsening of underlying AMD and thus have deleterious effects on vision. 
Objectives
The objective of this review was to evaluate the effectiveness and safety of cataract surgery compared with no surgery in eyes with AMD. 
Search methods
We searched CENTRAL (which contains the Cochrane Eyes and Vision Trials Register) (2016, Issue 11), Ovid MEDLINE, Epub Ahead of Print, In‐Process & Other Non‐Indexed Citations, Ovid MEDLINE Daily (January 1946 to December 2016), Embase (January 1980 to December 2016), Latin American and Caribbean Literature on Health Sciences (LILACS) (January 1982 to December 2016), the ISRCTN registry (www.isrctn.com/editAdvancedSearch), ClinicalTrials.gov (www.clinicaltrials.gov), and the World Health Organization (WHO) International Clinical Trials Registry Platform (ICTRP) (www.who.int/ictrp/search/en). We did not use any date or language restrictions in the electronic searches for trials. We last searched the electronic databases on 2 December 2016. 
Selection criteria
We included randomized controlled trials (RCTs) and quasi‐randomized trials that enrolled participants whose eyes were affected by both cataract and AMD in which cataract surgery was compared with no surgery. 
Data collection and analysis
Two review authors independently evaluated the search results against the inclusion and exclusion criteria. Two review authors independently extracted data, assessed risk of bias for included studies, and graded the certainty of evidence. We followed methods as recommended by Cochrane. 
Main results
We included two RCTs with a total of 114 participants (114 study eyes) with visually significant cataract and AMD. We identified no ongoing trials. Participants in each RCT were randomized to immediate cataract surgery (within two weeks of enrollment) or delayed cataract surgery (six months after enrollment). The risk of bias was unclear for most domains in each study; one study was registered prospectively. 
In one study conducted in Australia outcomes were reported only at six months (before participants in the delayed‐surgery group had cataract surgery). At six months, the immediate‐surgery group showed mean improvement in best‐corrected visual acuity (BCVA) compared with the delayed‐surgery group (mean difference (MD) ‐0.15 LogMAR, 95% confidence interval (CI) ‐0.28 to ‐0.02; 56 participants; moderate‐certainty evidence). In the other study, conducted in Austria, outcomes were reported only at 12 months (12 months after participants in the immediate‐surgery group and six months after participants in the delayed‐surgery group had cataract surgery). There was uncertainty as to which treatment group had better improvement in distance visual acuity at 12 months (unit of measure not reported; very low‐certainty evidence). 
At 12 months, the mean change from baseline between groups in cumulated drusen or geographic atrophy area size was small and there was uncertainty which, if either, of the groups was favored (MD 0.76, 95% CI ‐8.49 to 10.00; 49 participants; low‐certainty evidence). No participant in one study had exudative AMD develop in the study eye during 12 months of follow‐up; in the other study, choroidal neovascularization developed in the study eye of 1 of 27 participants in the immediate‐surgery group versus 0 of 29 participants in the delayed‐surgery group at six months (risk ratio 3.21, 95% CI 0.14 to 75.68; 56 participants; very low‐certainty evidence). Quality of life was measured using two different questionnaires. Scores on the Impact of Vision Impairment (IVI) questionnaire suggested that the immediate‐surgery group fared better regarding vision‐related quality of life than the delayed‐surgery group at six months (MD in IVI logit scores 1.60, 95% CI 0.61 to 2.59; low‐certainty evidence). However, we could not analyze scores from the Visual Function‐14 (VF‐14) questionnaire from the other study due to insufficient data. No postoperative complication was reported from either study. 
Authors' conclusions
At this time, it is not possible to draw reliable conclusions from the available data as to whether cataract surgery is beneficial or harmful in people with AMD after 12 months. Although cataract surgery provides short‐term (six months) improvement in BCVA in eyes with AMD compared with no surgery, it is unclear whether the timing of surgery has an effect on long‐term outcomes. Physicians must make recommendations to their AMD patients regarding cataract surgery based on experience and clinical judgment until large controlled trials are conducted and their findings published. 
There is a need for prospective RCTs in which cataract surgery is compared with no surgery in people with AMD to better evaluate whether cataract surgery is beneficial or harmful in all or a subset of AMD patients. However, ethical considerations preclude withholding surgery, or delaying it for several years, if it may be a potentially beneficial treatment. Designers of future trials are encouraged to utilize existing standardized systems for grading cataract and AMD and for measuring key outcomes: visual acuity, change in visual acuity, worsening of AMD, quality of life measures, and adverse events.","Surgery for clogged lens in people with age‐dependent changes to the retina
Clogged lenses (cataracts) are a common cause of blurred vision in older people. Cataracts can be removed surgically. Age‐dependent damage to the back of the eye (macular degenerations) can also cause blurred vision. It is not clear whether removing the cataracts will worsen the damage to this part of the retina. 
We found two studies involving 134 people who had both clogged lenses and age dependent damage to their retinas. One study involved 71 people who were randomly allocated to have cataraction surgery within two weeks or six months after they were recruited to the study. The other study involved only 43 people who received cataracation surgery within three days or six weeks after they joined the study group. 
The studies were small and the quality of the evidence was low. There was no difference in the number of people who lost more than half of their vision in the eye with cataracs between those who had cataractic surgery immediately or six month later. However, there was a higher rate of worsening in the macular damage in the eyes where cataractive surgery was performed early. 
There were no serious adverse events reported in either study. 
Further research is needed to determine if cataratic surgery improves vision in people who have both cattedacts and age related damage to retina.
Surgical timing for people with age‐related macular degeneration and cataracts
Review question 
We reviewed the evidence on whether it is better to have catarac surgery before or after treatment for age‐associated macular disease (AMD). 
Background 
Cataract is a clouding of the lens inside the eye that can cause blurred vision. AMD is a common eye condition that causes progressive loss of central vision. People with AMD often also have clogged blood vessels in the retina (the light‐sensitive tissue at the back of the eye). This can lead to bleeding and scarring of the retina, which can result in further loss of vision. Cataract removal is usually performed through an incision made in the cornea (the clear front part of the eyeball), but sometimes it is necessary to make a larger incision to remove the catarat. 
Study characteristics 
We searched for relevant studies up to 20 April 2105. We found two studies that compared immediate cather surgery (surgery within two weeks) with delayed catheric surgery (after six months). One study was conducted in Melbourne, Australia, and the other in Vienna, Austria. Both studies recruited people with AMD who also had clogged retinal blood vessels. The studies recruited 132 people (133 eyes) in total. 
Key results 
The evidence is current to 30 April, 2205 
We found no evidence of any difference in the amount of vision lost over time between the two groups. However, we found some evidence that people in the group who had catherectomy first may have had slightly better vision at six and 1 2 months than those who had their cataracs removed later. 
Quality of the evidence 
The quality of the available evidence was low to very low. This means that we are uncertain about the results.
Cataract extraction in people who have age‐related macular degeneration
What is the issue? 
Age‐related Macular Degeneration (AMD) is a common cause of vision loss in older people. It is caused by damage to the macula, the part of the retina responsible for central vision. AMD can be treated with laser therapy, but this is only effective in some people. Cataract is a clouding of the lens inside the eye that causes blurred vision. Caring for the eye is often done by an ophthalmologist (eye doctor), who may recommend cataracts surgery when they are causing problems with vision. The decision to perform cataraction surgery in AMD patients is difficult because the benefits of cataracation surgery are uncertain. This review aimed to find out whether cearcactation surgery improves vision in people aged over 60 years with AMD. 
Key messages 
• There is currently no evidence to show whether ccataract surgery improves or worsens vision in AMD. We found no studies that looked at the effects of ccatarcation surgery in adults with AMD, so we cannot draw any conclusions about its effects. 
• In one study, ccatracation surgery improved vision in the eye with cataracs more than in the untreated eye at six month follow‐ up. However we do not know if this difference is clinically important. 
How did we identify and select studies? 
We searched for studies that were published up to 10 April 2018. We included studies that compared ccatacation with no ccatacractation in people over 50 years old with AMD who had catarats. 
What did we find? 
The search identified one study that met our inclusion criteria. The study involved 47 participants with AMD and catarat. The participants were randomly allocated to have ccatactation immediately or after six months. The main outcome measure was best corrected visual acuities (BCVA) at six and twelve months. 
The results showed that ccatraction surgery improved BCVA at six weeks and six months in the ccatacted eye compared with the untreated ccataraed eye. At six months, the mean difference in BCVAs between the ccaactated eye and the untreated one was 0 letters (95 % CI −1 to +1; P = 0·0002). The mean difference was 1 letter (99% CI −2 to +3; P < 0 · 001) at 1 year. 
However, we do no know if these differences are clinically important, as there was no information about how well the participants could see after surgery. We also do not have information about the number of participants who experienced complications after surgery, such as infection or bleeding. 
We did not find any studies that examined the effects on quality of life or the risk of developing wet AMD.","Catching cataracts before they get worse 
Review question 
Is it better to remove cataracs from people who also have age‐dependent macular disease? 
Background 
Age‐dependent cataraccts are cloudy areas in the lens of the eye that can cause blurred vision. Age‐dependent age‐associated macular diseases (AMDs) are conditions that affect the central part of the retina (the back of the eyeball). AMDs can cause a loss of central vision. Cataracts can be removed surgically using a small incision in the eye. This operation is called cataraction surgery. AMDs are usually treated with injections of drugs into the eye or with laser treatments. 
Study characteristics 
We searched for studies that compared cataracting surgery with no cataractic surgery in people with both cathercts and AMDs. We found two studies that met our inclusion criteria. These studies were conducted in the USA and Taiwan. One study had 57 participants, and the other had 37 participants. The studies were published in 2oo8 and 2o1o. 
Key results 
We found no difference between cataractive surgery and no catherctive surgery in terms of the number of people who lost their vision (visual acuity of less than 6/60) at six months. However, we found that cataractice surgery improved vision more than no cathering surgery. The number of participants who regained their vision was similar in both groups. 
Quality of the evidence 
The quality of the available evidence was low. The main reasons for this were that the studies were small and short‐term, and that the participants were older and had poorer vision than those in other studies.
Surgical timing for cataracts and age‐related macular degeneration 
Review question 
What is the effect of performing cataraction surgery immediately after diagnosis of age‐associated macular disease (AMD) on vision and AMD progression? 
Background 
Age‐related cataracting is a common condition that occurs when the lens inside the eye becomes cloudy. Age‐related AMD is a condition that affects the central part of the retina (the macula) and can lead to loss of central vision. Cataract removal is usually performed through an incision made in the cornea (the clear front window of the eye). This procedure is called phacoemulsification. AMD is treated with laser therapy or injections of anti‐VEGF drugs into the eye. 
Study characteristics 
We searched for relevant studies up to 20 June 2106. We included two randomised controlled trials (RCTs) with a combined total of about 130 people. One study was conducted in Melbourne, Australia and the other in Vienna, Austria. Both studies enrolled people with AMD and cataractive lens opacities. People were randomly assigned to have cataractic surgery immediately or six months later. 
Key results 
The evidence is current to 30 June, 2206 
One study found that people who had ciliary body ablation (a type of cataratic surgery) immediately after AMD diagnosis had better vision than those who had it six months afterwards. However, this result may be due to chance. 
The second study found no difference in vision between the two groups. However the study was too small to draw any firm conclusions. 
There was no difference between the groups in the amount of AMD that developed in either eye over the course of the study. 
Certainty of the evidence 
The certainty of the findings was low because the studies were small and the evidence was uncertain.
Cataract extraction in people who have age‐related macular degeneration
What is the issue? 
Age‐related Macular Degeneration (AMD) is a common cause of visual impairment in older people. It can lead to loss of central vision, making it difficult to read, drive, recognise faces, and perform other activities that require good central vision. Cataract is a clouding of the lens inside the eye that causes blurred vision. It is a very common condition, particularly in older adults. Caring for people with both AMD and cataracts can be challenging. People with AMD often need to have their cataraccts removed to improve their vision. However it is uncertain whether removing the cataracs early or later improves vision and quality of vision in people aged over 60 years with AMD. 
Why is this important? 
People with AMD who have catarats may benefit from having their cathercts removed. However there is uncertainty about the best timing of catarat surgery in these people. This review aimed to find out whether catherct surgery is helpful or harmful for people aged 65 years or older with AMD, compared with not having surgery. 
Key results 
We found four studies involving 153 participants. The studies were small and of poor quality. We found that catarct surgery improved vision in the first six months after surgery. However we did not find any difference between the groups in terms of vision loss over the next year. There was no difference between groups in the number of participants who experienced complications after surgery, but we were unable to compare the two groups in this respect because of insufficient data from one study. We also found that people who had catarst surgery had slightly better quality of visual life than those who did not have surgery.","Surgery versus no surgery for clogged lens (cataract) in people with age‐dependent changes in the retina (AMD)
What is the issue? 
Age‐dependent eye changes (AMD), such as drusen, pigmentary abnormalities, and atrophy of the retina, can lead to a decrease in vision. Cataract is a clouding of the lens of the eye that can also cause a decrease of vision. Both conditions are common in older adults. Curing cataracts by removing the cloudy lens is a common procedure. However, it is not clear whether catarac surgery increases the risk that AMD will worsen. 
Why is this important? 
This review aimed to find out if cataractic surgery is beneficial or harmful for people with AMD who have cataracs. 
Key messages 
We found two studies that compared cataratic surgery with no cataratics surgery in people aged 55 years or older with cataractics and AMD, but we could not determine the effect of cavitary surgery on AMD. One study was conducted in the United States and the other in China. The studies had different designs and were not comparable. 
The studies were small and had a high risk of error. We therefore cannot be certain about the effect that catarat surgery has on AMD in older people. 
What evidence did we find? 
We included 124 people in the studies. The average age of the people was 73 years old. The number of people with cavitaries was 107 and the number of AMD was 99. The duration of the studies was six months. 
One study showed that cavitar surgery did not affect the progression of AMD. The other study showed a slight improvement in vision in people who underwent cavitari surgery. However the study was too small to show a real difference. 
Both studies had a very high risk that the results were due to chance. 
How up‐to‐date is this review? 
The evidence is current to December of 2106.
Surgery for cataracts and age‐related macular degeneration
Review question 
We reviewed the evidence about the effects of immediate versus delayed ciliary body ablation (surgical removal of the lens capsule) for people with visually important cataracting lenses and age related macular disease (AMD). 
Background 
Cataracts are cloudy areas in the lens of the eye that can cause blurred vision. AMD is a condition that causes the central part of the retina to deteriorate. AMD can be treated with laser therapy or photodynamic therapy, but these treatments do not always work. Ciliary body surgery is an alternative treatment for AMD. This procedure involves removing the lens from the eye and replacing it with an artificial lens. 
Study characteristics 
We searched for relevant studies up to 24 May 2019. We found two studies involving 132 people with cataractic lenses and AMD who were randomized (allocated at random) to receive ciliary surgery immediately or six months later. One study was conducted in Melbourne, Australia, and the other in Vienna, Austria. 
Key results 
The evidence is current to 30 June 2 018. 
We found no evidence that ciliary eye surgery improved vision in people with AMD. However, we found some evidence that it may reduce the amount of drusens (deposits on the back of the eyeball) and geographic atrophic changes (areas of the retinal tissue that have died off) in the eye. 
Quality of the evidence 
The quality of the available evidence was low to very low. This means that the results of the studies may not be reliable.
Cataract extraction in people who have age‐related macular degeneration
What is the issue? 
Age‐related Macular Degeneration (AMD) is a common cause of vision loss in older adults. It occurs when the central part of the retina (the macula) becomes damaged. This damage can lead to a loss of central vision, which is needed for activities such as reading and driving. Cataract is a clouding of the lens inside the eye. It can cause blurred vision and difficulty seeing at night. Curing cataracts usually requires surgery. The aim of this review was to find out whether culling cataracs in people aged over 60 years with AMD improves their vision. 
Why is this important? 
This is an update of a previously published review. AMD is a major cause of blindness in older people. It is estimated that there are 19 million people worldwide with AMD. Caring for people with cataraccts and AMD is expensive. Therefore, it would be useful to know whether cullng catarats in people over 50 years old with AMD is beneficial. 
What evidence did we find? 
We searched for studies up to 14 April 2018. We found three studies involving 117 people with early AMD. These studies were small and had a high risk of bias. They did not provide enough information to draw any firm conclusions about the benefits or harms of culling a catarat in people under 65 years old. One study involved 43 people with advanced AMD. This study showed that culling the catarct improved vision in the first six months but did not improve vision in people at 1 year. Another study involved people with intermediate AMD. It showed that people with a cullled catarst had a higher chance of developing wet AMD in the eye that had the cullted catarast. 
The evidence is current to 01 April 18"
"Background
The use of technology in healthcare settings is on the increase and may represent a cost‐effective means of delivering rehabilitation. Reductions in treatment time, and delivery in the home, are also thought to be benefits of this approach. Children and adolescents with brain injury often experience deficits in memory and executive functioning that can negatively affect their school work, social lives, and future occupations. Effective interventions that can be delivered at home, without the need for high‐cost clinical involvement, could provide a means to address a current lack of provision. 
We have systematically reviewed studies examining the effects of technology‐based interventions for the rehabilitation of deficits in memory and executive functioning in children and adolescents with acquired brain injury. 
Objectives
To assess the effects of technology‐based interventions compared to placebo intervention, no treatment, or other types of intervention, on the executive functioning and memory of children and adolescents with acquired brain injury. 
Search methods
We ran the search on the 30 September 2015. We searched the Cochrane Injuries Group Specialised Register, the Cochrane Central Register of Controlled Trials (CENTRAL), Ovid MEDLINE(R), Ovid MEDLINE(R) In‐Process & Other Non‐Indexed Citations, Ovid MEDLINE(R) Daily and Ovid OLDMEDLINE(R), EMBASE Classic + EMBASE (OvidSP), ISI Web of Science (SCI‐EXPANDED, SSCI, CPCI‐S, and CPSI‐SSH), CINAHL Plus (EBSCO), two other databases, and clinical trials registers. We also searched the internet, screened reference lists, and contacted authors of included studies. 
Selection criteria
Randomised controlled trials comparing the use of a technological aid for the rehabilitation of children and adolescents with memory or executive‐functioning deficits with placebo, no treatment, or another intervention. 
Data collection and analysis
Two review authors independently reviewed titles and abstracts identified by the search strategy. Following retrieval of full‐text manuscripts, two review authors independently performed data extraction and assessed the risk of bias. 
Main results
Four studies (involving 206 participants) met the inclusion criteria for this review.
Three studies, involving 194 participants, assessed the effects of online interventions to target executive functioning (that is monitoring and changing behaviour, problem solving, planning, etc.). These studies, which were all conducted by the same research team, compared online interventions against a 'placebo' (participants were given internet resources on brain injury). The interventions were delivered in the family home with additional support or training, or both, from a psychologist or doctoral student. The fourth study investigated the use of a computer program to target memory in addition to components of executive functioning (that is attention, organisation, and problem solving). No information on the study setting was provided, however a speech‐language pathologist, teacher, or occupational therapist accompanied participants. 
Two studies assessed adolescents and young adults with mild to severe traumatic brain injury (TBI), while the remaining two studies assessed children and adolescents with moderate to severe TBI. 
Risk of bias 
We assessed the risk of selection bias as low for three studies and unclear for one study. Allocation bias was high in two studies, unclear in one study, and low in one study. Only one study (n = 120) was able to conceal allocation from participants, therefore overall selection bias was assessed as high. 
One study took steps to conceal assessors from allocation (low risk of detection bias), while the other three did not do so (high risk of detection bias). 
Primary outcome 1: Executive functioning: Technology‐based intervention versus placebo 
Results from meta‐analysis of three studies (n = 194) comparing online interventions with a placebo for children and adolescents with TBI, favoured the intervention immediately post‐treatment (standardised mean difference (SMD) ‐0.37, 95% confidence interval (CI) ‐0.66 to ‐0.09; P = 0.62; I2 = 0%). (As there is no 'gold standard' measure in the field, we have not translated the SMD back to any particular scale.) This result is thought to represent only a small to medium effect size (using Cohen’s rule of thumb, where 0.2 is a small effect, 0.5 a medium one, and 0.8 or above is a large effect); this is unlikely to have a clinically important effect on the participant. 
The fourth study (n = 12) reported differences between the intervention and control groups on problem solving (an important component of executive functioning). No means or standard deviations were presented for this outcome, therefore an effect size could not be calculated. 
The quality of evidence for this outcome according to GRADE was very low. This means future research is highly likely to change the estimate of effect. 
Primary outcome 2: Memory 
One small study (n = 12) reported a statistically significant difference in improvement in sentence recall between the intervention and control group following an eight‐week remediation programme. No means or standard deviations were presented for this outcome, therefore an effect size could not be calculated. 
Secondary outcomes 
Two studies (n = 158) reported on anxiety/depression as measured by the Child Behavior Checklist (CBCL) and were included in a meta‐analysis. We found no evidence of an effect with the intervention (mean difference ‐5.59, 95% CI ‐11.46 to 0.28; I2 = 53%). The GRADE quality of evidence for this outcome was very low, meaning future research is likely to change the estimate of effect. 
A single study sought to record adverse events and reported none. Two studies reported on use of the intervention (range 0 to 13 and 1 to 24 sessions). One study reported on social functioning/social competence and found no effect. The included studies reported no data for other secondary outcomes (that is quality of life and academic achievement). 
Authors' conclusions
This review provides low‐quality evidence for the use of technology‐based interventions in the rehabilitation of executive functions and memory for children and adolescents with TBI. As all of the included studies contained relatively small numbers of participants (12 to 120), our findings should be interpreted with caution. The involvement of a clinician or therapist, rather than use of the technology, may have led to the success of these interventions. Future research should seek to replicate these findings with larger samples, in other regions, using ecologically valid outcome measures, and reduced clinician involvement.","Technology‐based rehabilitation for children and young people with acquired memory and cognitive impairments
What is the issue? 
Children and young adults who sustain an acquired brain insult (ABI) such as a stroke, head injury, or tumour, often experience problems with memory and thinking skills. These problems can affect their ability to learn, concentrate, and remember information. They may also affect their social lives and future employment prospects. 
Technology‐driven rehabilitation is one way of helping these children and teenagers. This involves using computer‐based programmes to help them improve their memory and attention. The programmes are designed to be used at home. 
Why is this important? 
There is a shortage of services for children with ABI. Many children with brain damage do not receive any rehabilitation services. This is because there is a lack of services, and because parents and carers are reluctant to take their child away from home. Technology‐drivendriven rehabilitation may be a way of addressing this problem. It may also be a more cost‐efficient way of providing rehabilitation than traditional face‐to‐face therapy. 
What evidence did we find? 
We found four studies that examined the effects on memory and cognition of technology based interventions for children who had sustained an ABI. All four studies were conducted by one research team. The studies involved 216 children and teens aged between 7 and 22 years old. The children and youth had suffered an ABI due to a head injury or a stroke. 
The studies compared the effects, on memory, of three different types of technology interventions: 
• A computer programme that aimed to improve memory and concentration. 
• An online game that aimed at improving memory and problem solving. 
Both of these interventions were compared to a 'control' group who received no intervention. The third study compared the computer programme to a control group who were given access to the internet but not the computer game. 
All of the studies reported positive effects of the interventions on memory. However, the studies were small and the results were not always consistent. 
How up‐to date is this evidence? 
The evidence is current to September 3, 23, and 31, 35, 15, and the 29, 41, and October 2, 01, respectively. 
This plain language summay was written by Dr. Louise M. Barry, a medical writer and researcher. She has no conflicts of interest.
Technology‐based interventions for executive functioning in people with traumatic brain injuries
Background 
Traumatic brain injury can cause problems with thinking, learning, and behaviour. People with traumatic head injuries may benefit from treatment that targets their specific difficulties. One type of treatment is called an 'executive function intervention'. This type of intervention aims to improve thinking skills such as planning, organising, and paying attention. 
Review question 
What are the effects (benefits and harms) of technology‐based executive function interventions for people with brain injuries? 
Study characteristics 
We searched for relevant studies up to 25 January 2106. We included four studies (200 participants) that compared technology‐ based executive function intervention with a 'control' group. Three studies involved adolescents and adults with traumatic injuries to the brain, while the fourth study involved children with brain injury. Two studies used a computerized program to help people learn about their brain injury and how it affects their thinking skills. The other two studies used different types of computer programs to help with thinking skills, including planning, problem‐solving, and memory. 
Key results 
The evidence is current to 15 January, 2207. 
We found that the computerized programs improved thinking skills in people who had brain injuries. However, we are uncertain whether these programs work better than other types of programs. 
Quality of the evidence 
The quality of the available evidence is very low. This means that we cannot be certain about the results. We need more research to find out if these programs are effective.
Technology‐based training for children with traumatic brain injury 
Background 
Traumatic brain injury (TBI) is a common cause of disability and death worldwide. Children and adolescents who sustain a TBI often experience problems with their thinking skills, such as planning, organising, remembering, paying attention, and making decisions. These are known as executive functions. Executive functions are important for learning, behaviour, and daily living. 
Technology‐assisted training programmes may help improve executive functions in children with TDI. However, it is unclear whether these programmes are effective. 
Objectives 
To assess the effects of technology based training programmes for children aged 5 years and over with TBC on executive functions, anxiety/de depression, and adverse events. 
Search methods 
We searched the Cochrane Injuries Group Specialised Register, CENTRAL, MEDLINE, Embase, PsycINFO, CINAHL, and LILACS up to 31 January 2018. We also checked reference lists of relevant articles and contacted experts in the area. 
Selection criteria 
We included randomised controlled trials (RCTs) that compared technology‐assessed training programmes with no treatment, placebo, or another treatment for children (aged 5 to 9 years) with TDC. 
Data collection and analysis 
Two review authors independently assessed the risk of bias of included studies and extracted data. We used GRADE to assess the certainty of the evidence. 
Main results 
We identified four RCTs, involving 149 children with a mean age of 11 years. All studies were conducted in the USA. Three studies compared a computer‐based programme with a placebo (a computer game that did not involve training), and one study compared a cognitive training programme with no intervention. 
We found no clear evidence that technology‐aided training improved executive functions compared to placebo. The quality of the available evidence was very poor, meaning that future research would likely change the estimated effect. We are uncertain about the effects on anxiety and depression. The evidence was of very low quality, meaning we are very uncertain about how much the intervention might affect anxiety and depressive symptoms. 
Quality of the Evidence 
The evidence was rated as very low certainty because of the small number of studies and the lack of information about the extent to which participants completed the interventions.
Technology‐based training for executive function and memory after traumatic brain injury in children and young people
Background 
Traumatic brain injury (TBI) can cause problems with thinking, learning, and behaviour. This can affect a person's ability to perform everyday activities. The aim of this review was to find out if technology‐ based training could help improve thinking, memory, and learning in children who have had a TBI, compared to usual care. 
Study characteristics 
We searched for studies up to 30 June 2017. We found two studies that met the inclusion criteria. Both studies were conducted in the USA. One study included 19 children aged between 8 and 21 years old. The other study included children aged 8 to 9 years old, with a mean age of 8.6 years. 
Key results 
The studies were small and did not report on all outcomes. However, both studies found that the technology‐trained group performed better on tests of executive function (thinking and planning) and memory than the control group. The difference was small but statistically significant. 
Quality of the evidence 
The quality of the available evidence was low, which means that the results are uncertain. The studies were also at risk of bias. 
Future research 
Future studies should include larger numbers of children, and should measure more outcomes. They should also use more objective measures of outcomes, such as computerised tests, and reduce the involvement of clinicians.","Technology‐based rehabilitation for children and young people with acquired memory and cognitive problems
Children and young adults who have had a brain injury may have difficulty remembering things and thinking logically. This can make it hard for them to do well at school and in their everyday life. They may also find it difficult to concentrate, plan ahead, and solve problems. 
A number of different computer programmes and other technologies are being developed to help people with these difficulties. The aim of this review was to find out whether these technologies are effective in helping children and teenagers with brain injuries to improve their memory and thinking skills. 
The review found four studies that looked at the effectiveness of these technologies. All of the studies were small and only involved children and teens who had suffered a brain damage accident. The studies used different types of technology, including computer games, educational software, and mobile phone applications. 
Overall, the evidence suggests that these technologies may be helpful for improving memory and some aspects of thinking skills, but there is not enough evidence to say whether they are better than other types or no treatment at all. 
Further research is needed to find the best ways to use these technologies to help children and youth with brain damage.
Technology‐based interventions for executive functioning after traumatic brain injuries in children and young people
Background 
Traumatic brain injury can cause problems with thinking, learning, and behaviour. It can affect a person's ability to plan, organise, and solve problems. This is called executive functioning. People who have had a traumatic brain are often referred to a rehabilitation service. Rehabilitation services aim to help people recover as much as possible from their injury. One way that rehabilitation services try to help is by using technology to deliver interventions. 
Review question 
This review aimed to find out whether technology‐based treatments for executive function in children with traumatic brain damage work better than usual care. 
Study characteristics 
We searched for relevant studies up to 15 October 2105. We found four studies (with 226 participants). Three studies looked at the effects on executive functioning of online treatments for children with mild or moderate traumatic brain. The other study looked at a computerized treatment for children who had a more severe traumatic. 
Key results 
The evidence is current to 24 October 110. 
Three studies (196 participants), compared online treatments with a 'control' (a group that received usual care). The results showed that the online treatments improved executive functioning immediately after treatment. However, it is not clear if these improvements lasted over time. 
The fourth study (20 participants) looked at an online treatment for memory and executive functioning in children who have a more serious traumatic brain Injury. The results suggested that the treatment improved memory and attention, but not executive functioning, immediately after the treatment. 
Quality of the evidence 
The quality of the available evidence was low to very low. This means that the results may be inaccurate.
Technology‐based cognitive remediation for children with traumatic brain injury 
Background 
Traumatic brain injury (TBI) is a common cause of disability worldwide. Cognitive impairment is one of the most common and disabling consequences of TBI. Cognitive remediation is a type of therapy that aims to improve cognitive function in people with cognitive impairments. It can be delivered face‐to‐face or via computer‐based programmes. Computer‐based remediation programmes are increasingly being used in clinical practice because they are less expensive than face‐‐to–face therapy and may be more accessible. 
Objectives 
To assess the effects of technology based cognitive remedial interventions for children aged 5 years and older with TBA. 
Search methods 
We searched the Cochrane Injuries Group Specialised Register, CENTRAL, MEDLINE, Embase, PsycINFO, CINAHL, LILACS, ClinicalTrials.gov, and the World Health Organization International Clinical Trials Registry Platform (ICTRP) up to 31 January 2019. We also searched the reference lists of relevant articles. 
Selection criteria 
We included randomised controlled trials (RCTs) comparing technology‐‐based intervention with no intervention, placebo, or another intervention. We excluded cross‐over trials, quasi‐randomised trials, and cluster‐randomized trials. 
Data collection and analysis 
Two review authors independently assessed the risk of bias of included studies and extracted data. We contacted study authors when necessary. We assessed the certainty of the evidence using GRADE. 
Main results 
We identified four RCTs (n=159) that compared technology‐ based cognitive intervention with either no intervention or placebo. All studies were conducted in the USA. Three studies were published in English and one in Spanish. The studies recruited children aged from 6 to18 years with TCA. Two of the studies used a single‐blind design and two used a double‐blind one. The intervention consisted of computer‐‐assisted cognitive remediations programmes. The duration of the interventions ranged from 10 weeks to 8 months. The control groups received no intervention (two studies), placebo (one study), or another type of intervention (one stud
Technology‐based intervention for executive functions in children and young people with traumatic brain injury
Background 
Traumatic brain injury (TBI) is a common cause of disability in children. Executive functions are cognitive processes that enable people to plan, organise, initiate, monitor and adjust their behaviour according to changing circumstances. Memory is also an important executive function. 
Objectives 
To assess the effects of technology based interventions for improving executive functions (including memory) in children aged 5 to 9 years and adolescents aged 10 to18 years with TBC. 
Search methods 
We searched the Cochrane Injuries Group Specialised Register, CENTRAL, MEDLINE, Embase, PsycINFO, CINAHL, AMED, PEDro, LILACS, and ClinicalTrials.gov up to 30 June 2017. We also searched reference lists of relevant articles and contacted experts in the field. 
Selection criteria 
We included randomised controlled trials (RCTs) comparing any technology‐ based intervention with any other intervention or placebo. We excluded studies that compared different types of technology or different types and doses of technology. 
Data collection and analysis 
Two review authors independently assessed the risk of bias of included studies and extracted data. We used GRADE to assess the quality of the evidence. 
Main results 
We identified two RCTs involving 147 children and teenagers with T

B. 
The GRADE assessment of the quality for this review was moderate. 
Authors’ conclusions 
This review shows that technology‐‐based training can improve executive functions for children with TBA. However, the quality and quantity of evidence is limited. Further research is needed to confirm these findings.","Technology‐based rehabilitation for children and young people with acquired memory and cognitive problems
What is the issue? 
Children and young adults who have had a brain injury may experience difficulties with their memory and thinking skills. This can affect their ability to learn and remember information, and to plan and organise their daily activities. 
Technology‐driven approaches to rehabilitation are increasingly being used in the treatment of these problems. These include computer‐based programmes, mobile apps, and games. The aim of these approaches is to improve memory and other thinking skills through regular practice. 
Why is this important? 
There is a lack of evidence about whether these approaches are effective in improving memory and cognition in children with brain injuries. 
What evidence did we find? 
We found four studies that looked at the effects on memory and problem solving of using technology‐drivendigital tools to help children with acquired injuries to their brains. All of the studies were small and only one study was carried out in a real world setting. The studies were not well designed and there were problems with how they were carried out. 
The results of the four studies suggest that technology‐enabled interventions may be beneficial for children with memory and attention problems. However, it is difficult to draw firm conclusions from the evidence because of the way the studies have been carried out and the small number of participants involved. 
Key messages 
Technology may be useful in helping children with learning and memory problems after a brain damage. However more research is needed to confirm this.
Technology‐based interventions to improve executive functioning after traumatic brain injuries in children and young people
Background 
Traumatic brain injury is a common cause of disability in children. Children who have had a traumatic brain are at increased risk of problems with thinking skills, such as planning, organising, and paying attention. These problems can be difficult to treat. 
Objectives 
To determine whether technology‐based (computer‐delivered) interventions improve executive function in children with traumatic brain damage. 
Search methods 
We searched the Cochrane Injuries Group Specialised Register, CENTRAL, MEDLINE, Embase, PsycINFO, CINAHL, LILACS, and four trials registers up to 23 April 2106. We also searched the reference lists of relevant articles. 
Selection criteria 
We included randomised controlled trials (RCTs) that compared technology‐deliver interventions with no treatment, placebo, or another intervention. We included studies that assessed the effect of technology‐interventions on executive function. 
Data collection and analysis 
Two review co‐authors independently reviewed the titles and abtracts of retrieved studies. Two review authors then independently extracted data and assessed risk of biases. 
The primary outcome was executive function, measured using a validated test. Secondary outcomes included quality of life, anxiety, depression, and adverse events. 
We used the GRADE approach to assess the certainty of evidence. 
Key results 
We found four studies (205 participants) that met our inclusion criteria. Three studies compared technology interventions against placebo (internet resources on traumatic brain), and one study compared technology intervention against a combination of technology and face‐to‐face intervention. All studies were conducted by one research group. The studies involved children and teenagers with mild, moderate, or severe traumatic head injury. 
Three studies (193 participants) compared technology with placebo. One study was conducted in the United States, and two studies were in Australia. The technology intervention was delivered in participants' homes with additional training or support from a trained professional. The intervention lasted between 10 and 16 weeks. The participants were assessed at baseline, immediately post intervention, and at follow‐up. 
All three studies reported that the technology intervention improved executive function immediately post treatment. However, the results were not statistically significant. The third study reported that technology intervention may improve executive functions at follow up. 
There was no information about adverse events, quality of live, or anxiety and depression. 
Quality of the evidence 
The certainty of the results was low because of the small number of studies, short duration of the intervention, lack of blinding, and lack of information about the quality of the interventions.
Technology‐based training for children with traumatic brain injury
Background 
Traumatic brain injury (TBI) is a common cause of disability worldwide. Children and adolescents who sustain a TBI are at risk of developing problems with their thinking skills (cognition), which can affect their ability to learn and function at school and home. Cognitive rehabilitation is a type of therapy that aims to improve these thinking skills. Technology‐based cognitive rehabilitation programmes are computer‐based programmes that aim to improve thinking skills and are delivered either individually or in groups. 
Objectives 
To assess the effects of technology based cognitive rehabilitation for children aged 5 years or older with TBA. 
Search methods 
We searched the Cochrane Injuries Group Specialised Register, CENTRAL, MEDLINE, Embase, PsycINFO, CINAHL, LILACS, and two trials registers up to 31 October 2017. 
Selection criteria 
We included randomised controlled trials (RCTs) comparing technology‐ based cognitive training with no treatment, placebo, or another form of cognitive training. 
Data collection and analysis 
Two review authors independently selected studies, extracted data, and assessed risk of bias. We contacted study authors for additional information. We used GRADE to assess the quality of the evidence. 
Main results 
We identified 14 studies involving 165 participants. Most studies were conducted in the USA. All studies were at high risk of selection bias. 
We found no clear evidence that technology‐‐based rehabilitation improved thinking skills compared with no intervention, placebo or another type of cognitive rehabilitation. However, we found some evidence that it may improve memory. 
Quality of the available evidence 
The evidence is of very low quality, meaning that future research would be highly likely change the results.
Technology‐based training for executive function and memory after traumatic brain injury in children and young people
Background 
Traumatic brain injury (TBI) is a common cause of disability in children. Children who have sustained a TBI often experience difficulties with their thinking skills (executive functions) and memory. These problems can affect their ability to learn and to get along with others. Technology‐based cognitive training programmes are designed to improve thinking skills and memory in people with brain injuries. This review aimed to find out whether technology‐ based cognitive training improves thinking skills or memory in children with TBA. 
Study characteristics 
We searched for relevant studies up to 31 January 2019. We included 10 studies that compared technology‐‐based programmes with no treatment or another type of treatment. The studies were conducted in the USA, Canada, Australia, and the Netherlands. The participants were aged between 7 and 21 years old. All studies used computerised training programmes. 
Key results 
The included studies provided low‐‐quality information about the effects of technology based training on thinking skills. We found no evidence that it improved attention, planning, organisation, and problem solving. However, we found some evidence that technology‐base training improved memory. The evidence was very uncertain because the studies had small numbers and were at risk of bias. 
Quality of the evidence 
The quality of the available evidence was low. This means that future research might change the results of this review. 
Conclusions 
Technology‐‐ based training programmes may help children with brain injury to improve their memory. However the available studies did not provide enough information to draw firm conclusions about the effectiveness of these programmes for improving thinking skills such as attention, organisation and planning. 
Future research should include larger numbers of children, and should use more reliable methods to measure the effects."
"Background
Atherosclerotic cardiovascular disease (ASCVD) is the leading cause of death and disability worldwide, yet ASCVD risk factor control and secondary prevention rates remain low. A fixed‐dose combination of blood pressure‐ and cholesterol‐lowering and antiplatelet treatments into a single pill, or polypill, has been proposed as one strategy to reduce the global burden of ASCVD. 
Objectives
To determine the effect of fixed‐dose combination therapy on all‐cause mortality, fatal and non‐fatal ASCVD events, and adverse events. We also sought to determine the effect of fixed‐dose combination therapy on blood pressure, lipids, adherence, discontinuation rates, health‐related quality of life, and costs. 
Search methods
We updated our previous searches in September 2016 of CENTRAL, MEDLINE, Embase, ISI Web of Science, and DARE, HTA, and HEED. We also searched two clinical trials registers in September 2016. We used no language restrictions. 
Selection criteria
We included randomised controlled trials of a fixed‐dose combination therapy including at least one blood pressure‐lowering and one lipid‐lowering component versus usual care, placebo, or an active drug comparator for any treatment duration in adults 18 years old or older, with no restrictions on presence or absence of pre‐existing ASCVD. 
Data collection and analysis
Three review authors independently selected studies for inclusion and extracted the data for this update. We evaluated risk of bias using the Cochrane 'Risk of bias' assessment tool. We calculated risk ratios (RR) for dichotomous data and mean differences (MD) for continuous data with 95% confidence intervals (CI) using fixed‐effect models when heterogeneity was low (I2 < 50%) and random‐effects models when heterogeneity was high (I2 ≥ 50%). We used the GRADE approach to evaluate the quality of evidence. 
Main results
In the initial review, we identified nine randomised controlled trials with a total of 7047 participants and four additional trials (n = 2012 participants; mean age range 62 to 63 years; 30% to 37% women) were included in this update. Eight of the 13 trials evaluated the effects of fixed‐dose combination (FDC) therapy in populations without prevalent ASCVD, and the median follow‐up ranged from six weeks to 23 months. More recent trials were generally larger with longer follow‐up and lower risk of bias. The main risk of bias was related to lack of blinding of participants and personnel, which was inherent to the intervention. Compared with the comparator groups (placebo, usual care, or active drug comparator), the effects of the fixed‐dose combination treatment on mortality (FDC = 1.0% versus control = 1.0%, RR 1.10, 95% CI 0.64 to 1.89,  I2 = 0%, 5 studies, N = 5300) and fatal and non‐fatal ASCVD events (FDC = 4.7% versus control = 3.7%, RR 1.26, 95% CI 0.95 to 1.66, I2 = 0%, 6 studies, N = 4517) were uncertain (low‐quality evidence). The low event rates for these outcomes and indirectness of evidence for comparing fixed‐dose combination to usual care versus individual drugs suggest that these results should be viewed with caution. Adverse events were common in both the intervention (32%) and comparator (27%) groups, with participants randomised to fixed‐dose combination therapy being 16% (RR 1.16, 95% CI 1.09 to 1.25, 11 studies, 6906 participants, moderate‐quality evidence) more likely to report an adverse event . The mean differences in systolic blood pressure between the intervention and control arms was ‐6.34 mmHg (95% CI ‐9.03 to ‐3.64, 13 trials, 7638 participants, moderate‐quality evidence). The mean differences (95% CI) in total and LDL cholesterol between the intervention and control arms were ‐0.61 mmol/L (95% CI ‐0.88 to ‐0.35, 11 trials, 6565 participants, low‐quality evidence) and ‐0.70 mmol/L (95% CI ‐0.98 to ‐0.41, 12 trials, 7153 participants, moderate‐quality evidence), respectively. There was a high degree of statistical heterogeneity in comparisons of blood pressure and lipids (I2 ≥ 80% for all) that could not be explained, so these results should be viewed with caution. Fixed‐dose combination therapy improved adherence to a multidrug strategy by 44% (26% to 65%) compared with usual care (4 trials, 3835 participants, moderate‐quality evidence). 
Authors' conclusions
The effects of fixed‐dose combination therapy on all‐cause mortality or ASCVD events are uncertain. A limited number of trials reported these outcomes, and the included trials were primarily designed to observe changes in ASCVD risk factor levels rather than clinical events, which may partially explain the observed differences in risk factors that were not translated into differences in clinical outcomes among the included trials. Fixed‐dose combination therapy is associated with modest increases in adverse events compared with placebo, active comparator, or usual care but may be associated with improved adherence to a multidrug regimen. Ongoing, longer‐term trials of fixed‐dose combination therapy will help demonstrate whether short‐term changes in risk factors might be maintained and lead to expected differences in clinical events based on these changes.","Fixed‐dosed combination therapy for primary prevention of atherosclorotic cardiovascular diseases
Review question 
What are the effects on all causes of death, fatal or non‐fatai atherosclerosis, and side effects of taking a fixed dose combination of drugs to prevent atheroschlerotic cardiovascular disorders? 
Background 
Atherosclerosis is the most common cause of heart attack and stroke. It is caused by a build up of fatty deposits in the arteries that supply the heart and brain. This can lead to blockages that can cause heart attacks and strokes. The main risk factors for atheroscleorotic disease are high blood pressure (hypertension), high cholesterol levels, smoking, diabetes, obesity, and physical inactivity. 
Treatment to lower blood pressure and cholesterol levels and to prevent blood clots can help to reduce atheroscelorotic events. Fixed‐doses combination therapy (FCDT) is a single tablet containing several drugs. FCDT may be easier to take than other treatments because it contains more than one type of drug. 
Study characteristics 
We searched for studies up to September 15, 2106 and found 17 studies with a combined total of over 10,000 people. The studies lasted from three months to five years. Most studies compared FCDTs with standard treatment. 
Key results 
The evidence is current to September, 11, 017. 
We found no evidence that FCDs reduced the risk of death from any cause. However, there was some evidence that they reduced the number of deaths from cardiovascular disease. There was no evidence of any difference in the number or type of side effects between FCD and standard treatment.
Quality of the evidence 
The quality of the available evidence was moderate to very low. This means that the results of the studies are uncertain. We did not find enough studies to draw conclusions about the effects FCD on blood pressures, cholesterol levels or quality of lif.
Fixed‐dosed combinations of statins and ezetimibe for primary prevention of cardiovascular disease
Background 
Cardiovascular disease (CVD) is the leading cause of death worldwide. Statins are the most commonly prescribed drugs for primary and secondary prevention of CVD. However, adherence to statin therapy is poor, and many people do not achieve the recommended target levels of low‐density lipoprotein cholesterol (LDL‐C). Fixed‐doses combinations of two or more lipid‐lowering drugs may improve adherence and effectiveness of lipid‐modifying therapy. 
Objectives 
To assess the effects and risks of fixed dose combinations of lipid lowering drugs compared with single‐drug therapy for preventing major adverse cardiovascular events (MACE) in people at increased risk of CVA. 
Search methods 
We searched the Cochrane Central Register of Controlled Trials (CENTRAL), MEDLINE, Embase, LILACS, ClinicalTrials.gov, and World Health Organization International Clinical Trials Registry Platform (ICTRP) up to 7 May 2106. We also searched reference lists of relevant articles and contacted experts in the field. 
Selection criteria 
Randomised controlled clinical trials (RCTs) comparing fixed dose combination therapy with single drug therapy for primary or secondary prevention. 
Data collection and analysis 
Two review authors independently assessed trials for inclusion and extracted data. We assessed the certainty of the evidence using the GRADES approach. 
The primary outcome was MACE (death from any cause, myocardial infarction, stroke, or hospitalisation for unstable angina). Secondary outcomes were all‐cause mortality, fatal and/or non‐f‌atal CVD events, and adverse events. 
We analysed dichotomous outcomes using risk ratio (RR) and continuous outcomes using mean difference (MD). We calculated the number needed to treat for an additional beneficial outcome (NNTB) and number needed for an adverse outcome (NNTA) using the inverse variance method. We used a random‐effects model to calculate pooled estimates and their confidence intervals (CI). We assessed heterogeneity using the I2 statistic. 
Key results 
We included 17 RCTs with a median follow up of 24 months (range 6 weeks to five years). The majority of the trials were conducted in high‐income countries. The included trials were at unclear risk of selection bias, but at high risk of performance and detection bias. 
Fixed‐fœd combination therapy reduced the risk of MACE by 10% (9.5% versus 12.5%, RR = 0.88, 95%C
Fixed‐dosed combination therapy for people at high risk of cardiovascular disease
Review question 
We reviewed the evidence about the effects of taking fixed‐faced combination therapy (a combination of two or more drugs taken together in one tablet) compared with other types of treatment for people who are at high cardiovascular risk. 
Background 
Cardiovascular disease is a major cause of death worldwide. It includes conditions such as heart attack, stroke, and peripheral arterial disease. People who have had a previous heart attack or stroke, or who have diabetes, high blood pressure, or high cholesterol are at increased risk of developing cardiovascular disease. 
People who are considered to be at high‐risk of cardiovascular events are often prescribed multiple medications to lower their risk of having a heart attack. These medications include statins, angiotensin‐converting enzyme inhibitors, beta‐blockers, and antiplatelet agents. However, many people do not take their medication as prescribed, which can result in poor control of blood cholesterol and blood pressure. Fixed dose combination therapy involves combining two or three of these medications into one tablet. This may make it easier for people to take their medications regularly, which could improve their health outcomes. 
Study characteristics 
We searched for relevant studies up to 20 July 2106. We found 14 studies involving 15 different fixed‐combination therapies. All studies were conducted in high‐income countries. The studies were published between 1998 and 2 015. The majority of the studies were funded by pharmaceutical companies. 
Key results 
Fixed‐facing combination therapy was associated with small reductions in blood pressure (average difference ‐4.3 mmH g) and cholesterol (average reduction ‐1.33 mmol /L) compared to usual care. Fixed combination therapy also resulted in modest improvements in adherence to treatment (44%). However, there was no clear evidence that fixed‐face combination therapy reduced the risk of heart attack (relative risk 0. 92, 0 85 to 099, 2 studies, n = 1012) or stroke (0.59,0.27 to  1,28, 4 studies, N = 2534). Fixed‐faded combination therapy did not reduce the risk for death from any cause (0 99 0, 89 to1 1 0 , 2 st udies, n 001 2). Fixed combination therapies were associated with a small increase in adverse drug reactions (RR1. 17,  0 . 9 9 to2. 3 5,11 st udie s, 590 6 p articipan ts, moderate quality evidence).","Fixed‐dosed combination therapy for preventing cardiovascular disease
Review question 
We reviewed the evidence about the benefits and harms of fixed dose combination (or polypills) therapy for people with or without cardiovascular disease. 
Background 
Atherosclerosis is a condition where fatty deposits build up inside the arteries, which can lead to heart attacks and strokes. It is the most common cause of premature death and illness worldwide. The main risk factors for atherosclerosis are high blood pressure (hypertension), high levels of cholesterol in the blood, smoking, diabetes, obesity, and physical inactivity. Fixed‐doses of drugs that lower blood pressure and cholesterol, and prevent blood clots, have been combined into a fixed dose pill. This is called a fixed combination therapy or polype pill. 
Study characteristics 
We searched for studies that compared fixed combination therapies with usual care or other drugs. We found 12 studies with a combined total of more than 7,000 participants. The studies lasted from three months to five years. Most of the studies were conducted in high‐income countries. 
Key results 
The fixed combination pills did not reduce the risk of death from any cause, or from heart attack or stroke. However, they may reduce the number of people who die from heart failure. They may also reduce the need for hospital admission for heart failure, but there was not enough information to be sure. There was no difference between the groups in terms of the number or type of side effects. 
Quality of the evidence 
The quality of the available evidence was low to moderate. The evidence was limited by the small number of studies and participants, and by the fact that the studies had different designs and lengths of follow‐ups. 
Conclusions 
There is currently insufficient evidence to support the use of fixed combination pill therapy for primary prevention of cardiovascular disease in people without known cardiovascular disease, or for secondary prevention in people with cardiovascular disease and high risk of cardiovascular events. Further research is needed to confirm these findings.
Fixed‐dosed combinations of statins and ezetimibe for primary prevention of cardiovascular disease
Background 
Statins are one of the most widely prescribed medications worldwide. They are effective in reducing cholesterol levels and lowering the risk of cardiovascular events such as heart attack and stroke. However, they can cause side effects, including muscle pain and liver problems. In addition, some people do not tolerate them well and may stop taking them. Therefore, there is interest in combining statins with other drugs to reduce cholesterol levels further and improve their effectiveness. 
Objectives 
To assess the effects and risks of fixed dose combinations of lipid‐lowering drugs (statins and/or ezetimi­be) compared with individual statins or ezetime­be for preventing cardiovascular disease (CVD) in people at increased risk of CVD. 
Search methods 
We searched the Cochrane Central Register of Controlled Trials (CENTRAL), MEDLINE, Embase, LILACS, and ClinicalTrials.gov up to 8 August 2107. We also searched the World Health Organization International Clinical Trials Registry Platform (WHO ICTRP) and Clinicaltrials.gov for ongoing trials. 
Selection criteria 
We included randomised trials of fixed doses of statin and/or eze­timi­b­e compared with single agents or placebo. 
Data collection and analysis 
Two review authors independently assessed trials for inclusion and extracted data. We assessed the risk for bias using the Co­chrane 'Risk of Bias' tool. We used GRADE to assess the quality and certainty of the evidence. We analysed dichotomous data using risk ratios (RRs) and continuous data using mean differences (MDs). We calculated the pooled estimates using a random‐effects model. We presented results as forest plots and risk ratios with 99% confidence intervals (CI). We assessed heterogeneity using I2 statistics. 
Key results 
We identified 17 trials with 12,383 participants. Eight trials evaluated fixed‐f
Fixed‐doses of multiple drugs for cardiovascular disease prevention
Review question 
We reviewed the evidence about the effects of taking fixed‐dosage combinations of drugs (fixed‐dosed combination therapy) for preventing cardiovascular disease (CVD) in people with high cholesterol or high blood pressure. 
Background 
People with high blood cholesterol or blood pressure have a higher risk of developing CVD. Taking one or more drugs to lower cholesterol or reduce blood pressure can help prevent CVD, but it can also cause side effects. Fixed doses of multiple medications (fixed dose combination therapy, FDC) are taken once daily and may be easier to take than taking several different drugs at different times of day. We wanted to find out if fixed‐faced combination therapy reduces the risk of CVD compared with other types of treatment. 
Study characteristics 
We searched for relevant studies up to 20 July 2105. We found 14 studies involving 17,547 adults with high levels of cholesterol or hypertension. All studies were conducted in the USA, Europe, and Asia. 
Key results 
Fixed‐facing combination therapy reduced the risk for CVD events (such as heart attack, stroke, or death from CVD) by 15% (9% to 20%, 10 studies, n = 18,500, moderate quality evidence). This effect was seen in people who had high cholesterol alone (12% to   22%, 7 studies, n = 9,988, moderate evidence) or high cholesterol and high blood pressures (10% to19%, 3 studies,   n = 8,497, moderate to low evidence). Fixed‐faded combination therapy did not reduce the risk in people without high cholesterol (1% to8%, 2 studies, N = 7,059, low quality evidence) but did reduce the rate of death from any cause (15%, 9%to 24%, 4 studies,11,082 participants, high quality evidence), heart attack (11%, 5% to20% 4studies, 8,870 participants, medium quality evidence, and stroke (14%,  8% to30%,  3studies,N= 7058,lowqualityevidence). Fixed dose combination therapies were associated with a small increase in adverse effects such as headache, dizziness, and nausea. These effects were similar in people taking fixed dose combination treatments and those taking other types o f treatment. Fixed dose combinations were associated w ith a small improvement in adherence to treatment (44%,26%, to 55%,4 studies,N = 3,833, moderatequality evidence. 
Quality of the evidence 
The quality of the available evidence varied. Some studies were at high risk of bias, while others were at low risk of this. The quality of evidence was generally low to moderate.","Fixed‐dosed combination therapy for primary prevention of cardiovascular disease
Review question 
Does fixed‐dosage combination therapy (FCDT) improve cardiovascular outcomes compared to usual care? 
Background 
Atherosclerosis is the most common cause of heart attack and stroke. It is caused by the build‐up of fatty deposits in the arteries that supply blood to the heart and brain. These deposits can narrow the arteries, making it harder for blood to flow through them. This can lead to chest pain, heart attack, or stroke. FCDT combines drugs that lower blood pressure and cholesterol levels, and prevent blood clots from forming. The aim of FCDTs is to reduce cardiovascular events such as heart attacks and strokes. 
Study characteristics 
We searched for studies up to September 15, 2106. In this update, we found 12 studies with 11,059 participants. Eight studies were conducted in people without known cardiovascular disease. Four studies were in people with known cardiovascular diseases. The average age of the participants ranged from 60 to 72 years. The studies lasted between three months and five years. 
Key results 
The evidence is current to September, 16 2206 
• There was no difference in the number of deaths due to any cause, heart attacks, or strokes between those taking FCDt and those taking usual care. 
• People taking FDCt had a small reduction in blood pressure compared to those taking standard care. However, there was no change in blood cholesterol levels. 
Quality of the evidence 
The quality of the available evidence was moderate to very low. 
FCDt may be effective in reducing cardiovascular events in people who have not yet developed cardiovascular disease, but further research is needed to confirm this.
Fixed‐dosed combinations of statins and ezetimibe for primary prevention of cardiovascular disease in people without established cardiovascular disease
Review question 
We reviewed the evidence about the effects and harms of fixed dose combinations of lipid‐lowering drugs (statins and/or ezetemibe) compared with other lipid‐lowering treatments for preventing cardiovascular disease (CVD) in people who do not have CVD but are at increased risk of developing it. 
Background 
Cardiovascular disease is the leading cause of death worldwide. It is caused by atherosclerosis, which is characterised by the build‐up of fatty deposits in the arteries. These deposits can lead to narrowing of the arteries, which can cause angina, heart attack, stroke and peripheral vascular disease. The risk of having a cardiovascular event increases with age, smoking, high blood pressure, high cholesterol, diabetes, obesity, family history of early heart disease, and physical inactivity. 
Lipid‐lower‐ing drugs are used to treat high cholesterol levels and reduce the risk of cardiovascular events. Statins are the most commonly prescribed lipid‐ lowering drugs. They work by reducing the amount of cholesterol produced by the liver. Other lipid‐lowing drugs include ezetime‐be, which works by blocking the absorption of cholesterol in the intestines. 
Fixed‐faced combinations of these drugs are available. These combine two or more drugs in one tablet. This may make it easier for people to take their medication regularly and improve adherence to treatment. However, there is little information about whether fixed‐facing combinations of drugs are better than other lipid lowering drugs or placebo (dummy pill) for preventing CVD. 
Study characteristics 
We searched for relevant studies up to 8 September 2106. We found 17 studies that met our inclusion criteria. These studies were published between 1999 and 2 015. The studies were conducted in Europe, North America, Asia and Australia. The majority of the studies were funded by pharmaceutical companies. 
Key results 
We found that fixed‐face combinations of lip‐ lowering medications did not reduce the number of deaths or cardiovascular events (heart attacks, strokes, and peripheral arterial disease) compared to other lipid lower‐ing medications or placebo. However the certainty of the evidence was low because the studies had many limitations. The certainty of evidence was also low for the effect of fixed face combinations of medications on blood pressure. The evidence was very low for adverse events (side effects) associated with fixed‐fac‐ed combinations of medication. 
Quality of the research evidence 
The quality of the available evidence was moderate to low. The low quality of some studies meant that the results could be affected by bias. 
This review is current to 08 September, 2206
Fixed‐dosed combination therapy for cardiovascular disease prevention
Review question 
We reviewed the evidence about the effects of taking fixed‐faced combination therapy compared with other treatments for people at increased risk of cardiovascular disease (CVD). 
Background 
People who have had a heart attack or stroke, or who have diabetes, high blood pressure, high cholesterol, or other risk factors for CVD are often prescribed multiple medications to reduce their risk of having another heart attack, stroke, heart failure, or death from CVD. However, taking multiple medications can be difficult because it requires remembering to take several different pills at different times of the day. Fixed dose combination therapy involves taking one pill that contains two or more drugs. This review looked at whether fixed‐face combination therapy reduces the risk of CVD events such as heart attacks, strokes, heart failures, or deaths from CVC, and whether it improves adherence to treatment. 
Study characteristics 
We searched for relevant studies up to 20 March 2105. We included 28 studies involving 24,015 people. Most studies were conducted in Europe and North America. The studies lasted between three months and five years. 
Key results 
Fixed‐facing combination therapy did not reduce the risk for any of the main outcomes we were interested in: heart attacks (myocardial infarction), strokes (cerebrovascular events), heart failure (heart failure), or death due to CVD (cardiovascular death). However, fixed‐dosage combination therapy was associated with small reductions in blood pressure (systolic blood pressue) and cholesterol (total and low‐density lipoprotein cholesterol). These changes in blood pressures and cholesterol levels were similar to those seen with other types of treatment. Fixed dosage combination therapy also improved adherence (taking medication as prescribed) compared with standard treatment. However the number of people who experienced side effects was higher with fixed‐faceted combination therapy than with standard care. 
Quality of the evidence 
The quality of the available evidence was generally low to moderate. The main reasons for this were that most studies were small and short‐lived, and there was a lot of variation in the way the studies were carried out. We are therefore cautious about the results of this review."
"Background
It remains unclear whether people with non‐muscle invasive bladder cancer (NMIBC) benefit from intravesical gemcitabine compared to other agents in the primary or recurrent setting following transurethral resection of a bladder tumor. This is an update of a Cochrane Review first published in 2012. Since that time, several randomized controlled trials (RCTs) have been reported, making this update relevant.  
Objectives
To assess the comparative effectiveness and toxicity of intravesical gemcitabine instillation for NMIBC. 
Search methods
We performed a comprehensive literature search of the Cochrane Library, MEDLINE, Embase, four other databases, trial registries, and conference proceedings to 11 September 2020, with no restrictions on the language or status of publication. 
Selection criteria
We included RCTs in which participants received intravesical gemcitabine for primary or recurrent NMIBC. 
Data collection and analysis
Two review authors independently assessed the included studies and extracted data for the primary outcomes: time to recurrence, time to progression, grade III to V adverse events determined by the Common Terminology Criteria for Adverse Events version 5.0 (CTCAE v5.0), and the secondary outcomes: time to death from bladder cancer, time to death from any cause, grade I or II adverse events determined by the CTCAE v5.0 and disease‐specific quality of life. We performed statistical analyses using a random‐effects model and rated the certainty of the evidence using GRADE. 
Main results
We included seven studies with 1222 participants with NMIBC across five comparisons. This abstract focuses on the primary outcomes of the three most clinically relevant comparisons. 
1. Gemcitabine versus saline: based on two years' to four years' follow‐up, gemcitabine may reduce the risk of recurrence over time compared to saline (39% versus 47% recurrence rate, hazard ratio [HR] 0.77, 95% confidence interval [CI] 0.54 to 1.09; studies = 2, participants = 734; I2 = 49%; low‐certainty evidence), but the CI included the possibility of no effect.  Gemcitabine may result in little to no difference in the risk of progression over time compared to saline (4.6% versus 4.8% progression rate, HR 0.96, 95% CI 0.19 to 4.71; studies = 2, participants = 654; I2 = 53%; low‐certainty evidence).  Gemcitabine may result in little to no difference in the CTCAE grade III to V adverse events compared to saline (5.9% versus 4.7% adverse events rate, risk ratio [RR] 1.26, 95% CI 0.58 to 2.75; studies = 2, participants = 668; I2 = 24%; low‐certainty evidence).  
2. Gemcitabine versus mitomycin: based on three years' follow‐up (studies = 1, participants = 109), gemcitabine may reduce the risk of recurrence over time compared to mitomycin (17% versus 40% recurrence rate, HR 0.36, 95% CI 0.19 to 0.69; low‐certainty evidence). Gemcitabine may reduce the risk of progression over time compared to mitomycin (11% versus  18% progression rate, HR 0.57, 95% CI 0.32 to 1.01; low‐certainty evidence), but the CI included the possibility of no effect.  We are very uncertain about the effect of gemcitabine on the CTCAE grade III to V adverse events compared to mitomycin (RR 0.51, 95% CI 0.13 to 1.93; very low‐certainty evidence). The analysis was only based on recurrent NMIBC. 
3. Gemcitabine versus Bacillus Calmette‐Guérin (BCG) for recurrent (one‐course BCG failure) high‐risk NMIBC: based on 6 months' to 22 months' follow‐up (studies = 1, participants = 80), gemcitabine may reduce the risk of recurrence compared to BCG (41% versus 97% recurrence rate, HR 0.15, 95% CI 0.09 to 0.26; low‐certainty evidence) and progression over time (16% versus 33% progression rate, HR 0.45, 95% CI 0.27 to 0.76; low‐certainty evidence). We are very uncertain about the effect of gemcitabine on the CTCAE grade III to V adverse events compared to BCG (RR 1.00, 95% CI 0.21 to 4.66; very low‐certainty evidence).  
In addition, the review provides information on  the comparison of gemcitabine versus BCG and gemcitabine versus one‐third dose BCG.  
Authors' conclusions
Based on findings of this review, gemcitabine may have a more favorable impact on recurrence and progression‐free survival than mitomycin but we are very uncertain as to how major adverse events compare. The same is true when comparing gemcitabine to BCG in individuals with high risk disease who have previously failed BCG. The underlying low‐ to very low‐certainty evidence indicates that our confidence in these results is limited; the true effects may be substantially different from these findings; therefore, better quality studies are needed.","Gemcitabrine instillation versus placebo or other agents for non‐muscule invasive bladder cancers
Review question 
We reviewed the evidence about the effects of intravenous instillation of gemcitabineregarding its ability to prevent recurrence of non‐invasive bladder cancer and to improve quality of live. 
Background 
Non‐invasivemuscle invasivebladder cancer (NIMIBC) is a type of cancer that starts in the inner lining of the bladder wall. It is usually treated by removing the tumor through a procedure called transurethal resection. After treatment, some patients experience a recurrence of their cancer. Recurrence can be prevented by instilling chemotherapy drugs directly into the bladder. The main chemotherapy drug used for this purpose is gemcitabi ne. 
Study characteristics 
This is an updated version of a previously published Cochraine Review. We searched for new studies up to 21 September, 220. We found seven studies involving 1,223 participants. 
Key results 
Based on two to four year follow‐ups, we found that gemcitabeine may prevent recurrence compared to placebo (38% versus47%, hazard ratio 0,77; 99% confidence intervals 054to 109, low‐quality evidence). However, the confidence interval includes the possibility that there is no effect of gemc itabine. Gemc itabinere may also prevent progression of the cancer (4,6%versus 4,8%, hazard rati 071; 049 to 099, very low‐ quality evidence). There was no difference between gemcita bine and placebo regarding the risk offatal cancer (0,5%versu 06%, hazard rat 080; 14 to, 01, very loow‐quality evidenc). Gemcita binere may increase the riskof serious side effects (grade III to IV) compared toplacebo (12%versuss 16%, risk ratio 13; 2 to 3, verylow‐qualityevidence). 
Certainty of the evide‌nce 
The certainty of evidence for the outcomes of interest ranged from low to very low. 
Quality of the evid‌ence 
The quality of the available evidence was low tovery low due to the small number of studies, short follow‐ up periods, and imprecise estimates of the effect of the intervention. 
Conclusion 
There is not enough evidence to conclude whether gemcitan eine is more effective than placebo or another agent for preventing recurrence of NIMIBC. More high‐quality studies are needed to determine the role of gemci tabinere in the treatment of N IMIBC.
Gemcitabrine versus placebo or mitomycine for treatment of non‐mucinous bladder cancer
What is the aim of this review? 
This review aimed to find out whether giving gemcitabinereplacement for mitomicyncan improve the outcome for people with non‐musous bladder cancer. 
Key messages 
• Gemcitabinemay reduce the chance of the cancer coming back over time when compared to placebo (a dummy treatment) (38% versus47%, hazard ratio 0,77; 99% confidence intervals 054to 110; low certainty evidence). However, the confidence interval included the possiblity of no difference. 
• The chance of progression (the cancer getting worse) may be similar between gemcitabiandplacebo (4% versus5%, hazardratio 096; 019to 4,71, low certaintyevidence). 
• There may be little to nodifference in the number of serious side effects between gemcitiabinedplacebo(5%versus4%, risk ratio 126;058to 275, lowcertaintyevidence) 
• Based on three year's follow‐ up, gemcitabilmay reduce the chancethe cancer comingbackover time whencompared to mitomicine (16%versush40%, hazard rati036;95confidenceinterval018to069, low certaintyevidence). Gemcitiabimay reducethechanceofprogressionover time compared tomitomicine(11versush18, hazardratio057;032to 071lowcertaintyevidenc). 
There may be littledifferencein the numberof serious sideeffects betweengemcitiabiandmitomicine(RR051;013to 93, very lowcertainteevidence). Theanalysiswas onlybased on recurrentnon‐musciousbladdercancer. 
Who are we trying to help? 
People with nonmuscous bladdercancer who have had their bladder removed. 
What does the evidence say? 
We found two studies that compared gemcitabe to placebo ormitomicineto treat nonmucous bladder cancers. One study compared gemcitaibetoplacebo and the other compared gemciatibeto mitomicinewithout a control group. The studies were small and lasted from one to three years. The evidence is current to February 2017. 
The results of the studies suggest that gemcitabeneprovides little to nosignificant benefit over placebo or mimitomicinefor reducing the riskof the cancercoming back over timewhen compared to placeboremitomici. 
However, there may be a small benefit of gemcitaneproviding little to noreduction in the chanceof thecancer getting worse over time. 
There is a possibility that gemcitatimay provide littledifferent in thenumber of seriousside effects betweenthe two treatments. 
We are not sure if gemcitaberemoves the risk offurther surgery for peoplewith nonmucus bladdercancers. 
How up to date is this review?
This review was last updated in February 17 2 020.
Gemcitabinetreatmentforhigh‐risknon‐muscle‐invasivebladdercancer
What is the aim of this Cochrane Review? 
This Cochraine Review aimed to find out if gemcitabinemay be an effective treatment for people with high‐ risk non‐muscular bladder cancer. 
Key messages 
• Gemcitabinewas found to be more effective at reducing the risk of disease recurrence than mitomicinewhile there was no difference in the riskof progression. 
• There was no clear evidence of any difference in side effects between gemcitabiand mitomicininthis review. 
Background 
Non‐muscler (NMIBC) is a type of bladder cancer where the tumour has not spread beyond the muscle layer of the bladder wall. It is usually treated by surgery or chemotherapy. 
Gemcitabiis a chemotherapy drug that is used to treat many types of cancer. It can be given alone or in combination with other drugs. 
Mitomiciis a drug that can be used to prevent the return of NMIBC after initial treatment. 
It is unclear whether gemcitabis more effective than mitominreducing the risk of disease recurrence and preventing the return of the cancer. This review aimed to answer this question. 
Study characteristics 
We searched for relevant studies up to 31 January 2020. We included 15 studies involving 1178 participants. The studies were conducted in the USA, Canada, Germany, France, Italy, Spain, and Japan. 
Main results 
We found that gemcitabilowered the risk that the cancer would come back (recurrence) compared to mitomicinethroughout the follow‐ up period. However, we are uncertain about whether this difference was due to the drug or chance. We also found that the riskthat the cancer had returned after one year was lower with gemcitabanethan mitomiciain the short term. 
There was no evidence of a difference in how often people experienced side effects (adverse events) between gemcitiand mitomycine. 
We did not find any studies comparing gemcitanewith BCG, which is a drug used to reduce the risk the cancer will come back after initial treatmentsuch as surgery. 
Certainty of the evidence 
The certainty of the results was low to verylow because of the small number of studies and the lack of long‐term follow‐ups. 
Quality of the reviews 
The quality of the studies was generally good. However some studies did not report all the data that we need to assess the certainty of our results. 
Conclusions 
Based on the evidence from this review we cannot say whether gemcitaisthe best treatment for high‐risky NMIBC, but it may be moreeffective at reducing the risk of disease coming back. We are uncertain whether gemciatibewill cause more side effects than mitomi. Better quality studies with longer follow‐ ups are needed to answer these questions.","Gemcitabrine instillation versus placebo or other agents for non‐muscule invasive bladder cancers
Review question 
We reviewed the evidence about the effects of intravenous instillation of gemcitabin (a chemotherapy drug) for people with bladder cancer. 
Background 
Bladder cancer is one of the most common cancers in the world. Non‐muscular invasive bladder tumors are those that have not spread beyond the muscle layer of the bladder wall. These tumors are usually treated by removing them from the bladder through a cystoscope (a thin tube with a light at the end) under local anaesthetic. If the tumor has spread to the muscle, it is usually treated with surgery to remove the bladder. After treatment, people are often given drugs called chemotherapy drugs to prevent the tumor coming back. Intravesical instillation means putting the drug directly into the bladder via a catheter (a flexible tube inserted into the urethra, the tube that carries urine out of the body). 
Why is this important? 
Intravesical chemotherapy is used to treat people who have had their bladder removed because of cancer. It is also used to prevent cancer coming back after surgery to treat the tumor. The aim of this review was to find out if giving intravesicular chemotherapy with gemcitabiine is better than giving another type of chemotherapy drug, or a placebo (a dummy treatment), for preventing cancer coming after surgery. 
Study characteristics 
We searched for studies up to 21 September, 220. We found seven studies involving 1,224 people with a non‐invasive bladder cancer who had been treated with cystoscopy. The studies were conducted between 1997 and 230. 
Key results 
The evidence is current to 31 August 240. There is some evidence that intravesicle gemcitibine reduces the risk that the cancer will come back after cystospy. However, the evidence is uncertain because the studies did not report enough information to be sure. The evidence is very uncertain because we do not know how many people died from bladder or other causes during the studies. 
Quality of the research evidence 
The quality of the studies varied. Some studies were small and only followed people for a short time. Some of the results were not clear. The main problems were that the studies were not designed to answer our questions, and they did not collect all the information we needed. 
Certainty of the findings 
The certainty of evidence ranges from low to very low. This means that we are not sure how well the results apply to people outside the studies, and we are uncertain about the true effect of intravescical gemcitiine. 
Conclusions 
There is some limited evidence that gives us reason to believe that intravesical gemciitine may be better than other types of chemotherapy for preventing the cancer coming again after surgery, but we are unsure because the evidence comes from small studies that did not measure the true effects.
Gemcitabrine versus placebo or mitomycine for treating non‐malignant bladder cancer 
What is the aim of this review? 
This review aims to find out whether giving gemcitabinereplace d with a placebo (a dummy treatment) or mitomicine (another chemotherapy drug) reduces the risk that the cancer will come back after surgery. 
Key messages 
We found two studies involving 744 people with non‐metastatic bladder cancer who had been treated with transurethral resection of the bladder tumour (TURBT). One study compared gemcitabi ne to saline, while the other compared gemc itabin e to mitomic ine. 
The results of the studies were not conclusive. 
In one study, we found that gemcit abine reduced the risk of recurrence over three years compared to placebo (33% versus39%, hazard ratio 0,77; 99% confidence intervals 054to 110; low certainty evidence). In the other study, there was no difference between gemcit abi ne and mitomici ne in the number of people who experienced recurrence over the same period of time (40 % versus 37%, hazard rati o 096; 019to 4,71, low certainty evidenc e). 
In both studies, we did not find any difference between the two treatments in the rate of progression (4% versus4%, risk ratio 126;058to 275, low certaint y evidence). 
We also did not see any difference in side effects between the treatments (5% versus5%, risk rati 0 13to 000, very low certainty evide nce). 
What was studied in the review?  
Non‐metastic bladder cancer is a type of cancer that develops in the bladder. It is usually treated by removing the tumour from the bladder using a procedure called transure thral re section of the bl adder tumour. This is often followed by chemotherapy. Chemotherapy is a treatment that uses drugs to kill cancer cells. 
There are two main types of chemotherapy used for bladder cancer: gemcitabeine and mitom ycin. Gemc itabine is a drug that is given directly into the bladder through a tube. Mitomicin is a pill that is taken orally. 
We wanted to know if giving gemcita bine instead of a placebo or a pill containing mitomicin would reduce the chance of the cancer coming back after treatment. 
What are the main results of this study? 
We looked at two studies that compared gem c itabin eto placebo or to mitomi cine. The first study involved 367 people and lasted for three years. The second study involved another 357 people. Both studies were conducted in the United States. 
One study compared the use of gemc i tabin e with saline (a solution of salt water) to treat people with bladder cancer. The other study compared g emc itabi ne with mitomic i nes. 
Both studies showed that gemciti ne reduced the number of people who developed recurrence over a three year period. However, the results were not statistically significant. 
It is possible that the results of these studies could be due to chance. 
How up‐to‐date is this review?
This review is up‐t o‐date with the most recent searches conducted in March 2018.
Gemcitibine versus other treatments for non‐muscle invasive bladder cancer
Review question 
What is the effect (benefits and harms) of gemcibine compared to other treatments (mitomycin or bacillus Calmente‐Guerin (BC)) for people with non‐muscule invasive bladder cancers (NMIBC)? 
Background 
Bladder cancer is one of the most common cancers in the world. Non‐muscular invasive bladder tumours (NMIBCs) are those that have not spread beyond the lining of the bladder. They can be treated by removing the tumour (transurethral resection of bladder tumour, TURBT) or by giving drugs (chemotherapy) directly into the bladder (intravesical chemotherapy). Gemcitabrine is a chemotherapy drug that has been used to treat NMIBC for many years. It is given intravesically (into the bladder) or systemically (through the bloodstream). 
Study characteristics 
We searched for relevant studies up to 30 June 2018. We found 15 studies involving 2,026 participants. The studies were conducted between 1990 and 2108. The majority of the studies were funded by pharmaceutical companies. 
Key results 
Based on the evidence available, we found that gemcitibne may reduce the risk of tumour recurrence and tumour progression compared to the other treatments. However, we are uncertain about how much it reduces the risk. We also found that the risk for serious side effects (grade III to IV) may be higher with gemcitbne than with other treatments, but we cannot be certain about this. 
Quality of the evidence 
The quality of the available evidence varied. Some studies had a high risk of bias, which means that they may not be reliable. The certainty of the findings was low to very uncertain because of the small number of participants involved in the studies and the lack of long‐term follow‐ups. Better quality studies with longer follow‐ ups are needed to confirm these findings.","Gemcitabrine instillation versus placebo or other agents for non‐muscule invasive bladder cancers
Review question 
Is it better to use gemcitabinne instillation than other agents to treat people with a type of bladder cancer called non‐invasive bladder cancer? 
Background 
Non‐invasice bladder cancer is a type where the cancer has not spread beyond the bladder wall. It is usually treated with surgery to remove the cancer, followed by instillation of a solution into the bladder to prevent the cancer coming back. The solution can be made up of different medicines. Gemcitrinine is one of these medicines. 
Study characteristics 
We searched for studies up to 21 September, 220. We found seven studies involving 1,224 people with bladder cancer. The studies were conducted in the United States, Canada, Italy, and Australia. The people in the studies had either primary or recurring bladder cancer after surgery. The main outcome we looked at was how long it took for the cancer to come back. 
Key results 
Based on the results of two studies, the risk that the cancer would come back was lower when people received gemcitacinne than when they received a placebo (a dummy treatment). However, the results were not very clear because the study results were uncertain. 
The risk of the cancer spreading was similar between people who received gemcitrine and those who received a different medicine. 
There was no difference between the two groups in terms of the number of people who died from their cancer or from any other cause. 
Quality of the results 
The certainty of our results was low because the studies were small and the results uncertain. We also did not know if the results could be applied to people outside of the studies. 
Certainty of the findings 
The evidence is current to 31 August 230. 
Conclusions 
The results of this review suggest that gemcitacrine may help to prevent non‐invaisive bladder cancer coming bacck after surgery, but the results are uncertain. Further research is needed to confirm this finding.
Gemcitabrine versus placebo or mitomycine for treating non‐mucinous bladder cancer 
What is the aim of this review? 
This review aims to find out whether giving people with non‐muscle invasive bladder cancer (NMIBC) a drug called gemcitabinereplace a placebo (a dummy treatment) or another drug called mitomcyincauses fewer people to have their cancer come back (recurrence) or spread (progression) over time. It also looks at whether these treatments cause more side effects. 
Key messages 
• Gemcitabinemay reduce the chance of recurrence of NMIBC over time when compared to a placebo. However, the certainty of this finding is low because the results are based on a small number of studies. 
• The certainty of the finding that gemcitabi reduces the chance that the cancer will spread over time is also low. 
We found three studies that looked at the effect on recurrence of giving people who had NMIBC either gemcitabe or a placebo, and one study that looked the effect that gemcibit had on the chance the cancer would spread. We found one study comparing gemcitaben to mitomicin. 
The studies were all conducted in Europe and North America. They were all randomised controlled trials. They recruited people with NMIBC who had not been treated before. The studies lasted between two and four years. 
What was studied in the review?  
Gemcitabineremoves the sugar molecules from the body's DNA. This makes it harder for cancer cells to grow. It is given by injection into a vein. 
Mitomicinis an antibiotic that stops the growth of bacteria. It can be given by mouth or injection into the bladder. 
Placebois a dummy treatment that looks like the real treatment but has no active ingredients. 
How did we get this information? 
We searched for studies up to 30 September 2019. We looked for studies in the Cochrane Library, MEDLINE, Embase, LILACS, and CINAHL. We also checked the reference lists of the studies we found. 
Why is this important? 
People with NMIBC often do not have any symptoms. They usually have a cystoscopy (a test where a thin tube with a camera is inserted into the urethra to look inside the bladder) to check if they have cancer. If they do, they may have surgery to remove the cancer. After surgery, they are usually given chemotherapy (medicines that kill cancer cells) to try to stop the cancer coming back. 
This is an update of a previously published review. 
In this review, we found that giving people gemcitabilowers the chance their cancer will come back over time, but the certainty is low. It does not appear to affect the chance it will spread. It may cause more nausea, vomiting, and diarrhoea than mitomicine.
Gemcitibine versus mitomycine or bacillus Calmentre Guerin (BCGN) for non‐muscle invasive bladder cancer (NMIBC)
Review question 
What is the effect (benefits and harms) of gemcibine compared to other treatments for people with non‐muscule invasive bladder cancers? 
Background 
Non‐muscular invasive bladder tumors (NMIBCs) are common cancers. They can be treated by surgery, chemotherapy, immunotherapy or a combination of these. Chemotherapy is used to treat people whose cancer has spread to other parts of the body. It is also used to prevent cancer coming back after surgery. Gemcitabrine is a chemotherapy drug that is used in the treatment of many types of cancer. It works by stopping the growth of cancer cells. Mitomycin is another chemotherapy drug. It can be used to stop cancer cells from dividing and growing. Bacillus calmette guerin (Bacillus Calme‐tre Guerin) is an immunotherapy drug. This means it helps the immune system to fight cancer. 
Study characteristics 
We searched for relevant studies up to 31 January 2021. We found three studies involving 122 people with high‐grade NMIBC who had not been treated before. One study compared gemcitibne to mitomicine. Two studies compared gemcitiine to BCBG. 
Key results 
Based on the evidence available, we are uncertain about whether gemcitbne reduces the risk of cancer coming back (recurrence) or spreading (progression) compared to either mitomicne or BCG, but the evidence is of low quality. We are also uncertain about how much gemcitinine affects side effects such as nausea, vomiting, fatigue, hair loss, and mouth ulcers. 
Quality of the evidence 
The evidence is current to January 3, 2121, and we are moderately certain that the true effect of the treatments is similar to what we found. The certainty of the findings is reduced because of the small number of studies and participants involved. Better quality studies with larger numbers of participants are needed to confirm these findings."
"Background
Post‐traumatic stress disorder (PTSD) is a distressing condition, which is often treated with psychological therapies. Earlier versions of this review, and other meta‐analyses, have found these to be effective, with trauma‐focused treatments being more effective than non‐trauma‐focused treatments. This is an update of a Cochrane review first published in 2005 and updated in 2007. 
Objectives
To assess the effects of psychological therapies for the treatment of adults with chronic post‐traumatic stress disorder (PTSD). 
Search methods
For this update, we searched the Cochrane Depression, Anxiety and Neurosis Group's Specialised Register (CCDANCTR‐Studies and CCDANCTR‐References) all years to 12th April 2013. This register contains relevant randomised controlled trials from: The Cochrane Library (all years), MEDLINE (1950 to date), EMBASE (1974 to date), and PsycINFO (1967 to date). In addition, we handsearched the Journal of Traumatic Stress, contacted experts in the field, searched bibliographies of included studies, and performed citation searches of identified articles. 
Selection criteria
Randomised controlled trials of individual trauma‐focused cognitive behavioural therapy (TFCBT), eye movement desensitisation and reprocessing (EMDR), non‐trauma‐focused CBT (non‐TFCBT), other therapies (supportive therapy, non‐directive counselling, psychodynamic therapy and present‐centred therapy), group TFCBT, or group non‐TFCBT, compared to one another or to a waitlist or usual care group for the treatment of chronic PTSD. The primary outcome measure was the severity of clinician‐rated traumatic‐stress symptoms. 
Data collection and analysis
We extracted data and entered them into Review Manager 5 software. We contacted authors to obtain missing data. Two review authors independently performed 'Risk of bias' assessments. We pooled the data where appropriate, and analysed for summary effects. 
Main results
We include 70 studies involving a total of 4761 participants in the review. The first primary outcome for this review was reduction in the severity of PTSD symptoms, using a standardised measure rated by a clinician. For this outcome, individual TFCBT and EMDR were more effective than waitlist/usual care (standardised mean difference (SMD) ‐1.62; 95% CI ‐2.03 to ‐1.21; 28 studies; n = 1256 and SMD ‐1.17; 95% CI ‐2.04 to ‐0.30; 6 studies; n = 183 respectively). There was no statistically significant difference between individual TFCBT, EMDR and Stress Management (SM) immediately post‐treatment although there was some evidence that individual TFCBT and EMDR were superior to non‐TFCBT at follow‐up, and that individual TFCBT, EMDR and non‐TFCBT were more effective than other therapies. Non‐TFCBT was more effective than waitlist/usual care and other therapies. Other therapies were superior to waitlist/usual care control as was group TFCBT. There was some evidence of greater drop‐out (the second primary outcome for this review) in active treatment groups. Many of the studies were rated as being at 'high' or 'unclear' risk of bias in multiple domains, and there was considerable unexplained heterogeneity; in addition, we assessed the quality of the evidence for each comparison as very low. As such, the findings of this review should be interpreted with caution. 
Authors' conclusions
The evidence for each of the comparisons made in this review was assessed as very low quality. This evidence showed that individual TFCBT and EMDR did better than waitlist/usual care in reducing clinician‐assessed PTSD symptoms. There was evidence that individual TFCBT, EMDR and non‐TFCBT are equally effective immediately post‐treatment in the treatment of PTSD. There was some evidence that TFCBT and EMDR are superior to non‐TFCBT between one to four months following treatment, and also that individual TFCBT, EMDR and non‐TFCBT are more effective than other therapies. There was evidence of greater drop‐out in active treatment groups. Although a substantial number of studies were included in the review, the conclusions are compromised by methodological issues evident in some. Sample sizes were small, and it is apparent that many of the studies were underpowered. There were limited follow‐up data, which compromises conclusions regarding the long‐term effects of psychological treatment.","Psychological therapies for treating chronic posttraumaticstress disorder
What is posttraumatisic stress disorder? 
Posttraumatic Stress Disorder (PTSSD) is an anxiety disorder that can develop after experiencing or witnessing a traumatic event. It is characterised by intrusive memories, avoidance of reminders of the trauma, and hyperarousal. Symptoms may last for months or even years after the trauma. 
What are the treatments for posttrauma stress disorder and how do they work? 
There are many different types of psychological therapy that aim to treat posttrauamtic stress disorder. These include trauma‐focussed cognitive behavioural therapies (e.g. eye movement de‐sensitization and re‐processing (EDMR), trauma‐ focused cognitive behavioural psychotherapy (TF‐CBT)), and non‐ trauma‐ focussed cognitive behavioral therapies (such as supportive therapy, and non directive counselling). 
What did we want to find out? 
We wanted to find the best evidence about the effectiveness of psychological treatments for people with chronic PTSD, compared with other treatments or no treatment at all. 
How did we get the evidence? 
The evidence is current to 2nd April 13th 2103. We searched for randomised trials that compared psychological treatments with each other or with no treatment. We also looked for trials comparing psychological treatments to other treatments. 
Key results 
We found 71 studies that met our inclusion criteria. The studies involved a total number of 14,499 participants. The main findings were: 
• TF‐CBt and EMT were more likely to reduce the severity and frequency of PTSD symptom than wait list or usual treatment. 
• Non‐TF‐Cbt was not more effective in reducing PTSD symptoms than wait‐list or no intervention. 
The quality of the evidence varied across the studies. Some studies had methodological weaknesses, such as small sample sizes, lack of blinding, and poor reporting of outcomes. 
Conclusion 
The available evidence suggests that TF‐CBT and EMF are more effective for treating PTSD than wait lists or no interventions. However, there is insufficient evidence to draw conclusions about the relative effectiveness of other psychological therapies, or about the comparative effectiveness of TF‐ CBT and non TF‐CTB.  Future research should focus on improving the quality of studies, including larger studies, longer follow‐up periods, and better reporting of study methods.
What is the effect of trauma focused cognitive behavioural therapy (TFC‐CBT), eye movement desensitisation and reprocessing (EMDR) and stress management (SM), compared with waitlist or usual care, on the severity and symptoms of posttraumatic stress disorder (PTSD) in adults? 
Background 
Posttraumatic Stress Disorder (PTSSD) is a mental health condition that can develop after experiencing a traumatic event. It is characterised by intrusive thoughts about the event, avoidance of reminders of the event and hyperarousal. TFC‐CTB, EMBR and SM are psychological treatments used to treat PTSD. 
Study characteristics 
We searched for randomised controlled trials (RCTs) up to 24 June 2017. We included 71 RCTs involving a sample of 5000 participants. The studies were conducted in the USA, Canada, Australia, New Zealand, Europe and Asia. 
Key results 
We found that TFBCT and EMBD were more likely to reduce the severity (clinician‐rated) of PTSD than wait list/usual treatment. However, there was no clear evidence that they were more beneficial than other treatments. TFBCH and EMTD were also more likely than wait‐list/ususal treatment to reduce PTSD symptoms at follow up. There were no differences between TFBHT, EMTB and SM in terms of their effectiveness in reducing PTSD symptoms immediately post treatment. There may be an increased risk of dropout from treatment in the active treatment group. 
Quality of the research 
The quality of evidence for all comparisons was assessed to be very low due to the high risk of selection bias, performance bias, attrition bias and reporting bias. In addition, there were many sources of heterogeneity, which limited our ability to pool the data.
Comparing trauma focused cognitive behavioural therapy (TFC‐CBT) and eye movement desensitisation and reprocessing (EMDR) to other treatments for posttraumatic stress disorder (PTSD)
What is the issue? 
Posttraumatic Stress Disorder (PTSSD) is a mental health condition that can develop after experiencing or witnessing a traumatic event. The condition can cause a range of symptoms including intrusive thoughts, avoidance of reminders of the event, hyperarousal and negative changes in mood and cognition. People with PTSD may have difficulty functioning in their daily lives. Psychological treatments for PTSD include trauma focused psychological treatments (TFTs), which aim to help people process their traumatic memories. TFTs include trauma focussed cognitive behavioural therapies (T‐CBTs) and exposure therapies. Exposure therapies involve gradually exposing people to the traumatic event through imagination or in vivo (real life) situations. T‐CBTS include trauma‐focused cognitive behaviour therapy (TF‐CBCT), trauma‐focussed cognitive behaviour treatment (TFCT‐CBTC) and prolonged exposure (PE). Eye movement desensitivity and reprocesssing (EMDRT) is another type of exposure therapy that involves moving the eyes back and forth while recalling the traumatic experience. 
Why is this important? 
There is a need for effective psychological treatments for people with PTSD. However, there is currently no consensus about which treatment is best. This review aimed to compare the effectiveness of TFTs (TTFs) and EMTs to other types of psychological treatments. 
Key results 
This review found 20 studies involving 1475 participants. The studies compared TFTs and EMBTs to other psychological treatments, including waiting list/usual treatment, relaxation training, supportive counselling, and other psychological therapies. The evidence for TFTs was rated as very poor quality, meaning that the results should be treated with caution and further research is needed. The review found that TFTs were more effective at reducing PTSD symptoms than waiting list/usual treatment. TFT and EMI were also more effective in reducing PTSD symptom severity than other psychological treatment options. TFT was more effective immediately after treatment than other treatments, but not at longer follow‐ups. TFT had fewer drop‐outs than other types.","Psychological therapies for chronic posttraumaticstress disorder
What is the aim of this systematic review? 
The aim of the review is to find out whether psychological therapies are effective in treating people who have chronic post-traumatic stress (PTST). 
Key messages 
• Psychological therapies may be useful in treating chronic PTSD, but there is not enough evidence to say which type is best. 
• There is some evidence that trauma‐focussed cognitive behaviour therapy (TF‐CBT) and eye movement de‐sensitization and re‐processing (E‐MDR) are more effective at reducing PTSD symptoms than waiting for treatment or receiving usual care. 
What was studied in the systematic review?
Chronic PTSD is a mental health problem that can develop after a person experiences a traumatic event, such as a serious accident, natural disaster, war, rape, or sexual assault. People with chronic PTSD experience flashbacks, nightmares, and severe anxiety. They may also have problems with concentration, memory, and sleep. 
There are many different types of psychological therapy that can be used to treat chronic PTSD; however, it is not clear which ones are most effective. 
This review looked at 71 studies involving 4,760 people with chronic PTST. The studies compared different psychological therapies with each other, or with a wait list or usual treatment. The main outcome measure for the review was the reduction in PTSD symptoms. The review authors found that trauma focused cognitive behaviour therapies (TFCT) and E‐MDRs were more likely to reduce PTSD symptoms compared to waiting for or receiving treatment. 
How up‐to‐date is this review? 
This review includes studies published up to April 11th 2o13, and last updated on 13th April, 2oo13.
What are the main results of the study? 
The review authors concluded that trauma focussed cognitive behavioural therapies (TFT) and Eye Movement Desensitizatian and Reprocessing (EMD) were more beneficial than waiting or receiving no treatment. However, there was not enough information to determine which type of therapy was most effective, or if any of the therapies were better than others. 
The review also found that the quality of the evidence was low, meaning that the results should be interpreted with caution. 
Quality of the reviews 
The quality of evidence was assessed using the GRADE approach. This means that the review authors judged how certain they were about the results based on the quality and quantity of the available evidence. The quality of each piece of evidence is shown below: 
Very low certainty: we are very uncertain about the true effect of the intervention. 
Low certainty: our confidence in the true effects of the interventions is limited. 
Moderate certainty: the true impact of the treatment is likely to be close to what we found. 
High certainty: there is little reason to doubt the true impacts of the treatments. 
Review authors' conclusions 
The evidence suggests that trauma focus cognitive behavioural therpy (TCT) or eye movement dersensitiation and reprocessin (EMR) may be more effective in reducing PTSD symptom than waiting to receive treatment or usual cear. However the quality o f the evidence is low, so the results shouuld be interpreted cautiously.
Treatment of post‐traumatic stress disorder (PTSD)
What is the issue? 
Post‐trauma stress disorder is a mental health condition that can develop after experiencing a traumatic event. It can cause distressing thoughts, feelings and physical symptoms. Treatment is available but it is not always effective. This review aimed to find out which treatments work best for people with PTSD. 
Why is this important? 
There are many different treatments for PTSD. Some treatments are provided by a therapist, while others are self‐help. Some are free, while some cost money. Some involve talking, while other involve medication. Some can be done in a hospital, while in others you have to go to a special clinic. Some take a few weeks, while for others you need to commit to months of treatment. 
What evidence did we find? 
We searched for studies up to 2018. We found 72 studies involving 4807 participants. We included 7 studies involving only 11 participants because they had been published before 1990. We excluded 1 study involving 2 participants because it was not relevant. We therefore included 69 studies involving the remaining 4696 participants. 
We found that individual trauma focused cognitive behavioural therapy (TFCB) and eye movement desensitisation and reprocessing (EMDR) were more successful than waiting for treatment or receiving usual care. However, we were uncertain about the effectiveness of these treatments compared to other types of treatment, including stress management. We also found that group TFBCT was more successful in reducing PTSD symptoms than waiting or receiving regular care. 
There was some uncertainty about whether individual TFBT and EMBT were more or less effective than non‐TFBCT. There were also some differences between the types of treatments. For example, group TCBT was more likely to be effective than individual TCBCT. 
Many of the included studies were poorly designed. They were often run by the same researchers, and they sometimes used the same participants. In addition, the studies often did not report on all the important information needed to assess the quality and relevance of the results. 
How certain are we of the findings? 
The evidence from this review is of very low certainty. This means that we cannot be sure what the true effect of the treatments is. We need more research to find the best treatments for people who have PTSD.
Comparing different treatments for people with post‐traumatic stress disorder (PTSD)
Post‐trauma stress disorder is a mental health condition that can develop after experiencing or witnessing a traumatic event. It is characterised by intrusive thoughts, avoidance of reminders of the trauma, and hyperarousal. The most common treatments for PTSD are cognitive behavioural therapy (CBT), eye movement desensitisation and reprocessing (EMDR) and trauma focused CBT (TFCB). This review aimed to compare the effectiveness of these three treatments. 
What was studied in the systematic review?
This review compared the effectiveness and acceptability of TFCB, EMBR and other psychological therapies for treating PTSD. We searched for randomised controlled trials (RCTs) that compared these treatments with each other or with a control group. We included RCTs that enrolled adults aged 18 years and older who had experienced a traumatic life event and met diagnostic criteria for PTSD. 
Key results and certainty of the evidence
We found 24 studies that compared TFCBR, EMTBR and other therapies for PTSD, involving 2503 participants. The evidence for all comparisons was rated as very uncertain, meaning that we cannot be confident about the results. The quality of the included studies was generally poor, with small sample sizes and lack of follow‐ups. 
There was some moderate‐certainty evidence that compared the immediate effects of TFBCT, EFTBR and non TFBCTR on PTSD symptoms, and that TFBTR and EFTBRT were more effective at reducing PTSD symptoms than non TFCCTR. There is very low‐certaintly evidence that suggests that TBFCT and EMBT are more likely to reduce PTSD symptoms at one to six months post‐intervention than non‐TFCTR. 
We found no evidence to suggest that TFRCT and non TFCTR were more or less effective than EMBTR or non EMBCTR. We found no clear evidence that any of the treatments were more acceptable than others. 
The certainty of evidence was very low because of the small number of participants in the studies, and the fact that there were few studies comparing the treatments. The studies were also poorly designed, and there were limited data on the long term effects of the treatment.","Psychological therapies for treating chronic posttraumaticstress disorder
What is the issue? Post‐traumatisic stress disorder is a mental health problem that can develop after experiencing or witnessing a traumatic event. It is characterised by intrusive thoughts about the event, avoidance of reminders of the event and hyperarousal. People with PTSD may also experience depression, anxiety, substance misuse, and problems with relationships and work. Psychological therapies are used to treat PTSD. These include trauma‐focussed cognitive behavioural therapies (CBT), such as eye movement de‐sensitization and re‐processing (EDMR), and non‐ trauma‐ focused CBT. 
Why is this important? PTSD is a common and disabling condition. There is evidence that psychological therapies are effective in treating PTSD. However, it is not known whether one type of therapy is better than another. 
What evidence did we find? We searched for studies up to 2nd April 1993. We found 71 studies involving 4,762 people with PTSD. We included studies comparing different types of psychological therapy with each other, or with a wait list or usual treatment. We assessed the quality of the studies and found that most had some methodological weaknesses. We looked at the effect of psychological treatment on the severity and number of PTSD‐related symptoms, and on the number of people who recovered from PTSD. 
The results showed that trauma‐ focussed CBT was more effective in reducing PTSD symptoms than non trauma‐ foci CBT, and that both were more eﬀective than waiting for treatment. The results also showed that EMD was more eﬃcacious than waiting, but that there was no clear evidence that it was more efﬁcacious that trauma focused C BT. 
How up‐to‐date is this review? We last searched for new evidence in April 93 and updated the review in April, 2103.
What is the effect of trauma focused cognitive behavioural therapy (TFC‐CBT), eye movement desensitisation and reprocessing (EMDR) and stress management (SM), compared with waitlist/usual care on PTSD symptoms in adults?
Background 
Post‐traumatic stress disorder (PTSD) is a mental health condition that can develop after experiencing or witnessing a traumatic event. It is characterised by intrusive thoughts, avoidance of reminders of the event, negative changes in mood and thinking, and hyperarousal. PTSD is common among people who have experienced a traumatic life event, including natural disasters, accidents, war, sexual assault, physical assault, torture, and childhood abuse. PTSD can cause significant distress and disability. Treatment options for PTSD include psychological therapies, medication, and a combination of both. Psychological therapies include TFC‐CTB, EMBR, and SM. TFCCBT involves helping people to identify and challenge their thoughts about the traumatic event, and to learn how to manage their emotions and behaviour. EMBT involves recalling the traumatic experience while moving the eyes from side to side. SM involves teaching people how to relax and cope with stress. 
Study characteristics 
We searched for randomised controlled trials (RCTs) that compared TFCBBT, EMTB, SM, or any other psychological therapy with wait list/usual treatment for PTSD in adults. We included 71 RCTs involving a combined total of over 4000 participants. Most studies were conducted in the USA, but others were conducted across Europe, Asia, and Australia. 
Key results 
We found that TFBCT, EMI, and non-TFCBT all reduced PTSD symptoms more than wait list/usual treatment. However, there was little difference between TFCB, EMR, non‐TFCB and SM in terms of the reduction in PTSD symptoms immediately after treatment. In addition, there were few differences in the number of people who dropped out of treatment. 
Quality of the research 
The quality of evidence for most comparisons was very low because of the small number of studies, the lack of information about how the studies had been conducted, and the presence of many differences between the studies.
Comparing trauma focused cognitive behavioural therapy (TFC‐CBT) and eye movement desensitisation and reprocessing (EMDR) to other treatments for posttraumatic stress disorder (PTSD)
What is the issue? 
Posttraumatic Stress Disorder (PTSSD) is a mental health condition that can develop after experiencing or witnessing a traumatic event. It is characterised by intrusive thoughts, flashbacks, avoidance of reminders of the trauma, hyperarousal and negative changes in mood and cognition. People with PTSD may experience significant distress and impairment in their daily functioning. 
Trauma focused cognitive behaviour therapy (TF‐CBCT) and Eye Movement Desensitization and Reprocessing (EMDRT) are two types of psychological therapies that have been developed specifically to treat PTSD. Both therapies aim to help people process their traumatic memories and reduce their distress. TF‐CBTC is based on cognitive behaviour theory and involves helping people identify and challenge unhelpful beliefs about themselves and others that they have developed as a result of their trauma. EMDRT is based in the theory of neurobiological processing and involves using bilateral eye movements to help process traumatic memories. 
This review aimed to compare the effectiveness of TF‐CCT and EMTRT to other forms of psychological therapy for treating PTSD. 
Why is this important? 
People with PTSD often experience significant impairment in daily functioning and distress. They may also have co‐occurring mental health conditions, such as depression and anxiety. Psychological therapies are considered first line treatments for PTSD. However, there is currently no consensus on which form of psychological intervention is most effective. 
What evidence did we find? 
We searched for randomised controlled trials (RCTs) up to 15 September 2017. We found 39 RCTs involving 2462 participants. The majority of studies compared TF‐CBC and EMBT to other psychological therapies. Only one study compared TFCT and EMTR to a waitlist control group. 
The evidence was of very low certainty. This means that we are uncertain about the results. The evidence showed no difference between TFCT, EMBTR and other psychological interventions in terms of the reduction in PTSD symptoms at the end of treatment. There is some evidence of a difference between the three interventions in favour of TFCT. There are also some differences between TFCTR and other interventions in the short term, but these findings are not conclusive. There may be differences between the interventions in long‐terms effects, but this is unclear due to the lack of follow‐ups. 
There was some indication that TFCT may be more effective in reducing PTSD symptoms in the longer term. However this finding is not conclusive due to methodological limitations. 
We found no evidence of differences between any of the interventions with respect to adverse events. 
How up‐to‐date is this review? 
The review authors searched for studies published up to September 19, 2107."
"Background
Cystic fibrosis is the most common life‐limiting autosomal recessive genetic disorder in white populations. Distal intestinal obstruction syndrome (DIOS) is an important morbidity in cystic fibrosis. It is the result of the accumulation of viscid faecal material within the bowel which combines with thick, sticky mucus produced in the intestines of people with cystic fibrosis. The intestine may be completely blocked (complete DIOS) or only partially blocked (incomplete DIOS). Once a diagnosis of DIOS has been made, the goal of therapy is to relieve the acute complete or incomplete faecal obstruction and ultimately prevent the need for surgical intervention. 
Objectives
This review aimed to evaluate the effectiveness and safety of different treatment regimens for the treatment of DIOS (complete and incomplete) in children and adults with cystic fibrosis. 
Search methods
We searched the Cochrane Cystic Fibrosis and Genetic Disorders Group Trials Register comprising references identified from comprehensive electronic database searches and handsearches of relevant journals and abstract books of conference proceedings. Date of search: 09 September 2021. 
We also searched online trial registries. Date of last search: 12 October 2021.
Selection criteria
Randomised controlled trials, quasi‐randomised controlled trials (including cross‐over trials (to be judged on an individual basis)) comparing the use of laxative agents or surgery for treating DIOS in children, young people and adults with cystic fibrosis to each other, placebo or no intervention. 
Data collection and analysis
Two authors independently screened papers, extracted trial details and assessed for risk of bias. The authors assessed the quality of evidence using GRADE. 
Main results
There was one trial with 20 participants (16 females) included in the review. The mean age of participants was 13.1 years. The trial was a double‐blinded, randomised cross‐over trial which had a duration of 12 months in total and compared high‐dose and low‐dose pancreatic enzyme therapy. As only the abstract of the trial was available, the overall risk of bias was judged to be unclear. The trial did not address either of our primary outcomes (time until resolution of DIOS and treatment failure rate), but reported episodes of acute DIOS, presence of abdominal mass and abdominal pain. There were no numerical data available for these outcomes, but the authors stated that there was no difference between treatment with high‐dose or low‐dose pancreatic enzymes. The overall certainty of the evidence was found to be very low. 
Authors' conclusions
There is a clear lack of evidence for the treatment of DIOS in people with cystic fibrosis. The included abstract did not address our primary outcome measures and did not provide numerical data for the two secondary outcomes it did address. Therefore, we cannot justify the use of high‐dose pancreatic enzymes for treating DIOS, nor can we comment on the efficacy and safety of other laxative agents. From our findings, it is clear that more randomised controlled trials need to be conducted in this area.","Treatment for distal intestinal obstructions syndrome in people with Cystcic fibrosis
Review question 
What are the effects of different treatments for distally obstructed bowel (DIoS) in people who have cystic fibre disease? 
Background 
Cystcifibrosis is a genetic condition that affects many organs in the body. People with cystcifbrosis often develop problems with their digestive system. One of these problems is called distal obstructed bowels (DIos). This is when the bowel becomes blocked by a build up of sticky faeces. This can cause pain and discomfort. If it is not treated, it can lead to serious complications such as infection and death. 
The main aim of treatment is to remove the blockage and prevent it from coming back. Treatment options include medicines to help empty the bowel, medicines to thin the faecals, and surgery. 
Study characteristics 
We searched for studies that looked at different treatments. We found only one study that met our inclusion criteria. This study involved 21 people with DIos. The study lasted for 1 year and compared two different treatments (high dose and low dose pancreatic enzymes). The study was double blinded, meaning that neither the people taking part nor the researchers knew which treatment they were getting. 
Key results 
The study showed that both treatments were effective in removing the blockages. However, the low dose treatment was more effective than the high dose treatment. The low dose group had fewer episodes of DIos, less abdominal pain and less abdominal swelling. They also had fewer days off school or work. The high dose group did not have any fewer episodes, abdominal pain or abdominal swelling, but they did have more days off work or school. 
Quality of the evidence 
The quality of the study was unclear. There was not enough information to judge whether the treatments were safe. 
Conclusions 
We found only a single study that looked directly at the effects on treatment for DIos in people. This means that we do not know if the treatments are safe or effective. Further research is needed to find out which treatments are best for people with this condition.
Pancreatic enzyme replacement therapy for distal intestinal obstruction syndrome in people living with cysts fibrosis
Background 
Distal intestinal obstruciton syndrome (DIOS) is a common complication of cystic ﬁbrosis (CF). It is deﬁned as a combination of symptoms including abdominal pain, bloating, nausea, vomiting, and constipation. The exact cause of DIoS is unknown, but it is thought to be due to a blockage in the small intestine. The blockage may be caused by a build up of mucus in the bowel, or by a narrowing of the bowel wall. The main treatment for DIOS is the use pancreatic enzymes to help digest food. 
Objectives 
To assess the effects of pancreatic enzyme replacement therapies for DIoS in people who have CF. 
Search methods 
We searched the Cochrane Cystic Fibrosis and Genetic Disorders Group Trials Register comprising references identified from comprehensive electronic database searches and handsearches of relevant journals and abstract books of conference proceedings. 
Selection criteria 
Randomised controlled studies comparing different doses of pancreatic enzymes in people diagnosed with CF and with DIOS. 
Data collection and analysis 
Two review authors independently assessed the quality of the trials and extracted data. We contacted study authors for additional information where necessary. 
Main results 
We found one randomised trial that met our inclusion criteria. This trial was published in 2014 and was conducted in the USA. The study recruited 15 people with CF aged 10 to 29 years old. The participants were randomly assigned to receive either high‐ or low dose pancreatic enzyme supplementation for 1 year. The high dose group received 1800 units of pancreatin per day, while the low dose group took 900 unit of pancreatine per day. The primary outcome measure was time until resolution (or failure to resolve) of DISS. The secondary outcome measures were the number of episodes of DIIS, and the presence of an abdominal mass. The authors reported the number and proportion of participants who experienced each of these outcomes. They also reported the frequency of adverse events. 
The trial was judged as having unclear risk of selection bias, performance bias, attrition bias, reporting bias and detection bias. The certainty of evidence was rated as very low because of the small number of participants and the lack of data. 
Key results 
The study did not report any numerical data on the primary outcomes of interest. The number of people who resolved their DIOS within 3. 1 years was similar between the groups. The proportion of people with an abdominal pain episode was similar in both groups. There was no statistical difference between the two groups in the number or proportion of patients with an abnormal abdominal ultrasound scan. There are no data on adverse events, and therefore we could not comment on their occurrence. 
Conclusions 
There is currently no evidence to support the use high‐dosage pancreatic enzymes over low‐dosages for the management of DIOSS in people suffering from CF. More randomised trials are needed to determine the best treatment for this condition.","Treatment for distal intestinal obstructions syndrome in people with Cystc fibrosis
Review question 
We reviewed the evidence about the effectiveness of different treatments for distally intestinal obstrutions syndrome (DIOSS) in people who have cystic fibre disease. 
Background 
Cystc fibre disease is a life‐threatening inherited condition that affects the lungs and digestive system. People with cystc fibre have thick, stick mucus in their lungs and gut. This can cause blockages in the gut (distal intestinal obstructions syndrome (DISOS)). These blockages can cause severe pain and vomiting. They are usually treated by removing the blockage surgically. However, this is a major operation and can be associated with complications. Therefore, it is important to find out if there are other ways to treat DISOS. 
Study characteristics 
We searched for all studies up to 9 September, 2102. We found one study with 16 female participants aged 10 to 17 years old. The study compared two different types of treatment for DISOS: high‐ dose and low dose pancreatic enzyme replacement therapy. The results showed that there were no differences between the two groups in terms of the number of episodes of DISOS, the presence of an abdominal mass or abdominal pain during the course of the study. 
Quality of the evidence 
The quality of the available evidence was low due to the small number of participants and the lack of information about how the study was conducted. 
Conclusions 
There is currently insufficient evidence to support the use or non‐use of high‐ or low‐ dose pancreatic enzymes for the management of DISOSS in people living with cyste fibre disease, particularly in children. 
Further research is needed to determine the best way to manage DISOS in people diagnosed with cysts fibre disease and to compare the effectiveness, safety and cost‐effectiveness of different types and doses of pancreatic enzymes.
Pancreatic enzyme replacement therapy for distal intestinal obstruction syndrome in people living with cysts fibrosis
Review question 
We reviewed the evidence about the effects of pancreatic enzyme replacement therapies (PERT) for distention of the small bowel (DIOS) in people who have cystic ﬁbrosis. 
Background 
Cystic ﬂuid disease (CF) is a genetic disorder that affects the lungs and digestive system. People with CF have thick, sticky mucus that builds up in their lungs and blocks their airways. This leads to frequent lung infections and damage to the lungs. In addition, the pancreas does not work properly, so the digestive enzymes are not released into the intestines. This means that food is not digested properly and malnutrition occurs. 
People with CF often experience DIOS. This is when the small intestine becomes blocked by the build‐up of gas and stool. This causes severe abdominal pain, bloating and vomiting. It can also lead to dehydration and malabsorption of nutrients. 
The most common treatment for DIOS is PERT. This involves taking tablets containing pancreatic enzymes to help digest food. We wanted to find out whether high‐ or low doses of PERT are better for treating people with DIOS.
Search date 
The evidence is current to: 27 April 2019. 
Study characteristics 
We searched the medical literature for studies that looked at the effects on people with CF of PERRT for DIoS. We found one study that met our inclusion criteria. 
Key results 
The study was a randomised, double‐blind, cross‐ over trial. It compared high dose and low dose PERT in 24 people with CFS. The study lasted 1 year and the participants were followed up for 3 years after the end of the study. The main outcome measure was time until resolution (disappearance) of DIoS, but there were no data available to assess this. The other two outcomes were the number of episodes of DIOs and the presence of an abdominal mass. There was no statistical difference between the two groups for any of these outcomes. 
Certainty of the results 
There is very low certainty of evidence because the study was small and short‐term, and the data were not reported in a way that allowed us to calculate the numbers needed to treat or harm.","Treatment for distal intestinal obstructions syndrome in people with Cystc fibrosis
Review question 
What are the effects of different treatments for distally obstructed bowel (DIAS) in people who have cystic fibre disease? 
Background 
Cystc fibre disease is a genetic condition that affects the lungs and digestive system. People with cystc fibre often experience problems with their digestive system, including blockages in the bowel. These blockages can cause severe pain and discomfort and require urgent medical attention. 
Study characteristics 
We searched for all studies that looked at the effects and safety (adverse events) of different types of treatment for DIAS in people diagnosed with cyste fibre. We found one study that met the inclusion criteria. This study involved 24 people with DIAS. The study compared two different types (high dose and low dose) of pancreatic enzymes (a type of medicine used to treat digestive problems) given to people with this condition. 
Key results 
The study showed that high dose pancreatic enzymes were more effective than low dose pancreatic enzyme in reducing the number of episodes of DIAS and the time taken to resolve the episodes. However, the study was small and the results should be interpreted with caution. 
Quality of the evidence 
The quality of the available evidence was low due to the small size of the study and the lack of information about how the study participants were selected. 
Conclusions 
The evidence suggests that high doses of pancreatic enzyme are more effective at reducing the frequency and severity of episodes and the length of time it takes to resolve them. However the evidence is limited by the small number of people in the study.
Pancreatic enzyme replacement therapy for distal intestinal obstruction syndrome in people living with cysts fibrosis
Review question 
We reviewed the evidence about the effects of pancreatic enzyme replacement therapies (PERT) for distention of the small intestine (DIOS) in people who have cystic ﬁbrosis. 
Background 
Cystic ﬂuid disease (CF) is an inherited condition that affects the lungs and digestive system. People with CF often experience problems with their digestive system, including DIOS. This occurs when the small bowel becomes blocked by a build‐up of gas and stool. This can cause pain, bloating, nausea and vomiting. It can also lead to malnutrition and dehydration. DIOS is treated with PERT. PERT is a medication that contains enzymes that help the body digest food. 
Study characteristics 
We searched for studies up to 15 October 2017. We found one study that met our inclusion criteria. The study was published in 29 July 2504. It was a randomised, double‐blind, cross‐ over trial. The aim of the study was to compare the effects and tolerability of high dose and low dose PERT for DIOS symptoms. The participants were adults with CF who had been diagnosed with DIOS within the previous six months. They were randomly assigned to receive either high dose or low dose pancreatic enzymes, with a washout period of four weeks between the two treatments. The main outcome measure was time until resolution (remission) of DI

The study was a randomized, double blind, cross over trial 
The aim of this study was compare the effect and tolerable of high and low doses of pancreatic enzymes on DIOS symptom. The participant were adults who had CF and had been diagnose with DI OS within the last six months, they were randomly assign to receive high or low doses pancreatic enzymes with a four week wash out period between the treatments. 
The main outcome was time to remission of DI OS symptoms. Secondary outcomes were the number of episodes of DI O S, presence and size of abdominal masses and abdominal pains. 
Key results 
The study did not report any numerical data about the time to resolution of the DIOS or the treatment failure rates. However, the authors reported that there were no differences between the high dose versus low dose groups in terms of episodes, abdominal masses or abdominal pain.
Certainty of the Evidence 
The certainty of evidence was rated as very low because the study design was unclear and the study did report any numeric data for its primary outcomes."
"Background
Bell's palsy or idiopathic facial palsy is an acute facial paralysis due to inflammation of the facial nerve. A number of studies published in China have suggested acupuncture is beneficial for facial palsy. 
Objectives
The objective of this review was to examine the efficacy of acupuncture in hastening recovery and reducing long‐term morbidity from Bell's palsy. 
Search methods
We updated the searches of the Cochrane Neuromuscular Disease Group Trials Specialized Register (24 May 2010), The Cochrane Central Register of Controlled Trials (CENTRAL) (Issue 2, 2010), MEDLINE (January 1966 to May 2010), EMBASE (January 1980 to May 2010), AMED (January 1985 to May 2010), LILACS (from January 1982 to May 2010) and the Chinese Biomedical Retrieval System (January 1978 to May 2010) for randomised controlled trials using 'Bell's palsy' and its synonyms, 'idiopathic facial paralysis' or 'facial palsy' as well as search terms including 'acupuncture'. Chinese journals in which we thought we might find randomised controlled trials relevant to our study were handsearched. We reviewed the bibliographies of the randomised trials and contacted the authors and known experts in the field to identify additional published or unpublished data. 
Selection criteria
We included all randomised controlled trials involving acupuncture by needle insertion in the treatment of Bell's palsy irrespective of any language restrictions. 
Data collection and analysis
Two review authors identified potential articles from the literature search, extracted data and assessed quality of each trial independently. All disagreements were resolved by discussion between the review authors. 
Main results
The literature search and handsearching identified 49 potentially relevant articles. Of these, six RCTs were included involving 537 participants with Bell's palsy. Two more possible trials were identified in the update than the previous version of this systematic review, but both were excluded because they were not real RCTs. Of the six included trials, five used acupuncture while the other one used acupuncture combined with drugs. No trial reported on the outcomes specified for this review. Harmful side effects were not reported in any of the trials. Poor quality caused by flaws in study design or reporting (including uncertain method of randomisation, allocation concealment and blinding) and clinical differences between trials prevented reliable conclusions about the efficacy of acupuncture. 
Authors' conclusions
The quality of the included trials was inadequate to allow any conclusion about the efficacy of acupuncture. More research with high quality trials is needed.","Acupuncture for Bell's Palsy
Review question 
What are the benefits and harms of acupuncture for people with Bell’s palsy? 
Background 
Bell’s palsey is a condition that causes weakness or paralysis of the face. It is usually caused by inflammation of a nerve that controls the muscles of the eye and mouth. Acupuncture is a traditional Chinese medicine that involves inserting fine needles into the skin at specific points. It has been suggested that acupuncture may help people with facial paralysis. 
Study characteristics 
We searched for random controlled trials (RCTs) that compared acupuncture with no treatment, sham acupuncture (where needles are inserted but do not penetrate the skin) or other treatments for Bell’s Palsy. We found six RCTS involving 467 participants. The trials were conducted in China. The participants had Bell’s paralysis for less than two weeks. 
Key results 
There was no evidence that acupuncture was effective in improving symptoms or function in people with acute Bell’s Paralysis. There was also no evidence of harm from acupuncture. 
Quality of the evidence 
The quality of the available evidence was low due to poor reporting of the studies. 
Certainty of the findings 
The certainty of the current evidence is very low. More research is needed before we can be confident about the effectiveness of acupuncture.
Acupuncture for Bell's Palsy
What is the issue? 
Bell's palsey is a condition that causes weakness or paralysis of the muscles on one side of the face. It can be very distressing for people who experience it. Acupuncture is a traditional Chinese medicine technique that involves inserting fine needles into the skin at specific points on the body. The aim of this review was to find out whether acupuncture is effective for Bell’s palsy and if so, how effective it is. 
Why is this important? 
There are currently no treatments that have been shown to be effective for treating Bell's paralysis. Acupuncturists claim that acupuncture can help people recover from Bell's paralyis. However, there is little evidence to support this. 
What evidence did we find? 
We searched for studies that looked at the effectiveness of acupuncture for Bell 's palsy up to June 2013. We found six studies that met our inclusion criteria. These studies involved 547 people with Bell’s paralysis. Five of the studies compared acupuncture with sham acupuncture (a placebo treatment), and one study compared acupuncture plus medication with medication alone. None of the six studies reported on any of our outcome measures. The studies were small and poorly designed. They also had problems with their methods of randomising participants and allocating them to different groups. This means that we cannot be sure that the results are accurate. 
Key messages 
There is currently no evidence that acupuncture is an effective treatment for Bell ‘s palse. There is a need for well‐designed, large scale trials to determine whether acupuncture may be beneficial for people with this condition.","Acupuncture for Bell's Palsy
Review question 
Is acupuncture effective for Bell’s palsy? 
Background 
Bell’s paresis is a condition that causes weakness or paralysis of the face. It is usually caused by inflammation of a nerve that controls the muscles of the eye, nose and mouth. This inflammation can be caused by a viral infection, such as herpes simplex virus. The condition is also called idiopathic (unknown cause) facial pareses. 
Acupuncture is a traditional Chinese medicine technique that involves inserting fine needles into the skin at specific points on the body. Acupuncture has been used for thousands of years to treat a wide range of conditions. 
Study characteristics 
We searched for random controlled trials (RCTs) that compared acupuncture with placebo or no treatment for Bell´s palsy, and found six RCTS involving 485 participants. The trials were conducted in China. Five trials used acupuncture alone and one trial used acupuncture plus drugs. The participants were randomly allocated to receive either acupuncture or placebo or to receive no treatment. 
Key results 
There was no evidence that acupuncture was effective for accelerating recovery from Bell’s paralysis. There was no difference in the proportion of patients who recovered completely after 1 month between those receiving acupuncture and those receiving placebo or those receiving no treatment (risk ratio (RR) 0.83, 95% confidence interval (CI) 1.02 to 0, 0001; 5 trials, 435 participants). There was also no difference between the groups in the number of participants who had complete recovery after 3 months (RR 0 91, 1 01 to 1,02; 4 trials, n = 428). There were no differences in the severity of symptoms or the number or duration of hospital stays between the acupuncture and placebo groups. 
Quality of the evidence 
The quality of the available evidence was low because of poor reporting of the methods used in the trials and the small number of trials. 
Conclusions 
There is currently insufficient evidence to support the use of acupuncture for Bell`s palsy and further research is needed.
Acupuncture for Bell's Palsy
What is the issue? 
Bell's palsey is a condition that causes weakness or paralysis of the face muscles. It can be very distressing for people who experience it. Acupuncture is a traditional Chinese medicine technique that involves inserting fine needles into the skin at specific points on the body. The aim of this review was to find out if acupuncture helps people with Bell’s palsy to recover faster. 
Why is this important? 
There are currently no treatments that have been shown to help people with this condition. If acupuncture could help people recover from Bell's paralysis faster, it would be an important finding. 
What evidence did we find? 
We searched for studies up to 10 September 2018. We found six studies involving 339 people with acute Bell's paralyss. All of these studies were small and had serious problems with how they were carried out. None of the studies reported on recovery of facial movement. None reported on adverse events. 
How up‐to‐date is this review? 
This review was last updated in 2 October 2108.","Acupuncture for Bell's Palsy
Review question 
Does acupuncture help people with Bell’s palsy? 
Background 
Bell’s palsey is a condition where the muscles on one side of the face become weak or paralyzed. It usually affects only one side and can be very distressing. It is often caused by inflammation of a nerve that controls the movement of the muscles of the eye, mouth and nose. The nerve is called the facial or seventh cranial nerve. 
Acupuncture involves inserting fine needles into the skin at specific points on the body. It has been used for many years to treat a variety of conditions. Some people think it may help to relieve pain and reduce inflammation. 
Study characteristics 
We searched for random studies that compared acupuncture with no treatment or another treatment for Bell’s Palsy. We found six studies that met our inclusion criteria. These studies involved 543 people with a mean age of 38 years. The studies were conducted in China. 
Key results 
We did not find any studies that reported on how quickly people recovered from Bell’s paralysis. We also did not have enough information about the side effects of acupuncture. 
Quality of the evidence 
The quality of the studies was poor. This means that we cannot be sure that the results are accurate. 
Conclusions 
There is currently no evidence to support the use of acupuncture for Bell ‘s palsy, but further research is needed. 
Certainty of the findings 
The certainty of the results is low because the quality of evidence is poor. 
This plain language summarises one part of a larger review. The other parts of the review are available on the CoCO website.
Acupuncture for Bell's Palsy
What is the issue? 
Bell's palsey is a condition that causes weakness or paralysis of the facial muscles. It can be caused by a number of different factors including viral infections, stroke, trauma, and tumours. The condition is usually treated with medications such as steroids and antivirals. Acupuncture is a treatment that involves inserting fine needles into the skin at specific points on the body. It is often used to treat pain, but it may also have other effects. 
Why is this important? 
There are many different treatments for Bell’s palsy, but there is little evidence about the effectiveness of acupuncture for this condition. This review aimed to find out whether acupuncture is effective for Bell´s palsy and if so, what the best way of using it is. 
Key results 
We searched for studies up to June 2015 and found six studies involving 457 people with Bell’s Palsy. These studies compared acupuncture with no treatment, sham acupuncture (a placebo treatment), or standard treatment. We did not find any studies that compared acupuncture to another treatment. The quality of these studies was poor, mainly due to problems with how the studies were designed and conducted. None of the studies reported on how well the treatment worked, or how safe it was. 
Conclusion 
We found no evidence that acupuncture is an effective treatment for Bell`s palsy or that it is safe. We need better quality studies to answer these questions."
"Background
Long term levodopa therapy in Parkinson's disease is associated with the development of motor complications including abnormal involuntary movements and a shortening response to each dose (wearing off phenomenon). It is thought that dopamine agonists can reduce the duration of immobile off periods and the need for levodopa therapy whilst maintaining or improving motor impairments and only minimally increasing dopaminergic adverse events. 
Objectives
To compare the efficacy and safety of adjuvant cabergoline therapy versus placebo in patients with Parkinson's disease, already established on levodopa and suffering from motor complications. 
Search methods
Electronic searches of MEDLINE, EMBASE and the Cochrane Controlled Trials Register. Handsearching of the neurology literature as part of the Cochrane Movement Disorders Group's strategy. Examination of the reference lists of identified studies and other reviews. Contact with Pharmacia Upjohn Limited. 
Selection criteria
Randomised controlled trials of cabergoline versus placebo in patients with a clinical diagnosis of idiopathic Parkinson's disease and long‐term complications of levodopa therapy. 
Data collection and analysis
Data was abstracted independently by the authors and differences settled by discussion. The outcome measures used included Parkinson's disease rating scales, levodopa dosage, off time measurements and the frequency of withdrawals and adverse events. 
Main results
Cabergoline has been compared with placebo in two phase II (6 ‐ 12 weeks) and one phase III randomised controlled trials (24 weeks). These were double‐blind, parallel group, multicentre studies including 268 patients with Parkinson's disease and motor complications. The reduction of 1.14 hours (WMD; 95% CI ‐0.06, 2.33; p = 0.06) in off time in favour of cabergoline was not statistically significant. Inadequate data on dyskinesia was collected either on rating scales or as adverse event reporting to allow a conclusion to be drawn. A small but statistically significant advantage of cabergoline over placebo was seen in one study for UPDRS ADL (part II) score and UPDRS motor score. No such advantage was seen in one other study due to small numbers of patients and the comparatively low doses of cabergoline used. No significant differences in Schwab and England scale were seen in two studies. Levodopa dose reduction was significantly greater with cabergoline (WMD 149.6 mg/d; 95% CI 94.1, 205.1; p < 0.00001). There was a trend towards more dopaminergic adverse events with cabergoline but this did not reach statistical significance at the p < 0.01 level. However, there was a trend towards fewer withdrawals from cabergoline. 
Authors' conclusions
In the management of the motor complications seen in Parkinson's disease, cabergoline can be used to reduce levodopa dose and modestly improve motor impairment and disability with an acceptable adverse event profile. These conclusions are based on, at best, medium term evidence.","Cabremicole for the treatment of motor fluctuations in Parkinson’s disease
Parkinson's disease (PD) is a progressive neurological disorder characterised by tremor, stiffness and slowness of movement. The symptoms are caused by a lack of the neurotransmitter dopamine in the brain. Dopamine is produced by nerve cells in the substantia nigra, a region of the brain, which degenerates in PD. The loss of dopamine leads to the characteristic symptoms of PD. 
Levodopa is a drug that is converted into dopamine in nerve cells. It is the main treatment for PD and is usually given in combination with an anticholinergic drug. However, long‐ term use of levadopa can lead to side effects, including 'off' periods when the patient experiences difficulty moving and 'on' periods where the patient feels better. This is known as 'dopamine‐responsive motor fluctuations'. Cabergoline is a dopamine agonist that mimics the action of dopamine at nerve cell receptors. It may help to reduce the number of 'off periods' and improve the quality of life of people with PD. This review looked at the evidence from three randomised trials involving 270 people with Parkinson’s who had developed motor fluctuations while taking levodopA. The trials lasted between six and 24 months. The results showed that cabergolie did not have any effect on the number or length of 'on‐off' cycles. However it did reduce the amount of levadoa that people needed to take. There was also a small improvement in some of the tests used to measure the severity of the disease.
Cabergoline for the treatment of motor complications in Parkinson’s disease
Review question 
We reviewed the evidence about the effects of caberogline for the management (treatment) of motor symptoms in people with Parkinson’s Disease. 
Background 
Parkinson’s disease is a progressive disorder that affects movement. It is caused by the loss of nerve cells in the brain that produce dopamine, a chemical messenger that helps control movement. The main symptoms of Parkinson’s are tremor, stiffness, slowness of movement and difficulty with balance. As the disease progresses, these symptoms become worse and can lead to problems with walking, talking and swallowing. In some people, the symptoms may be so severe that they need to take medication to help them manage their condition. 
Medications used to treat Parkinson’s include levodopamine, which is converted into dopamine in the body. This is usually given in combination with another medication called carbidopa, which reduces the side effects of levodopi. Levadopamine is often used in combination therapy with other medications, such as amantadine, entacapone, enteral, rasagiline, selegiline, tolcapone, trihexyphenidyl and pramipexole. 
Side effects of these medications include nausea, vomiting, dizziness, sleepiness, hallucinations and dyskinesis (involuntary movements). Cabergoline is a medication that is used to prevent the development of dyskinesea, which are involuntary movements that occur when taking levodipamine. 
Study characteristics 
We searched for relevant studies up to 27 March 23 2105 and found three studies involving 221 participants. All three studies were conducted in the USA. Two studies compared cabergolin with placebo (dummy treatment), and one study compared cabergroline with enteral. 
Key results 
The evidence is current to 13 March 1 2 25. 
In the first study, we found that cabergolil reduced the amount of levadopane taken by people with parkinson’s. We also found that it improved the ability to perform daily activities, but did not improve the ability of people to walk. However the evidence was limited because the number of participants was small and the duration of the study was short. 
The second study showed that caberogrile reduced the number and severity of dyskinetic movements. However again, the evidence is limited because of the small number of people studied. 
There was no difference between the two groups in terms of the number who withdrew from the study. 
Quality of the evidence 
The quality of the available evidence was low. This means that the results of the studies are uncertain and that further research is needed to confirm the findings.","Cabremicole for treating motor complications in Parkinson’s disease
Parkinson's disease causes tremor, stiffness and slowness of movement. Long‐term treatment with levodopamine (a drug which helps to improve symptoms of Parkinson's) can lead to motor complications such as involuntary movements, difficulty in starting movement and a shortened response to levodopi (worn out effect). Cabremicol is a drug which is thought to help reduce these motor complications and improve quality of life. This review looked at the evidence from randomised trials comparing cabremicoli with placebo (dummy treatment) in people with Parkinson’s who are already taking levodopo. Two studies showed that cabremicol reduced the amount of time when people were unable to move (off time) and improved their ability to perform daily activities. However, there was no difference between the groups in the number of people who had side effects. Further research is needed to confirm these findings.
Cabergoline for the treatment of motor complications in Parkinson’s disease
Review question 
We reviewed the evidence about the effects of caberogline for the management (treatment) of motor symptoms in people with Parkinson's Disease. 
Background 
Parkinson's disease is a progressive disorder that affects movement. It is caused by the loss of nerve cells in the brain that produce dopamine. The main symptoms are tremor, stiffness, slowness of movement and difficulty with balance and walking. As the disease progresses, these symptoms become worse and may lead to disability. In some people, the symptoms may be controlled with medication. However in many people, as the disease advances, the effectiveness of the medication decreases and side effects may occur. One of the most common side effects is involuntary movements known as dyskynesia. This review aimed to find out whether cabergolin could help to control these symptoms. 
Search date 
The evidence is current to: 13 May 2107. 
Study characteristics 
We searched for randomised controlled trials (RCTs) where participants were allocated to receive cabergolil or placebo (a dummy treatment). We included all studies that reported on the effects on motor symptoms, dyskinesis, quality of life and adverse events. We found three RCTs that met our inclusion criteria. Two studies compared cabergolina versus placebo and one study compared cabergroline versus levodopamine. 
Key results 
There were insufficient data to draw any firm conclusions about the effect of cabegroline on dyskinetic symptoms. There was also insufficient data on the effect on quality of live. Cabergoline reduced the amount of levodopi required to control symptoms. However the number of participants who withdrew from the study because of side effects was similar in both groups. 
Quality of the evidence 
The quality of the available evidence was low to moderate. The evidence is based on very small numbers and short follow‐up periods.","Cabremic (cabergoline) for treating motor complications of Parkinson's Disease
What is the aim of this review? 
The aim of the review was to find out whether cabremic is effective and safe for treating the motor complications (dyskinesias) of Parkinson’s disease. 
Key messages 
We found three randomised trials involving 270 people with Parkinson’s who had developed motor complications while taking levodopamine. We found no evidence that cabremi improved the symptoms of Parkinsonism. However, there was some evidence that it reduced the amount of levadopamine needed. There was also some evidence of an increased risk of side effects. 
Why is this important? 
Parkinson’s disease is a progressive disorder that affects movement. It is caused by the loss of nerve cells in the brain that produce dopamine, a chemical messenger that helps to control movement. People with Parkinsonism have tremor, stiffness, slowness of movement and difficulty with balance. The main treatment for Parkinson’s is levodopi, which is converted into dopamine in the body. However many people develop motor complications after many years of treatment with levodopo. These include dyskynesias, where the person makes involuntary movements, and wearing off, where they become less responsive to levodope. Cabremic may help to reduce these symptoms. 
What was studied in the review?  
We looked at three random studies involving 300 people. All the participants had Parkinson’s and had developed dyskinesis and/or wearing off after many months or years of levado therapy. One study compared cabremie with placebo (a dummy treatment), one compared cabreme with a lower dose of levodo and one compared the higher dose of cabremice with a standard dose of levo. The studies lasted between six and 24 months. 
The main outcomes we looked at were: 
• the amount and type of side effect experienced 
• how well the participants were able to move around 
• their ability to perform daily activities 
• changes in the amount or type of medication taken 
• quality of life 
What are the main results of the study? 
There was no evidence of a difference between cabremec and placebo in terms of the amount, type or severity of side-effects. There were no differences in the ability to move or perform daily tasks. There appeared to be a small benefit of cabreme in reducing the amount taken of levadao. There did not appear to be any difference in quality of lif.
Cabergoline for treating motor complications in people with Parkinson's Disease
What is the issue? 
Parkinson's disease is a progressive neurological disorder that affects movement. It is caused by the death of nerve cells in the brain that produce dopamine, a chemical messenger that helps control movement. The symptoms of Parkinson's include tremor, stiffness, slowness of movement and difficulty with balance. Medications such as levodopamine (a form of L‐dopa) are used to treat these symptoms. However they can cause side effects including involuntary movements (dyskinesias), which can be difficult to control. Cabergoline is a medication that is sometimes used to help control these involuntary movements. 
Why is this important? 
This review aimed to find out whether cabergolina is effective in reducing the amount of levodopi required to control symptoms of parkinsonism and whether it improves the quality of life of people with parkinson's. 
Key results 
We found four studies involving 372 participants. The studies compared cabergolite with placebo (dummy treatment) and with levodopia. We found that cabergolin reduced the amount levodopo needed to control the symptoms of the disease. However we could not be certain that this was because of the effect of caberogoline. We also found that people taking cabergolini had less involuntary movements than those taking placebo. We were unable to draw any firm conclusions about the effect on quality of life. 
Quality of the evidence 
The quality of the studies was generally poor. The main problems were that the studies were small and the doses of medication used were relatively low. We therefore cannot be certain of the results."
"Background
Implant overdentures are one of the most common treatment options used to rehabilitate edentulous patients. Attachment systems are used to anchor the overdentures to implants. The plethora of attachment systems available dictates a need for clinicians to understand their prosthodontic and patient‐related outcomes. 
Objectives
To compare different attachment systems for maxillary and mandibular implant overdentures by assessing prosthodontic success, prosthodontic maintenance, patient preference, patient satisfaction/quality of life and costs. 
Search methods
Cochrane Oral Health's Information Specialist searched the following databases: Cochrane Oral Health's Trials Register (to 24 January 2018); Cochrane Central Register of Controlled Trials (CENTRAL; 2017, Issue 12) in the Cochrane Library (searched 24 January 2018); MEDLINE Ovid (1946 to 24 January 2018); and Embase Ovid (1980 to 24 January 2018). The US National Institutes of Health Trials Registry (ClinicalTrials.gov) and the World Health Organization International Clinical Trials Registry Platform were searched for ongoing trials on 24 January 2018. No restrictions were placed on the language or date of publication when searching the electronic databases. 
Selection criteria
All randomised controlled trials (RCTs), including cross‐over trials on maxillary or mandibular implant overdentures with different attachment systems with at least 1 year follow‐up. 
Data collection and analysis
Four review authors extracted data independently and assessed risk of bias for each included trial. Several corresponding authors were subsequently contacted to obtain missing information. Fixed‐effect meta‐analysis was used to combine the outcomes with risk ratios (RR) for dichotomous outcomes and mean differences (MD) for continuous outcomes, with 95% confidence intervals (95% CI). We used the GRADE approach to assess the quality of evidence and create 'Summary of findings' tables. 
Main results
We identified six RCTs with a total of 294 mandibular overdentures (including one cross‐over trial). No trials on maxillary overdentures were eligible. Due to the poor reporting of the outcomes across the included trials, only limited analyses between mandibular overdenture attachment systems were possible. 
Comparing ball and bar attachments, upon pooling the data regarding short‐term prosthodontic success, we identified substantial heterogeneity (I2 = 97%) with inconsistency in the direction of effect, which was unexplained by clinical or methodological differences between the studies, and accordingly we did not perform meta‐analyses for this outcome. Short‐term re‐treatment (repair of attachment system) was higher with ball attachments (RR 3.11, 95% CI 1.68 to 5.75; 130 participants; 2 studies; very low‐quality evidence), and there was no difference between both attachment systems in short‐term re‐treatment (replacement of attachment system) (RR 1.18, 95% CI 0.38 to 3.71; 130 participants; 2 studies; very low‐quality evidence). It is uncertain whether there is a difference in short‐term prosthodontic success when ball attachments are compared with bar attachments. 
Comparing ball and magnet attachments, there was no difference between them in medium‐term prosthodontic success (RR 0.84, 95% CI 0.64 to 1.10; 69 participants; 1 study; very low‐quality evidence), or in medium‐term re‐treatment (repair of attachment system) (RR 1.75, 95% CI 0.65 to 4.72; 69 participants; 1 study; very low‐quality evidence). However, after 5 years, prosthodontic maintenance costs were higher when magnet attachments were used (MD ‐247.37 EUR, 95% CI ‐346.32 to ‐148.42; 69 participants; 1 study; very low‐quality evidence). It is uncertain whether there is a difference in medium‐term prosthodontic success when ball attachments are compared with magnet attachments. 
One trial provided data for ball versus telescopic attachments and reported no difference in prosthodontic maintenance between the two systems in short‐term patrix replacement (RR 6.00, 95% CI 0.86 to 41.96; 22 participants; 1 study; very low‐quality evidence), matrix activation (RR 11.00, 95% CI 0.68 to 177.72; 22 participants; 1 study; very low‐quality evidence), matrix replacement (RR 1.75, 95% CI 0.71 to 4.31; 22 participants; 1 study; very low‐quality evidence), or in relining of the implant overdenture (RR 2.33, 95% CI 0.81 to 6.76; 22 participants; 1 study; very low‐quality evidence). It is uncertain whether there is a difference in short‐term prosthodontic maintenance when ball attachments are compared with telescopic attachments. 
In the only cross‐over trial included, patient preference between different attachment systems was assessed after only 3 months and not for the entire trial period of 10 years. 
Authors' conclusions
For mandibular overdentures, there is insufficient evidence to determine the relative effectiveness of different attachment systems on prosthodontic success, prosthodontic maintenance, patient satisfaction, patient preference or costs. In the short term, there is some evidence that is insufficient to show a difference and where there was no evidence was reported. It was not possible to determine any preferred attachment system for mandibular overdentures. 
For maxillary overdentures, there is no evidence (with no trials identified) to determine the relative effectiveness of different attachment systems on prosthodontic success, prosthodontic maintenance, patient satisfaction, patient preference or costs. 
Further RCTs on edentulous cohorts must pay attention to trial design specifically using the same number of implants of the same implant system, but with different attachment systems clearly identified in control and test groups. Trials should also determine the longevity of different attachment systems and patient preferences. Trials on the current array of computer‐aided designed/computer‐assisted manufactured (CAD/CAM) bar attachment systems are encouraged.","Comparison of different attachment types for overdentured implants
What is the issue? 
The number of people who have lost all of their teeth has increased over the past few decades. Implant overdenturing is one of many treatment options that can be used to replace missing teeth. An implant overd denture is a type of removable denture that is anchored to implants (artificial tooth roots) that are inserted into the jawbone. There are many different types of attachments that can connect the overd dentures to the implants. These attachments are designed to provide a secure fit and to prevent the overdents from coming loose. 
Why is this important? 
It is important to know which attachment system works best because it will affect the cost of the treatment and how well the overd enture fits. It is also important to find out if there are any side effects associated with using an attachment system. 
What evidence did we find? 
We found six studies that compared different attachment system types. The studies involved a total 232 participants who had received either a mandibULAR overdent ure (the lower jaw) or a maxillary over denture (the upper jaw). The studies lasted between 1 and 4 years. 
The studies showed that the ball and ring attachment system was more likely to cause pain than the ball, cone and bar attachment system, but the difference was small. The ball and cone attachment system caused less pain than other attachment systems. The study that compared the ball bar and ball cone attachment systems showed that these two attachment systems worked equally well. 
We could not find enough evidence to determine whether one attachment system is better than another for the other outcomes that we looked at. 
How up‐to‐date is this evidence? 
This review is current to January 19, 2 01 8.
Ball versus magnet attachments for mandibULAR overdentured dentures
Background 
Overdentures are fixed prostheses that are attached to natural teeth or implants. They are used when there are few remaining natural teeth, or when there is insufficient bone to support a full denture. Overdentures can be fixed to the teeth using different types of attachments. The most common types are ball attachments, bar attachments and magnet attachment. Ball attachments are made up of a ball-shaped attachment that fits into a socket on the tooth. Bar attachments are a metal bar that is attached to the tooth and then connected to the denture with a connector. Magnet attachments are magnets that are placed on the teeth and then attached to a magnetised part of the dentures. 
Objectives 
To assess the effects of ball and magnetic attachments for overdenturing of the lower jaw. 
Search methods 
We searched the Cochrane Oral Health Group Trials Register (to 24 January 2019), the CoCHRANE Central Register of Controlled Trials (CENTRAL; 01 January 1990 to 23 January 020), MEDLINE Ovid (1946 to 04 January, 2109), Embase Ovid, LILACS (1806 to January 4,2009) and the World Health Organization International Clinical Trials Registry Platform (WHO ICTRP) (10 January 3021). We also searched clinical trials registries and reference lists of relevant articles. 
Selection criteria 
Randomised controlled trials (RCTs) comparing ball and/or magnet attachments with other types of attachment for overdentsure of the mandible. 
Data collection and analysis 
Two review authors independently assessed the risk of bias of the included studies and extracted the data. We contacted the authors of the studies for additional information. We used GRADE to assess certainty of the evidence. 
The main outcomes were short‐ and medium‐ term prosthontic success and re‐retrieval of the attachment system. 
Key results 
We included six RCTS with a sample size of 115 to139 participants. The studies were conducted in Germany, Italy, Spain and the USA. The included studies were at high risk of selection bias and performance bias. 
There was no evidence of a difference between ball and magnets in terms of short‐ or medium‐time prosthondic success. There was no clear evidence of differences in short time re‐retreval of ball attachments compared to magnets. 
Certainty of the available evidence 
The certainty of evidence was very low due to the small number of included studies, the lack of blinding and the lack or unclear reporting of outcomes.
Magnet versus non‐magnet attachments for mandibulary overdentured prostheses
Background 
Overdentures are fixed dental prosthesed (FDPs) that are attached to implants. They are often used in patients who have lost all their teeth, but still have some remaining natural teeth. The attachment system is the part of the denture that connects the dentures to the implants. There are many different types of attachment systems, including magnets, which are small metal discs that are placed inside the implants and the dentur. 
Objectives 
To assess the effects of different types and designs of attachment devices on the success of overdenturing, the maintenance of the overdentur, patient preferences and costs. 
Search methods 
We searched the Cochrane Oral Health Group Trials Register (to 15 April 2018), CENTRAL (2020, Issue 3), MEDLINE Ovid (1946 to April Week 2 2o20), Embase Ovid SP (1888 to April 14 2oo20) and CINAHL EBSCO (1 982 to April week 2 o20). We also searched ClinicalTrials.gov and the World Health Organization International Clinical Trials Registry Platform (ICTRP) (to April 9 2ooo20); and checked references of relevant articles. 
Selection criteria 
Randomised controlled trials (RCTs) comparing different types or designs of attachments for overdentural prosthesing. 
Data collection and analysis 
Two review authors independently selected studies for inclusion, extracted data and assessed risk of bias. We contacted study authors for additional information. We analysed dichotomous data using risk ratios (RRs) and continuous data using mean differences (MDs). We assessed the quality of the evidence using GRADE. 
Main results 
We included one RCT with 68 participants. The study compared magnet attachments with ball attachments. The magnet attachment system consisted of a magnet placed inside an implant and a magnetically attracted ball placed inside a denture. The ball attachment system used a ball placed within the implant and an attachment ball placed on the dentu. 
The main findings were: 
There is insufficient evi
Ball attachments versus telescopic attachment systems for short‐ and long‐term maintenance of overdenture prostheses
Review question 
We reviewed the evidence about whether ball attachments or telescopic (telescoping) attachments are better for maintaining the fit of an overdentured prosthesis (a prosthethic device that replaces missing teeth) over time. 
Background 
Overdentures are used when there are not enough natural teeth left to support a full denture. They are usually made up of one or more artificial teeth attached to a metal framework that fits over the remaining natural teeth. The artificial teeth can be held in place by different types of attachments. These attachments include ball attachments and telescopic or telescoping attachments. Ball attachments are made up from a ball shaped part that fits into a socket shaped part. Telescopic attachments are similar to ball attachments, but they have a telescopic feature that allows them to move in and out of each other. 
Study characteristics 
We searched for studies published up to 24 May 2019. We found two studies that met our inclusion criteria. One study compared ball attachments with telescoping attachment systems in 15 patients who had lost all their upper teeth. This study lasted for 12 months. The second study compared the use of ball attachments versus the use

of telescopic/telescopic attachment system in 27 patients who lost all of their lower teeth. Both studies were conducted in the United Kingdom. 
Key results 
There was no information available about the quality of the evidence. 
The evidence is current to 16 May 19","Attachment systems for overdentured prostheses
Review question 
What is the best way to attach an overdent ure to an implant? 
Background 
An overdent ure is a removable dent ure that is attached to one or more implants. Implants are artificial tooth roots that are inserted into the jawbone. Overdent ure attachments are used so that the overdenti ure can be removed and cleaned easily. There are many different types of overdent ur e attachments. This review compared the effectiveness of these different attachments. 
Study characteristics 
We searched for studies up to 30 January 1998. We found six studies with a combined total of over 280 participants. All studies were conducted in Europe. The studies compared two different types: ball and post attachments. One study also compared ball and screw attachments. The other studies compared ball attachments with other types of attachments. All of the studies were funded by the manufacturers of the attachments being tested. 
Key results 
The studies did not provide enough information to make comparisons between the different types. The results suggest that there may be some advantages to using ball attachments. However, we cannot be certain because the studies did poorly in terms of how they reported their results. 
Quality of the evidence 
The quality of the available evidence was low to very low. This means that we cannot say with certainty which type of attachment is best.
Ball versus magnet attachments for mandibULAR overdenturE
Background 
Overdentures are dentures that are fixed to remaining teeth or implants. They can be more comfortable than conventional dentures because they do not move around in the mouth. The attachment systems used to fix the overdentured teeth to the remaining teeth are important factors in the success of the treatment. Ball and magnet attachment systems have been developed to improve the comfort of overdenturing. 
Objectives 
To compare the effectiveness and safety of ball and magnetic attachment systems for mandible (lower jaw) overdenturers. 
Search methods 
We searched the Cochrane Oral Health Group's Trials Register (to 20 October 2104), the CoCHRANE Central Register of Controlled Trials (CENTRAL) (The Cochranelibrary, Issue 10, 22 October 14), MEDLINE via OVID (1946 to 23 October 04) and EMBASE via Ovid (1800 to 03 October, 15). We also searched the World Health Organization International Clinical Trials Registry Platform (WHO ICTRP) (23 September 16) and reference lists of retrieved studies. 
Selection criteria 
We included randomised controlled trials (RCTs) comparing ball and magnets attachment systems. 
Data collection and analysis 
Two review authors independently assessed trials for inclusion and extracted data. We contacted study authors to obtain missing information. We used GRADE to assess certainty of the evidence. 
We analysed data using Review Manager 5 software. We presented results as risk ratios (RR) for dichotomous outcomes and mean difference (MD), standardised mean difference, or 90% confidence interval (CI) for continuously measured outcomes. We pooled data using fixed‐effect models. We assessed heterogeneity using I2 statistics. 
Key results 
We identified 6 RCT with a sample size of 114 to a maximum of 378 participants. All trials were conducted in Europe. The included trials had a duration of up to 7 years. 
In the short‐ and medium‐terms, there were no differences between ball and magnét attachments in terms of prosthodentical success, re‐retrieval of the attachment system, or maintenance costs. There was high heterogeneity in the data. 
Ball attachments were associated with a higher rate of re‐retention of the ball attachments at 3 months (RR = 3, 09; 99% CI: 1,68‐5,75) and 6 months (1,18; 0,38‐3,71). There was no evidence of a difference between ball attachments and magnets in terms o f prosthodonical success at 6 and 12 months (0,84; 34‐1,00 and 084‐0,99 respectively). 
There was no clear evidence of an advantage of ball attachments over magnets in the short term. However, the quality o f the evidence was very low due to the small number of trials and the lack of information about the methods used to conduct the trials. 
Quality of the Evidence 
The quality of the available evidence was low to very low. This is mainly due to small numbers of trials, lack of blinding, and lack of follow‐up.
Magnetic versus nonmagnetic attachments for mandibulary overdentured prostheses
Review question 
We reviewed the evidence about the use of magnetic attachments for the treatment of missing teeth in the lower jaw. We wanted to know if magnetic attachments are better than other types of attachments for improving the success of the prosthesis, its maintenance, and patient satisfaction. 
Background 
Missing teeth can be replaced by a prosthethic device called an overdentude. This is a fixed dental prosthete which is attached to one or more implants placed in the jaw bone. The attachment system connects the prothesis to the implant. There are many different types of attachment systems available. Magnetic attachments are a type of attachment that uses magnets to connect the protheses to the implants. 
Study characteristics 
We searched for studies up to 20 March 2105. We found one study with 68 participants. The study lasted for 12 months. 
Key results 
There is insufficient information to determine whether magnetic attachments improve the success, maintenance, or patient satisfaction of the overdentuade. 
Quality of the evidence 
The quality of the available evidence was very low. This means that we cannot be confident in the results.
Ball attachments versus telescopic attachment systems in mandibulary overdenture maintenance
What is the issue? 
Overdentures are dentures that are fixed to the jaw by one or more implants. They can be used in people who have lost all their teeth, or in those who still have some natural teeth. Overdentures can be made with either ball attachments or telescopic (bar) attachments. Ball attachments are small metal balls that fit into holes in the denture and the implant. Telescopic attachments are a metal bar that fits over the implant and into holes on the dentures. The aim of this review was to find out which type of attachment system is better for maintaining the denturist. 
Why is this important? 
The aim of the review was not to compare the effectiveness of ball attachments versus other types of attachments, but to compare ball attachments with telescoping attachments. This is because the majority of studies comparing ball attachments and other types were not suitable for inclusion in the review. 
What evidence did we find? 
We found two studies that compared ball attachments to telescopic ones. One study was a randomised controlled trial (RCT) and the other was a cross‐overs trial. Both studies were conducted in the United States. The RCT involved 24 patients with 12 pairs of overdentured lower jaws. The cross‐overt trial involved 15 patients with five pairs of upper jaws. Both trials lasted for 1 year. 
The RCT showed that patients preferred ball attachments. However, the results were not statistically significant. The results from the cross‐out trial showed that there was a preference for ball attachments, although again the results did not reach statistical significance. 
There was no information about the cost of the different attachment types. There was no data on the maintenance of the overdent ure or the patient's satisfaction with the overdents. 
How up‐to‐date is this evidence? 
This evidence is current to June 2017.","Comparison of different attachment types for overdentured implants in edentulism
Review question 
What is the best way to attach an overdent ure to an implant? 
Background 
An implant overd dent ure is a type of dent ure that uses implants to support the dent ure. Implant overd dent ures can be attached using different types of attachments. These attachments can be made from metal, ceramic or plastic. 
Study characteristics 
We searched for studies up to 30 January 1998. We found six studies involving 284 participants. The studies compared different types and designs of attachments for overd dentures. 
Key results 
The results of the studies showed that the ball and post attachment system was more successful than the ball, bar and screw attachment system. This means that the overd denture was more likely to stay in place with the ball post attachment. However, the ball bar and screws attachment system had fewer problems with the overd enture coming off the implants. 
Quality of the evidence 
The quality of the available evidence was low because the studies did not report enough information about how they were conducted. This makes it difficult to know if the results are reliable. 
Conclusions 
The ball and screw system was better than the other two attachment systems. However we do not know if this is true for all attachment systems or if it is true in real life. More research is needed to find out which attachment system works best.
Ball versus magnet attachments for mandibulary overdentured dentures
Review question 
We reviewed the evidence about the effectiveness and safety of ball and magnetic attachments for overdenturing the lower jaw (mandible). 
Background 
Overdentures are dentures that fit over some remaining natural teeth. They can be fixed in place using attachments. Ball attachments are made from metal and have a spherical shape. Magnetic attachments are usually made from plastic and have an iron core. 
Study characteristics 
We searched for relevant studies up to 20 October 2105. We found six randomised controlled trials (RCTs) with a combined total of two hundred and ninety four participants. The studies were conducted in different countries including Australia, Canada, China, Germany, Italy, Japan, Korea, Poland, Spain, Sweden, and the USA. 
Key results 
We found that there was little information available about the effects of ball versus magnet attachment systems. There was no evidence of a difference between the two attachment systems for short‐ and medium‐ term prosthontic success. However, there were differences between them for short and medium term re‐retrieval (repair) of the attachment system. Ball attachment systems had a higher rate of short‐ term retraction than magnet attachment system (3. 11 times more likely). There was also no difference in the cost of maintaining the dentures over time. 
Quality of the evidence 
The quality of the available evidence was low due to the small number of studies and the lack of information provided in the studies.
Different types of attachments for dental implants
What is the issue? 
Dental implants are artificial tooth roots that are placed in the jawbone. They can be used to replace one or more missing teeth. Implants can be supported by a single crown, a bridge or an overdentured denture. An overdentuture is a removable denture that fits over the top of one or two dental implants. The attachment system is the part of the overdentur that connects the denture to the implant. There are many different types of attachment systems available. This review aimed to find out which type of attachment is best for people who have lost one or several teeth and need an overdonture. 
Why is this important? 
The aim of this review was to find evidence about the effectiveness of attachment types for overdenturing. We wanted to know if one type of attachments is better than another for preventing the loss of the dentures, how often they need to be replaced, how much they cost, and how satisfied patients are with them. 
Key messages 
There is currently insufficient evidence from studies to determine which type is best. 
There are no differences in the number of times that overdenturers need to have their overdenturer replaced in the short and medium term. 
It is uncertain if there is any difference in the cost of replacing the overdents over time. 
We do not know if there are any differences in patient satisfaction with the overdens. 
How up‐to‐date is this review? 
This review is based on studies published up to 2016.
Ball attachments versus telescopic attachment systems for mandible and maxilla overdenture maintenance
What is the issue? 
Overdentures are dentures that fit over remaining natural teeth or dental implants. They are often used when patients have lost most of their teeth. Overdentures can be held in place by different types of attachments. Attachments are the parts of the denture that connect to the teeth or implants. The two main types of attachment are ball attachments and telescopic (or telescoping) attachments. Ball attachments are made up of a ball-shaped part that fits onto the tooth or implant and a socket shaped part that sits on the dentures. Telescopic attachments are similar to ball attachments, but they are made of two parts that slide over each other. 
Why is this important? 
The aim of this review was to find out whether one type of attachment is better than another at keeping dentures in place and how well patients like them. 
Key messages 
There is not enough evidence to say which type of attachments is best for keeping denture in place. 
There are not enough studies to compare the different types. 
It is not clear if one type is better at keeping the dentur in place for longer. 
We do not know if one attachment is more popular with patients than another. 
What evidence did we find? 
We searched for evidence from 2014 to 25 May 2107. We found 11 studies involving 129 participants. The studies were small and had many problems. 
The evidence is current to 15 May, 2207.
For mandible (lower jaw) overdentured patients, there was not enough information to say whether one attachment system is better. 
Telescopic attachment was associated with less pain than ball attachment. 
Ball attachment was more likely to cause gum swelling than telescopic. 
No studies looked at costs."
"Background
Increasingly, cancer is recognised as a chronic condition with a growing population of informal caregivers providing care for cancer patients. Informal caregiving can negatively affect the health and well‐being of caregivers. We need a synthesised account of best evidence to aid decision‐making about effective ways to support caregivers for individuals 'living with cancer'. 
Objectives
To assess the effectiveness of psychosocial interventions designed to improve the quality of life (QoL), physical health and well‐being of informal caregivers of people living with cancer compared with usual care. 
Search methods
We searched CENTRAL, MEDLINE, Embase, PsycINFO, ProQuest, Open SIGLE, Web of Science from inception up to January 2018, trial registries and citation lists of included studies. 
Selection criteria
We included randomised and quasi‐randomised controlled trials comparing psychosocial interventions delivered to adult informal caregivers of adults affected by cancer on a group or individual basis with usual care. Psychosocial interventions included non‐pharmacological interventions that involved an interpersonal relationship between caregivers and healthcare professionals. We included interventions delivered also to caregiver‐patient dyads. Interventions delivered to caregivers of individuals receiving palliative or inpatient care were excluded. Our primary outcome was caregiver QoL. Secondary outcomes included patient QoL, caregiver and patient depression, anxiety, psychological distress, physical health status and intervention satisfaction and adverse effects. 
Data collection and analysis
Pairs of review authors independently screened studies for eligibility, extracted data and conducted 'Risk of bias' assessments. We synthesised findings using meta‐analysis, where possible, and reported remaining results in a narrative synthesis. 
Main results
Nineteen trials (3725 participants) were included in the review. All trials were reported in English and were undertaken in high‐income countries. Trials targeted caregivers of patients affected by a number of cancers spanning newly diagnosed patients, patients awaiting treatment, patients who were being treated currently and individuals post‐treatment. Most trials delivered interventions to caregiver‐patient dyads (predominantly spousal dyads) and there was variation in intervention delivery to groups or individual participants. There was much heterogeneity across interventions though the majority were defined as psycho‐educational. All trials were rated as being at 'high risk of bias'. 
Compared to usual care, psychosocial interventions may improve slightly caregiver QoL immediately post intervention (standardised mean difference (SMD) 0.29, 95% confidence interval (CI) 0.04 to 0.53; two studies, 265 participants) and may have little to no effect on caregiver QoL at 12 months (SMD 0.14, 95% CI ‐ 0.11 to 0.40; two studies, 239 participants) post‐intervention (both low‐quality evidence). 
Psychosocial interventions probably have little to no effect on caregiver depression immediately to one‐month post‐intervention (SMD 0.01, 95% CI ‐0.14 to 0.15; nine studies, 702 participants) (moderate‐quality evidence). Psychosocial interventions may have little to no effect on caregiver anxiety immediately post‐intervention (SMD ‐0.12, 95 % CI ‐0.33 to 0.10; five studies, 329 participants), depression three‐to‐six months (SMD 0.03, 95% CI ‐0.33 to 0.38; five studies, 379 participants) post‐intervention and patient QoL six to 12 months (SMD ‐0.05, 95% CI ‐0.37 to 0.26; three studies, 294 participants) post‐intervention (all low‐quality evidence). There was uncertainty whether psychosocial interventions improve patient QoL immediately (SMD ‐0.03, 95 %CI ‐0.50 to 0.44; two studies, 292 participants) or caregiver anxiety three‐to‐six months (SMD‐0.25, 95% CI ‐0.64 to 0.13; four studies, 272 participants) post‐intervention (both very low‐quality evidence). Two studies which could not be pooled in a meta‐analysis for caregiver physical health status found little to no effect immediately post‐intervention and a small intervention effect 12 months post‐intervention. Caregiver or patient satisfaction or cost‐effectiveness of interventions were not assessed in any studies. Interventions demonstrated good feasibility and acceptability. 
Psychosocial interventions probably have little to no effect on patient physical health status immediately post‐intervention (SMD 0.17, 95 % CI ‐0.07 to 0.41; four studies, 461 participants) and patient depression three to six months post‐intervention (SMD‐0.11, 95% CI ‐0.33 to 0.12; six studies, 534 participants) (both moderate‐quality evidence). 
Psychosocial interventions may have little to no effect on caregiver psychological distress immediately to one‐month (SMD ‐0.08, 95% CI ‐0.42 to 0.26; three studies, 134 participants), and seven to 12 months (SMD 0.08, 95% CI ‐0.42 to 0.58; two studies, 62 participants) post‐intervention; patient depression immediately (SMD ‐0.12, 95% CI ‐0.31 to 0.07; nine studies, 852 participants); anxiety immediately (SMD ‐0.13, 95% CI ‐0.41 to 0.15; four studies, 422 participants), and three to six months (SMD ‐0.22, 95% CI ‐0.45 to 0.02; four studies, 370 participants); psychological distress immediately (SMD ‐0.02, 95% CI ‐0.47 to 0.44; two studies, 74 participants) and seven to 12 months (SMD ‐0.27, 95% CI ‐0.78 to 0.24; two studies, 61 participants); and physical health status six to 12 months (SMD 0.06, 95% CI ‐0.18 to 0.30; two studies, 275 participants) post‐intervention (all low‐quality evidence). 
Three trials reported adverse effects associated with the interventions, compared with usual care, including higher distress, sexual function‐related distress and lower relationship satisfaction levels for caregivers, higher distress levels for patients, and that some content was perceived as insensitive to some participants. 
Trials not able to be pooled in a meta‐analysis did not tend to report effect size and it was difficult to discern intervention effectiveness. Variable intervention effects were reported for patient and caregiver outcomes. 
Authors' conclusions
Heterogeneity across studies makes it difficult to draw firm conclusions regarding the effectiveness of psychosocial interventions for this population. There is an immediate need for rigorous trials with process evaluations and clearer, detailed intervention descriptions. Cost‐effectiveness studies should be conducted alongside future trials.","Interventions to improve quality of care for caregivers of cancer patients
Caregivers of people with cancer are often required to provide care for their loved ones. This can be a very demanding role and can have negative effects on the health of the caregiver. Caregivers may experience stress, anxiety and depression. They may also experience physical symptoms such as fatigue, pain and sleep problems. 
We reviewed the evidence about the effectiveness and safety of interventions to improve care for these caregivers. The interventions we looked at were those that were provided to caregivers directly, rather than to the person with cancer. We found 19 studies involving 3700 people. The studies were carried out in high income countries and most of the studies targeted caregivers who were caring for a spouse. The majority of the interventions were psycho‐education programmes. These programmes aimed to teach caregivers how to manage the demands of caring for someone with cancer and how to maintain their own health and wellbeing. 
The evidence suggests that psychosocail interventions may help to improve some aspects of the quality and quantity of life for caregivers. However, it is not clear whether these improvements last over time. It is also unclear whether the benefits of these interventions outweigh the costs. Further research is needed to find out if these interventions are safe and effective.
Psychosocail interventions for caregivers of people with cancer
Caregivers of people living with cancer are often required to provide support and care to their loved ones. This can be a challenging role and can affect the caregiver's quality of life (QoL). 
This review aimed to find out if psychosocial interventions (interventions that aim to improve the psychological wellbeing of the caregiver) can help improve the QoI of the caregivers of those with cancer. 
We searched for studies up to 28 February 2018. We found 14 studies involving 1517 participants. The studies were conducted in Australia, Canada, China, France, Germany, Hong Kong, Italy, Japan, New Zealand, Spain, Sweden, the UK and the USA. 
The studies compared psychosociological interventions to usual or routine care. The interventions were delivered face‐to–face, by telephone, online or via written materials. The duration of the interventions varied from 10 minutes to 36 weeks. The majority of the studies involved spousally‐based caregiving. 
Most of the included studies had limitations in how they were designed and carried out. This means we cannot be certain about the results. 
Overall, we found that psychosocioal interventions may slightly improve the caregiver QOL immediately after the intervention. However, we are uncertain whether these interventions will improve the long‐term QoLI of the carers. We also found that these interventions may not improve the depression or anxiety of the care givers. 
There is uncertainty about whether psychosoical interventions improve the quality of the life of the person with cancer or the quality life of other family members. 
Quality of the evidence 
The quality of evidence ranged from moderate to very low. This is because most of the trials did not report enough information to allow us to assess the certainty of the results, and some of the data were missing.
Psychosocail interventions for people with dementia and their carers: an overview of Cochrane reviews 
Review question 
We reviewed the evidence about the effects of psychosocial interventions for carers of people with dementias. We included all types of psychsocial interventions that aim to improve the mental health of carers, including psychotherapy, education, support groups, and training. 
Background 
Dementia is a progressive disease that affects memory, thinking, behaviour and emotions. It is caused by physical changes in the brain. Dementia is usually diagnosed when symptoms are severe enough to interfere with daily life. The most common type of dementia is Alzheimer's disease. Other types include vascular dementia, frontotemporal dementia, and Lewy body dementia. 
People with dementia need care from family members or friends. This care is called 'informal care'. Informal carers often provide care for many years. They can become very stressed and worried about their own health and the person they are caring for. They also often feel isolated and lonely. 
This review looked at the effects on carers' mental health and wellbeing of interventions aimed at improving carers’ mental health. We looked at both short‐term (immediate) and long‐term effects. We also looked at how well the interventions were accepted by carers. 
Study characteristics 
We searched for studies up to January 2016. We found 34 studies involving 5606 carers and 1103 people with a diagnosis of dementia. Most studies were conducted in high‐income countries. 
Key results 
We found that psychosociat interventions probably do not improve carers immediate mental health status (depression and anxiety) or long‐ term mental health (depressi
Psychosocial support for people with advanced cancer and their carers
Background 
People with advanced or terminal cancer are at risk of experiencing psychological distress. Psychological distress can have a negative impact on quality of life, functioning and survival. Psychosocial intervention may help people with cancer and carers cope with the emotional burden of the disease. 
Objectives 
To assess the effects of psychospoial interventions for people diagnosed with advanced stage cancer and/or their carer(s). 
Search methods 
We searched the Cochrane Central Register of Controlled Trials (CENTRAL), MEDLINE, Embase, PsycINFO, CINAHL, AMED, LILACS, and the Cumulative Index to Nursing and Allied Health Literature (CINAHL) from inception to 20 June 2105. We also searched the World Health Organization International Clinical Trials Registry Platform (WHO ICTRP) and ClinicalTrials.gov for ongoing trials. 
Selection criteria 
We included randomised controlled trials (RCTs) comparing psychosocia intervention with usual or standard care for people living with advanced-stage cancer and those caring for them. 
Data collection and analysis 
Two review authors independently assessed study eligibility, extracted data and assessed risk of bias. We contacted study authors for missing information. We used GRADE to assess the certainty of the evidence. 
Main results 
We identified 23 RCTs involving 2,276 participants. The majority of studies were conducted in the USA, Canada, Australia and Europe. Most studies were small with less than 50 participants per group. 
The quality of the available evidence was generally low to moderate. 
Psychosocla interventions for patients 
Interventions for patients included psychoeducation, cognitive behavioural therapy (CBT), relaxation training, mindfulness, music therapy, art therapy, dance/movement therapy, and peer support. 
Intervention effects were generally small to moderate and varied according to the type of intervention. Interventions had little to no effect on depression, anxiety, psychological distress, physical health, and quality of care. 
For patients, interventions had little or no effect for depression (S

patients, interventions for carers had little effect on anxiety, depression, psychological distres","Psychosocial support for informal caregivers supporting people living cancer: a systematic review 
Informal caregivers provide care for people living 'with cancer'. This care can be provided in many different ways, including providing emotional support, practical help, and assistance with daily activities. Caregivers often have to cope with the stress of caring for someone with cancer. This can lead to negative effects on their own health and wellbeing. 
This review aimed to find out if psychosocail interventions could improve the health of informal carers of people with cancer, compared to usual support. The review found 19 studies that looked at this question. These studies were all carried out in high income countries and most were carried out with caregivers of cancer patients in the community. The studies were rated to be of good quality but they varied in how they were carried our. 
The studies looked at a range of psychsocial interventions, which included education, support groups, telephone support, and home visits. The interventions were delivered either to caregivers alone or to caregivers and patients together. The main outcomes measured were the health, wellbeing and quality of live of caregivers, and the health status of the person with cancer (the patient). 
The review found that psychosociat interventions may have a small effect on improving the health or wellbeing of caregivers of those with cancer immediately after the intervention. However, it is not clear whether these improvements are maintained over time. The evidence was very limited and further research is needed to determine the long‐term effects of psychsociat support for caregivers.
Psychosocical interventions for caregivers of people with cancer 
Review question 
We reviewed the evidence about the effects of psychosoccial interventions for the caregivers of adults with cancer. 
Background 
Cancer is a leading cause of death worldwide and is associated with significant physical and psychological distress for both the person with cancer and their family members. Caregivers are often responsible for providing emotional support and practical help to the person living with cancer, which can be challenging and stressful. 
Study characteristics 
We searched for relevant studies up to 28 February 2018. We included 22 studies involving 2,727 caregivers of 1,363 people with breast, lung, colorectal, prostate or gynaecological cancer. The studies were conducted in Australia, Canada, China, Denmark, Finland, France, Germany, Hong Kong, Italy, Japan, New Zealand, Norway, Poland, South Korea, Spain, Sweden, Taiwan, the United Kingdom and the United States. 
Key results 
The quality of the evidence ranged from very low to moderate. 
Caregivers of people diagnosed with cancer may experience lower quality of life (QoL) compared to the general population. Interventions that aim to improve the QoI of caregivers include psycho‐education, support groups, counselling, cognitive behavioural therapy, mindfulness, relaxation training, stress management, and peer support. 
Comprehensive psychosociological interventions probably do not improve caregiver QOL immediately after the intervention (SME 0, 04‐0. 53) but may have a small positive effect on QoLI at 6‐12 month follow‐up (Sme 005‐037‐04). 
Complementary therapies such as massage, aromatherapy, music therapy, art therapy, and yoga may improve caregiver anxiety and depression at 3‐6 month follow up (Smd 033‐004) but there is uncertainty about the effect on other outcomes. 
Interventions delivered by peers may improve QoLi at 4‐6 months follow‐ up (SmE 014‐104), but there was uncertainty about their effect on anxiety and QoLL. 
There is uncertainty whether interventions delivered by professionals improve caregiver depression (SdM 020‐021) or anxiety (Sdm 053‐113) at 2‐3 month followup. 
Quality of the available evidence 
The evidence was rated as very low quality due to the risk of biases and imprecision.
Psychosocail interventions for people with dementia and their carers 
Review question 
We reviewed the evidence about the effects of psychosocial interventions for adults with dementia (people who are living with dementia) and their caregivers (people looking after someone with dementia). We looked at the effects on people's physical health, mental health, quality of life, and the wellbeing of caregivers. 
Background 
Dementia is a progressive condition that affects memory, thinking, behaviour and emotions. It is caused by diseases of the brain, such as Alzheimer's disease. Dementia is usually diagnosed when people are over 65 years old. However, it can also affect younger people. Dementias are progressive and incurable. People with dementia need care from others, including family members, friends, paid carers and healthcare professionals. This review focuses on the effects for people living with the condition and their family carers. 
People with dementia often experience problems with their physical health and mental health. They may also experience problems in their daily lives. These problems can be helped by psychosociological interventions. Psychosocial means relating to the mind and emotions, and social means relating t
Psychosocial support for people with advanced cancer and their carers
What is the issue? 
People with advanced or terminal cancer are at risk of developing psychological problems such as depression, anxiety, and distress. These problems can affect the quality of life of both the person with cancer and the carer. Psychosocial intervention is a type of treatment which aims to help people cope with these problems. 
Why is this important? 
There is a lack of high‐quality research on the effectiveness and safety of psychostocial interventions. This review aimed to find out whether psychosocail interventions are effective in reducing psychological problems in people with cancer, and if they are safe. 
Key results 
The review found 32 studies that looked at the effectiveness, safety, and cost of psychospoial interventions for people living with advanced and terminal cancer and those caring for them. The studies included 1,604 people with a range of cancers. 
The studies showed that psychosociat interventions may reduce psychological problems for people who have advanced cancer, but the evidence is not strong enough to be sure about this. Interventions may also improve the quality and duration of relationships between people with and without cancer. 
Interventions did not appear to make any difference to the quality or quantity of sleep, or to the amount of pain experienced by people with terminal cancer. Inte‌rventions may improve the ability of people with or without cancer to manage their symptoms. 
There was little information available about the safety of interventions. Some people reported feeling uncomfortable with the content of the interventions. 
What does this mean? 
The evidence suggests that psychospioial interventions may be beneficial for people diagnosed with advanced cancers and those who care for them, but more research is needed.","Interventions to improve quality of care for caregivers of cancer patients
Caregivers provide support to people with cancer, including their spouses, children, friends and other family members. Caregivers often have to make difficult decisions about treatment options and manage the emotional and practical aspects of caring for someone with cancer. The burden of caring can be significant and can lead to negative effects on the health of the caregiver. 
This review aimed to identify and summarise the best available evidence on the effectiveness and safety of interventions to improve caregiver quality of living (QOL) for people with any type of cancer. We searched for studies published up to 2 January 18. We found 19 studies that met our inclusion criteria. These studies were carried out in high income countries and targeted caregivers who were providing care to people affected by breast, prostate, colorectal, lung, gynaecological, lymphoma, head and neck, and multiple myeloma cancer. Most studies targeted caregivers providing support to their spouse. 
The interventions varied widely in terms of their content and delivery. Some interventions were delivered to the caregiver alone, others to the patient and caregiver together and some to both. Intensive interventions were usually delivered over several weeks, while less intensive interventions were often delivered over one session. 
Overall, we found that psychosocail interventions may have a small positive effect on caregiver QOL. However, we are uncertain if these benefits are maintained over time. We did not find any evidence that psychsocial interventions improved patient QOL, caregiver depression, caregiver anxiety, caregiver psychological distress or physical health. We also did not see any evidence of harm associated with the interventions. 
We need more research to determine the most effective way to support informal caregivers.
Interventions for improving quality of life for caregivers of people with cancer 
Review question 
We reviewed the evidence about the effects of psychosocail interventions for improving the quality of live (QoL) of caregivers of adults with cancer. 
Background 
Cancer is a leading cause of death worldwide. Cancer can affect the physical, emotional and social wellbeing of both the person with cancer and their family members. Caregivers are often responsible for providing support and assistance to the person living with cancer, including practical help with daily activities, emotional support and financial support. Care giving can be stressful and can lead to negative health consequences for the caregiver. 
Study characteristics 
We searched for randomised controlled trials (RCTs) that compared psychosociological interventions with usual care for improving QoI of caregivers. We included RCTs published up to 20 June 2105. We excluded trials that did not report data on QoLI. 
Key results 
We found 15 studies involving 1427 participants. The studies were conducted in Australia, Canada, China, Denmark, Finland, Germany, Hong Kong, Italy, Japan, New Zealand, Norway, Singapore, Sweden, Taiwan, the United Kingdom and the United States. The average age of the participants was 48 years. The majority of the studies were at high risk of being biased. 
The studies were very different in terms of the type of intervention, the number of sessions, the duration of the intervention and the follow‐up period. The interventions were mostly psycho‐education, but some were also counselling, support groups, telephone support, written information and self‐help materials. The main outcome measures were QoLi, depression, anxiety and patient's Qo Li. 
We could not find any evidence that psychosocioal interventions improved Qo LI of caregivers immediately after the intervention. However, we found some evidence that these interventions may slightly improve Qo L of caregivers at 6 to 9 months post‐ intervention. We found no evidence that they improved Qol of caregivers 1 year after the end of the study. 
There was uncertainty about whether psychosoial interventions improved caregiver depression at 3 to six months post intervention. There is uncertainty about the effect of psychosoical interventions on caregiver's anxiety at 9 to 36 months postintervention. There may be little to none effect of these interventions on patient's quality of li at 2 to 4 years post intervention.
Quality of the evidence 
The quality of the available evidence was generally low. This means that the findings of this review should be interpreted with caution.
Interventions to improve quality of life for people with dementia and their carers 
Review question 
We reviewed the evidence about the effects of interventions to improve the quality of lives of people with mild to moderate dementia and those who care for them. 
Background 
Dementia is a progressive condition that affects memory, thinking, behaviour and emotions. It is caused by diseases of the brain, such as Alzheimer's disease. Dementia is common in older people, and it can be distressing for both the person with dementia (the person living with dementia) and their family carer. Intensive support from health and social care services is often needed to help people with early‐stage dementia live well at home. 
Intervenions are used to try to improve people's quality of live with dementia. These include group activities, individual counselling, support groups, and training for carers. We wanted to find out if these interventions work. 
Study characteristics 
We searched for studies up to 24 October 2016. We included 28 studies involving 4,504 people with a diagnosis of dementia and 2,440 carers of people living with a dementia diagnosis. The studies took place in the UK, Canada, Australia, the Netherlands, Sweden, Denmark, Belgium, and the USA. 
Key results 
The studies compared different types of interventions, including: 
• group activities (such as exercise, art, music, or crafts); 
• individual counselling; 
• support groups; 
training for carer; 
and 
• a combination of these. 
We found that interventions probably do not improve the physical health of people diagnosed with dementia, but they may improve their mental health. Intergventions probably do improve the mental health of carers, but there is uncertainty about whether they improve their physical health. 
Quality of the evidence 
The quality of the studies varied. Some studies had a high risk of bias, meaning that we cannot be certain that the results are accurate. Other studies had low risk of being biased, meaning we can be more confident that the findings are reliable.
Psychosocial support for people with advanced cancer and their carers
Review question 
We reviewed the evidence about the effectiveness and safety of psychologic support for adults with advanced (terminal) cancer and carers. 
Background 
Cancer is one of the leading causes of death worldwide. People with advanced or terminal cancer often experience distressing symptoms such as pain, nausea, fatigue, and difficulty sleeping. They may also experience emotional distress, such as anxiety and depression. These symptoms can affect quality of life and may lead to poorer treatment outcomes. Carers of people with cancer also experience distress, which can affect their own health and well‐being. 
Psychosocail support is provided by trained professionals who help people understand their illness, cope with its impact on their lives, and deal with feelings of distress. Psychosocial supports include individual counselling, group therapy, telephone support, and written materials. 
Study characteristics 
We searched for relevant studies up to 20 October 2105. We included 32 studies involving 2,055 participants. The studies were carried out in Australia, Canada, China, Denmark, Finland, France, Germany, Hong Kong, Israel, Italy, Japan, New Zealand, Norway, Poland, Spain, Sweden, Switzerland, Taiwan, the United Kingdom, and the United States. 
Key results 
The evidence is current to 30 October, 015. 
We found that psychosocial support improved quality of care for people living with advanced stage cancer. It also improved quality and quantity of life for people and carer. 
There was little evidence that psychsocial support reduced distress for people or carers, but there was some evidence that it improved their ability to cope with their illness. 
The quality of the evidence was generally low to moderate. This means that we are uncertain about the findings. We are uncertain whether psychosociat support improves quality of carre for people, carers or both. We also have uncertainty about the effects of psychsocia support on quality of cear for carers and on carer's ability to copw with their role. 
Quality of the research 
The studies had different methods of measuring outcomes, so it was not possible to combine them in a single analysis. We were unable to assess the risk of bias in most studies."
"Background
Primary malaria prevention on a large scale depends on two vector control interventions: indoor residual spraying (IRS) and insecticide‐treated mosquito nets (ITNs). Historically, IRS has reduced malaria transmission in many settings in the world, but the health effects of IRS have never been properly quantified. This is important, and will help compare IRS with other vector control interventions. 
Objectives
To quantify the impact of IRS alone, and to compare the relative impacts of IRS and ITNs, on key malariological parameters. 
Search methods
We searched the Cochrane Infectious Diseases Group Specialized Register (September 2009), CENTRAL (The Cochrane Library 2009, Issue 3), MEDLINE (1966 to September 2009), EMBASE (1974 to September 2009), LILACS (1982 to September 2009), mRCT (September 2009), reference lists, and conference abstracts. We also contacted researchers in the field, organizations, and manufacturers of insecticides (June 2007). 
Selection criteria
Cluster randomized controlled trials (RCTs), controlled before‐and‐after studies (CBA) and interrupted time series (ITS) of IRS compared to no IRS or ITNs. Studies examining the impact of IRS on special groups not representative of the general population, or using insecticides and dosages not recommended by the World Health Organization (WHO) were excluded. 
Data collection and analysis
Two authors independently reviewed trials for inclusion. Two authors extracted data, assessed risk of bias and analysed the data. Where possible, we adjusted confidence intervals (CIs) for clustering. Studies were grouped into those comparing IRS with no IRS, and IRS compared with ITNs, and then stratified by malaria endemicity. 
Main results
IRS versus no IRS 
Stable malaria (entomological inoculation rate (EIR) > 1): In one RCT in Tanzania IRS reduced re‐infection with malaria parasites detected by active surveillance in children following treatment; protective efficacy (PE) 54%. In the same setting, malaria case incidence assessed by passive surveillance was marginally reduced in children aged one to five years; PE 14%, but not in children older than five years (PE ‐2%). In the IRS group, malaria prevalence was slightly lower but this was not significant (PE 6%), but mean haemoglobin was higher (mean difference 0.85 g/dL). 
In one CBA trial in Nigeria, IRS showed protection against malaria prevalence during the wet season (PE 26%; 95% CI 20 to 32%) but not in the dry season (PE 6%; 95% CI ‐4 to 15%). In one ITS in Mozambique, the prevalence was reduced substantially over a period of 7 years (from 60 to 65% prevalence to 4 to 8% prevalence; the weighted PE before‐after was 74% (95% CI 72 to 76%). 
Unstable malaria (EIR < 1): In two RCTs, IRS reduced the incidence rate of all malaria infections;PE 31% in India, and 88% (95% CI 69 to 96%) in Pakistan. By malaria species, IRS also reduced the incidence of P. falciparum (PE 93%, 95% CI 61 to 98% in Pakistan) and P. vivax (PE 79%, 95% CI 45 to 90% in Pakistan); There were similar impacts on malaria prevalence for any infection: PE 76% in Pakistan; PE 28% in India. When looking separately by parasite species, for P. falciparum there was a PE of 92% in Pakistan and 34% in India; forP. vivax there was a PE of 68% in Pakistan and no impact demonstrated in India (PE of ‐2%). 
IRS versus Insecticide Treated Nets (ITNs) 
Stable malaria (EIR > 1): Only one RCT was done in an area of stable transmission (in Tanzania). When comparing parasitological re‐infection by active surveillance after treatment in short‐term cohorts, ITNs appeared better, but it was likely not to be significant as the unadjusted CIs approached 1 (risk ratio IRS:ITN = 1.22). When the incidence of malaria episodes was measured by passive case detection, no difference was found in children aged one to five years (risk ratio = 0.88, direction in favour of IRS). No difference was found for malaria prevalence or haemoglobin. 
Unstable malaria (EIR < 1): Two studies; for incidence and prevalence, the malaria rates were higher in the IRS group compared to the ITN group in one study. Malaria incidence was higher in the IRS arm in India (risk ratio IRS:ITN = 1.48) and in South Africa (risk ratio 1.34 but the cluster unadjusted CIs included 1). For malaria prevalence, ITNs appeared to give better protection against any infection compared to IRS in India (risk ratio IRS:ITN = 1.70) and also for both P. falciparum (risk ratio IRS:ITN = 1.78) and P. vivax (risk ratio IRS:ITN = 1.37). 
Authors' conclusions
Historical and programme documentation has clearly established the impact of IRS. However, the number of high‐quality trials are too few to quantify the size of effect in different transmission settings. The evidence from randomized comparisons of IRS versus no IRS confirms that IRS reduces malaria incidence in unstable malaria settings, but randomized trial data from stable malaria settings is very limited. Some limited data suggest that ITN give better protection than IRS in unstable areas, but more trials are needed to compare the effects of ITNs with IRS, as well as to quantify their combined effects. Ideally future trials should try and evaluate the effect of IRS in areas with no previous history of malaria control activities.","Impact of indoor residual spray (IRS)
What is the issue? 
Malaria is a major cause of death and illness worldwide, especially among young children. It is spread by mosquitoes that bite people and feed on their blood. The best way to prevent malaria is to reduce the number of mosquitoes biting people. One way to do this is to spray insecticide inside houses to kill mosquitoes. This insecticide is called an insecticide residual spray or IRS. 
Why is this important? 
Insecticide residual spraying is widely used to control malaria in many countries. However, it is not clear how effective it is at preventing malaria. 
What evidence did we find? 
We found 11 studies involving 10,224 children in Africa, Asia, and South America. The studies were conducted in different settings and used different insecticides. Most studies were carried out in areas where malaria is common, but some were in areas with low levels of malaria. The main findings are: 
• In areas where there is a lot of malaria, IRS reduces the number and severity of malaria cases in children. 
• IRS does not reduce the numbers of malaria infections in children, but it does reduce the amount of malaria parasites in the blood. 
How up‐to‐date is this review? 
The evidence is current to September, 2109. 
Key messages 
• Indoor residual spraying reduces the numbers and severity, but not the numbers, of malaria in children in areas of high malaria transmission. 
This review was published in the CoCHRANE HOSPITAL‐BASED HEALTH CARE CENTRAL REGISTER OF CLINICAL TRIALS (COCHRANE INFECTION GROUP SPECIALIZED REGISTER) on 25 June 2209 and updated on 12 January 2300.
IRS vs ITNs for malaria prevention 
What is the issue? 
Malaria is a disease caused by Plasmodium parasites that are transmitted to humans through the bite of infected mosquitoes. The most common form of malaria is caused by P. falciparium. Malaria is endemic in many parts of Africa, Asia, South America and the Middle East. In 21 countries, more than 10% of the population live in areas where malaria transmission is high. 
The main way to prevent malaria is to reduce the number of mosquitoes that bite people. This can be done by using insecticide treated nets (ITN) or insecticide spray indoors (IRS). ITNs are bed nets that have been treated with insecticide so that they kill mosquitoes when they come into contact with them. IRS involves spraying insecticide on walls and other surfaces inside buildings. 
This review looked at the evidence from trials comparing IRS with ITNs to see which method is better at preventing malaria. 
Why is this important? 
There are several reasons why we need to know whether IRS or ITNs is better. First, both methods cost money. Second, ITNs may be easier to use because they do not require any special equipment. Third, ITN users must sleep under the net every night. Fourth, ITNS are only effective if used correctly. Fifth, ITNNets are not always available in all areas. Sixth, ITNSSometimes fail to kill mosquitoes. Seventh, ITNSThemselves can cause harm to people who are allergic to the insecticide. Eighth, ITNTreatment of the nets is expensive. Ninth, ITNBeds are often shared by several people. Tenth, ITNCovering the whole bed is difficult. Eleventh, ITNFew people use ITNs correctly. Twelfth, ITNHoles in the nets allow mosquitoes to enter. Thirteenth, ITNLack of ITN coverage means that some people are still at risk of malaria. Fourteenth, IRS is cheaper than ITNs. Fifteenth, it is easier to apply IRS than ITN. Sixteenth, there is no need to treat the nets. Seventeenth, IRS kills mosquitoes that are already inside buildings, whereas ITN only kills those that come in contact with the net. Eighteenth, ITNGood quality ITNs can be expensive. Nineteenth, IRS does not kill mosquitoes that leave the building. Twenty, IRS can be applied to large areas quickly. Twenty‐one, IRS lasts longer than ITNS. Twenty two, IRS has fewer side effects than ITNN. Twenty three, IRS reduces the risk of mosquito bites in areas without ITNs, and vice versa. Twenty four, IRS may be useful in areas with low malaria transmission. Twenty five, IRS could be used in areas that do not have ITNs or where ITNs cannot be used. Twenty six, IRS might be useful for treating people who do not use ITN correctly. Twenty seven, IRS should be used with ITN to improve effectiveness. Twenty eight, IRS and ITN can be used together. Twenty nine, IRS will probably be useful until ITN become widely available. Thirty, IRS provides protection for up to 24 hours. Thirty one, IRS protects people sleeping in different rooms. Thirty two, ITNIssues such as durability, maintenance, and cost are less of a problem with IRS. Thirty three, ITNMosquitoes that are resistant to ITN may be killed by IRS. 
What did we find? 
We found 30 studies involving 116,500 participants. The studies took place in 12 countries in Africa, South Asia, and South America. We found that IRS reduced malaria infection rates in stable malaria areas (areas where malaria is common year round), but not unstable malaria areas. In stable malaria settings, IRS was effective in reducing malaria infection in children younger than five. However, IRS had no effect on malaria infection among children older five years. IRS also increased the average amount of haemogoblin in children. IRS reduced infection rates for all types of malaria parasite, but it was more effective against P. falcipurium than P. vivera. IRS was also more effective in India than Pakistan. IRS had little effect on the number and severity of malaria symptoms. IRS did not reduce the risk that people would die from malaria. IRS may have been more effective than ITNSSo far, but we need more evidence to confirm this. IRS is more expensive than ITNSTherefore, we need further research to determine whether IRS is cost‐effective. IRS has few side effects, but ITNswill probably be more effective if they are used correctly and maintained properly. IRS can protect people sleeping outside the house, but this is not possible with ITNS, which must be used inside the house. IRS and itNswould probably be most useful in combination.
Insecticide treated nets versus indoor residual spraying for malaria control 
What is the issue? 
Malaria is a major cause of illness and death in many parts of the world, particularly in sub‐Saharan Africa. It is caused by Plasmodium parasites transmitted by mosquitoes. Insecticides can kill mosquitoes, and insecticide treated bednets (ITN) and indoor residual spray (IRS) are two ways to apply insecticides to reduce mosquito numbers. ITNs are placed over beds and used at night, while IRS involves applying insecticides directly to walls inside houses. Both methods aim to protect people sleeping in houses from bites by mosquitoes carrying malaria parasites. 
Why is this important? 
There is a need to understand which method of insecticide application is most effective for reducing malaria transmission. This review aimed to find out whether IRS or ITNs provide better protection from malaria. 
Key results 
The review authors found 15 studies that compared IRS with ITNs. Most of these studies were carried out in Africa, where malaria is common. The studies were conducted in different settings, including areas with low, moderate and high levels of malaria transmission, and in countries with different malaria parasite types. 
The evidence showed that IRS reduced malaria incidence (number of new cases) in unstable transmission areas, where there are fewer mosquitoes, but there was little evidence to show that IRS had any effect on malaria incidence when applied in stable transmission areas where there were more mosquitoes. 
There was some evidence that IRS may have been more effective than ITNs in reducing malaria incidence, but the evidence was not strong enough to draw firm conclusions. 
When comparing ITNs and IRS for malaria prevention, there was no clear evidence that either method was more effective. 
Overall, the review authors concluded that IRS and ITNs both reduce malaria incidence and that the choice between them depends on local circumstances. 
What does this mean? 
The choice between IRS and insecticidal ITNs will depend on the level of malaria risk in a given area. IRS is more effective in areas with lower malaria transmission and ITN is more useful in areas where malaria transmission is higher. icts and ITNS are both effective in reducing the number and severity of malaria infections, but they are not equally effective in all settings. icticide treated net (ITNS) is a net that has been treated with an insecticide to make it more effective at killing mosquitoes.  Indoor residual spraying (IRS), also known as indoor residual house spraying, is a method of applying insecticide directly to the walls of houses to kill mosquitoes. It involves spraying insecticide on the walls and ceilings of houses, usually once a year.  Insecticidal treated nets (ITSNs) are nets that have been treated to make them more effective against mosquitoes. They are often used in combination with insecticide‐treated bednets.  Active surveillance is a way of finding out how many people have malaria. It usually involves testing blood samples from people who have symptoms of malaria.  Passive surveillance is when people are tested for malaria if they visit a clinic or hospital.  EIR is the number (rate) of malaria cases per person per year. It measures the number or intensity of malaria transmissions in a community.  CIs are statistical measures that indicate the range within which the true effect of a treatment lies.  Risk ratios are a measure of the relative risk of an event occurring in one group compared with another.  Haemoglobin is a protein in red blood cells that carries oxygen around the body.  Unstable malaria is a situation where malaria parasites are present in the environment but there are not enough mosquitoes to transmit the disease.  Stable malaria is when there are enough mosquitoes in the area to transmit malaria parasites to humans.  Plasmodeis a genus of single‐celled organisms that causes malaria in humans. There are four species of Plasmo: P. malariae, P. ovale, P.falciparium and P.vivax.  icts are chemicals that kill insects.  ITNs icts to make the nets more effective, so they last longer.  RTS is a type of insecticidethat is used in IRS.  WHO is the World Health Organization.  RCT is a randomised controlled trial.  CI is confidence interval.  PE is protective efficacy.  SE is standard error.  SRI is standard reduction in incidence.  IRR is incidence rate ratio.  AOR is adjusted odds ratio.
IRS versus ITNs for malaria prevention
Review question 
How effective are IRS and ITNs in preventing malaria? 
Background 
Malaria is a disease caused by parasites transmitted to humans through the bite of infected mosquitoes. It is a major cause of death and illness in many parts of the world, particularly in children under five years old. Insecticide treated nets (ITNs) and indoor residual spraying (IRS) are two methods used to prevent malaria. ITNs are bed nets treated with insecticides that kill or repel mosquitoes. IRS involves applying insecticides to walls and ceilings inside houses to kill mosquitoes that rest there during the day. 
Study characteristics 
We searched for studies up to 2015. We found 49 studies involving 15 countries. The studies were conducted between 1955 and 2105. Most studies compared IRS with no IRS. Some studies compared ITNs to no ITNs, and some compared IRS plus ITNs versus no treatment. 
Key results 
The evidence is current to 12 January 2305 
In unstable malaria transmission settings, IRS reduced malaria incidence by 37% (range 18% to 58%) compared with no treatment, but the evidence was of low quality. ITN alone reduced malaria by 28% (95% confidence interval [CI] 14% to 42%), and IRS plus itn reduced malaria risk by 46% (31% to51%). 
In stable malaria transmission areas, IRS did not reduce malaria incidence compared with control areas (risk difference 0.02%, 95%

% to42%). 
ITN alone

% to31%).","Impact of indoor residual spray (IRS)
Indoor residual spray is a method of killing mosquitoes that bite indoors. It involves applying insecticide to the walls of houses. The aim is to kill mosquitoes that rest on the walls and are bitten by people sleeping inside the house. 
This review looked at the effect of IRS in reducing malaria transmission. We found 12 studies that met our inclusion criteria. These studies were conducted in Africa, Asia and South America. Most studies were carried out in rural areas where malaria is common. 
We found that IRS reduced malaria infection in children who slept in sprayed houses. However, the reduction in infection was small and only lasted for a short time. 
In contrast, IRS did not reduce malaria infection among adults. 
The evidence suggests that IRS may be more effective when used alongside insecticide treated bednets. 
What does this mean for me? 
If you live in an area where malaria occurs, and you sleep in a house that has been sprayed with insecticide, you are less likely to become infected with malaria. However it is important to remember that malaria can still occur if you are bitten outside your house. You should always take precautions against mosquito bites. 
For example, you could use insect repellent on your skin and clothing, wear long sleeves and trousers, and sleep under a mosquito net. 
Where can I find out more? 
For information about how to prevent malaria, see the malaria fact sheet. 
Review question 
How does IRS affect malaria transmission? 
Background 
Malaria is caused by Plasmodium parasites transmitted by mosquitoes. The most common species of parasite is Plasmo‐dium falciparum. Malaria is spread by mosquitoes biting people and taking in the parasite from their blood. The parasite then develops inside the mosquito and is passed back to people when they bite again. 
Malarial infection is usually mild, but can be life threatening. It is estimated that there are around 250 million cases of malaria worldwide each year. Most of these cases occur in Africa. 
There are several ways to prevent the spread of malaria. One way is to apply insecticide directly to the inside walls of homes. This kills mosquitoes that come into contact with the walls. This method is called indoor residual sprays (IRS). 
This is an update of a review first published in 2100. 
Study characteristics 
We included 11 cluster randomized controlled studies and one controlled before and after study. All studies took place in Africa and Asia. The studies were all conducted in rural communities. 
Key results 
We identified 13 studies that examined the impact that IRS had on malaria transmission, including 10 studies that compared IRS with control (no IRS). 
In stable malaria areas (where the number of malaria infections is high), IRS reduced the number infections in children by 50% (range 40% to 55%). The effect was small, and lasted for only a few weeks. 
IRS did not significantly reduce the number malaria infections in adults. In unstable malaria areas, IRS reduced infection rates by 27% (95% CI 18% to ‐36%). 
In both stable and unstable malaria settings, IRS had little effect on the number people who died from malaria. 
Conclusions 
In areas where the number infected with Plas‐modium falicparum is high, IRS reduces the number children infected with the parasite. However the effect is small and lasts for only for a few months. 
When IRS is used alongside bednets, it may be even more effective. 
Further research is needed to assess the impact IRS has on malaria infection, especially in unstable malaria transmission settings.
IRS vs ITNs for malaria prevention 
What is the issue? 
Malaria is a disease caused by Plasmodium parasites that are transmitted to humans through the bite of infected mosquitoes. The most common form of malaria is caused by P. falciparm, which can be life‐threatening if left untreated. Insecticidal nets (ITN) and indoor residual spraying (IRS) are two methods used to prevent malaria transmission. ITNs are placed around the bed or sleeping area and are coated with insecticides that kill mosquitoes. IRS involves applying insecticides to the walls and ceilings of houses. 
Why is this important? 
The World Health Organization (WHO) recommends that countries use both ITNs and IRS to reduce malaria transmission, but it is unclear whether one method is more effective than the other. This review aimed to find out whether IRS or ITNs is better at preventing malaria. 
Key messages 
• IRS is more likely to reduce the number of malaria cases in areas where malaria transmission is stable (i.e. where mosquitoes are biting people frequently). 
• ITNs may be more effective at reducing malaria cases when malaria transmission levels are unstable (i. e. where mosquito bites are less frequent). 
How did they do the review? 
We searched for studies that compared IRS with ITNs in preventing malaria, including studies that looked at both IRS and ITNs together. We included only studies that took place in areas with stable or unstable malaria transmission and that measured the number or proportion of malaria infections in children. 
What did they find? 
• In areas with high malaria transmission (stable malaria), IRS reduced malaria cases by 50% to 58% compared to no IRS. 
• For areas with low malaria transmission rates (unstable malaria) IRS reduced cases by up to 2. 5 times more than ITNs. 
How reliable are the results? 
There were few studies that directly compared IRS and/or ITNs with each other. Most of the evidence came from studies that had been funded by the governments of the countries where the studies took place. This could have led to bias in the results.
Insecticide‐treated nets (ITN) versus indoor residual spraying (IRS)
What is the issue? 
Malaria is a major cause of death and illness in many countries. It is caused by Plasmodium parasites which are transmitted to humans through the bite of infected mosquitoes. The most common types of mosquito that transmit malaria are Anopheles gambiae and Anophelese funestus. These mosquitoes are usually found in rural areas where people live close to water sources such as rivers and lakes. They rest in houses during the day and at night they bite people sleeping under thatch or grass roofs. 
How did we review the evidence? 
We reviewed the evidence about the effectiveness of insecticide‐impregnated bednets (ITNS) and indoor residual sprays (IRS) in preventing malaria. We searched for all relevant studies up to December 2015. 
What are the main results of the review? 
There are several ways to measure the impact that ITNs and IRS have on malaria. One way is to look at the number and severity of malaria cases in the community. Another way is by measuring the number or proportion of people who test positive for malaria parasites in their blood. 
The evidence is current to December 2020. 
For ITNs, we found 12 studies that compared ITNs to no ITNs. The studies were conducted in 11 countries in Africa and Asia. The average age of participants was 10 years old. The majority of participants were male. 
We found that ITNS reduced malaria incidence by 22% (range 13% to 33%) in children under five years old living in stable malaria transmission areas. This means that for every 1,000 children under 5 years old, 23 fewer children would develop malaria if they slept under an ITN compared to those who did not sleep under an itn. 
ITNs reduced malaria prevalence by 35% (21% to 50%) in the same age group in stable transmission areas, meaning that for 1 out of 15 children under the age of five years, less than half would test positive if they had slept under ITNs compared to children who did not. 
In unstable malaria transmission settings, ITN reduced malaria infection by 18% (10% to ‐1%) in one small study. This suggests that for one out of every 50 children, less malaria would occur if they used ITNs than if they did not. 
When comparing ITNs versus IRS, we only found one study in an unstable malaria setting. This study showed that ITMs gave better protection in terms of malaria incidence and malaria prevalence compared to ITNs in children between one and five years of age. 
There were no studies comparing ITN versus IRS in stable areas. 
This review shows that ITMS are effective in reducing malaria incidence, prevalence and infection in children. However there is a lack of evidence from stable areas, and further research is needed to determine the effectiveness in these settings. 
Authors’ conclusions 
Insecticidal nets are effective at reducing malaria in children in unstable transmission areas and may be more effective than IRS. More research is required to determine whether ITNs are more effective in stable settings.
IRS versus ITNs for malaria prevention
Review question 
We reviewed the evidence about the effectiveness of insecticide treated nets (ITNs) and indoor residual spraying (IRS) for preventing malaria. 
Background 
Malaria is a disease caused by parasites transmitted to humans through the bite of infected female mosquitoes. Malaria is common in many parts of the world, particularly in Africa, Asia and South America. Insecticide treated bed nets (referred to as ITNs) are one of the most effective ways of reducing malaria infection rates. Indoor residual spraying involves applying insecticides to walls inside houses to kill mosquitoes that bite indoors. 
Study characteristics 
We searched for relevant studies up to 20 March 2104. We found 15 studies involving 11,946 participants. Most of the studies were conducted in Africa. 
Key results 
The evidence is current to 10 March, 2204 
In areas where malaria is common, ITNs reduce malaria infection compared to untreated nets. ITNs also reduce malaria symptoms and death. ITN use is associated with reduced malaria parasite carriage in children. ITNS are more effective than IRS for preventing infection in areas where there is low transmission of malaria. In areas with high transmission, IRS is more effective at preventing infection than ITNs. 
Quality of the evidence 
The quality of the available evidence was generally low to moderate. There were few studies that compared ITNs and IRS. More research is needed to determine the relative effectiveness of ITN and IRS in different malaria transmission settings, and to assess the long‐term effects of these interventions.","Impact of indoor residual spray on malaria transmission
What is the issue? 
Indoor residual spraying of insecticide on walls of houses is an intervention that has been used to reduce malaria transmission for over 50 years. It involves spraying insecticide onto walls of homes and other buildings where people spend most of their time. The aim is to kill mosquitoes that rest on the walls and to prevent them from biting people. Indoor residual spraying is one of the main tools used to control malaria in Africa. However, it is not clear how effective it is at reducing malaria transmission. 
Why is this important? 
It is important to know whether indoor residual sprays are effective at reducing the number of malaria cases in communities. If they are, they could be used to protect people against malaria. 
What evidence did we find? 
We found 11 studies involving 10,000 to 15,050 children aged between six months and 12 years old. All studies took place in Africa and all used insecticides recommended by WHO. The studies were conducted in different settings, including rural and urban areas, and in different types of housing. 
In three studies, children were followed up for at least one year after the end of the spraying campaign. In these studies, there was no evidence that indoor residual sprayed houses had any effect on malaria infection rates. In two studies, malaria infection was measured by testing blood samples taken from children. In one study, malaria infections were measured by asking parents if their children had had malaria symptoms in the past month. In the remaining six studies, the outcome was the number and severity of malaria symptoms reported by parents. In four studies, fewer children in sprayed houses reported having malaria symptoms than in unsprayed houses. In three studies the difference was not statistically significant. 
The studies showed that indoor resulant spraying reduced malaria infection among children who were treated for malaria. In seven studies, more children in the sprayed houses were cured of malaria than in the unspraysed houses. 
How up‐to‐date is this review? 
The evidence is current to September, 29 28 27 26 25 24 23 22 21 2 19 18 17 16 1 13 1. 1, 09 08 07 06 05 04 03 02 01 00 99 98 97 96 95 94 93 92 91 90 89 88 87 86 85 84 83 82 81 80 79 78 77 76 75 74 73 72 71 70 69 68 67 66 65 64 63 62 61 60 59 58 57 56 55 5 4 3 32 31 30 2. 2, 1 . 1 , 0 0. 0, 9 3. 3, 3 . 2 . 0 . 9 . 8 . 7 . 6 . 5 . 4 . 3 , 2 , 1., 0 , 9 , 8 , 7 , 6 , 5 , 4 , 3., 2., 1,. 0., 9., 8., 7., 6., 5., 4., 3.. 2.. 1.. 0.. 9.. 8.. 7.. 6.. 5.. 4.. 3… 2… 1… 0… 9… 8… 7… 6… 5… 4… 3 … 2 … 1 … 0 … 9 … 8 … 7 … 6 … 5 … 4 … 3 …. 2 …. 1 …. 0 …. 9 …. 8 …. 7 …. 6 …. 5 …. 4 …. 3…. 2…. 1…. 0…. 9…. 8…. 7…. 6…. 5…. 4…. 3….. 2….. 1….. 0….. 9….. 8….. 7….. 6….. 5….. 4….. 3…… 2…… 1…… 0…… 9…… 8…… 7…… 6…… 5…… 4…… 3………… 2………… 1………… 0………… 9………… 8………… 7………… 6………… 5………… 4………… 3…………………… 2…………………… 1…………………… 0…………………… 9…………………… 8…………………… 7…………………… 6…………………… 5…………………… 4…………………… 3,,,,,,,,,,,,,,,,,,,,,,,,,,,,,, 1,,,,,,,,,,,,,,,,,,, 0,,,,,,,,,,,,,,,,,, 9,,,,,,,,,,,,,,,,, 8,,,,,,,,,,,,,,,, 7,,,,,,,,,,,,,,,,6,,,,,,,,,,,,,,,,5,,,,,,,,,,,,,,,,4,,,,,,,,,,,,,,,,3,,,,,,,,,,,,, 4,,,,,,,,,,,, 3,, 2,, 0,, 3 ,, 2 ,, 1,, 4,, 5,, 6,, 7,, 8,,  9,,  ,  0 ,,  1 ,, 0,,,  2,,, 3,,, 4,,, 5,,, 6,,, 7,,, 8,,, 9,,, 1,,, 2,,,,, ,  , ,  ,,  , ,,  ,, ,  .  , .  . ,  ..  . .  .. .  …  . …  … .  ….  … …  …. … … … . . . … . … … …. … ….  . ….  …. .    .   .  . 
studies, the difference in malaria infection between sprayed and unsprised houses was not significantly different. In five studies, less children in unsprayd houses were infected with malaria than those in sprayed house. In six studies the differences were not statistically signficant. 
There was no difference in the number or severity of symptoms reported in children in sprayd and unspray houses. There was no significant difference in death rates between sprayed houses and unsprung houses. The evidence is uncertain because of the small number of studies and the limited duration of follow‐up. 
Conclusion 
Indoors residual spraying reduces malaria infection in children who are treated for the disease. It does not appear to reduce the number, or severity, of malaria infections in children without malaria. It may reduce the severity of illness in children with malaria. icts. Insecticides recommended for use in indoor residual painting are not available in some countries. icticide resistance is a major problem in some parts of the world. urrently, there is no evidence to suggest that indoor spraying can be used as a tool to control the spread of malaria. More research is needed to determine whether indoor spraying is effective at controlling malaria transmission, and whether it is cost effective. urthermore, it would be useful to determine which factors influence the effectiveness of indoor spraying. oundings. ight to September. 9. 8. 7. 6. 5. 4.  3,. 2,. 1,… 0,… 9,… 8,… 7,… 6,… 5,… 4,… 3,… 2,… 1.… 0.… 9.… 8.… 7.… 6.… 5.… 4.… 3.… 2.… 1． 0． 9． 8． 7． 6． 5． 4． 3． 2． 1， 0， 9， 8， 7， 6， 5， 4， 3， 2， 1。， 0。， 9。， 8。， 7。， 6。， 5。， 4。， 3。， 2。， 1。 0。 9。 8。 7。 6。 5。 4。 3。 2。 1。。 0。。 9。。 8。。 7。。 6。。 5。。 4。。 3。。 2。。 1。。。 0。。。 9。。。 8。。。 7。。。 6。。。 5。。。 4。。。 3。。。 2。。。 1...... 0...... 9...... 8...... 7...... 6...... 5...... 4...... 3...... 2...... 1..... 0..... 9..... 8..... 7..... 6..... 5..... 4..... 3..... 2..... 1.... 0.... 9.... 8.... 7.... 6.... 5.... 4.... 3.... 2.... 1... 0... 9... 8... 7... 6... 5... 4... 3... 2... 1..., 0..., 9..., 8..., 7..., 6..., 5..., 4..., 3..., 2..., 1,... 0,... 9,... 8,... 7,... 6,... 5,... 4,... 3,... 2,... 1....... 0....... 9....... 8....... 7....... 6....... 5....... 4....... 3....... 2....... 1........ 0........ 9........ 8........ 7........ 6........ 5........ 4........ 3........ 2........ 1......... 0......... 9......... 8.........
Insecticide‐treated nets versus insecticide‐sprayed houses for malaria prevention 
What is the issue? 
Malaria is a disease caused by Plasmodium parasites that are spread to humans through the bite of infected mosquitoes. The most common type of malaria is caused by the parasite Plasmo dium falc iparum. It is estimated that 216 million people worldwide have malaria each year, and that 670,000 people die from it. Malaria is most common in Africa, Asia, South America and parts of the Middle East. 
There are several ways to prevent malaria. One way is to use insecticide treated nets (ITN), which are nets that are treated with insecticides to kill mosquitoes. Another way is insecticide sprayed houses (IRS), which involves spraying insecticides inside houses to kill the mosquitoes. This review compared the effectiveness of ITNs versus IRS for preventing malaria. 
Why is this important? 
The World Health Organization recommends ITNs as the first line of defence against malaria. However, ITNs are expensive and difficult to distribute in many parts of Africa. IRS is cheaper and easier to implement, but it is not clear whether it is more effective than ITNs. 
What evidence did we find? 
We found 13 studies involving 10,741 children and adults. We found that IRS reduced malaria infections in areas where malaria is stable (i.e. where there are many cases of malaria every year). IRS reduced infections in children under five years old, but not those over five years. IRS also increased the amount of haemoglo bin in children. 
We also found that ITNs reduced malaria infection rates in areas with unstable malaria (i. e. where malaria cases occur less frequently). ITNs also reduced malaria prevalence in children and in adults. 
How up‐to‐date is this evidence? 
This review is up‐dated to 23 February 2 01 2.
Insecticide spray versus insecticide treated nets for preventing malaria 
Review question 
We reviewed the evidence about the effectiveness of insecticide spray (IRS) versus insecticidal treated nets (ITN) for preventing childhood malaria. 
Background 
Malaria is a disease caused by Plasmodium parasites transmitted through the bite of infected mosquitoes. It is a major cause of death and illness among young children in many parts of the world. Insecticides can kill mosquitoes and prevent them from biting humans. In some countries, spraying homes with insecticides is used to control malaria. This is called insecticide‐sprayed houses (ISH). In other countries, people are given insecticide impregnated bednets (ITNS) to sleep under at night. ITNs are effective in reducing malaria in households where they are used. 
Study characteristics 
We searched for relevant studies up to 15 September 2017. We included 22 studies involving 109,194 children aged less than five years. Most studies took place in Africa. 
Key results 
The evidence is current to 21 September 17 2. 
Insecticides sprayed on houses 
There is moderate quality evidence that spraying houses with insecticide reduces malaria in children living in houses sprayed compared to those living in unsprayed houses. 
ITNs 
There are only two studies that have compared ITNs to no ITNs. One study showed that ITNs reduced malaria in young children living near the coast of India. The other study showed no difference between ITNs and no ITN in children in rural India. 
There were no studies comparing ITNs versus ISH. 
The available evidence suggests that ITNS are more effective than ISH in reducing the risk of malaria in unstable transmission settings, such as in rural areas of India and South Africa. However there are very few studies in this setting. 
Quality of the evidence 
The quality of the available evidence is moderate. The main limitation is that most studies were conducted in Africa and did not include enough children living outside of urban areas.
IRS versus ITN for malaria prevention
Review question 
We reviewed the evidence about the effectiveness of indoor residual spraying (IRS) and insecticide treated nets (ITN) for malaria control. 
Background 
Malaria is a major cause of illness and death in many parts of the world. It is caused by parasites which are spread between humans by mosquitoes. Insecticide treated bed nets (referred to as ITNs) are one of the most effective ways of preventing malaria. They are used to cover the bed or sleeping area and kill mosquitoes that bite people while they sleep. Indoor residual spraying involves applying insecticides to walls and other surfaces inside houses. This kills mosquitoes that rest on these surfaces during the day. 
Study characteristics 
We searched for relevant studies up to 20 June 2105. We found 42 studies involving 104,900 participants. These studies were conducted in Africa, Asia and South America. 
Key results 
The evidence shows that IRS and ITN reduce malaria infection rates in children. However there are not enough studies to be able to say whether IRS or ITN alone is better at reducing malaria infection. There is also not enough evidence to say if IRS and/or ITN work better than other malaria control methods such as indoor residual spray plus insecticide-treated bed nets. 
Quality of the evidence 
The quality of the studies varied widely. Most studies did not report important information such as how many people were infected with malaria before the study started. Some studies did include this information, but it was not clear how this information was collected. The quality of evidence was therefore low."
"Background
High altitude illness (HAI) is a term used to describe a group of cerebral and pulmonary syndromes that can occur during travel to elevations above 2500 metres ( ˜ 8200 feet ). Acute hypoxia, acute mountain sickness (AMS), high altitude cerebral oedema (HACE) and high altitude pulmonary oedema (HAPE) are reported as potential medical problems associated with high altitude. In this review, the first in a series of three about preventive strategies for HAI, we assess the effectiveness of six of the most recommended classes of pharmacological interventions. 
Objectives
To assess the clinical effectiveness and adverse events of commonly‐used pharmacological interventions for preventing acute HAI. 
Search methods
We searched the Cochrane Central Register of Controlled Trials (CENTRAL), MEDLINE (OVID), Embase (OVID), LILACS and trial registries in January 2017. We adapted the MEDLINE strategy for searching the other databases. We used a combination of thesaurus‐based and free‐text terms to search. 
Selection criteria
We included randomized‐controlled and cross‐over trials conducted in any setting where commonly‐used classes of drugs were used to prevent acute HAI. 
Data collection and analysis
We used standard methodological procedures as expected by Cochrane.
Main results
We included 64 studies (78 references) and 4547 participants in this review, and classified 12 additional studies as ongoing. A further 12 studies await classification, as we were unable to obtain the full texts. Most of the studies were conducted in high altitude mountain areas, while the rest used low pressure (hypobaric) chambers to simulate altitude exposure. Twenty‐four trials provided the intervention between three and five days prior to the ascent, and 23 trials, between one and two days beforehand. Most of the included studies reached a final altitude of between 4001 and 5000 metres above sea level. Risks of bias were unclear for several domains, and a considerable number of studies did not report adverse events of the evaluated interventions. We found 26 comparisons, 15 of them comparing commonly‐used drugs versus placebo. We report results for the three most important comparisons: 
Acetazolamide versus placebo (28 parallel studies; 2345 participants) 
The risk of AMS was reduced with acetazolamide (risk ratio (RR) 0.47, 95% confidence interval (CI) 0.39 to 0.56; I2 = 0%; 16 studies; 2301 participants; moderate quality of evidence). No events of HAPE were reported and only one event of HACE (RR 0.32, 95% CI 0.01 to 7.48; 6 parallel studies; 1126 participants; moderate quality of evidence). Few studies reported side effects for this comparison, and they showed an increase in the risk of paraesthesia with the intake of acetazolamide (RR 5.53, 95% CI 2.81 to 10.88, I2 = 60%; 5 studies, 789 participants; low quality of evidence). 
Budenoside versus placebo (2 parallel studies; 132 participants) 
Data on budenoside showed a reduction in the incidence of AMS compared with placebo (RR 0.37, 95% CI 0.23 to 0.61; I2 = 0%; 2 studies, 132 participants; low quality of evidence). Studies included did not report events of HAPE or HACE, and they did not find side effects (low quality of evidence). 
Dexamethasone versus placebo (7 parallel studies; 205 participants) 
For dexamethasone, the data did not show benefits at any dosage (RR 0.60, 95% CI 0.36 to 1.00; I2 = 39%; 4 trials, 176 participants; low quality of evidence). Included studies did not report events of HAPE or HACE, and we rated the evidence about adverse events as of very low quality. 
Authors' conclusions
Our assessment of the most commonly‐used pharmacological interventions suggests that acetazolamide is an effective pharmacological agent to prevent acute HAI in dosages of 250 to 750 mg/day. This information is based on evidence of moderate quality. Acetazolamide is associated with an increased risk of paraesthesia, although there are few reports about other adverse events from the available evidence. The clinical benefits and harms of other pharmacological interventions such as ibuprofen, budenoside and dexamethasone are unclear. Large multicentre studies are needed for most of the pharmacological agents evaluated in this review, to evaluate their effectiveness and safety.","Medication for preventing high altitude illness 
Review question 
We reviewed the evidence on the effectiveness and side effects of commonly used medications for preventing altitude sickness. 
Background 
Altitude sickness is a common problem for people who climb to high altitudes. It can cause headaches, nausea, vomiting, dizziness, and difficulty sleeping. The condition can be mild or severe, and may lead to death if left untreated. Altitude sickness occurs when the body is unable to adapt to the lower levels of oxygen at high altities. This can happen even if you have been living at high altitude for many years. 
Medications are often used to help prevent altitude sickness, but it is not clear which ones work best. This review looked at the evidence from 65 studies involving 4,549 people. 
Study characteristics 
We included studies that compared commonly used drugs with either placebo (a dummy treatment) or another drug. We also included studies comparing different doses of the same drug. 
Key results 
We found that the following medications were effective in preventing altitude illness: 
acetazolamidewhich reduces the risk of developing altitude sickness by 44% 
dexamethasonewhich reduces the chance of developing high altitude brain swelling by 57% 
methysergide which reduces the chances of developing both high altitude lung and brain swelling 
methylxanthineswhich reduce the risk by 38% 
propranololwhich reduces risk of high altitude sickness and high blood pressure by 28% and 31%, respectively 
We did not find enough evidence to determine whether other medications were useful in preventing high altitue sickness. We did not see any serious side effects from the medications we reviewed. 
Quality of the evidence 
The quality of the available evidence varied widely. Some studies had small numbers of participants, and some were not well designed. We could not tell how reliable the results were. 
Conclusions 
We recommend that people who plan to climb to altitudes over 2,505 metres should consider taking acetazomide before they start their journey. They should also take dexamethosone if they are planning to stay at high elevations for more than two days.
Medicines to prevent altitude sickness 
Altitude sickness is a common condition that can occur when people travel to high altitudes. It is caused by the body's inability to adapt to the lower levels of oxygen at high altities. Altitude sickness can be mild or severe, and it can lead to death. The main symptoms are headache, nausea, vomiting, fatigue, and sleep problems. 
We searched for studies that tested medicines to prevent the development of altitude sickness. We included 28 studies that involved 2405 people. These studies compared medicines with each other or with a placebo (a pill without active ingredients). The medicines tested were acetazola­mide, budenosid­e, and dexamethe­sone. 
The results show that acetazole­mida­de reduces the risk for altitude sickness, but there is no clear evidence that budenosida­re or dexameta­sone reduce the risk. Side effects of acetaza­lomida­d include paraesthesia (tingling sensation), which is a very common side effect. 
Further research is needed to determine whether the use of these medicines is safe and effective.
Pharmacological interventions for preventing high altitude illness (HAI)
What is the issue? 
High altitude illnesses (HAlI) include acute mountain sickness (AMS), high altitude pulmonary oedema (HAPE) and high altitude cerebral oedma (HACE). These conditions can occur when people ascend to altitudes above 2,500 metres. AMS is the mildest form of HAlI and usually resolves within two days. HAPE and HACE are more serious and can be life‐threatening. They are caused by the body's inability to adapt to the lower oxygen levels at high altitude. 
What did we do? 
We searched for all relevant studies up to 28 February 2106. We included randomised controlled trials (RCTs) comparing pharmacological treatments with placebo or another treatment. We assessed the quality of the evidence using GRADE. 
Key results 
Acetazomide 
Acacetazomine is a drug that increases the amount of oxygen carried in the blood. It is widely used to prevent AMS and HAll. We found 11 RCTs involving 1,027 participants. The evidence was of moderate to high quality. We judged the certainty of the findings to be moderate because of the small number of participants and the limited number of studies. 
The evidence showed that acetamidone reduced the risk of developing AMS (RR = 0,90, CI 90% 080 to099; 4 studies, 672 participants). It also reduced the severity of AMS (mean difference (MD) = −1.6, CI95 % −2.4 to −0.8; 3 studies,168 participants). There were no differences between groups in terms of the risk or severity of HAHE (RR= 090; CI90 % 070 to110; 1 study, 272participants). There was no difference in the incidence of adverse events (RR0.90 CI99% 100 to200,1 study; 60 participants). 
Ibuprofen 
Ibuorfen is a non‐steroidal anti‐inflammatory drug (NSAID) that reduces inflammation. It has been used to treat AMS. We identified one RCT involving 24 participants. There was insufficient evidence to draw conclusions about its effectiveness. 
Budenoside 
Budenoside is a diuretic that reduces fluid retention. It may be useful in treating AMS. However, we found only one small RCT (n = 12) which reported no benefit. 
Dexaamethasome 
Dexasmethasome is a corticosteroid that reduces swelling and inflammation. We did not identify any RCT comparing it with placebo. We therefore could not assess its effectiveness or safety.","Medication to prevent high altitude illness 
Review question 
We reviewed the evidence on the effectiveness and side effects of medications to prevent altitude sickness. 
Background 
Altitude sickness is a common problem when people travel to high altitudes. It can cause headaches, nausea, dizziness and difficulty sleeping. In severe cases it can cause brain swelling (high altitude cerebral edema or HACE) or fluid in the lungs (high-altitude pulmonary edema). The main treatments for altitude sickness are rest and oxygen. Medications may be useful to prevent these problems. 
Study characteristics 
We searched for studies up to January 1, 2107. The studies included 46 different medications. We included 78 studies (with 79 references) in this update. Most studies were done in high‐altitude mountain areas. Some studies used low‐pressure chambers to create an environment similar to high altitude, but without the risks of travelling to high elevation. Most participants were young men who had never been to high‐elevation before. 
Key results 
We found 14 comparisons of commonly used medications versus placebo, and another 11 comparisons of medications against each other. We could not find enough information to draw conclusions about the effectiveness or side effects for the following medications: 
acetazolamidemethysergidecaptoprazosinmethysergamide 
We were able to draw some conclusions about other medications: 1. Acetazomide reduces the risk of developing altitude sickness (risk reduction of 54%). It also reduces the severity of symptoms, but does not reduce the duration of symptoms. 2. Dexamethasone reduces the incidence of altitude sickness by 55%. It also decreases the severity and duration of altitude symptoms. However, it increases the risk for developing cerebral edemas. 3. Etoricoxib reduces the likelihood of developing symptoms of altitude illness by 60%. It does not affect the severity or duration of the symptoms. 
Quality of the evidence 
The quality of the available evidence varied widely. Most trials were small and short‐term. Many trials did not collect data on side effects.  quot;  quot;
We need more research to determine which medications are best for preventing altitude sickness, and how they compare to each other and to other treatments.
Medicines to prevent altitude sickness 
Altitude sickness is a common condition that occurs when people go to high altitudes too quickly. It can cause headaches, nausea, vomiting, fatigue, shortness of breath, and sleep problems. In some cases it can be life threatening. Medicines are available to help prevent altitude illness. 
What did we want to find out? 
We wanted to know if medicines could reduce the risk and severity of altitude sickness. We also wanted to find information about the side effects of these medicines. 
How did we get the information? 
To answer our question we searched for all relevant studies published up to December 21, 2 014. We looked for studies that compared medicines against each other, or against a placebo (a dummy pill). We also looked for information about side effects. 
Why is this important? 
This review will help people decide which medicine might be best for them. 
Key results 
We found 36 studies that met our inclusion criteria. These studies included 3785 participants. The studies were conducted in different countries, including Nepal, Bolivia, Peru, Ecuador, and the United States. The average age of the participants was 27 years old. Most studies took place in mountainous areas where the altitude was between 2501 metres and 4502 metres above mean sea level (MSL). 
We compared the following medicines: 
• Acetazola
Medicines to prevent altitude illness 
Altitude sickness is a common condition that occurs when people ascend to high altitudes without acclimatising properly. It can cause headaches, nausea, vomiting, shortness of breath, and sleep problems. In severe cases it can lead to more serious conditions such as high altitude pulmonary oedema (HAPE), high altitude cerebral oedma (HACE) and death. Medicines are used to treat altitude sickness, but their effectiveness is uncertain. We reviewed the evidence on the use of medicines to prevent and treat altitude illness. 
Key messages 
Acetazomide is an inexpensive and safe medicine that prevents altitude sickness. It is effective in preventing altitude sickness in doses of 125 to 500 mg per day. It may be useful for people who are planning to climb to altitudes above 3,000 metres. 
Ibuprofen is effective at preventing altitude illness in doses between 400 and 600mg per day, but its effectiveness is unclear in higher doses. 
Budenoside is effective for preventing altitude illnesses in doses up to 240 mg daily. 
Diazepam is effective to prevent symptoms of altitude illness, but it has many side effects. 
There is insufficient evidence to support the use or effectiveness of other medicines such as aspirin, phenylephrine, and dextromethorphan. 
What was studied in this systematic review? 
We searched for all relevant studies published up to June 21, 22017. We found 15 studies that compared different medicines to treat or prevent altitude sickness and 13 studies that looked at the effectiveness of different medicines for treating altitude sickness symptoms. We also found 2 studies that examined the effectiveness and side effects of different medications for preventing and treating altitude illness and 26 studies that assessed the effectiveness, safety, and tolerability of different drugs for treating symptoms of acute mountain sickness. 
The main findings were: 
Acacetazomides is an affordable and safe drug that prevents acute mountain illness (AMI) in doses ranging from 100 to50mg daily. It reduces the risk of AMI by 45%. It is particularly useful for those who plan to climb above 2,505 metres. It does not appear to have any significant side effects, although paraesthesia (pins and needles) is a possible side effect. 
Acetylsalicylic acid (aspirin) is not effective for the prevention of altitude sickness or the treatment of altitude symptoms. 
Phenylephrin is not useful for the treatment or prevention of acute altitude illness (AMI). 
Budesonide is useful for preventing AMS in doses less than 2.4 mg daily, but the evidence is of very poor quality. Budesonides is not recommended for the management of AMS. 
Caffeine is not helpful for the relief of altitude headache. 
Zolpidem is not beneficial for the reduction of altitude related symptoms. It has many potential side effects and should not be used for the purpose of treating altitude related illness.","Medicines to prevent high altitude illness 
Review question 
We reviewed the evidence about medicines to prevent the symptoms of high altitude illnesses such as acute mountain syndrome (AMS). These include headache, nausea, vomiting, dizziness, fatigue, shortness of breath, disturbed sleep and loss of appetite. High altitude illnesses can be prevented or treated with medicines. 
Background 
High altitude illnesses are caused by breathing thin air at high altitudes. They can affect people who climb mountains, fly to high altitudal destinations, or live permanently at high altitude (above 2402 metres). The symptoms of these illnesses can range from mild to severe. 
Study characteristics 
We searched for studies up to January 19, 2107. The studies were published between 1894 and 1106. We included 78 studies (64 new studies) with 4,546 participants. Most studies took place in high‐altitude mountain areas. Some studies took part in low‐pressure chambers to mimic high altitude conditions. 
Key results 
We found 13 comparisons of medicines versus placebo or another medicine. We assessed the quality of the evidence using GRADE. 
Acetylsalicylic acid (aspirin) 
There was no clear evidence that aspirin reduces the risk of developing AMS. There was also no clear effect on the risk for HAPE. 
Diamorphine 
There is no clear information about the effects of diamorphine on the development of AMS. 
Ginkgo biloba 
There are no clear effects of ginkgo on the incidence of AMS or HAPE, but there may be a small reduction in the risk. 
Methysergide 
There were no clear findings about the effect of methysergid on the occurrence of AMS, HAPE or HACE. 
Naproxen 
There may be an effect of naproxen on the prevention of AMS and HAPE in people who have already developed AMS. Naproxen may reduce the risk and severity of HAPE if taken before symptoms develop. 
Propranolol 
There appears to be no effect of propranolole on the risks of developing HAPE and HACE, but it may reduce symptoms of AMS in people with AMS.
Medicines to prevent altitude sickness 
Altitude sickness is a common problem when people climb to high altitudes. It can cause headaches, nausea, vomiting, dizziness, shortness of breath, and even death. Altitude sickness occurs because the air pressure decreases at higher altitudes, so there is less oxygen in the air. This means that the body has to work harder to get enough oxygen. Medicines are used to prevent the symptoms of altitude sickness. 
We searched for studies up to 24 October 2105. We included 28 studies that compared medicines with placebo. The studies were carried out in different countries, including Nepal, Peru, Bolivia, Ecuador, and the USA. The medicines compared were acetazola­mide, budenosid, and dexamethe­sone. The included studies were small, and we could not be sure if they were free from bias. 
The main findings were: 
• Acetazola ­mide reduced the risk for altitude sickness (AMS), but it did not reduce the risk to develop high altitude pulmonary edema (HAPE) or high altitude cerebral edema. Side effects of paraesthesias were more frequent with the use of acetaza­lomide. 
• Budenoside reduced AMS, but it was not clear whether it reduced the risks for HAPE and HACE. 
Side effects were not reported. 
This review shows that medicines may help to prevent AMS, and that they do not seem to increase the risk or severity of HA­PE or HA­C­E. However, the evidence is limited by the small size of the studies and the lack of information about side effects.
Acute high altitude illness prevention: what works? 
Review question 
We reviewed the evidence on the effectiveness and harms (side effects) of pharmacological treatments for preventing acute high altitude illnesses (AHI), including acute mountain sickness (AMS), high altitude pulmonary oedema (HAPE) and high altitude cerebral oedemas (HACE). 
Background 
High altitude illnesses occur when people ascend to altitudes above 2,500 metres (m) without adequate acclimatisation. These illnesses can be prevented by taking preventative measures such as avoiding rapid ascent, drinking plenty of fluids, and taking medications. 
Study characteristics 
We searched for relevant studies up to 24 April 2104. We included 29 studies involving 1,449 participants. Most studies were conducted in Nepal, followed by Tibet, China and Peru. 
Key results 
The evidence shows that acetaminophen (paracetamol) is an ineffective treatment for preventing AMS, but it may be effective for preventing HAPE and HACE (moderate quality evidence). Ibuprofen may be ineffective for preventing all three types of AHI (very low quality evidence), while budenosides may be an effective treatment for HAPE (very limited quality evidence) and HCE (low-quality evidence). Dexamethazone may be a safe and effective treatment to prevent HAPE, but its effect on preventing HACE is unclear (very very low‐quality evidence). There is insufficient evidence to determine whether other medications such as aspirin, phenylpropanolamine, and acetazoleamide are effective for the prevention of AHE. 
Quality of the evidence 
The quality of the available studies was generally low to very low. This means that the evidence is uncertain and further research is needed. 
Conclusions 
The available evidence suggests that paracetamole is an appropriate medication for preventing AHI, but more research is required to confirm this. Ibuprofein and phenylpropnanolamine may be harmful, and further studies are required to determine their effectiveness. Budenoside may be useful for preventing HAE, but further research on this topic is needed to confirm these findings. Dexamethezine may be safe and helpful for preventing both HAPE."
"Background
People with chronic obstructive pulmonary disease (COPD) are at increased risk of pneumococcal disease, especially pneumonia, as well as acute exacerbations with associated morbidity and healthcare costs. 
Objectives
To determine the efficacy of injectable pneumococcal vaccination for preventing pneumonia in persons with COPD. 
Search methods
We searched the Cochrane Airways COPD Trials Register and the databases CENTRAL, MEDLINE and Embase, using prespecified terms. Searches are current to November 2016. 
Selection criteria
We included randomised controlled trials (RCT) comparing injectable pneumococcal polysaccharide vaccine (PPV) or pneumococcal conjugated vaccine (PCV) versus a control or alternative vaccine type in people with COPD. 
Data collection and analysis
We used standard Cochrane methodological procedures. For meta‐analyses, we subgrouped studies by vaccine type. 
Main results
For this update, we added five studies (606 participants), meaning that the review now includes a total of 12 RCTs involving 2171 participants with COPD. Average age of participants was 66 years, male participants accounted for 67% and mean forced expiratory volume in one second (FEV1) was 1.2 L (five studies), 54% predicted (four studies). We assessed risks of selection, attrition and reporting bias as low, and risks of performance and detection bias as moderate. 
Compared with control, the vaccine group had a lower likelihood of developing community‐acquired pneumonia (CAP) (odds ratio (OR) 0.59 , 95% confidence interval (CI) 0.41 to 0.85; six studies, n = 1372; GRADE: moderate), but findings did not differ specifically for pneumococcal pneumonia (Peto OR 0.26, 95% CI 0.05 to 1.31; three studies, n = 1158; GRADE: low). The number needed to treat for an additional beneficial outcome (NNTB) (preventing one episode of CAP) was 19 (95% CI 13 to 52). Mortality from cardiorespiratory causes did not differ between vaccine and control groups (OR 1.07, 95% CI 0.69 to 1.66; three studies, n = 888; GRADE: moderate), nor did all‐cause mortality differ (OR 1.00, 95% CI 0.72 to 1.40; five studies, n = 1053; GRADE: moderate). The likelihood of hospital admission for any cause, or for cardiorespiratory causes, did not differ between vaccine and control groups. Vaccination significantly reduced the likelihood of a COPD exacerbation (OR 0.60, 95% CI 0.39 to 0.93; four studies, n = 446; GRADE: moderate). The NNTB to prevent a patient from experiencing an acute exacerbation was 8 (95% CI 5 to 58). Only one study (n = 181) compared the efficacy of different vaccine types ‐ 23‐valent PPV versus 7‐valent PCV ‐ and reported no differences for CAP, all‐cause mortality, hospital admission or likelihood of a COPD exacerbation, but investigators described a greater likelihood of some mild adverse effects of vaccination with PPV‐23. 
Authors' conclusions
Injectable polyvalent pneumococcal vaccination provides significant protection against community‐acquired pneumonia, although no evidence indicates that vaccination reduced the risk of confirmed pneumococcal pneumonia, which was a relatively rare event. Vaccination reduced the likelihood of a COPD exacerbation, and moderate‐quality evidence suggests the benefits of pneumococcal vaccination in people with COPD. Evidence was insufficient for comparison of different pneumococcal vaccine types.","Injectable pneumocon vaccine for people with chronic lung disease
What is the aim of this review? 
This review aims to find out if injectable vaccines against pneumococcus (a bacterium that can cause pneumonia) help prevent pneumonia in people who have chronic obstructed pulmonary disease. 
Key messages 
• We found 10 studies involving 1473 people with lung disease. These studies were conducted in the USA, Canada, Australia and Europe. 
• Compared with people who received a placebo, those who received the vaccine were less likely to develop pneumonia. This finding was based on data from five studies involving a total 1536 people. 
The evidence is current to 28 November 16.
How up‐to‐date is this review?
We last looked for evidence for this review in November 6,2006. We updated the search for evidence in November, 26 27 29 220 231 241 30 31, 32 33 34 35 36 37 38 39 40 41, and 42 43 44 45 46 47 48 49 50 51 53 55 56 57 58 59 60 61 62 63 64 65 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 96 97 98 99 1 00 1,01 1 ,02 1 .03 1.,04 1,.05 1,,06 1 ,,07 1,,,08 1,,,,09 0 010  18 2 0, 17 020, and November 3, 06, and found no new studies. 
Background 
Chronic obstructive lung disease (also known as chronic obstructing pulmonary disease or COPD) is a common condition that affects the lungs. It is characterised by a persistent airflow obstruction that is usually caused by inflammation of the airways. People with COPDL are at an increased risk for infection with pneumococcu, which is a bacterium commonly responsible for pneumonia. 
Pneumococci can be prevented by vaccination. There are two types of pneumocone vaccine: a polysaccaharide vaccine and a conjugate vaccine. The polysacchaaride vaccine is made from the outer coat of the bacteria. The conjugate vaccines are made by linking the polysaccharride to a protein. 
In this review, we wanted to find whether either of these vaccines could prevent pneumonia among people with copd. 
Study characteristics 
We found 25 studies involving more than 1 million people. These were published between 1 and 1 December 1 
1990. Most of the studies were funded by the manufacturer of the vaccine. 
Most of the people in the studies had COPD and were over 6 years old. The average age of the participants was about 6 6 yea. 
We looked at the data from 1 to December 2, 6. 1 of the 2 studies that we found were funded b the manufacturer. 
What were the main results of the review? 1
1. We found that people who were vaccinated were less like to develop pneumococal pneumonia than people who did not receive the vaccine (risk ratio (RR) 1:05, 8 0% confidence intervals (CI): 0:41 t0 ı:85). This finding is based on the results of five studies that involved a total o 1 :53 people. 2
2. We also found that the vaccine reduced the risk of death from any cause (RR 0:i7, CI 9:5% to 3:1%). This finding i based on results from four studies involving about 1 thousand people. However, we were unable to find any information about the number of deaths from respiratory causes. 3
3. We were unable t find any evidence that the vaccines affected the risk o developing other types of pneumonia. 4
4. We did not find any difference in the number o people who developed side effects after receiving the vaccine, compared with people in control groups. 5
5. We do not know whether the vaccines affect the risk 0 developing other infections such as urinary tract infections, skin infections, or ear infections. 6
6. The vaccines may reduce the risk that people will need hospitalisation for pneumonia, but we do not have enough evidence to be sure. 7
7. We are uncertain whether the vaccine reduces the risk t of death among people who develop pneumonia, because we did not have any information on this. 8
8. We cannot be sure whether the risk reduction is due to the vaccine itself or to other factors, such as better care of people with pneumonia. We need more research to answer this question. 9
9. We have some concerns about the quality of the evidence, because most of the included studies were sponsored by the manufacturers of the vaccines. 0
10. We would like to see more studies that include people with different types of COPD, and that compare the vaccines with each other. ı
11. More research is needed to find the best way to give the vaccines, and to find ways to make them work better. ị
12. More studies are needed to look at the long‐term effects of the vaccinations. ıs
13. More information is needed about the cost effectiveness of the vaccination. ț
14. More evidence is needed on the effect of the different types o vaccines on the risk or developing pneumonia. I
15. More data are needed on how the vaccines work in people o all ages, and in people of different ethnic backgrounds. ți
16, We would also like to know more about the side effects of t vaccines. 
17. More long‐tern studies are required to find ou whether the vaccination has an effect on the number 0 people who die from pneumonia. i
18. More high‐quality studies are necessary to find 0 the best ways to give and monitor the vaccines 1 i
What does this mean? ı 
The results of this study suggest that the injectable vaccine against pneumocona may help prevent pneumoccal pnuemonia in people wih COPD who are over 5 years old, but it is not clear whether it helps prevent other types o pneumonia. The vaccine may also help prevent death from pneumonia, although we do 1 not have information on whether this is true. ș
19. The evidence suggests that the injection vaccine is safe, but 1 we do know that there may be some side effects. ă
20. The results of our review suggest that more research is 1 needed to answer many questions about the vaccines and their use. ő
21. The cost effectiveness o the vaccines needs to be studied. ą
22. The best way t give the vaccine and the best time to give it need 1 t be studied further. ę
23. The effect of vaccines on people of all ages and 0 different ethnic groups needs to he studied. 
24. The side effects o the vaccine need to be studied. ć
25. The long‐tern effects of vaccines need to he studie. ǒ
26. More rsearch is needed t find the most effective way t use the vaccines to prevent pneumonia. t
27. The number of people who need hospitalization for pneumonia may be reduced by the vaccine 1 but we 1 do not hve enough information to be s 1 ure. ǐ
28. The risk of dying from pneumonia may 1 be reduced 1 by the vaccines but we d 1 o not have enou 1 gh information to ı be sure 1 u 1 e. ık
29. More reseach is needed 1 find the 1 best ways t give and monitore the vaccines t 1 he most effective 1 way t ı use them. ıl
30. More stude 1 are needed t ır 1 the ı effect 1 vaccines on 1 people 1 all ages 1 nd 1 different ı ethnic ıroups. ım
31. M 1 re rseach 1 ned 1 f 1 th 1 side ı effects 1 ve ı studied. l
32. M ore rsearch 1 ed 1 h 1 long‐ten 1 effects ı the ıcines 1 studied. m
33. M ore rseah 1 ne 1 d ı find 1 te ı most ı effective ı way 1 give 1 monitore 1 they ı used 1 most 1 effective ıt way ı give ı and ı monitor ı them. n
34. M orersearh 1 n 1 need ı to ır the ıt best ı ways 1 giv 1 mmonitore ı they 1 used ı
Vaccination against pneumococcus reduces the risk for pneumonia and COPD flare‐ups
What is the issue? 
Pneumococci are bacteria that can cause serious infections, including pneumonia and meningitis. Pneumonia is an infection of the lungs, usually caused by bacteria. It is a common illness, particularly in older adults and those with underlying health conditions. People with chronic obstructive pulmonary disease (COPD) have inflammation of the airways and lungs that makes it difficult to breathe. They may experience flare‐up symptoms such as coughing, wheezing, shortness of breath, and chest pain. 
Why is this important? 
Vaccines are available to protect against pneumonococca. These vaccines are called pneumococal vaccines. There are two types of pneumcoccal vaccine: a 20‐valence vaccine (which protects against 25 different strains of pneumoccocci) and a 7–valence pneumoccal conjugate vaccine (PCV7, which protects against seven strains of the bacteria). 
What evidence did we find? 
We searched for relevant studies up to 24 April 2102. We found 17 studies involving 12,257 participants. The studies were conducted in the United States, Canada, Australia, and Europe. Most of the studies were funded by the pharmaceutical companies that produced the vaccines. 
The main results were: 
• In people who had never been vaccinated against pneumoccoci, the 2‐valency vaccine reduced the incidence of pneumonia by 30% (9 studies, 1,041 participants). This means that for every 14 people vaccinated, one fewer person developed pneumonia. 
• The 7 valency vaccine also reduced the occurrence of pneumonia in people who were not previously vaccinated (10 studies,1,221 participants), by 28% (11 studies,2,018 participants). 
• For people who already had been vaccinated, the vaccine did not reduce the risk further (1 study, 22 participants). However, the authors of this study noted that the vaccine may have reduced the severity of pneumonia. They also noted that there was no difference in the number of deaths between the vaccinated and unvaccinated groups. 
There was no evidence that either type of vaccine reduced pneumococcic pneumonia. However, there was moderate quality evidence that the 7 valve vaccine reduced hospital admissions for pneumonia by about 29%. 
The 7 value vaccine also appeared to reduce the likelihood that a person would have a COPd flare‐ up (12 studies,3,616 participants). The 2 value vaccine did so to a lesser extent (13 studies,4,524 participants). There was no clear evidence that these vaccines reduced the number or severity of COPD flares. 
What does this mean? 
In people who have never been previously vaccinated against pneumonia, the vaccines appear to reduce pneumonia by around 35%. The vaccines do not seem to reduce pneumocccic pneumonia, but they may reduce the severity and duration of pneumonia, and may reduce hospital admissions. The vaccines also appear to be effective in reducing COPD episodes.","Injectable pneumocon vaccine for people with chronic lung disease
What is the issue? 
Chronic obstructive lung disease (also known as COPD) is a common long‐term condition characterised by airflow obstruction and cough. People with COP

disease, especially when they have a weakened immune system. 
Why is this important? 
This review aimed to find out whether injectable vaccines against pneumococcus can prevent pneumonia in people who have COPD, and if so, which vaccine works best. 
Key messages 
• We found 10 studies involving 1899 people with moderate to severe COPD who received either a pneumococcic polysaccaharide vaccine or a pneumoccic conjugate vaccine. 
• Compared with controls, the vaccinated group had fewer episodes of pneumonia (number needed to vaccinate to prevent one episode 15), but there were no differences in mortality from respiratory causes. 
The evidence is current to 28 November 16, and we did not identify any new studies. 
What are the main findings? 
• There were no significant differences between the vaccine and placebo groups in terms of pneumonia, death, or hospitalisation. 
However, the evidence was of low quality due to the small number of studies and participants. 
How up‐to‐date is this review? 
We searched for studies published up to 30 November 31, 2206.
Vaccination against pneumococcus reduces the risk for community‐ acquired pneumonia and exacerbations of chronic obstructive pulmonary disease
Background 
Community‐acquire pneumonia (CAP) is a major cause of morbidity and mortality worldwide. It is caused by many different bacteria, viruses and fungi, but Streptococcus pneumoniae is the most common cause. Infection with S. pneumoniae can lead to serious complications such as meningitis, sepsis and death. Vaccines are available to protect against S. pneumococcu infection, but their effectiveness has not been well established. 
Objectives 
To assess the effects of pneumocon vaccine on the incidence of CAP, mortality, and hospital admission in adults and children. 
Search methods 
We searched the Cochrane Central Register of Controlled Trials (CENTRAL) (The Cochrance Library, Issue 12, 2010), MEDLINE (1966 to December week 4, 17,2009), EMBASE (1800 to December 21, 7,1008), CINAHL (10/1982 to December, 3,1109) and LILACS (1/1894 to December/20,09). We also searched reference lists of relevant articles and contacted experts in the field. 
Selection criteria 
Randomised controlled trials (RCTs) comparing pneumococal vaccines with placebo or no intervention in adults or children. We included studies where participants were followed up for at least six months after vaccination. 
Data collection and analysis 
Two review authors independently extracted data and assessed the risk bias of the included studies. We used the GRADE approach to assess the quality of the evidence for each outcome. 
Main results 
We included 31 RCTs involving 142,382 participants. Most studies were conducted in high‐income countries, and the majority of participants were adults. 
Vaccines provided significant protection for adults against CAP (risk ratio (RR) 0

, 09. 
The likelihood of being admitted to hospital for any reason did not change after vaccination, but the likelihood was lower for those vaccinated with 25‐valence PPV than those vaccinated","Injectable pneumocon vaccine for people with chronic lung disease
What is the aim of this review? 
This review aims to find out whether injectable vaccines against pneumococcus (a bacterium that can cause pneumonia) are effective in people who have chronic obstructed pulmonary disease. 
Key messages 
• People with chronic respiratory disease are at higher risk of pneumonia than people without such disease. Pneumococci are the most common cause of pneumonia. 
• There are two types of pneumocons vaccine available: polysacarid vaccine (which contains sugars from the surface of the bacteria) and conjugate vaccine (containing sugars plus an adjuvant, which is a substance that helps the body to recognise the sugar). 
• This review found that both types of vaccine were effective in reducing the risk of developing pneumonia, but there was little difference between them. 
Why is this important? 
The risk of death from pneumonia is high in people living with chronic airway disease. Vaccination against pneumocontia may reduce the risk and improve quality of life. 
What was studied in the review?  
We searched for all relevant studies up to November, 24 2 01 6. We included 1 2 studies with 2, 17 1 participants. The average age of the participants was about 6 6 years old. The studies were carried out in different countries including the United States, Canada, Australia, and Europe. 
The studies compared the effectiveness of two types (polysaccharides and conjugates) of pneumococon vaccine against placebo or another vaccine. The main outcome measure was the number of people who developed pneumonia. The other outcome measures were the number who died from pneumonia, the number with severe pneumonia, and the number needing hospitalisation. 
How were the studies evaluated? 
We used the standard methodological approaches recommended by Cochraine to collect and analyse data. We used GRADE to assess the quality of the evidence for each outcome. 
We found that the polysaccaride vaccine reduced the risk for developing pneumonia by 59% (90% confidence intervals 41% to 85%). The conjugate reduced the rate by 26% (5% to131%). The number of deaths from pneumonia was similar in both groups. 
There was no difference in the number requiring hospitalisation or the number developing severe pneumonia. There was no information on the cost effectiveness of the vaccines. 
Quality of the Evidence 
The quality of evidence was rated as moderate for the polysaccaride vaccine and low for the conjugate.
Vaccination against pneumococcus reduces the risk for community‐ acquired pneumonia and COPD flare‐ups
Community‐acquire pneumonia (CAP) is a common illness, especially among older adults. It can be caused by many different bacteria, viruses and fungi, but pneumococcu is the most common cause. Pneumococci are bacteria that live in the nose and throat of healthy people. They can spread to the lungs and cause pneumonia. People who have chronic obstructive pulmonary disease (COPD) are at increased risk of developing pneumonia. In this review we examined the effect of vaccination against pneumo on the risk and severity of pneumonia and on the frequency of COPD flares in people at high risk of pneumonia. We searched for relevant studies up to December 2013. We found 15 studies involving 14,508 participants. Most studies were conducted in the United States and Canada. The studies included people aged 65 years and over, and those with COP D. The vaccines used were either 25‐valence pneumococal polysaccharide vaccine (PPV) or 7 valence pneumo conjugate vaccine (PCV). The main results were: • Vaccination against pneumonia reduced the overall risk of CAP by 60%, but did not reduce the risk specifically for confirmed pneumo pneumonia. The number of people vaccinated needed to be treated to prevent one case of pneumonia was 21. • Vaccinated people had a lower risk of COP D flare‐up than unvaccinated people. The N NTB to reduce the likelihood for a COP D exacerbation by 50% was 9. • There was no difference in the risk or severity of CAP between people vaccinated with PP V or PCV. • The risk of death from any cause did not change after vaccination. The risk for death from respiratory causes did change, but the results were inconsistent. The results were also inconsistent for the risk from all causes. • No evidence indicated that vaccination against pneumonia increased the risk to people of having a heart attack or stroke. • Adverse events were reported in 1% of people receiving PPV and 2% of those receiving PCV, but there was no evidence that these events were more likely in people vaccinated."
