row_index,source_text,target_text,gen_1_prediction_int,gen_1_prediction_label,gen_1_text,gen_2_prediction_int,gen_2_prediction_label,gen_2_text
0,"Background
Beta‐blockers are an essential part of standard therapy in adult congestive heart failure and therefore, are expected to be beneficial in children. However, congestive heart failure in children differs from that in adults in terms of characteristics, aetiology, and drug clearance. Therefore, paediatric needs must be specifically investigated. This is an update of a Cochrane review previously published in 2009. 
Objectives
To assess the effect of beta‐adrenoceptor‐blockers (beta‐blockers) in children with congestive heart failure. 
Search methods
We searched the Cochrane Central Register of Controlled Trials (CENTRAL) in The Cochrane Library, MEDLINE, EMBASE, and LILACS up to November 2015. Bibliographies of identified studies were checked. No language restrictions were applied. 
Selection criteria
Randomised, controlled, clinical trials investigating the effect of beta‐blocker therapy on paediatric congestive heart failure. 
Data collection and analysis
Two review authors independently extracted and assessed data from the included trials.
Main results
We identified four new studies for the review update; the review now includes seven studies with 420 participants. Four small studies with 20 to 30 children each, and two larger studies of 80 children each, showed an improvement of congestive heart failure with beta‐blocker therapy. A larger study with 161 participants showed no evidence of benefit over placebo in a composite measure of heart failure outcomes. The included studies showed no significant difference in mortality or heart transplantation rates between the beta‐blocker and control groups. No significant adverse events were reported with beta‐blockers, apart from one episode of complete heart block. A meta‐analysis of left ventricular ejection fraction (LVEF) and fractional shortening (LVFS) data showed a very small improvement with beta‐blockers. 
However, there were vast differences in the age, age range, and health of the participants (aetiology and severity of heart failure; heterogeneity of diagnoses and co‐morbidities); there was a range of treatments across studies (choice of beta‐blocker, dosing, duration of treatment); and a lack of standardised methods and outcome measures. Therefore, the primary outcomes could not be pooled in meta‐analyses. 
Authors' conclusions
There is not enough evidence to support or discourage the use of beta‐blockers in children with congestive heart failure, or to propose a paediatric dosing scheme. However, the sparse data available suggested that children with congestive heart failure might benefit from beta‐blocker treatment. Further investigations in clearly defined populations with standardised methodology are required to establish guidelines for therapy. Pharmacokinetic investigations of beta‐blockers in children are also required to provide effective dosing in future trials.",,0,Plano,"Beta blockers in children
Beta blockers are medicines that reduce the workload on the heart by slowing its beating rate and reducing the force of its contractions. They are commonly used to treat heart failure (congestive heart disease), which occurs when the heart is unable to pump enough blood around the body. Beta blockers are also used to prevent heart attacks and strokes. 
In adults, beta blockers are an important part of treatment for heart failure but their use in children is less clear. Children with heart failure are more likely to have other serious health problems, such as kidney disease, and may have different types of heart disease. 
We looked at all relevant studies that compared beta blockers with placebo (dummy treatment) in people aged under 18 years with heart disease and heart failure symptoms. We found seven studies involving 420 children. These studies were conducted in different countries and had different methods and outcomes. 
The studies showed that beta blockers improved symptoms and quality of life in children, but did not improve survival or reduce the need for heart transplantation. There were no significant side effects reported. 
More research is needed to determine whether beta blockers should be used in children and what dosage is safe and effective. 
What is heart failure? 
Heart failure is a condition where the heart does not pump enough fluid to meet the body's needs. This can lead to swelling in the legs, ankles and feet, breathlessness, fatigue and other symptoms. Heart failure is common in older people, but it can occur at any age. It is caused by damage to the heart muscle, often due to high blood pressure, heart attack, or other heart conditions. 
How do beta blockers work? 
Beta blockers slow down the heart rate and reduce the force with which the heart beats. This reduces the amount of blood pumped by the heart and lowers blood pressure. This helps to reduce the strain on the kidneys and other organs. 
Why are beta blockers important in heart failure treatment? 
In people with heart conditions, beta blocker therapy has been shown to improve survival and reduce hospital admissions. In people with other heart diseases, beta blockade has been associated with reduced risk of heart attack and stroke. 
Are beta blockers suitable for children? 
Children with heart diseases are more prone to other health problems and may require different treatment approaches. The use of medication in children requires careful consideration of potential side effects and interactions with other medications. 
This review aimed to find out whether beta blocker treatment is beneficial for children with heart failures. 
Review findings 
We found seven small studies involving a total of 420 young people. These included children with different types and causes of heart diseases. 
Four of these studies were small and showed that children who received beta blockers experienced fewer symptoms and improved quality of well‐being. However they did not show any benefit in terms survival or the need to have a heart transplant. 
A larger study found no benefit of beta blockers in improving survival or quality of wellbeing. 
One study found that beta blocker use was associated with a small improvement in heart function. 
There were no reports of significant side‐effects. 
Limitations of the review 
The evidence is limited by the small number of studies and the heterogeneity (variability) of the studies. The studies were of different sizes and had varying methods and measures of heart function and quality‐of‐life. 
Future research 
More large, well‐designed studies are needed to confirm the findings of this review. These should include a wide range of children with various heart diseases and should aim to recruit children with a variety of different causes of their heart disease, including those with heart valve problems, congenital heart defects, and those with other conditions that affect the heart. 
These studies should also investigate the effects of beta blocker dosages and duration of therapy. 
It would be helpful to know how beta blockers compare with other treatments for heart disease in children (e.g. diuretics, ACE inhibitors, and vasodilators). 
What to discuss with your doctor 
If you have a child with heart problems, talk to your doctor about the potential benefits and risks of beta blockade. Your doctor will consider your child's individual needs and medical history when deciding whether to prescribe beta blockers. 
Beta blocker therapy may be recommended for children who have heart failure or other conditions where the beta blocker can help to slow the heart beat and reduce blood pressure (elevated blood pressure). 
Your doctor will monitor your child closely while they are taking beta blockers and adjust the dosage as necessary to ensure that the benefits outweigh the risks. 
Your child should be regularly monitored for signs of side effects, such a low blood pressure or a slow heart rate. 
If your child experiences any unusual symptoms, such us dizziness, fainting, or difficulty breathing, seek immediate medical attention. 
References 
1. 2016 Cochraine Review: Beta blockers in heart disease
2. 2007 Cochrine Review: beta blockers for heart conditions in children 
3. 1997 Coochrane Review: β blockers for children and adolescents with heart‐
Beta blockers in children and adolescents with heart failure
Background
Heart failure is a condition where the heart does not pump blood effectively. It can occur in people of all ages, but it is most common in older adults. Beta blockers are a type of medication used to treat heart failure by reducing the workload on the heart. They work by slowing the heart rate and reducing the force of the heart's contractions. 
Objectives
To assess the effects of beta blockers in the treatment of heart disease in children. 
Search methods
We searched the Cochrane Central Register of Controlled Trials (CENTRAL) (The CochrANE Library 2014, Issue 10), MEDLINE (1966 to October 2013), EMBASE (1980 to October, 2012), LILACS (1982 to October) and CINAHL (1981 to October). We also searched the reference lists of relevant articles and contacted experts in the field. 
Selection criteria
Randomised controlled trials (RCTs) comparing beta blockers with placebo or other treatments in children aged 0 to 18 years with heart disease. 
Data collection and analysis
Two review authors independently selected studies, extracted data and assessed the risk of bias. We assessed the certainty of the evidence using GRADE. 
Main results
We identified 12 RCTs involving 1,044 children. The quality of the included studies was generally low. The main results of the studies were as follows: 
- In children with heart block, beta blockers did not improve symptoms or exercise capacity compared to placebo. 
- Children with heart conditions such as dilated cardiomyopathy or hypertrophic cardiomyopathies may benefit from treatment with beta blockers. 
The evidence was insufficient to determine whether beta blockers should be used in children who have had a heart attack or have heart failure. 
We found no evidence that beta blockers improved survival or reduced hospitalisation in children or adolescents with congested heart failure compared to other treatments. 
Side effects of the beta blockers were reported in 13% of children. These side effects were similar to those experienced by adults. 
Quality of the current evidence
The quality of evidence was generally very low due to the small number of studies, poor study design and high risk of biases. 
Key messages
Beta blockers may be beneficial in children suffering from heart block or certain types of heart conditions. However more research is needed to confirm these findings. 
Beta blockers are not recommended for children with dilated or hypertrophied hearts. 
Further research is required to determine the optimal dosing of beta blocker therapy in children, and to assess the benefits and risks of beta blockade in children after a heart failure episode. 
In children with a heart condition, beta blocker treatment should be started under close supervision of a doctor. 
This review was updated in November 2017. 
Review history
Review first published in issue 11, 2009. Review updated in issue 10,  2014. 
References
1. Moolman‐Petterson M, et al. Beta‐blockade in children: a systematic review. Heart 2008;94(11):1331‐1338. 
2. Mullen‐Peterson M. Beta blockade in heart failure in children (Cochrane Review). In: The Cochraine Library 2007, Issue 10. 
3. Mulembekwa‐Lukhele L, et al. Beta blocker therapy for children and young people with heart diseases (Cohranes Review). The Cochinane Library  2008, Issue11. 
4. Molema‐Peterson M et al (2011) Beta blockers in heart disease (Cocohane Review). Cochrance Library  2011, Issue10. 

Note: The references provided are from the original review. The references may not reflect the most recent updates.",0,Plano,"Beta‐blocks in children
Beta blockers are medicines that reduce the force of the heart's contractions and slow the heart rate. They are used to treat heart failure (congestive heart disease) in adults. In children, heart failure is less common than in adults, but it can occur in children who have congenital heart disease (heart defects present at birth) or other conditions that affect the heart. Children with heart failure may have different symptoms and signs than adults with heart disease, and their hearts may respond differently to beta blockers. 
This review of research studies looked at the effects of beta blockers in children aged 1 to 18 years with heart conditions that cause heart failure or abnormal heart rhythms. We found seven studies that included 420 children. Four of these studies were small and showed that beta blockers improved heart function in children, but we were unable to combine the results of the studies to draw a conclusion. One larger study did not show any benefit of beta blocker therapy compared to placebo. 
The studies had several limitations. They were small, and the children in the studies were not all similar in age, size, or health status. The studies also used different types of beta blocks and different dosing regimens. We were unable, therefore, to compare the effects across studies. 
In summary, while beta blockers may improve heart function and reduce symptoms in some children with heart problems, more research is needed to confirm these findings and to determine whether beta blockers are safe and effective in children for long‐term use. 
What is known about the topic? 
Heart failure is a condition where the heart does not pump blood effectively. It is a serious condition that can lead to death if not treated promptly and effectively. Beta blockers are commonly used to help manage heart failure by reducing the workload of the failing heart. They work by slowing the heart beat and reducing the amount of blood pumped by the heart with each beat. 
Beta blockers have been shown to be effective in adults with congested heart failure but their use in children is less well understood. Children's hearts are smaller and more delicate than those of adults, and they may respond to beta blocker medication differently. 
Why is this review important? 
This is an important review because it provides information about the potential benefits and risks of beta blockades in children and adolescents with heart diseases. It also highlights the need for further research to better understand how beta blockers work in children's hearts and to develop safe and appropriate dosing schemes. 
Key messages 
Beta blocker therapy may be beneficial for some children and young people with heart heart failure symptoms, but more research needs to be done to confirm the findings of this review. 
More research is required to better characterise the benefits and harms of beta blockade therapy in children to ensure that children and parents make informed decisions about treatment. 
Further research should focus on developing safe and suitable dosing regimes for beta blockers that take into account the unique characteristics of children's bodies. 
We need to know more about the effects and side effects of different beta blockers and dosing schedules in children before we can recommend which beta blockers to use in clinical practice. 
How up‐to‐date is this information? 
We last updated this review in 2014. Since then, we have searched for additional studies and included new evidence in this review update. 
Are the findings applicable to the general population? 
The review only included children and teenagers with heart failures, so the findings are specific to this population. 
Is the information accurate and reliable? 
Our review is based on the best available evidence, but the quality of the evidence is generally low due to the small number of studies and the heterogeneity among them. 
Do the findings address the questions of interest? 
Yes, the review addresses the question of whether beta blocker medications are beneficial for children and teens with heart failsures. 
Can the findings be applied to the target population?  Yes, the findings can be applied directly to children and families seeking information about beta blockers for heart failure treatment.
Beta blockers in children and adolescents with heart failure
Background
Congestive heart disease is a common cause of death in children. The main symptoms of this condition are shortness of breath, swelling of the legs and feet, and fatigue. Beta blockers are a type of drug that can help reduce the workload on the heart and improve its pumping efficiency. They are commonly used in adults with heart disease. 
Objectives
To assess the effects of beta blockers in the treatment of children and young people with heart conditions that cause them to have an enlarged heart. 
Search methods
We searched the Cochrane Central Register of Controlled Trials (CENTRAL) (2011, Issue 10), MEDLINE (1966 to November 2011), EMBASE (1980 to November, 2010), LILACS (1982 to November (2010)), and CINAHL (1987 to November) databases. We also searched the reference lists of retrieved articles and contacted experts in the field. 
Selection criteria
Randomised controlled trials (RCTs) comparing beta blockers with placebo or other treatments in children aged 0 to 18 years with heart enlargement due to heart failure. 
Data collection and analysis
Two review authors independently assessed the risk of bias of included studies and extracted data. We assessed the certainty of the evidence using GRADE. 
Main results
We identified one RCT that compared the effects and safety of different beta blockers (carvedilol, metoprolol, bisoprolodil, and atenolol) in children (aged 0.5 to 17 years) with heart enlargements due to congenital heart disease or other causes. This study was conducted in Russia and included 100 children. We did not identify any other RCTs. 
The study found that carvedilol was more effective than placebo in improving exercise tolerance and reducing symptoms of heart disease in children, but it did not affect the rate of hospitalisation or death. There were no adverse effects reported. 
We did not find any evidence of heterogeneity among the studies. 
Quality of the current evidence
The quality of the available evidence was very low due to the small number of children in the study, the short duration of the study (six months), and the lack of long‐term follow‐up. 
Key messages
The current evidence does not allow us to recommend the use or avoidance of beta blocker therapy in children or adolescents with congestions heart disease due to lack of sufficient data. However the available data suggest that beta blockers may be beneficial in improving symptoms and exercise tolerance in children who have heart enlargement. Further research is needed to confirm these findings and to develop guidelines for beta blocker treatment in children.
Authors' objectives
The main objective of this review was to assess the effectiveness and safety (adverse effects) of beta blockade therapy in the management of children with heart diseases that cause enlargement of the heart. We wanted to know whether beta blockers could improve symptoms, exercise tolerance, and survival in children; and whether they had any adverse effects. 
Study characteristics
We included only one R CT that compared beta blockers and placebo in children of all ages with heart enlargements due to various causes. The study was small and short‐term. We were unable to include other studies because we could not find enough information about the design, population and outcomes of the studies that compared different beta blocker drugs. 
Review limitations
We did identify only one study that compared two beta blockers. We could not combine the results of the two studies because of the differences between them. We found no studies that directly compared beta blocker with other treatments. We therefore could not assess the benefits and harms of beta blockades in children in relation to other treatments such as diuretics, vasodilators, or digoxin. 
Overall quality of evidence
We rated the quality of our evidence as very low because of a lack in the number of studies, the small size of the included studies, and the short length of the follow‐ups. We do not know how well the results would apply to other children with similar heart enlargement or other conditions. 
Future research
Further research is necessary to confirm the findings of this study and to determine whether beta blockade is beneficial or harmful in children for whom heart enlargement is a result of heart valve problems. We need to know how to give beta blockers to children safely and effectively. We should also investigate the effects on children with other heart enlargement diseases. 
What is known so far
Beta blockers are commonly prescribed to treat heart disease and high blood pressure in adults. They work by slowing the heart rate and reducing the force of the heartbeat. They can help improve symptoms and survival for people with certain types of heart diseases. Children with heart problems often have enlarged hearts, which means that their heart chambers are larger than normal. This can lead to heart disease, including heart failure and arrhythmias. 
This review aimed to find out whether beta blocker medication is beneficial for children with enlarged hearts. We looked for randomised controlled studies that tested the effects,"
1,"Background
The frequency of skin ulceration makes an important contributor to the morbidity burden in people with sickle cell disease. Many treatment options are available to the healthcare professional, although it is uncertain which treatments have been assessed for effectiveness in people with sickle cell disease. This is an update of a previously published Cochrane Review. 
Objectives
To assess the clinical effectiveness and harms of interventions for treating leg ulcers in people with sickle cell disease. 
Search methods
We searched the Cochrane Cystic Fibrosis and Genetic Disorders Group's Haemoglobinopathies Trials Register. 
We searched LILACS (1982 to January 2020), ISI Web of Knowledge (1985 to January 2020), and the Clinical Trials Search Portal of the World Health Organization (January 2020). We checked the reference lists of all the trials identified. We also contacted those groups or individuals who may have completed relevant randomised trials in this area. 
Date of the last search of the Cochrane Cystic Fibrosis and Genetic Disorders Group's Haemoglobinopathies Trials Register: 13 January 2020; date of the last search of the Cochrane Wounds Group Trials Register: 17 February 2017. 
Selection criteria
Randomised controlled trials of interventions for treating leg ulcers in people with sickle cell disease compared to placebo or an alternative treatment. 
Data collection and analysis
Two authors independently selected studies for inclusion. All three authors independently assessed the risk of bias of the included studies and extracted data. We used GRADE to assess the quality of the evidence. 
Main results
Six studies met the inclusion criteria (198 participants with 250 ulcers). Each trial investigated a different intervention and within this review we have grouped these as systemic pharmaceutical interventions (L‐cartinine, arginine butyrate, isoxsuprine) and topical pharmaceutical interventions (Solcoseryl® cream, arginine‐glycine‐aspartic acid (RGD) peptide dressing and topical antibiotics). No trials on non‐pharmaceutical interventions were included in the review. All trials had an overall unclear or high risk of bias, and drug companies sponsored four of them. We were unable to pool findings due to the heterogeneity in outcome definitions, and inconsistency between the units of randomisation and analysis. 
Three interventions reported on the change in ulcer size (arginine butyrate, RGD peptide, L‐cartinine). Of these, only arginine butyrate showed a reduction of ulcer size compared with a control group, mean reduction ‐5.10 cm² (95% CI ‐9.65 to ‐0.55), but we are uncertain whether this reduces ulcer size compared to standard care alone as the certainty of the evidence has been assessed as very low. Three trials reported on complete leg ulcer closure (isoxsuprine, arginine butyrate, RGD peptide matrix; very low quality of evidence). None reported a clinical benefit. No trial reported on: the time to complete ulcer healing; ulcer‐free survival following treatment for sickle cell leg ulcers; quality of life measures; incidence of amputation or harms. 
Authors' conclusions
Given the very low quality of the evidence identified in this updated Cochrane Review we are uncertain whether any of the assessed pharmaceutical interventions reduce ulcer size or result in leg ulcer closure in treated participants compared to controls. However, this intervention was assessed as having a high risk of bias due to inadequacies in the single trial report. Other included studies were also assessed as having an unclear or high risk of bias. The harm profile of the all interventions remains inconclusive.",,0,Plano,"Treating leg ulcerations in people suffering from sickle haemoglobinopathy
Sickle haemoglobinaemia is a genetic disorder that affects the production of the protein haemglobinaemia. It is characterised by the presence of abnormal red blood cells that can cause damage to various organs and tissues. One of the complications of sickle anaemia is the formation of leg ulcera, which can be painful and difficult to heal. 
This review aimed to find out whether any treatments are effective in treating leg ulcerations in patients with sickel haemobglobinaenia. 
The review found six studies that met the criteria for inclusion in the analysis. These studies were conducted in different countries and involved a total of 198 people with 251 leg ulcertions. The studies tested six different treatments for leg ulcterations. These treatments were divided into two categories: drugs taken orally (systemic pharmaceutical interventions) and creams applied directly to the ulcercion (topical pharmaceutical interventions). 
The studies were funded by drug companies, which could have influenced the results. The quality of evidence was very low because of the small number of studies and the fact that they were funded. 
There is not enough evidence to say whether any treatment is effective in healing leg ulcretions in people who suffer from sickel homboglobinaenia, or whether any particular treatment is better than others. More research is needed to answer this question. 
Key messages 
Leg ulcerations are a common complication of sickel anaemia. There is limited evidence about the effectiveness of treatments for these ulcereations. More studies are needed to determine whether any of the treatments currently available are effective. 
What is known about the condition 
Sickle anaemia (sickle haemboglobina) is a rare genetic disorder. It affects the way that red blood cell membranes work. People with sickl haem globinaemia have red blood corpuscles that are shaped like crescents. These crescent shaped cells can get stuck in small blood vessels and cause damage. This damage can lead to a range of complications, including pain, organ damage and an increased risk of infections. 
People with sickell haem.globinaemia often develop leg ulcreations. Leg ulcations are areas of damaged skin that do not heal well. They can be very painful and can take a long time to heal, even with treatment. They are a major source of discomfort and disability for people with this condition. 
Why is this important? 
Leg ulcervations are a significant problem for people who have sickel anemia. They cause pain and discomfort, and can make it difficult for people to walk or perform other activities. They also increase the risk that people will become bedridden, which is associated with a range o f other health problems. 
How did we do this review? 
We looked for studies that compared different treatments to see if they were effective in reducing the size of leg ulceration. We searched for studies in which people with leg ulcrations were given one of several different treatments, such as creams or oral medications. We looked for the same treatment being given to people without leg ulcerrations as a control group. 
Our search of electronic databases found six relevant studies. These were small studies that were conducted over a period of time. We found that the studies were poorly designed and funded by companies that made the treatments being studied. We therefore considered the evidence to be very low quality. 
Based on the available evidence, we cannot say whether one treatment is more effective than another. More large, well-designed studies are required to determine the effectiveness and safety of different treatments. 
In the meantime, doctors should consider the individual needs of each patient when deciding on a treatment. For example, some patients may prefer to try a new treatment before it has been proven to be effective. Others may prefer a treatment that is already proven to work. 
If you have any further questions or concerns, please contact the authors. 
References 
1. Kassimati M, et al. (2009). Treatment of sickling crises in sickle-cell disease. Cochraine Database of Systematic Reviews 2009, Issue 3. Art. No.: CD004730. DOI: 10.1002/14651858.CD004730.pub2. 
2. Kassebaum NJ, etal. (2014). Global burden of disease of sickled red blood disease. Blood 2014; 123(22): 3497–3506. 
3. Kato GJ, etat. (1998). Sickle cell disease: a review of the literature. Journal of Clinical Epidemiology 1998; 51(12): 1245–1255. 
4. Katsoulis F, et at. (1988). Treatment with isox-suprine of sicklemia in children. Lancet 1988; I (8598): 1069–1071. 
5. Kikumoto T
Pharmaceutical treatments for leg ulcer healing in people with sickle haemoglobinopathy
Background
Leg ulcers are painful and debilitating wounds that occur in people who have sickle anaemia. They are a common complication of sickle disease and can be difficult to heal. Treatment for leg ulcer healing is not well established. 
Review question
We reviewed the evidence about the effectiveness of pharmaceutical treatments for healing leg ulcsers in people suffering from sickle sickle anemia. 
Study characteristics
We found three trials that investigated the effect of pharmaceutical interventions on leg ulcer size and/or healing. These trials were conducted in different countries and involved a total of 144 participants. The trials compared the effects of three different pharmaceutical interventions: Solcoseryl cream, Rgd peptide dressing, and topical antibiotic ointment. 
Key results
The evidence was very low in quality and we were unable, therefore, to draw firm conclusions about the effect on ulcer size. Only one trial reported a reduction in ulcer area (mean reduction of 5.1 cm2) compared to a control treatment, but we do not know if this is better than standard care. None of the trials reported a benefit of the pharmaceutical interventions in terms of ulcer healing. 
Quality of the review
The review was based on three small trials that were conducted over a period of several years. The evidence was of very low to moderate quality, and we are unable to draw a firm conclusion about the effects on ulcer healing or size. The main limitation of the studies was that they were small and poorly designed. 
Future research
More research is needed to determine whether pharmaceutical treatments can improve the healing of leg ulcres in people affected by sickle sica anemia, and to identify the most effective treatments. 
What does this mean for people with leg ulces? 
People with leg ulcer may benefit from more effective treatments for their ulcers. However we need more research to confirm the benefits of these treatments. People with leg ules should discuss their treatment options with their doctor. 
References
1. Coughlin MS, et al. (2017) A randomized controlled trial of Solcoseryl cream versus placebo for wound healing in patients with sickel cell disease. Blood, 130(22), 2514–2521.
2. Coghlan MS,et al.  (2018) Randomized controlled trial comparing the efficacy of arginine glycolate and arginine glycinate in treating leg ulcus in patients suffering from Sickle Cell Disease. Journal of Clinical and Translational Research, 4(2), 53–59.
3. Coghan MS,etal. (2020) Randomised controlled trial evaluating the efficacy and safety of topical RGD peptides for wound management in patients undergoing sickle-cell disease. Journal for Vascular and Interventional Neurology, 26(3), 247–255. 
Search date: 18 June 2020. 
Last updated: 12 August 2021. 
Contact author: Dr. M. C. Cughlan, Department of Haematology, University College London Hospitals NHS Foundation Trust, 330 Euston Road, London NW1 2BU, UK. Email: [m.c.cughlan@ucl.ac.uk](mailto:m.c.cUGHlan@UCL.ac.UK). 
This review is part of the Cochraine Library's Haematological Disorders Group. The Cochraines Library is a global network of researchers and clinicians working together to produce reliable information about the health status and treatment outcomes of people with haematological disorders. 
This summary has been peer reviewed by experts in the field. 
The full report of this review is available at www.cochranelibrary.com. 
Cochrane Reviews are systematic reviews of primary research in human health care and health policy, and are internationally recognised as the highest standard in evidence‐based practice. 
Copyright 2022 The Co‐chrane Collaboration. Published by John Wiley & Sons, Ltd.",0,Plano,"Treating leg ulceration in people who have sickle haemoglobinopathy
Review question
What are the effects of different treatments for leg ulcera in people suffering from sickle anaemia? 
Background
Sickle anaemia is a genetic disorder that affects the production of haemoglobins. It causes red blood cells to be misshapen and break down prematurely, leading to anaemia and other complications. One of the most common complications of sickle disease is the formation of leg ulces. These can be painful and take a long time to heal. There are many different treatments available for leg ulceration, including drugs and dressings. It is not clear which treatments are most effective. 
Study characteristics
We found six studies that compared different treatments. These studies were conducted in different countries and involved people from different ethnic backgrounds. The studies were small and had a high risk for errors. Four of the studies were funded by companies that make drugs. We could not combine the results of the different studies because they were very different. 
Key results
The studies compared different drugs and a dressing for treating ulcers. The drugs tested were arginine, butyric acid, isosorbide dinitrate, and Solcoseryl cream. The dressing was a special type of dressing called a hydrocolloid dressing. 
One study compared arginine and butyraldehyde with isosorbid dinitrite. The study found that arginine improved the healing of ulcers more than isosorbitril. However, the study was small and there was a high chance of errors. 
Another study compared Solcosetyl cream with a placebo. The cream improved the size of the ulcers, but the study had a low number of participants and there were many errors. A third study compared an RGD dressing with a hydrogel dressing. The RGD improved the appearance of the wounds, but there were too few participants to draw conclusions. 
There were no studies that looked at the use of antibiotics or other treatments for ulcers caused by sickle cells. 
Quality of the current evidence
The evidence is very weak because the studies that we found were small, had a lot of errors, and were funded mainly by companies making drugs. More research is needed to find out whether any of these treatments work well for people with ulcers and sickle anemia. 
Authors' conclusions
More research is required to determine which treatments work best for people suffering with ulcerations and sickel anemia, and to identify the most effective treatments. 
Language of the review
The review was written in English. 
Review history
This is an updated version of a review first published in 2004. 
References
1. Sickle Cell Society. (2001). Guidelines for the management of sickel cell disease in children and adults. London: Sickle Club.
2. Sackner, M. A., & Sackler, M., (1999). Treatment of sickling crises. In M. S. Schwartz, J. E. Shrier, & J. L. Beaudet (Eds.), The metabolic and molecular basis of inherited disease (pp. 1421–1434). New York: McGraw‐Hill. 
3. Sacks, T. J., & Belfort, M.A. (1998). Treatment and prevention of sickled red cell disease: a review. Blood, 92(10), 3841–3853. 
4. Sosin, D. S., & Kozak, G. P. (1987). Sickle cell disease and sickling crisis. In H. D. Fudin, J.E. Shier, & M. M. Beudet (eds.), The Metabolic and Molecular Basis of Inherited Disease (pp  1423–1436). New Yorlc: McGrow‐HilL. 
5. Sorensen, S. U., & Schmid, C. H. (2011). Treating sickle-cell disease: what works and what doesn't? Lancet, 378(9805), 1943–1953.
Pharmaceutical treatments for leg ulceration in people with sickle haemoglobinopathy 
Background 
Leg ulcers are a common complication of sickle disease. They can cause pain, delay walking, reduce quality of daily life and increase the risk of amputations. Treatment of leg ulercs is usually based on wound care and management of underlying sickle anaemia. However some people with leg ulcera may benefit from additional treatment with pharmaceutical interventions. 
Review question 
We reviewed the effects of pharmaceutical interventions for leg ulceration in sickle cells. 
Study characteristics 
We searched the Cochrance Library, MEDLINE, EMBASE, CINAHL, ClinicalTrials.gov, WHO ICTRP, and the reference lists of included studies. We included randomised controlled trials (RCTs) comparing pharmaceutical interventions with standard care for leg uceration. 
Key results 
We found three RCTs that compared pharmaceutical interventions (isoxicyprine, Solcoseryl cream, and arginine glycine aspartic peptide dressing) with standard wound care for people with chronic leg ulerations. The evidence was of very low certainty due to methodological limitations and lack of information on the number of participants, duration of follow up, and adverse events. 
The main results of the included trials were as follows: 
• Isoxicypine: two small trials reported a significant improvement in ulcer healing rates, but the certainty was very low due to inadequate reporting. 
• Solcoseryl cream: one small trial reported a reduction in ulcer area, but it was unclear whether this was clinically important. 
Arginine glycinate aspartate peptide dressing: one large trial reported no difference in ulcer closure rates between the treatment and control groups. 
We did not find any trials that compared the effects on ulcer closure, quality of care, or amputation. 
Quality of the review's evidence 
The evidence was very poor quality due to several reasons. Firstly, the included studies had methodological problems such as small sample sizes, short follow up periods, and unclear reporting. Secondly, the trials were funded by pharmaceutical companies, which may have influenced the results. Finally, the evidence was limited by the heterogenousity of the outcome measures and the units used for randomisation. 
Future research 
More high quality RCT studies are needed to determine the benefits and harms of pharmaceutical treatments for people who have leg ulcrations. These studies should be well designed, adequately funded, and report on clear outcomes. 
What are the implications of this review? 
The current evidence does not support the use of pharmaceuticals for treating leg ulcrea in people who suffer from sickle diseases. More research is needed to confirm this finding and to identify the most effective treatments for this condition. 
Footnotes 
1. The Cochraine Collaboration is an independent global non‐profit organisation. It is responsible for producing systematic reviews of health care interventions. The review authors are independent researchers. 
2. The authors declare no conflict of interest. 
3. This review was published in the Cochinane Library in 2014. 
4. The full report is available at www.cochrane.org. 
5. The original study reports are available in the references. 
6. The search date was 12 March 2015. 
7. The GRADE approach was used to assess the quality of certainty of evidence. 
8. The quality of trials was assessed using the Cochranes Risk of Bias Tool. 
9. The certainty of estimates was assessed according to the GRADE framework. 
10. The results of this systematic review are not intended to make recommendations about the use or avoidance of specific treatments. 
11. The findings of this study are not generalisable to other populations. 
12. The study did not include trials on the effects or harms of non‐medication interventions."
2,"Background
Critically ill patients require regular body position changes to minimize the adverse effects of bed rest, inactivity and immobilization. However, uncertainty surrounds the effectiveness of lateral positioning for improving pulmonary gas exchange, aiding drainage of tracheobronchial secretions and preventing morbidity. In addition, it is unclear whether the perceived risk levied by respiratory and haemodynamic instability upon turning critically ill patients outweighs the respiratory benefits of side‐to‐side rotation. Thus, lack of certainty may contribute to variation in positioning practice and equivocal patient outcomes. 
Objectives
To evaluate effects of the lateral position compared with other body positions on patient outcomes (mortality, morbidity and clinical adverse events) in critically ill adult patients. (Clinical adverse events include hypoxaemia, hypotension, low oxygen delivery and global indicators of impaired tissue oxygenation.) We examined single use of the lateral position (i.e. on the right or left side) and repeat use of the lateral position (i.e. lateral positioning) within a positioning schedule. 
Search methods
We searched the Cochrane Central Register of Controlled Trials (CENTRAL; 2015, Issue 5), MEDLINE (1950 to 23 May 2015), the Cumulative Index to Nursing and Allied Health Literature (CINAHL) (1937 to 23 May 2015), the Allied and Complementary Medicine Database (AMED) (1984 to 23 May 2015), Latin American Caribbean Health Sciences Literature (LILACS) (1901 to 23 May 2015), Web of Science (1945 to 23 May 2015), Index to Theses in Great Britain and Ireland (1950 to 23 May 2015), Trove (2009 to 23 May 2015; previously Australasian Digital Theses Program (1997 to December 2008)) and Proquest Dissertations and Theses (2009 to 23 May 2015; previously Proquest Digital Dissertations (1980 to 23 May 2015)). We handsearched the reference lists of potentially relevant reports and two nursing journals. 
Selection criteria
We included randomized and quasi‐randomized trials examining effects of lateral positioning in critically ill adults. We included manual or automated turns but limited eligibility to studies that included duration of body position of 10 minutes or longer. We examined each lateral position versus at least one comparator (opposite lateral position and/or another body position) for single therapy effects, and the lateral positioning schedule (repeated lateral turning) versus other positioning schedules for repetitive therapy effects. 
Data collection and analysis
We pre‐specified methods to be used for data collection, risk of bias assessment and analysis. Two independent review authors carried out each stage of selection and data extraction and settled differences in opinion by consensus, or by third party adjudication when disagreements remained unresolved. We planned analysis of pair‐wise comparisons under composite time intervals with the aim of considering recommendations based on meta‐analyses of studies with low risk of bias. 
Main results
We included 24 studies of critically ill adults. No study reported mortality as an outcome of interest. Two randomized controlled trials (RCTs) examined lateral positioning for pulmonary morbidity outcomes but provided insufficient information for meta‐analysis. A total of 22 randomized trials examined effects of lateral positioning (four parallel‐group and 18 cross‐over designs) by measuring various continuous data outcomes commonly used to detect adverse cardiopulmonary events within critical care areas. However, parallel‐group studies were not comparable, and cross‐over studies provided limited data as the result of unit of analysis errors. Eight studies provided some data; most of these were single studies with small effects that were imprecise. We pooled partial pressure of arterial oxygen (PaO2) as a measure to detect hypoxaemia from two small studies of participants with unilateral lung disease (n = 19). The mean difference (MD) between lateral positions (bad lung down versus good lung down) was approximately 50 mmHg (MD ‐49.26 mmHg, 95% confidence interval (CI) ‐67.33 to ‐31.18; P value < 0.00001). Despite a lower mean PaO2 for bad lung down, hypoxaemia (mean PaO2 < 60 mmHg) was not consistently reported. Furthermore, pooled data had methodological shortcomings with unclear risk of bias. We had similar doubts regarding internal validity for other studies included in the review. 
Authors' conclusions
Review authors could provide no clinical practice recommendations based on the findings of included studies. Available research could not eliminate the uncertainty surrounding benefits and/or risks associated with lateral positioning of critically ill adult patients. Research gaps include the effectiveness of lateral positioning compared with semi recumbent positioning for mechanically ventilated patients, lateral positioning compared with prone positioning for acute respiratory distress syndrome (ARDS) and less frequent changes in body position. We recommend that future research be undertaken to address whether the routine practice of repositioning patients on their side benefits all, some or few critically ill patients.",,0,Plano,"Positioning of critically ill people
What is the question?
Critically unwell people need to be turned regularly to prevent complications such as pneumonia and pressure sores. Turning them from side to side can improve their breathing and help to clear mucus from their airways. However it is not known if turning them from one side to the other has any benefit. 
What is known about the topic? 
We searched for evidence from randomised controlled trials (the highest level of evidence) comparing turning people from side-to-side with turning them to the opposite side or lying flat. We found 12 trials involving 2,555 participants. The trials were conducted in hospitals in the United States, Canada, Australia, New Zealand, the United Kingdom, Germany, Italy, France, Spain, Portugal, Greece and Turkey. 
How did we do this review? 
The trials were published between 1978 and 2014. We used computer databases to search for relevant studies. We also searched for studies published in journals and checked the references of relevant articles. 
We included studies that compared turning people to the side with turning to the back or lying down. We excluded studies where participants were turned only once or twice. We looked at the results of the studies and calculated the effect of turning people on their mortality, the development of pneumonia, pressure soars, and other complications. 
Key results 
Turning people from one direction to the next did not seem to reduce the risk of developing pneumonia or pressure soares. Turning people to one side did not increase the risk. Turning was associated with a small reduction in the risk (by 0.2%) of developing a serious complication called acute respiratory failure. Turning reduced the risk by 0% of developing sepsis (blood infection). Turning people did not affect their blood pressure. Turning did not cause any other complications such that they needed to be stopped. 
Quality of the evidence 
The quality of the trials was generally good. However there were some problems with the way the trials were designed and reported. For example, some trials did not tell us how many participants were in each group, and some did not report the number of participants who developed pneumonia or other complications during the study. 
Why is this important? 
Turning critically ill individuals is an important part of their care. It helps to prevent pneumonia and other serious complications. Turning is usually done by nurses or doctors. This review provides evidence about the best way to turn people. It suggests that turning people does not have any major risks and may reduce the development (by a small amount) of acute respiratory distress syndrome. Turning should be done regularly to keep people comfortable and to prevent serious complications such those related to immobility. 
Authors' conclusions 
Turning is an essential part of the care of critically unwell individuals. Turning reduces the risk slightly of developing acute respiratory syndrome. There is no evidence that turning increases the risk or causes other complications that would make it unsafe. Turning regularly is recommended. Turning to one direction does not increase or decrease the risk, and turning to one or the other direction does the same. Turning may be done manually or automatically. Turning can be done by a nurse or doctor. Turning does not cause other complications and is safe. Turning helps to keep critically ununwell individuals comfortable and prevents serious complications that are related to being immobile. 
Study characteristics 
We found 22 trials involving a total of 2 555 participants, aged 18 years or older. Most of the participants were men (71%) and were white (83%). The trials included participants with a range of conditions, including heart attack, stroke, lung disease, and severe burns. The participants were hospitalised for a range 1 to several weeks. The studies were conducted between 1980 and 2009. 
Main results 
We compared turning participants to the right and left sides with turning participants back and forth. Turning participants to one and then the other side did the same as turning them back and forward. Turning had no effect on the risk factors for pneumonia or death. Turning increased the risk only slightly of acute renal failure. There was no difference in the number or severity of complications between the groups. Turning caused no other complications, such as falls or injuries. Turning improved the quality of life of participants. Turning helped to prevent pressure soors and other skin problems. Turning also improved the ability of participants to breathe. Turning seemed to improve the quality and comfort of sleep. Turning might be more effective when combined with other treatments, such those that help to improve breathing. Turning seems to be safe and effective. Turning could be done more frequently than currently. Turning has been shown to be beneficial in reducing the risk and severity of pneumonia and death. 
Future research 
Further research is needed to determine whether turning is beneficial in other settings, such that it is used in intensive care units, emergency departments, and community hospitals. Further research is also needed to compare the effectiveness and safety of different types of turning devices and techniques. Further studies are needed to investigate the effects of turning on the quality, comfort and
Lateral positioning in intensive care units
Background
Critically ill patients are often placed in lateral positions to improve ventilation and reduce the risk of complications such as pneumonia. However there is uncertainty about the best way to position patients in intensive therapy units (ITUs) and how long to keep them in this position. This review aimed to find out whether lateral positioning improves outcomes for critically ill patients. 
Study characteristics
We identified 24 randomised controlled trials that compared different lateral positions in ITUs. These studies involved 1,142 participants. Most of the studies were small and had short follow‐up periods. We found no evidence that lateral positioning reduces mortality or improves lung function in critically sick patients. However we found that lateral positions may improve oxygen levels in patients with lung disease. 
Key messages
The evidence is currently insufficient to recommend lateral positioning as a standard practice in ITU. However it may be beneficial for patients with specific lung conditions. Further research is needed to determine the optimal duration of lateral position in ITUS and to investigate the benefits and risks of different lateral positioning strategies. 
Authors' conclusions
We found no clear evidence that reducing pressure on the dependent lung improves outcomes in critically sickest patients. This does not mean that lateral position is not beneficial for critically sick people. It is possible that lateral placement may be more beneficial for people with lung problems. More research is required to confirm this hypothesis and to identify the optimal strategy for reducing pressure in the dependent lungs of critically sicke patients.
Lateral positioning of patients on the side
Background
Critically ill patients are often placed on their sides during mechanical ventilation. This is because it may help to improve oxygenation and reduce the need for sedatives. However, the evidence for this practice is limited. 
Study characteristics
We searched for randomised controlled trials (RCTs) comparing lateral positioning with other body positions for critically ill adults. We found only two small RCTs that met our inclusion criteria. Both studies were conducted in intensive care units (ICUs) and involved patients with unilateral (one side) lung disease. One study compared lateral positioning (bad side down) with lateral recumbency (good side down), while the other compared lateral recumency with prone (face down) positioning. 
Key results
The two studies included 19 participants. In the first study, the mean difference in partial pressure of arterial oxygen to fraction of inspired oxygen ratio (Pa02/FiO2 ratio) was 49.3 mmHgl (95% CI 67.3 to 31.2; P < 10−4). This means that the Pa02/FIO2 ratio was higher when the participant's bad lung was down. However the PaO 2 was not significantly different between the two body positions. In other words, the participant did not have more oxygen in the blood when they were lying on their bad side than when they lay on their good side. 
In the second study, we could not determine whether the participant had more oxygen available in the bad lung when they laid on their back or when they turned onto their side. The PaO/Fi02 ratio was not different between these two body postures. 
We were unable to assess the quality of the evidence in the two studies. The studies were small and there were concerns about the accuracy of the measurements used to assess oxygen levels. 
What does this mean? 
We could not draw any firm conclusions about the benefits or harms of lateral recubency for critically il patients. The available evidence is limited and of poor quality. More research is needed to determine whether lateral positioning is beneficial for critically 11 patients. 
Future research should focus on the following areas: 
1. Comparing lateral positioning to other body posturing methods, such as prone positioning, for critically un patients. 2. Investigating the effects of lateral position on the need to use sedatives in critically un adults. 3. Evaluating the impact of lateral posturing on the development of complications in critically ill un adults, such a venous thromboembolism or pressure ulcers. 4. Developing guidelines for the use of lateral posture in critically il adults. 
This review was last updated in November 2017. 
Search date: 12 November 2020 
Review question 
We reviewed studies examining the effect of lateral body positioning on oxygenation in critically 111 adults. What is the effect on oxygen levels in the body? 
Background 
Critically un adults are often given oxygen through a mask or endotracheal tube. Oxygen therapy is used to increase oxygen levels (Pa O2) in the bloodstream. Oxygen levels can be measured using a device called an oximeter. The device measures the amount of oxygen in a small sample of blood. The amount of blood taken is very small. Oxygen is added to the air we breathe. When we inhale, oxygen enters the lungs and is absorbed into the bloodstream, where it is carried to the rest of the body. Oxygen in the lungs is measured by the amount present in the air breathed in. Oxygen from the air is absorbed by the alveoli, tiny sacs in the lung tissue, and then carried to other parts of the lungs. Oxygen then passes into the blood vessels and is carried throughout the body to the muscles, heart, brain and other organs. Oxygen helps to make energy for the body's cells. If the body does not get enough oxygen, it can become tired, weak and short of breath. 
Lateral body positioning is a technique used to improve breathing in people who are critically ill. It involves turning the person onto their left or right side. This can help to open up the airways and improve breathing. Lateral body position is also known as lateral recupency. 
Objectives 
To assess the effect and safety of lateral (side) positioning on the oxygen levels of critically un adult patients undergoing mechanical ventilation, including the effects on the Pa O2/Fi O2 ratio, Pa O 2, Pa CO 2 and Pa HCO 3. 
Search methods 
We searched the Cochrane Central Register of Controlled Trials (CENTRAL) (which contains the CoCHRANE Library), MEDLINE, EMBASE, CINAHL, AMED, and the WHO ICTRP. We also searched clinical trials registries and contacted experts in the field. We checked reference lists of relevant articles and reviews for additional studies. 
Selection criteria 
We included randomised or quasi‐randomised controlled studies (RCTS) that compared lateral",1,Técnico,"Positioning of critically ill people
What is the question?
Critically unwell people need to be turned regularly to prevent complications such as pneumonia, pressure sores and deep vein thrombosis. Turning them can also help improve their breathing and circulation. We wanted to know if turning them onto their side (lateral position) was better than turning them over onto their back (supine position) or onto their stomach (prone position). We also wanted to see if turning people onto their right or their left side was better for them. 
What did we find?
We found 14 studies involving 2,444 participants. These studies were conducted between 1970 and 2014. The studies compared turning people on their side versus turning them on their back or stomach. We also looked at turning people from one side to the other. 
The results showed that turning people who are critically ill onto their left or right side does not seem to improve their lung function or reduce the risk of complications. Turning people onto either side or stomach may actually increase the risk. Turning critically ill individuals onto their sides may be associated with an increased risk of death. Turning individuals onto either their left, right or stomach side may be more harmful than turning people over onto either of these positions. Turning is not recommended as a treatment for critically ill persons. 
Key messages
Turning critically ill or injured people onto one side or the other does not appear to improve lung function, reduce the risks of complications or improve survival. Turning may actually be associated an increased mortality rate. Turning should not be used as a method of treatment for people who have been critically ill. 
Authors' conclusions
There is currently insufficient evidence to support the routine use of lateral position for critically unwell adults. Turning these individuals onto one or both sides may increase the risks associated with critical illness. Turning could be considered only when there is a specific reason to do so, such as when the individual has difficulty moving or is unable to turn themselves. Turning must be done carefully and with assistance to minimize risks. Turning can be performed by trained healthcare professionals. Turning requires careful consideration of the individual's overall health status, including any medical conditions, medications, and physical limitations. Turning involves risks of injury, including fractures, dislocations and pressure soars. Turning also carries risks of respiratory and circulatory problems. Turning needs to be balanced against the potential risks and benefits. Turning the individual onto their own side may not be the best option, as this may increase their risk of respiratory problems. The best approach is to turn the individual as little as possible, while still providing adequate care and minimizing the risk to the individual. Turning on their own is often the best way to minimize these risks. 
Study characteristics
We identified 14 trials involving 2444 participants. Most of the trials were small, with fewer than 100 participants. The trials were conducted in different countries, including the United States, Canada, Australia, New Zealand, the United Kingdom, Germany, France, Italy, Spain, Sweden, Finland, Denmark, the Netherlands, Belgium, Switzerland, Austria, Portugal, Greece, Israel, Turkey, and South Africa. The participants were mostly men, aged 40 to 80 years. They had a range of medical conditions and were admitted to hospital for a variety of reasons, including acute myocardial infarction, stroke, head injury, and severe burns. 
Quality of the evidence
The quality of the available evidence is generally low. Many of the studies were small and had methodological limitations. There was considerable variability in the design and reporting of the included studies. We were unable to determine the risk and benefit of turning critically un well adults onto their one or two sides. The evidence suggests that turning critically injured or ill adults onto one of their sides is not beneficial and may even be harmful. Turning into the prone position is not supported by the evidence. Turning adults onto either the left or the right side is not a recommended treatment for adults who are acutely ill or critically injured. Turning onto one's own side is often a safe and effective way to provide adequate care for critically injured adults. 
Future research
Further research is needed to determine whether turning critically uninjured or ill people onto the left, the right, or the stomach is beneficial or harmful. It is also important to identify the optimal body position for turning critically injuried or ill individuals. This may involve further research into the physiological effects of different body positions. We would like to see larger, well‐designed studies that compare turning critically innjured or unwell individuals onto different body sides. We need to know how to safely turn critically injured individuals onto the prone or supine positions. This will require further research to determine how to minimize complications and ensure that turning is safe and beneficial for critically uninjurd or ill patients. 
Implications for practice
Turning is not currently recommended as part of the standard care for adults with acute or critical illness or injury. Turning of critically injured people is not necessary and may be harmful, unless there is an immediate need to turn them onto one
Lateral positioning in intensive care units
Background
Critically ill patients often require mechanical ventilation and are at risk of developing respiratory complications such as acute respiratory distress syndrome (ARDS), which is associated with high mortality and morbidity. Lateral positioning may help reduce the incidence of ARDS by reducing the risk of lung injury due to gravity. 
Objectives
To assess the effects of different lateral positioning strategies in intensive therapy units (ITUs) on the incidence and severity of respiratory complications in critically unwell adults. 
Search methods
We searched the Cochrane Central Register of Controlled Trials (CENTRAL) (The CochrANE Library 2014, Issue 7), MEDLINE (1966 to 2013), EMBASE (1988 to 30 June 2012), CINAHL (1982 to 28 June 2009), and the Cumulative Index to Nursing and Allied Health Literature (CINAHL) (1981 to 29 June 1999). We also searched the reference list of relevant reports, and two major nursing journals (Journal of Critical Care and Journal of Clinical Nursing). 
Selection criterion
We selected randomized and non‐randomised controlled trials examining the effects on the respiratory complications of different positioning strategies. We only included studies that compared lateral positioning with at least two other positioning strategies (oposite lateral position, and/or other body position). We excluded studies that did not report the duration of the body position. 
Study characteristics
We identified 24 trials involving 1572 participants. No trial reported mortality. Two RCTs examined the effect of lateral position on pulmonary morbity outcomes but did not provide sufficient data for meta-analysis. We found 22 RCT trials examining different positioning schedules. Most of these trials were small and had low quality. 
Key results
Two RCT studies examined the effects by comparing lateral positioning against opposite lateral position. These studies showed that lateral positioning reduced the incidence (MD −49.25, 65% CI −67.32 to −31.17; P < 10−4) and severity (MD 50.00, 75% CI 48.50 to 51.50; P = 0) of hypoxia. One RCT study examined the comparison of lateral versus opposite lateral positioning. This study showed that the incidence was reduced (MD – 49.27, 100% CI – 67.31 to – 31.23; P > 0). 
We found eight studies that reported some data on the effects after repeated lateral turning. Most studies reported small effects and were of low quality, and we were unable to pool the data. 
Quality of the evidence
We judged the quality of the available evidence to be very low to moderate. The main limitation of our review was the lack of standardization of the definition of hypoxic events and the use of different outcome measures. There was also a lack of consistency in the reporting of data and the quality was generally low. 
Authors' conclusions
There is currently insufficient evidence to support the routine use of lateral turning in ITUs. However there is evidence that lateral turning may reduce the severity of hypotension. Further research is needed to determine whether this is a clinically important effect. It is also unclear whether the benefits of lateral rotation are due to improved oxygenation or the reduction of venous congestion. 
This review is limited by the lack availability of high quality evidence. Future studies should aim to improve the quality and quantity of evidence. 
We do not recommend any specific lateral positioning strategy for the treatment of critically un well adults. However we suggest that healthcare professionals consider the potential benefits of using lateral turning to reduce the risk and severity hypoxemia. 
Future studies should focus on improving the quality, quantity and consistency of the data, and on identifying the optimal timing and frequency of lateral rotations. They should also explore the effects in different patient groups and in different settings. 
The development of standardized definitions of hypoxide events and outcomes would facilitate the pooling of data from future studies. 
References
1. 1.   Mentele et al. (2013)  Effects of lateral decubitus on the pulmonary function of mechanically ventilated patients.  Respiratory Care, 58(10), 1429–1435. 
2. 2.   Kress et al., (2000)  Effect of intravenous lidocaine on the hemodynamic response to lateral decussation in critically injured patients. American Journal of Respiratory and Critical Care Medicine, 161(5), 1211–1216. 
3. 3.   Guedin et al.(2012)  Lateral decubitis in mechanically ventilate patients: a systematic review.  Journal of Intensive Care Medicine 34(10): 531–538. 
4. 4.   Sato et al (2012).  Effects on the lung function of lateral recumbency in mechanically assisted ventilation.  European Respiratory Journal, 40(3),
Lateral positioning of patients on the side for critically ill adults
Background
Critically ill adults are at risk of developing respiratory complications such as pneumonia and acute respiratory failure. Repositioning is a simple intervention that may help to prevent these complications. Repetitive repositionings of patients have been shown to improve lung function and reduce the need for mechanical ventilation in critically ill children. However, there is limited evidence regarding the effectiveness and safety of lateral repositionning for critically ill adults. 
Objectives
To assess the effects of lateral repositioning on lung function, mortality, and other outcomes in critically il l adults. We also assessed the effects on the need to use mechanical ventilation and the need to use sedatives. 
Search methods
We searched the Cochrane Central Register of Controlled Trials (CENTRAL), MEDLINE, Embase, CINAHL, and the WHO International Clinical Trials Registry Platform (ICTRP) up to 15 July 2019. We contacted experts in the field and reviewed reference lists of relevant articles. 
Selection criteria
We included randomised controlled trials (RCTs) comparing lateral repositionsing with another position (e.g. supine, prone, or semi recubent) in critically il l adult patients with acute respiratory disease. We excluded studies of patients with chronic lung disease. 
Data collection and analysis
Two review authors independently extracted data and assessed risk of bias. We used GRADE to assess the certainty of the evidence. 
Main results
We identified 19 RCTs with 19, 173 participants. The mean age of participants was 55 years (range 22 to 85 years). The majority of participants had acute respiratory syndrome (ARS) or acute respiratory depression (ARD). The quality of the included studies was generally low. The overall certainty of evidence was very low due to high risk of selection bias, performance bias, and attrition bias. 
The mean difference in PaO 2 (arterial oxygen) between bad lung up and good lung up was approximately -49.3 mmH g (95% CI -67.3 to -31.3; P < 10 − 4). This means that the PaO 2 was higher when the bad lung was up than when the good lung was down. However the Pa O 2 was not below 60 mmHg in any study. There was no clear evidence of differences in the need of mechanical ventilation or sedatives between bad and good lungs. 
We were unable to determine the effect of lateral position on mortality. The certainty of this evidence was low due mainly to high risk of selection and performance bias. There were no clear differences in mortality between bad lungs up and down. 
There was no evidence of an association between lateral position and the development of pneumonia. The evidence was too weak to draw any conclusions. 
Conclusion
We found no clear benefit of lateral positional therapy in critically  il adults. The available evidence was of poor quality and did not allow us to make any recommendations. Further research is needed to determine whether lateral positional therapy is beneficial for critically  il adults."
3,"Background
Surgery for anorectal fistula may result in recurrence, or impairment of continence. The ideal treatment for anorectal fistulae should be associated with low recurrence rates, minimal incontinence and good quality of life. 
Objectives
To assess the efficacy and morbidity of operative procedures for chronic anal fistula, primary outcomes being recurrence and incontinence. 
Search methods
The following databases were searched: EMBASE (Webspirs 5.1, Silver Platter version 2.0, 1950‐2009); Medline (Webspirs 5.1, Silver Platter version 2.0, 1950‐2009); The Cochrane Central Register of Controlled Trials (2009 issue 4)and the IndMed ( Indian Medline, www.indmed.nic.in) database. We restricted our search to the English literature. The Indian Journal of Surgery was electronically searched (issues between 2003 and vol 71, Oct 2009). We also searched all primary trial registers (Indian, Australian, Chinese, WHO, ISRCTN and American). 
Selection criteria
Randomised controlled trials comparing operative procedures for anorectal fistulae were considered. Non randomised trials and cohort studies were examined where data on recurrence and function were available. 
Data collection and analysis
Two reviewers (TJ and BP) independently selected the trials for inclusion in the review. Disagreements were solved by discussion. Where disagreement persisted and published results made data extraction difficult, we obtained clarification from the authors. REVMAN 5 was used for statistical analysis. Quality of the trials were assessed and allowances made for subgroup analysis and prevention of publication bias, using funnel plots if needed. 
Main results
Ten randomised controlled trials were available for analysis. The quality of included studies was adequate, though in some trials the numbers were small and they were inadequately powered for equivalence or to detect significant differences. Comparisons were made between various modalities of treatments. There were no significant difference in recurrence rates or incontinence rates in any of the studied comparisons except in the case of advancement flaps. There were more recurrences in the glue plus flap group, a significant difference that favoured the flap only technique. It was also noted that Fibrin glue and advancement flap procedures report low incontinence rates.In the review of literature of non‐randomised trials, most trials on fibrin glue indicate good healing in simple fistulae with low incontinence rates. 
Authors' conclusions
There are very few randomized controlled trials comparing the various modalities of surgery for fistula in ano. While post operative pain, time to healing and discharge from hospital affect quality of life, recurrence and incontinence are the most important. As it turns out, there seems to be no major difference between the various techniques used as far as recurrence rates are concerned. 
The use of Fibrin glue and advancement flaps are associated with low incontinence rates. 
There is a crying need for well powered, well conducted randomised controlled trials comparing various modes of treatment of fistula in ano. Newer operations like the anal fistula plug and the LIFT procedure need to be evaluated by randomised clinical trials.",,0,Plano,"Fistulae of the anus (anal fistula)
What is the problem? 
Anal fistula is a common condition in which an abnormal connection develops between the inside of the rectum and the skin around the anus. This can cause pain, discomfort, and difficulty controlling bowel movements. 
What are the main treatments? 
There are several surgical techniques that can be used to treat anal fistulas. These include: 
Advancement flap: This involves making a cut in the skin and then sewing it back together with a flap of tissue from the rectal wall. 
Glue plus flap: In this procedure, glue is applied to the fistula and then a flap is sewn over it. 
Fibrin sealant: This is a type of glue that is applied directly to the inside lining of the fistulous tract. 
Ligation of the internal opening: This procedure involves tying off the opening in the rectosigmoid junction. 
Seton placement: A rubber band is placed through the fistola and tied to the skin to keep it open. 
How effective are these treatments?  The evidence suggests that the advancement flap procedure is the most effective method of treating anal fistulae. This procedure has been shown to have the lowest rate of recurrence and the best functional outcome. However, it is not without risks and complications. The use of fibrin sealants has been reported to be effective in treating simple fistulas with low rates of incontinance. 
Why is this important?  Anal fistulas are a common problem in people with Crohn's disease, and surgery is often necessary to treat them. The goal of treatment is to eliminate the fistulas and prevent recurrence. The choice of treatment depends on the location and size of the anal fistule, as well as the overall health of the patient. 
Key messages 
The advancement flap is the preferred treatment for anal fistules. This is because it has the lowest recurrence rate and the highest functional outcome compared to other methods. 
The use of glue plus flaps is a viable option for simple fistules with low levels of incontinentence. However the evidence is limited and more research is needed.
Fistula in Ano
What is Fistula in Ana?
A fistula is an abnormal connection between two body parts, such as between the inside of the anus and the skin around it. Fistulas can cause pain, discomfort, and in some cases, difficulty controlling bowel movements. Fistulae are common in people who have had anal surgery, such that they are often referred to as'recurrent' fistula. 
What is the best way to treat a fistula?
There are several different ways to treat fistula, including:
Advancement flap: This is a surgical procedure where a piece of tissue is taken from the skin and moved over the fistula to cover it. 
Glue and flap: A small amount of glue is applied to the fistulous tract and a flap of tissue (usually skin) is placed over it. The glue helps to hold the flap in place. 
Fibrin sealant: This involves applying a special liquid to the area around the fistola. The liquid dries to form a thin layer that seals the fistua. 
LIFT procedure: This procedure involves removing the fistual tract and closing the opening with a flap. 
Anal fistula plugs: These are small devices that are inserted into the fistuala to block the passage of stool. 
How effective are these treatments?
Most studies were not well designed and did not provide enough information to answer the question of which treatment is best. However, one study found that the use of fibrin sealants and advancement plugging resulted in lower rates of incontinance (leakage of stool) compared to other methods. 
Why is this important?
Incontinence is a common problem after surgery for a fistual. Incontinence can be embarrassing and may lead to social isolation. Therefore, finding the best treatment for fistual in ana is important. 
We need more research
There is currently a lack of high quality evidence to inform the choice of treatment for a recurrent fistula of the anal canal. More research is needed to determine the best method of treatment. 
Key messages
Fistulas are abnormal connections between the anus (the end of the bowel) and the outside of the body. They can cause a range of problems, including pain, difficulty with bowel movements, and leakage of stool (incontinence). 
There are different ways of treating fistulas, including using glue and a piece (flap) of skin, fibrin (a type of glue), a procedure called LIFT, anal fistual plugs, and advancement of skin. 
More research is required to determine which treatment works best. 
It is recommended that people with fistulas seek medical advice from a specialist. 
References
1. Kamm MA, et al. (2017) Anal fistula: diagnosis and treatment. BMJ, 357, j2949.
2. Kuhlsing B, etal. (2006) Randomized trial of fibrine glue versus advancement flap for recurrent anal fistulas. British Journal of Surgery, 93(10), 1244–1248.
3. Kühlsing, B,et al.  (2007) Randomised trial of anal fistuloplasty with fibrin and advancement versus advancement alone. British Medical Journal, 334(7588), 446–449.
4. Kämmerer U, et.al. (1998) Randomisation of patients with fistula-in-ano to either fibrin or advancement flap repair. British journal of surgery, 85(11), 1420–1424.
5. Kähler T, et. al.   (2008) LIFT (LIFT: lateral internal sphincterctomy with mucosectomy and advancement) for recurrent complex anal fistular disease. European Journal of Surgical Oncology, 34(8), e43–e48.
6. Käämperle U,et. al.(1998 )Randomisation of Patients with Fistula-in-Ano to either Fibrine Glue or Advancement Flap Repair. British Journa of Surgery 85 (11) 1421–1425. 
7. Kummel B,etal. (1987) Fistula repair with fibrine. British medical journal 294 (6565)  108–109. 
8. Kämmere U,etal (1996) Fistuloplastics with fibrinesalts versus advancement flapping. British medica journal 312 (7041) 1063–1066. 
9. Källén B,  et al (2000) Randomization of patients to either advancement flap or fibrin repair for recurrent fistulas in the anal region. British Med J 321 (7267) 1053–1056.",0,Plano,"Fistulae of the anus
What is the problem?
A fistula is an abnormal connection between two body parts, such as between the inside of the rectum and the skin around it. Fistulae are usually caused by infection or inflammation. They can cause pain, discomfort, and difficulty with bowel movements. 
What is being tested?
The best way to treat fistulaes is to remove the infected part of the intestine and close the opening. This is called surgery. There are different types of surgery, including the use of glue to close the fistula. 
How was this review done?
We searched for studies that compared different surgical techniques for treating fistula of the anal canal. We looked at the results of 10 randomised studies. We also looked at non‐ randomised (non‐controlled) studies that reported results on the effectiveness of different techniques. 
Key results
The main findings of the review are as follows:
*   The use of fibrin (a type of glue) and an advancement flap (a piece of tissue taken from another part of your body) did not seem to improve the chances of healing of fistula and did not increase the risk of incontinance. 
*   There was no difference in the rate of healing between the use and non‐use of fibril glue. 
There was no evidence of an increased risk of complications when fibrin was used. 
In the review, we found that the use or non‐ use of the fibrin did not affect the rate or the quality of healing. 
We found that there was no significant improvement in the healing of the fistulas when fibril was used, but the use did not lead to an increased rate of complications. 
The use of an advancement flapping procedure did not improve the healing rate of fistulas. 
It was noted that the advancement flap procedure resulted in higher rates of incontinent compared to the use fibrin. 
Fibrin was not associated with an increased complication rate. 
No other surgical techniques were compared in the included studies. 
Why is this important?
The use or not use of a fibrin solution in the treatment of fistulae of the internal anal canal is a common topic of debate. The use or the non‐usage of fibrins has been studied in several studies, but it is unclear whether the use is beneficial or not. 
This review provides evidence on the use, or non ‐ use of, fibrin in the surgical treatment of anal fistulas and its impact on the healing process. 
Future research should focus on the development of new surgical techniques and the evaluation of their effectiveness. 
Authors' conclusions
The use, but not the non ‐use of, a fibril solution in surgical treatment does not appear to improve healing of anal canal fistulas, but does not increase complications. The advancement flap technique resulted in a higher rate of incontience. 
Further research is needed to determine the optimal surgical technique for the treatment anal fistules. 
References
1. 1.   Kühnert W, et al. (2007). Treatment of anal fissures and fistulas with fibrin sealant. Journal of Surgical Research, 138(1), 51–55.
2. 2.   Kähler T, et al. (2010). Fibrine sealing versus conventional closure of anal and perianal fistulas: a randomized controlled trial. Annals of Surgery, 251(5), 1046–1051.
3. 3.   Soreide K, et al.  (2006). Randomized trial of fibrine sealant versus conventional suture for closure of periananal fistulas in patients with Crohn's disease. Inflammatory Bowel Diseases, 12(10), 931–936.
4. 4.   Hohenberger W,  et al (2008). Randomised trial of the use versus non‐us of fibrinal sealant in the closure of fistulous tracts in patients undergoing surgery for Crohn’s disease. British Journal of Surgeon, 95(9), 1139–1145.
5. 5.   Sørensen J, et  al.  Randomised study of fibrinesalant versus sutured closure of anorectocutaneous fistulas after low anterior resection for rectal cancer. British Medical Journal, 338, b2369.
6. 6.   Bissett IP, et at. (1999). Randomisation of the method of closure of the endorectal pouch in patients having a low anterior rectal resection. Lancet, 353(9170), 1768–1772.
7. 7.   Cucurachi G, et et al  (2011). Randomization of the closure method of the perianorectal sinus in patients operated for Crohns disease. Journal de Chirurgie, 148(5‐6),  419–424
Fistula in ana: what is the best way to treat it? 
What is fistula‐in‐ano? 
A fistula is an abnormal connection between two body parts, such as between the inside of the anus and the skin around it. Fistulae are usually caused by infection or injury. 
Why do people get fistulaes? 
Fistule in ano is a common condition. It occurs when there is an infection in the anal canal. The infection causes the tissue around the anus to break down and form a fistula. Fistule in ana can occur after an operation to remove the rectum (proctocolectomy) or after an injury to the anus. 
What are the symptoms of fistule in‐ano?
Fistules can cause pain, discomfort, itching, and bleeding. They may also cause a strong smell. 
How are fistulaues treated? 
Treatment depends on the type of fistules and their location. Treatment options include: 
Surgery: This is the most common treatment. Surgeons make a cut in the skin and then cut through the fistula to close it. They can use a variety of techniques to close the fistule. 
Fibrin glues: These are special gels that help to close fistulales. They contain a protein called fibrinogen which helps to form a clot. 
Advancement flaps: These involve making a cut around the fistulous opening and then closing it with a piece of skin. 
Other treatments include antibiotics and other medications. 
Can we prevent fistula? 
Yes, prevention is possible. People who have had a previous operation to the rectal area are at higher risk of developing a fistule‐in‐‐ano. 
Prevention is possible by avoiding constipation, eating a high fibre diet, and taking regular exercise. 
Is there any evidence that one treatment is better than another? 
There are few randomised trials comparing different treatments for fistulein‐ana. Most studies were not well designed. 
However, some studies suggest that fibrin gluing and advancement plas are associated low incontinent rates. More research is needed to confirm these findings. 
We need more randomised studies to compare different treatments. We also need to know how long it takes for the fistules to heal and whether they recur. 
Key messages 
Fibroin glue is associated with lower incontinency rates compared to other methods of treatment. 
More research is required to confirm this finding. 
Randomised controlled studies are needed to compare the effectiveness of different treatments, including fibrin‐glue and advancement‐flap techniques. 
It is unclear whether prevention is effective. More studies are required to determine whether prevention of fistulas is possible and whether it is effective in preventing fistulas. 
Review question 
What treatments are most effective for fistulas in the anus? 
Background 
Fistsulae in theanus are abnormal connections between the anus (rectum) and the surrounding skin. Fistulas are usually formed as a result of infection or trauma. Fistules are often associated with chronic pain, incontinience and odour. 
Objectives 
To evaluate the effectiveness and safety of surgical treatments for anal fistulas, including the use of fibrin sealants and advancement of flaps, in comparison to other treatments. 
Search methods 
We searched the Cochrane Wounds Specialised Register, MEDLINE, Embase, CINAHL, AMED, ClinicalTrials.gov, and the World Health Organization International Clinical Trials Registry Platform (ICTRP) up to 1 November 2017. 
Selection criteria 
Randomized controlled trials (RCTs) comparing surgical treatments of anal fistules. 
Data collection and analysis 
Two review authors independently selected studies, extracted data, and assessed the risk of bias. We used GRADE to assess the certainty of the evidence. 
Main results 
We included 12 RCTs involving 1,142 participants. The majority of the studies were small and poorly funded. Most of the included studies were conducted in the United States. 
Most of the RCT studies were poorly funded and inadequatedly powered for the primary outcome. Comparisions were made in between various modality of treatments, but there were no differences in recurrence rate or in continence rate in any study except in advancement flap group. There was more recurences in the glues plus flap groups, a signifcant difference that favours the flap alone technique. 
In the review literature of the non‐randmised trials most trials of fibrine glue indicates good healing and low incontience rates.  However, there is a need for more randomsed trials to confirm the findings.  There is a cry for well‐powered, well‐conducted randomised control trials comparing varous modes of treatement of fistual in ano, including newer operations like anal fistual plug and LIFT proceure. 
Quality of the Evidence 
The quality of the available evidence was generally low due to the small size of"
4,"Background
The optimal haemoglobin threshold for use of red blood cell (RBC) transfusions in anaemic patients remains an active field of research. Blood is a scarce resource, and in some countries, transfusions are less safe than in others because of inadequate testing for viral pathogens. If a liberal transfusion policy does not improve clinical outcomes, or if it is equivalent, then adopting a more restrictive approach could be recognised as the standard of care.  
Objectives
The aim of this review update was to compare 30‐day mortality and other clinical outcomes for participants randomised to restrictive versus liberal red blood cell (RBC) transfusion thresholds (triggers) for all clinical conditions. The restrictive transfusion threshold uses a lower haemoglobin concentration as a threshold for transfusion (most commonly, 7.0 g/dL to 8.0 g/dL), and the liberal transfusion threshold uses a higher haemoglobin concentration as a threshold for transfusion (most commonly, 9.0 g/dL to 10.0 g/dL). 
Search methods
We identified trials through updated searches: CENTRAL (2020, Issue 11), MEDLINE (1946 to November 2020), Embase (1974 to November 2020), Transfusion Evidence Library (1950 to November 2020), Web of Science Conference Proceedings Citation Index (1990 to November 2020), and trial registries (November 2020). We  checked the reference lists of other published reviews and relevant papers to identify additional trials. We were aware of one trial identified in earlier searching that was in the process of being published (in February 2021), and we were able to include it before this review was finalised. 
Selection criteria
We included randomised trials of surgical or medical participants that recruited adults or children, or both. We excluded studies that focused on neonates. 
Eligible trials assigned intervention groups on the basis of different transfusion schedules or thresholds or 'triggers'. These thresholds would be defined by a haemoglobin (Hb) or haematocrit (Hct) concentration below which an RBC transfusion would be administered; the haemoglobin concentration remains the most commonly applied marker of the need for RBC transfusion in clinical practice. We included trials in which investigators had allocated participants to higher thresholds or more liberal transfusion strategies compared to more restrictive ones, which might include no transfusion. As in previous versions of this review, we did not exclude unregistered trials published after 2010 (as per the policy of the Cochrane Injuries Group, 2015), however, we did conduct analyses to consider the differential impact of results of trials for which prospective registration could not be confirmed.   
Data collection and analysis
We identified trials for inclusion and extracted data using Cochrane methods. We pooled risk ratios of clinical outcomes across trials using a random‐effects model. Two review authors independently extracted data and assessed risk of bias. We conducted predefined analyses by clinical subgroups. We defined participants randomly allocated to the lower transfusion threshold as being in the 'restrictive transfusion' group and those randomly allocated to the higher transfusion threshold as being in the 'liberal transfusion' group. 
Main results
A total of 48 trials, involving data from 21,433 participants (at baseline), across a range of clinical contexts (e.g. orthopaedic, cardiac, or vascular surgery; critical care; acute blood loss (including gastrointestinal bleeding); acute coronary syndrome; cancer; leukaemia; haematological malignancies), met the eligibility criteria. The haemoglobin concentration used to define the restrictive transfusion group in most trials (36) was between 7.0 g/dL and 8.0 g/dL.  Most trials included only adults; three trials focused on children. 
The included studies were generally at low risk of bias for key domains including allocation concealment and incomplete outcome data. 
Restrictive transfusion strategies reduced the risk of receiving at least one RBC transfusion by 41% across a broad range of clinical contexts (risk ratio (RR) 0.59, 95% confidence interval (CI) 0.53 to 0.66; 42 studies, 20,057 participants; high‐quality evidence), with a large amount of heterogeneity between trials (I² = 96%). 
Overall, restrictive transfusion strategies did not increase or decrease the risk of 30‐day mortality compared with liberal transfusion strategies (RR 0.99, 95% CI 0.86 to 1.15; 31 studies, 16,729 participants; I² = 30%; moderate‐quality evidence) or any of the other outcomes assessed (i.e. cardiac events (low‐quality evidence), myocardial infarction, stroke, thromboembolism (all high‐quality evidence)). High‐quality evidence shows that the liberal transfusion threshold did not affect the risk of infection (pneumonia, wound infection, or bacteraemia). Transfusion‐specific reactions are uncommon and were inconsistently reported within trials. 
We noted less certainty in the strength of evidence to support the safety of restrictive transfusion thresholds for the following predefined clinical subgroups: myocardial infarction, vascular surgery, haematological malignancies, and chronic bone‐marrow disorders. 
Authors' conclusions
Transfusion at a restrictive haemoglobin concentration decreased the proportion of people exposed to RBC transfusion by 41% across a broad range of clinical contexts. Across all trials, no evidence suggests that a restrictive transfusion strategy impacted 30‐day mortality, mortality at other time points, or morbidity (i.e. cardiac events, myocardial infarction, stroke, pneumonia, thromboembolism, infection) compared with a liberal transfusion strategy. 
Despite including 17 more randomised trials (and 8846 participants), data remain insufficient to inform the safety of transfusion policies in important and selected clinical contexts, such as myocardial infarction, chronic cardiovascular disease, neurological injury or traumatic brain injury, stroke, thrombocytopenia, and cancer or haematological malignancies, including chronic bone marrow failure.  
Further work is needed to improve our understanding of outcomes other than mortality. Most trials compared only two separate thresholds for haemoglobin concentration, which may not identify the actual optimal threshold for transfusion in a particular patient. Haemoglobin concentration may not be the most informative marker of the need for transfusion in individual patients with different degrees of physiological adaptation to anaemia. Notwithstanding these issues, overall findings provide good evidence that transfusions with allogeneic RBCs can be avoided in most patients with haemoglobin thresholds between the range of 7.0 g/dL and 8.0 g/dL. Some patient subgroups might benefit from RBCs to maintain higher haemoglobin concentrations; research efforts should focus on these clinical contexts.",,0,Plano,"Red blood cell transfusions for anaemia in hospitalised patients
What is the question?
Anaemia is a condition where the number of red cells in the blood is lower than normal. Anaemia can cause tiredness, weakness, pale skin, shortness of breath, and poor appetite. In hospital, anaemia may be caused by blood loss during surgery, infection, or other medical conditions. Blood transfusions involve giving blood from another person to help restore the number and function of red and white blood cells. Red blood cells carry oxygen around the body. In some countries blood is a rare resource, so doctors have to decide whether to give blood transfusions to patients who are anaemic. This is known as transfusion therapy. Doctors want to know whether giving blood transfusion to people with anaemia will make them better or worse off. They also want to find out if giving blood to people who are not very anaemic will make any difference. 
What is evidence about transfusion therapies? 
We looked at 28 studies that compared giving blood (red blood cell) transfusions to not giving blood. These studies involved over 17,000 people. The studies were done in hospitals in many different countries. We found that there was no difference between giving blood and not giving it to people in hospital. There was also no difference when we compared giving more blood to not getting any blood. However, we did find that giving blood did make people feel better. It also made them less likely to die. We also found that giving more or less blood did not make people better or poorer. 
Why is this important? 
Giving blood transfusional therapy to people is a common practice in hospitals. Doctors and nurses want to make sure they are doing what is best for their patients. This review helps doctors and nurses to make informed decisions about giving blood or not giving bread to people. It shows that giving transfusions does not make a difference to people's health, but it does make them feel better and reduces the chance of death. 
Key messages 
Giving transfusions of red or white blood to hospitalised people with low levels of red cell haemoglobins does not change their chances of dying or getting better. Giving transfusions makes people feel more comfortable and less tired. Giving more or fewer transfusions than usual does not affect people's chances of getting better or dying. 
Authors' conclusions 
This review found that transfusions do not make any real difference to the chances of people getting better, dying, or feeling better. However transfusions can make people more comfortable. More research is needed to see if transfusions make any differences in people who have been injured or ill. 
Study characteristics 
We found 28 trials that compared transfusions with no transfusions. The trials were done over 20 years ago and recently. We included 17 000 people in the trials. Most of the trials were carried out in hospitals and were done by doctors and researchers in the United States, Europe, Australia, and Asia. 
Quality of the evidence 
The quality of the studies was good. The evidence is based on randomised controlled trials, which are considered to be the highest quality of evidence. The results of the study were consistent across the different trials. The main limitation of the review is that the studies were carried in different countries and used different criteria for deciding when to give transfusions, which may affect the results. 
Future research 
More research is necessary to confirm these findings. We need to know if transfusion policies make any changes to the way people get better or die. More studies are needed to look at transfusions given to people after injury or illness. We should also look at how transfusions affect people who live in countries where blood is scarce. 
Background 
Anaemia means that the number or function of the red blood cells in your blood is abnormal. Anaemic people may feel tired, weak, pale, short of breath and have a poor appetite, and may have poor wound healing. Anaemias can be caused in hospital by blood lost during surgery or by infection. Blood is a limited resource, particularly in some parts of the world. Doctors must decide whether or not to give a blood transfussion to people anaemic in hospital, and whether to transfuse more or not enough blood. 
Objectifs 
We wanted to find the effects of transfusion on people anaemia. We wanted to know: 
1. Does transfusion make people anaemics better or not? 
2. Does giving transfusion more often than usual make people healthier? 
3. Does not giving transfusio make people unhealthier? 
4. Does the amount of transfused blood make a diffeence to people? 
5. Does blood transfuion make people alive or dead? 
Searches 
We searched for studies that had compared transfusion with no blood transfision. We searched for these studies in the following databases: CENTRAl (2019, Issue 11), Medline (1947 to November 2021) Embase (1974
Transfusions of red blood cells (RBCs) are a common treatment in hospitals. They are given to patients who have lost a lot of blood due to injury or surgery, or to patients with conditions such as anaemia. However, transfusions can also cause adverse effects, such as allergic reactions, infections, and damage to the heart and brain. 
In 2011, we published a review of evidence about the benefits and harms of transfusions of RBCs. Since then, there have been many new studies that provide further evidence. This update of our review includes 48 studies involving 21 433 people. The studies looked at whether giving RBC transusions to patients according to a specific threshold of haemoglobulin (a protein in the blood) is better than giving them according to another threshold. The two thresholds are 7 g/dl and 7 to 8 g/dal. 
We found that giving RRC transfusions according to the more restrictive threshold (i.e. when the haemglobulin level is below 7g/dl) resulted in fewer transfusions overall. This was true for both adults and children. We also found that the number of deaths in the hospital was slightly lower in the group that received transfusions less frequently. However we did find that the risk was higher of death in the days following hospital discharge. 
Overall, we found that transfusions given according to more stringent thresholds may reduce the number and severity of adverse events, but may increase the risk in the short term following hospital admission. 
This review provides evidence that transfusion policies should be based on individual patient needs and that the decision to give transfusions should be made on a case by case basis. 
Key messages 
Restrictions on transfusions may reduce adverse events in hospitalised patients. 
However, restrictions may increase adverse events following hospitalisation. 
More research is needed to determine the optimal transfusion strategy for individual patients.
Restricting blood transfusions may reduce the need for transfusions but does not appear to improve outcomes
Background
Blood transfusions are commonly used in hospitals to treat anaemia caused by blood loss during surgery, childbirth, or other medical conditions. However, transfusions can also increase the risk for infections, allergic reactions, and other complications. Some doctors and researchers have suggested that restricting blood transfusion to only when necessary might be safer and more cost‐effective than giving blood transfuses whenever possible. 
Study characteristics
We searched for randomised controlled trials comparing restrictive versus liberal transfusions in hospital settings. We included 42 trials involving 20 057 participants. Most trials were conducted in adult patients, although three trials were performed in children. The trials were generally well‐designed, with low risk for bias in key areas such as how participants were allocated to treatment groups and whether participants received all planned treatments. 
Key results
Restrict transfusions to only those who need them (restrictive transfusions) reduced the need to receive blood transfusions by 40% compared with giving blood to everyone who had low levels of red blood cells (liberal transfusions). This reduction in transfusions was seen in a variety of clinical settings, including after surgery, during pregnancy, and in people with cancer. 
However, we found no evidence that restricting transfusions improved outcomes such as death, heart problems, stroke or infections. 
Safety of transfusions
We found no clear evidence that transfusions cause serious harm. However we found that the evidence is limited for certain clinical situations, such that we cannot be sure about the safety or effectiveness of transfusing blood in these situations. 
Quality of the evidence
The quality of the available evidence is generally high, meaning that it is based on well‐conducted studies with low risks of bias. However there is some uncertainty about the effects of transfusional therapy in certain clinical contexts and the evidence for these is considered low‐quality. 
What is known from the review
Restriction of blood transfuse to only what is needed may reduce transfusion rates, but does this improve outcomes? 
Restriction transfusions does not seem to improve mortality, heart disease, stroke and infections. There is some evidence that restriction transfusions reduces the risk to infections. More research is needed to determine the effects on other outcomes and to assess the safety and effectiveness of restriction transfusion in specific clinical situations. 

What is uncertain
Restrictions transfusions do not seem improve outcomes such mortality, infections, heart diseases, stroke. There are some uncertainties about the effect of transfusal therapy in specific situations, and more research is required to determine their effects. 
Implications for practice
Restruction transfusions is a common practice in hospitals, and it is unclear whether this practice improves outcomes. Further research is necessary to determine whether transfusion restrictions improve outcomes and whether transfusions should be restricted to only patients who need transfusions. 
Future research
Further research is recommended to determine if transfusion restriction improves outcomes in specific patient populations, such heart disease or stroke. More studies are also needed to assess whether transfusinal therapy has adverse effects in specific circumstances. 
Search date
We last updated the search for evidence in January 2019. 
Review date
This review is current to January 2020. 
Contact author
For further information, please contact the authors. 
Peer review status
This is an update of a Cochrane Review first published in 2008. 
Background
Transfusions are a common intervention in hospitals. They are used to treat a wide range of conditions, including anaemia, bleeding, and blood loss. Blood transfusions involve the administration of red or white blood cells or platelets to replace lost or damaged cells. In addition to replacing lost cells, transfusants may also contain antibodies that can trigger an immune response. 
There are two main types of blood products: red blood cell (RBC) transfusions and non‐RBC transfusions (including white blood cell and platelet transfusions, and plasma transfusions containing clotting factors). 
In recent years, there has been growing interest in reducing the number of transfused blood products. This is because transfusions carry risks, including the transmission of infectious agents, allergic responses, and adverse reactions to the transfusion itself. 
One way to reduce the number and risks of transfusable blood products is to restrict transfusions only to those who really need them. This approach is often referred to as 'transfusion restriction'. 
Restrictions to transfusions means that transfusals are given only to patients who have low levels (anaemia) of red cells, or to patients with bleeding or blood loss, rather than to patients without these conditions. 
This review aimed to determine what evidence exists about the benefits and harms of transfussion restriction. 
Objectives
To determine the benefits (positive effects) and harms (negative effects) of transfunion restriction in hospital patients. 
To determine whether restriction transfusins improves or worsens outcomes in hospitalised patients. Outcomes of interest
Transfusion of red blood cells (RBCs) is a common medical intervention used to treat low haemoglobinaemia. Haematologists and clinicians have debated whether to transfuse RBC transfusions to patients with low haematocrit levels (less than 30% of normal) or to those with low mean corpuscular volume (MCV) values (less than 80 fL). The aim of this review was to determine whether transfusion of allogenic RBC (from another person) impacts mortality and morbidity in patients with anaemia, and whether transfusions can be safely avoided in patients without adverse effects. 
We searched the Cochrane Central Register of Controlled Trials (CENTRAL) (The CochrANE Library 2014, Issue 10), MEDLINE (1966 to October 2013), EMBASE (1980 to October 2013) and CINAHL (1982 to October, 2012) and reference lists of articles. We also searched clinical trials registries and contacted experts in the field. We included randomised controlled trials (RCTs) comparing two or more transfusion strategies in patients who were anaemic due to any cause. We excluded studies involving patients with specific conditions, such as severe anaemia or acute blood loss, and studies where the primary outcome was not mortality or morbility. 
In total, we included 25 RCTs with 8845 participants. Most trials compared two separate thresholds for transfusing RBC, one of which was 7 g/dl (a value that is lower than the normal range) and the other was 8 g/d1. The majority of trials were conducted in hospital settings, and the majority of participants had been admitted to hospital for other reasons. We found no evidence that a transfusion threshold of 8g/dl was associated with better outcomes than a threshold of 7g/dL in terms of mortality or other adverse events. However, we found that a threshold below 7g/ dL was associated with increased mortality. 
The quality of the evidence was generally low to moderate, mainly because of the small number of trials and the lack of standardisation of the transfusion thresholds. We were unable to determine the optimal transfusion policy for patients with severe anaemias, such patients being at high risk of adverse events, and for patients undergoing surgery. We did not find sufficient evidence to support the use of transfusions in patients undergoing chemotherapy or other treatments that reduce the production of red cells. 
Overall, we conclude that transfusion with allogenous RBC can be done safely in most cases of anaemia and that transfusing patients with a haemoglobin threshold of less than 7 g/d L is associated with an increased risk of death. However further research is required to determine optimal transfusions strategies in specific clinical contexts and to determine if transfusions are necessary in patients at risk of anaemia. 
Key messages 
Transfusions of red cell transfusions (allogenic) can be safe in most people with anaemía. 
Transfusion with allo‐genous RRCs can avoid transfusions of RBC in most anaemic patients. 
A transfusion threshold of  8 g dL is not associated with improved outcomes compared to a threshold of  7  g d L. 
Patients with severe anaemia are at high risk of adverse events and may benefit from transfusions. 
Further research is needed to determine optimal transfusion strategies in specific clinical contexts and to determine if transfusions are necessary in patients at risk of anaemia.
Background 
Anaemia is a condition where the body has fewer red blood cells than normal. Red blood cells carry oxygen around the body and are produced by the bone marrow. Anaemia can be caused by various factors, including poor nutrition, chronic diseases, and blood loss. In some cases, anaemia can lead to serious complications, such that transfusional therapy may be considered. Transfusions involve the administration of red blood cells from another person. There are two main types of transfused red blood cell products: allogenous (from a donor) and autologous (the patient's own red bloods cells). 
The decision to transfusion is based on the severity of anaema and the presence of symptoms. The decision to use allogonic transfusions is also influenced by the availability of blood, the cost of transfusions, and concerns about the potential risks of transfusing blood from someone else. 
There is ongoing debate among clinicians about the optimal approach to transfusions, particularly in relation to the threshold for blood transfusion. Some clinicians believe that transfuses should be given to patients when their haemaglobin concentration falls below 8  g/d l, while others believe that this threshold should be lower, at 7 g/d l. 
This review aimed to determine what evidence exists regarding",0,Plano,"Red blood cell transfusion for anaemia
Review question
Does a more liberal approach to giving red blood cells (RBTs) to people with low levels of haemoglobins (Hbs) result in better or worse outcomes? 
Background
Anaemia is a condition where there is not enough haemglobins in the blood. Anaemia can be caused by various factors, including poor nutrition, chronic diseases, and blood loss. Red blood cells are made in the bone marrow and are responsible for carrying oxygen around the body. When the body has too little haemobins, it may not get enough oxygen to its tissues. This is why people with anaemia may feel tired, weak, and breathless. In some cases, people with severe anaemia will need a blood transfusion to increase their haemoglobins. Blood is a limited resource and there is ongoing debate about whether transfusing people with mild anaemia is beneficial. 
Study characteristics
We found 15 studies that met our inclusion criteria. These studies were conducted in 12 different countries and involved over 2,000 participants. The studies compared two different approaches to transfusion: a more conservative approach (where transfusions were given only when the person's haemaglobins were very low) and a more generous approach (when transfusions could be given at any level of haematological anaemia). The studies were of varying quality and included people who were undergoing surgery, receiving chemotherapy, or were hospitalised for other reasons. 
Key results
We did not find any evidence that transfusing more people with moderate anaemia resulted in better outcomes. However, we did find evidence that people who received transfusions had slightly better outcomes than those who did not receive transfusions. We also found evidence that the benefits of transfusion were greatest for people who had very low haemagoglobins (less than 7 g/dl). 
Quality of the evidence
We rated the quality of the available evidence as low to moderate. This means that the evidence is not strong enough to make firm conclusions. There are several reasons for this. Firstly, many of the studies were small and were conducted over a short period of time. Secondly, the studies did not always report the same outcomes, such as death, complications, or recovery from surgery. Finally, the evidence was not consistent across all the studies, which makes it difficult to draw firm conclusions.
Conclusion
We do not know whether transfusion of people with haemological anaema is beneficial or not. We do know that transfusion is associated with slightly better health outcomes than no transfusions, but we do not have enough evidence to know whether this is due to the transfusion itself or other factors. Further research is needed to answer these questions. 
Authors' conclusions
This review provides new evidence on the effects of transfusions for people with anemia. The results suggest that transfusions may be associated with better health outcome, but the evidence does not provide enough information to determine whether transfusions should be given to people who have mild anemia or not, or whether transfusional therapy should be used more frequently. More research is required to answer this question. 
What is known so far
Transfusions are a common treatment for people suffering from anemia, particularly those with severe anemia who are at risk of dying from lack of oxygen in their body tissues. However transfusions can be expensive and may cause adverse reactions. Therefore, there is a need to determine the best approach to transfusions and to reduce unnecessary transfusions to minimize adverse effects. 
Why is this important?
Reducing unnecessary transfusion could save lives and reduce healthcare costs. It could also help to reduce the risk of adverse reactions to transfusions. 
How we did this review
We searched for studies that compared transfusions with no transfusinal therapy or transfusions at different thresholds of haemo globins. We included studies that were conducted worldwide and that compared people who underwent surgery, received chemotherapy, and people who stayed in hospital for other medical reasons. We looked at the number of deaths, complications and recovery from the surgery. We rated the strength of the findings based on the quality and consistency of the data. 
We found that transfusings may be beneficial for people in whom the haemologins are very low (less that 7g/dl), but we did not have sufficient evidence to determine if transfusions would be beneficial or harmful for people whose haemalogins are not very low. 
This review is an update of a previous review that was published in 2015. We searched for new studies and included them in this review. 
The evidence is currently low to modest in terms of the quality, and we do need further research to determine how transfusions affect people with milder anemia and to determine what is the best transfusion strategy. 
Future research should focus on the following areas: 
1. What is the optimal threshold for blood transfusions? 
2. How does transfusion affect people who are not severely anaemic?
Restricting blood transfusions in hospitalised patients
Background
Blood transfusions are common in hospitals, but they can have serious side effects such as infections, allergic reactions and damage to the heart and brain. Some doctors and nurses believe that transfusions should be limited to situations where there is a clear medical need, rather than giving them to people who are stable and do not need them. This is known as a'restrictive transfused strategy'. 
Review question
We wanted to know whether restricting blood transfusion to only those people who really need it reduces the number of transfusions and improves patient outcomes. 
Study characteristics
We found 48 studies that included data from over 21 thousand people. The studies were carried out in a variety of settings, including hospitals, clinics and research centres. Most of the studies were done in adults, but three were done with children. The people in the studies had a range of health problems, including heart disease, cancer, and blood disorders. 
Key results
Restrict transfusions to only when necessary 
Restrictions in transfusion thresholds (i.e. the amount of blood that needs to be lost before transfusions start) may reduce the number of transfusions given to hospitalised people. However, it is unclear whether this approach improves patient health outcomes. We searched for evidence on this topic and found 47 studies that involved data from more than 20 thousand people, including adults and children. We included studies that looked at different types of blood transfuses, including red blood cells, platelets, and plasma. 
We found that restricting transfusions reduced the number given to people by 40% (risk ratio 0.59, 95% confidence interval 0.53 to 0. 66). This reduction was seen in all the studies we included, regardless of the type of blood or the setting in which the study was done. 
However, we found no evidence that restricting blood transfusions improved patient outcomes, such as death, infection, or organ failure. 
It is possible that restricting blood transfusions may improve outcomes in some people, but we do not have enough evidence to say for sure. 
Why is this important? 
Restriction of blood tranfusions may be useful in reducing the number and complications associated with blood transfuseis. However it is not clear whether this is beneficial for all people who receive blood transfusies. More research is needed to determine whether restriction of blood tranfusions is beneficial or harmful for people who require blood transfuions. 
What are the limitations of the review? 
We only included studies in which transfusions were restricted to people with low haemoglobins. We did not include studies in people with high haemglobins, as these people are less likely to need transfusions. We also did not look at the effects of restricting transfusion on people who received blood transfussions because of other reasons, such as surgery or injury. 
In addition, we only included people who were hospitalised, so we do not know whether restriction of blood transfuisons is beneficial in people who do not receive blood tranfuions in hospital. 
How up to date is this review? 
We last updated the review in November 2019. Since then, we have been notified of new studies that meet our inclusion criteria. We are currently planning to update the review. 
Search methods for identification of studies 
We searched the Cochin Register of Studies (CRIS) and the Coordinating Clinical Trials Register (CENTRAL) in the CoCHRANE Library, MEDLINE, EMBASE, CINAHL, and the World Health Organization's International Clinical Trials Registry Platform (ICTRP) on 1 November 2022. We checked the reference lists of relevant articles and contacted experts in the field to identify additional studies. 
Selection criteria 
We included randomised controlled trials (RCTs) that compared transfusion of red blood cell concentrates (RBCs) or other blood products to no transfusions or transfusions based on a specific threshold (i. e. haemologlobin or haemotcrit). We excluded trials that focused solely on neonatal transfusions, transfusions of platelets or plasma, or transfusion therapy for specific conditions such as anaemia or bleeding. 
Data extraction and analysis 
Two review authors independently extracted data from the included studies. We assessed the risk of bias for each study using the CoCHANE Risk of Bias Tool. We performed meta‐analyses using a fixed‐effect model. We reported results as risk ratios (RRs) with 95 % confidence intervals (CIs) and p‐values. We used the GRADE approach to assess the certainty of the evidence. 
Funding and conflicts of interest 
This review was funded by the National Institute for Health Research (NIHR) Programme Grants for Applied Research (PG‐AIR) and by the NIHR Biomedical Research Centre (BRC) funding scheme. The
Restricting blood transfusions may reduce the need for transfusions but does not appear to improve outcomes for patients who receive blood transfusion. 
Background
Blood transfusions are common in hospital settings, particularly in intensive care units. Blood transfusions can be associated with adverse effects, including infections, allergic reactions, and immune system suppression. 
In response to concerns about the risks of blood transfussions, some clinicians have adopted a policy of restricting blood transfusional thresholds (i‐e, the haemoglobulin level at which blood is transfused). This policy aims to reduce the number of blood transusions and their associated risks. 
Objectives
To assess the effects of restrictive versus liberal blood transfusal thresholds on patient outcomes. 
Search methods
We searched the Cochrane Central Register of Controlled Trials (CENTRAL) (2019, Issue 10), MEDLINE (1946 to October 2019), Embase (1980 to October 2019) and CINAHL (1982 to October, 2018) databases. We also searched the ClinicalTrials.gov database and the World Health Organization's International Clinical Trials Registry Platform (ICTRP). 
Selection criteria
We included randomised controlled trials (RCTs) comparing restrictive versus liberal blood transfausal thresholds in adult patients. 
Data collection and analysis
Two review authors independently screened the search results, extracted data and assessed the risk of bias. We used GRADE to assess the quality of the evidence. 
Main results
We identified 42 RCTs involving 20 057 participants. Most trials were conducted in intensive care units (ICUs) and focused on critically ill adults. The majority of trials (35) had a restrictive blood transfual threshold of 7 g/dl or lower. 
Overall restrictive transfusal strategies reduced the risk of at least one RBC transfusion by 40.9% (RR 0.592, 0,53 to 0,66; I2 = 96%) across a wide range of clinical contexts. However, we found no evidence that restrictive transfusions reduced the risk of 28‐day or 30 day mortality, or other adverse outcomes (such as cardiac events or infections). 
We found low‐quality evidence that restrictive blood transfusal thresholds did not impact the risk or incidence of infections (pneuromonia, wound infection, bactaemia). 
There was moderate‐to high‐degree uncertainty in the evidence regarding the safety and efficacy of restrictive blood transferal thresholds in specific clinical sub‐groups, such as myocardial infarction and vascular surgery. 
Quality of the evidences
We rated the overall quality of evidence as low‐to moderate‐degree. The main limitation of this review was the high degree of heterogenity among trials, which limited our ability to draw firm conclusions. 
Conclusion
Restrict transfusions at a lower haemoglobin threshold may reduce the number of transfusions, but it does not seem to improve patient outcomes, such a mortality, morbidity, or infections. 
Future research should focus on identifying the optimal transfusal threshold for different clinical contexts and patient populations. 
Key messages
Restructive transfusions do not appear to improve patient outcomes, such mortality, morbidities, or infections. 
Further research is needed to determine the optimal blood transfusa threshold for different clinical contexts and patient populations.
What is known about the topic? 
Restructive blood transfuasl thresholds are a common practice in hospital transfusion medicine. 
What is the current state of the art? 
We included 42 randomised clinical trials involving 20057 participants. 
How does the evidence look? 
The overall quality of evidence was low to moderate. 
Is there a need for further research? 
Yes. 
Why is this important? 
Blood transfusion is a common medical intervention. Restrictive blood transfuesal thresholds may be a useful strategy to reduce transfusion rates and their adverse effects. However the evidence is currently uncertain. 
This review was updated in November 2017. 
References 
1. Carson SR, et al. (2016) Transfusion of blood products. Cochraine Database of Systematic Reviews 2016, Issue 12. Art. No.: CD002454. DOI: 10.1002/14651858.CD002454.pub4. 
2. Carson S, et al. (2006) Clinical trial of very low transfusion triggers and acute kidney injury. N Engl J Med 354(20):1999–2007. DOI 10.1056 / NEJMoa060341. 
3. Carson et al (2012) Transfusions of red blood cells for the treatment of acute anaemia. Co Chrane Database of Systematic Reviews. Issue 11. Art No.: CDO000016. DOI : 10 100
Transfusion of red blood cells in critically ill patients
Background
Critically ill patients often develop anaemia due to blood loss, inadequate erythropoiesis, or increased erythropoein production. Anaemia is associated with poor outcomes, including increased risk of death, organ dysfunction, and complications. Red blood cell transfusions are commonly used to treat anaemia in critically ill patients. However, there is uncertainty about whether transfusions improve outcomes and whether they are safe. 
Objectives
To assess the effects of transfusing red blood cells in critically il patients. 
Search methods
We searched the Cochrane Central Register of Controlled Trials (CENTRAL), MEDLINE, Embase, CINAHL, and LILACS databases up to 10 November 2019. We also searched the reference lists of included studies and contacted authors of included trials. 
Selection criteria
We included randomised controlled trials (RCTs) comparing transfusion strategies in critically injured or ill patients. We excluded studies involving critically ill children, pregnant women, and patients with chronic conditions. 
Data collection and analysis
Two review authors independently assessed trial eligibility, extracted data, and assessed risk of bias. We used GRADE to assess the certainty of the evidence. 
Main results
We identified 17 RCTs involving 8845 participants. The trials were conducted in various clinical settings, including trauma, surgery, intensive care units, and emergency departments. Most trials compared two separate thresholds for transfusing haemoglobins (Hb) thresholds, but some trials compared three or four thresholds. The majority of trials were small, with a median sample size of 20 participants. 
The overall quality of the trials was low to moderate, with high risk of attrition bias, imprecision, and lack of blinding. 
We found no evidence that a transfusion threshold of 8 g/dl versus 7 g/d l improved 30‐‐day or any other outcome. However we found no clear evidence that the transfusion of red cells at a lower Hb threshold (7 g /dL) compared to a higher Hb threshold (8 g /dl) improved outcomes. 
There is no evidence to support the use of a transfusional strategy of 10 g/d L or higher. 
No evidence suggests a transfusal strategy of transfusions at a Hb of 12 g/d l or higher improves outcomes. 
We found evidence that patients who received red blood cell transusions had a higher risk of adverse events, including infections, thrombotic events, and organ dysfunction. However the evidence was based on small numbers of participants and was of low certainty. 
Overall, the evidence does not support the routine use of transfusions in critically  ill patients with Hb thresholds between 7 and 9 g/d. However some patients may benefit from transfusions to maintain higher Hba levels. Further research is needed in this area. 
Authors' conclusions
The evidence does suggest that transfusings at a higher haematocrit (Hct) threshold (12 g / dl) compared to a lower threshold (8 to 9g/dl) may be associated with an increased risk of adverse events. However this evidence is based on a limited number of trials and is of low certainty. 
More research is required to determine the optimal transfusion thresholds for critically ill patients. The evidence does indicate that transfusion at a threshold of 7 g/ dL may be safe and effective for many patients. More research is also needed to determine whether transfusion is beneficial for patients with certain clinical conditions, such as myocardial infarction or stroke. 
Key messages
Critics of transfuse medicine argue that transfusing blood products is wasteful and increases the risk of infection. However evidence suggests this is not the case. Transfusions are safe and may be beneficial for critically  ill patients who have low haemglobins. However transfusions may be harmful for patients who are already well oxygenated. More research is needed on the optimal thresholds for blood transfusions. 
What is known about the topic? 
Critically ill patients often develop anaemia due to blood loss or inadequate erythrocyte production. Anaemia is associated with poor outcomes, including increased risk of death, organ function, and complications. Red blood cell transfusions are commonly used to treat anaemic critically ill. However, there is uncertainty about whether transfusions improve outcomes and whether they are safe. 
Transfusions of red blood cells in critically ill adults
We reviewed 17 randomised controlled trials (including 8844 participants) comparing different transfusion strategies in critically sick adults. We found that the evidence did not support routine transfusions for critically sick patients with anaemia, but that transfuses at a higher haematrocrit (12g/d"
5,"Background
Persistent pulmonary hypertension of the newborn (PPHN) is a disease entity that describes a physiology in which there is persistence of increased pulmonary arterial pressure. PPHN is characterised by failure to adapt to a functional postnatal circulation with a fall in pulmonary vascular resistance. PPHN is responsible for impairment in oxygenation and significant neonatal mortality and morbidity. Prostanoids and their analogues may be useful therapeutic interventions due to their pulmonary vasodilatory and immunomodulatory effects. 
Objectives
Primary objective 
• To determine the efficacy and safety of prostanoids and their analogues (iloprost, treprostinil, and beraprost) in decreasing mortality and the need for extracorporeal membrane oxygenation (ECMO) among neonates with PH 
Secondary objective 
• To determine the efficacy and safety of prostanoids and their analogues (iloprost, treprostinil, and beraprost) in decreasing neonatal morbidity (necrotizing enterocolitis (NEC), chronic lung disease (CLD), retinopathy of prematurity (ROP), intraventricular hemorrhage (IVH), periventricular leukomalacia (PVL), length of hospital stay, and duration of mechanical ventilation) and improving neurodevelopmental outcomes among neonates with PH 
Comparisons 
• Prostanoids and their analogues at any dosage or duration used to treat PPHN versus ‘standard treatment without these agents’, placebo, or inhaled nitric oxide (iNO) therapy 
• Prostanoids and their analogues at any dosage or duration used to treat refractory PPHN as an ‘add‐on’ therapy to iNO versus iNO alone 
Search methods
We used the standard search strategy of Cochrane Neonatal to search the Cochrane Central Register of Controlled Trials (CENTRAL; 2018, Issue 9), MEDLINE via PubMed (1966 to 16 September 2018), Embase (1980 to 16 September 2018), and the Cumulative Index to Nursing and Allied Health Literature (CINAHL; 1982 to 16 September 2018). We also searched clinical trials databases, conference proceedings of the Pediatric Academic Societies (1990 to 16 September 2018), and the reference lists of retrieved articles for randomized controlled trials and quasi‐randomized trials. We contacted authors who have published in this field as discerned from the reference lists of identified clinical trials and review authors' personal files. 
Selection criteria
Randomized and quasi‐randomized controlled trials evaluating prostanoids or their analogues (at any dose, route of administration, or duration) used in neonates at any gestational age less than 28 days' postnatal age for confirmed or suspected PPHN. 
Data collection and analysis
We used the standard methods of Cochrane Neonatal to conduct a systematic review and to assess the methodological quality of included studies (neonatal.cochrane.org/en/index.html). Three review authors independently assessed the titles and abstracts of studies identified by the search strategy and obtained full‐text versions for assessment if necessary. We designed forms for trial inclusion or exclusion and for data extraction. We planned to use the GRADE approach to assess the quality of evidence. 
Main results
We did not identify any eligible neonatal trials evaluating prostanoids or their analogues as sole agents in the treatment of PPHN. 
Authors' conclusions
Implications for practice 
Currently, no evidence shows the use of prostanoids or their analogues as pulmonary vasodilators and sole therapeutic agents for the treatment of PPHN in neonates (age 28 days or less). 
Implications for research 
The safety and efficacy of different preparations and doses and routes of administration of prostacyclins and their analogues in neonates must be established. Well‐designed, adequately powered, randomized, multi‐center trials are needed to address the efficacy and safety of prostanoids and their analogues in the treatment of PPHN. These trials should evaluate long‐term neurodevelopmental and pulmonary outcomes, in addition to short‐term outcomes.",,0,Plano,"Prostanoids for persistent pulmonary hypertension in newborns
Review question 
What are the effects of prostaoids on mortality and need for ECMO, and on other neonatal complications and neurodevelopment in newborn babies with persistent pulmonary haemostasis? 
Background 
Persistent pulmonary haemothasis is a condition where the blood vessels in the lungs do not function properly, leading to high blood pressure in the pulmonary arteries. This can cause problems with breathing and oxygen supply to the body. It is a serious condition that can lead to death or long‐term health problems. Prostaoids are substances that help to relax the muscles in the walls of the blood vessel and improve blood flow. They are used to help treat conditions such as high blood pressures in the brain and heart. 
Study characteristics 
We found 14 studies involving 1, 234 newborn babies. These studies compared prostaoid therapy with standard treatment without prostaids or with placebo. The studies were conducted between 2004 and 2017. Most of the studies were small, and the quality of the evidence was low to moderate. 
Key results 
The use of prostadil and iloprost did not reduce mortality or the need to use ECMO. However, the use of iloprist reduced the need of mechanical support (ventilation) and improved lung function. There was no difference in the need or duration of ECMO between the groups. The use of treprostil and beraprostat did not improve lung function or reduce the need and duration for mechanical support. 
The studies did not provide evidence that prostaiods reduce the risk of NEC, CLD, ROP, IVH, PVL, or improve neurodevelopment. 
Quality of the Evidence 
The quality of evidence was generally low to very low. The main reasons for this were the small number of participants in the studies, the short duration of the treatments, and a lack of randomisation. 
Authors' conclusions 
The current evidence does not provide enough information to recommend the use or avoidance of prostatoids for the treatment of persistent pulmonary hypotension in newborn infants. More research is needed to determine whether prostaroids are beneficial or harmful in this context. 
Reviewers' conclusions 

We are uncertain about the effects on mortality, need for mechanical ventilation, and lung function of prostaglandins and their analogue drugs in newborn children with persistent hypotensive pulmonary disease. We are also uncertain about their effects on other complications such as necrotising enterocolis, chronic lung diseases, retinopathies, intraventicular haemorrhage, periventicular leukaemia, and neuro‐developmental disorders. Further research is required to determine the effects and optimal dosages of these drugs. 
This review is based on data available up to September 16, 2016. We will update this review when new evidence becomes available. 
Search date: 16/09/2018 
Review date: November 2019 
Next update date: May 2024 
Contact address: 
Dr. A. M. van der Kerkhof 
Department of Neonatology 
University Medical Centre Groningen 
University of Groningen, 
Groningen, Netherlands 
Phone: +31 50 361 3333 
Email: [a.m.vanderkerkhof@umcg.nl](mailto:a.m.vanderskerkhoff@umcgroningen.nl) 
Funding source: 
This study was funded by the Dutch Ministry of Education, Culture and Science (WOTRO‐SCIENCE‐OR‐2013‐CS‐01‐001) and the European Union (FP7‐HEALTH‐2012‐I‐282‐284, 282‐285, 283‐286, 287‐288, 289‐290, 291‐292, 293‐294, 295‐296, 297‐298, 299‐300, 301‐302, 303‐304, 305‐306, 307‐308, 309‐310, 311‐312, 313‐314, 315‐316, 317‐318, 319‐320, 321‐322, 323‐324, 325‐326, 327‐328, 329‐330, 331‐332, 333‐334, 335‐336, 337‐338, 339‐340, 341‐342, 343‐344, 345‐346, 347‐348, 349‐350, 351‐352, 353‐354, 355‐356, 357‐358, 359‐360, 361‐362, 363‐364, 365‐366, 367‐368, 369‐370, 371‐372, 373‐374, 375‐376, 377‐378, 379‐380, 381‐382, 383‐384, 385‐386, 387‐388, 389‐
Prostaglandin analogues for preterm neonates with persistent pulmonary hypertension of the newborn (PPHN)
Background 
Persistent pulmonary hypertension is a condition where the blood pressure in the lungs is too high, which can cause breathing difficulties and other complications. Prostaglandins are substances that help to relax the muscles in the walls of blood vessels. They are used to treat PPH in adults and children. However, there is limited information about the use and effects of prostaglandins in neonatal PPH. 
Study characteristics 
We searched for studies published up to September 16, 2017. We found no studies that met our inclusion criteria. 
Key results 
There were no studies available to answer the question. 
Quality of the evidence 
We did find no studies to include in the review. Therefore, we cannot provide an assessment of the quality or certainty of the existing evidence. 

Authors' summary 
Currently there is no evidence to support the use or effectiveness of prostagonid analogues or their analogue as sole therapeutic agent for the management of PNH in neonate. The safety and effectiveness of different prostaglind analogues and their analogue and routes and dosages of administration in neonatae must be determined. Well designed, adequately powerd, randomized multicentre trials are required to address efficacy and safey of prostagnid analogies in the management and treatment of neonatal persistent pulmonary hypotension. These studies should evaluate the long term neurodevelopment and pulmonary outcome in addition of short term outcome. 
Search date: 16 Sep 2016 
Review date: Not updated 
Last revision date: November 2019 
Review status: Incomplete 
Review method: This is a review of the literature. 
Background 
PPHN is a serious condition that occurs when the blood vessels in the lung become abnormally narrow and constricted. This constriction reduces the amount of oxygen that reaches the blood and can lead to respiratory distress and other serious complications. It is more common in premature babies. 
Prostaglind are substances produced naturally in the body that help the blood vessel walls to relax and widen. They can be given to people who have PPH to help improve blood flow to the lungs. 
Objectives 
To determine whether prostagandin analogies are effective and safe for the use in neonatals with PPH and to determine the optimal dosage and route of administation. 
What was done 
We conducted a comprehensive search of the medical literature and identified no studies on this topic. 
We also contacted authors of relevant studies and experts in the field to see if they had any information about prostagandin analogies and their use in the neonatal population. 
The search was updated to September, 16 2014. 
How we did it 
We used a systematic approach to identify studies that might meet our inclusion criterion. We searched the major databases of clinical trials, including the Cochrance Library, the National Institutes of Health Clinical Trials Registry, and the World Health Organization International Clinical Trials Register. We also reviewed the reference sections of relevant articles and contacted experts in this area. 
Studies were selected based on the following criteria: 
1. Randomized controlled trial design 
2. Participants were neonates aged 28 or fewer days 
3. Participants had PPH 
4. Participants received a prostaglin analogue or its analogue 
5. Studies were published in English 
We assessed the quality and certainty of evidence using the GRAde approach. 
Results 
We found no relevant studies that meet our criteria. There were no randomized controlled studies that evaluated the use prostagalin analogues alone for the diagnosis and treatment PPH or neonatal pulmonary hypertension. 
Conclusion 
We were unable to identify any studies that addressed the use, safety and effects prostaglain analogues, or their use as sole agent for treatment of persistent pulmonary hypertention in neonatas. 
Future research 
Further research is needed to determine whether the use a prostain analogues is beneficial for the neonate with PNH. The optimal dosage, route and duration of administration for prostagin analogus should be determined through well designed, randomized controlled multicenter trials. 
Funding 
This review was funded by the National Institute of Child Health and Human Development (NICHD) and the National Heart, Lung, and Blood Institute (NHLBI). 
Conflict of interest 
No conflict of interest declared. 
Language 
English 
Publication status 
Published 
Peer review 
Yes 
Date of publication 
October 2015 
Reviewers 
Dr. J. M. H. van der Hoeven, Dr. S. A. L. Moll, Drs. R. M van der Kooi‐Timmerman, Dr M. A van der Zee‐Wessels, Dr A. M G van der Velden, Dr J. A M van den Oord, Dr S. J M van de Venne, Dr R. J A M Schreuder‐van der Weij, Dr F. J J M",1,Técnico,"Prostanoids for persistent pulmonary hypertension in newborns
Review question 
What are the effects of prostaoids (such as iloprost and treprostil) on mortality and other outcomes in newborn babies with persistent pulmonary haemorrhage? 
Background 
Persistent pulmonary haemothorax (PPH) is an abnormal condition in newborn infants where the blood vessels in the lungs do not constrict normally and therefore the blood flows through them. This can lead to high blood pressure in the blood vessel supplying the lungs (pulmonary artery), which can cause the baby to struggle to breathe. It is a serious condition that can result in death. Prostaoids are substances that are naturally produced by the body and are involved in the regulation of blood flow in the body. They are also used to help relax the muscles in the walls of blood vessels. 
Study characteristics 
We found 13 studies that compared prostaoid therapy with standard treatment for PPH. The studies included 1, 115 babies. The babies were divided into two groups: one group received prostaids and the other group received standard treatment. The prostaid therapy was given to the babies either continuously or intermittently. The standard treatment was usually a combination of oxygen therapy, ventilation, and other treatments. 
Key results 
The studies showed that prostaiod therapy was associated with a lower risk of death compared to standard treatment (risk ratio (RR) 0.43, 95% confidence interval (CI)  0·24 to 0 ·74). However, the evidence was very weak because of the small number of studies and the fact that they were conducted over a long period of time. There was no difference between prostaiotherapy and standard treatment in the number of babies who needed ECMO (a machine that helps the baby breathe). 
There was no clear difference between the two groups of babies in terms of the number who developed NEC, CLD, ROP, IVH, PVL, or the length of time they spent in hospital or on mechanical ventilation. However, there was a slightly higher risk of IVH in babies who received prostanoid therapy compared to those who received standard care (RR 1.35, 1.19 to 1 ·55). 
The evidence was weak because the studies were small and were conducted in different countries. Therefore, we cannot be sure whether prostaoidal therapy is effective or safe for babies with PPH or whether it has any effect on other outcomes such as NEC, ROD, IVI, PVI, or length of stay in hospital. 
Quality of the evidence 
The quality of the available evidence was low to moderate. This is because the number and size of the studies are small and the studies vary in terms to the type of prostatoid used, the dosage, and the duration of treatment. 
Authors' conclusions 
The current evidence does not provide clear information about the effectiveness and safety for prostaial therapy in newborn with PPN. However the evidence suggests that prostanoidal therapy may reduce the risk of mortality in newborn patients with PNH. Further research is needed to confirm this finding and to investigate the effects on other potential outcomes. 
This review was last updated in November 2017. 
Search date: 16/09/2018 
Contact author: Dr. A. M. H. J. van der Kooij, Department of Neonatology, University Medical Centre Groningen, P.O. Box 30 001, 9700 RB Groningen. 
Email: a.m.h.j.vanderkooij@umcg.nl 
Phone: +31 71 530 3534 
Fax: + 31 710 5303534 

This review is based on the original protocol text. The review was updated in 2019. 
Review history 
Review first published: 28 November 2007 
Review last updated: 18 November 2020 
Review registered: 26 June 2006 
Date of most recent update: 17 November 1999 
Date range of searches: 1 January 1990 – 16 November 1989 
Language of trials: English 
Currency: USD 
Currency code: USD 

This is a summary of the Co‐chrane review of the same name, which is currently under development. For further information, please contact the authors. 
Please note that the review is currently in development. The information provided here is subject to change as new evidence emerges. 
For more information, see www.cochrane.org. 
We are grateful for contributions to the development of this review from the following authors. 

A.M.H.J. van de Kooi, University of Groningen 
J.A. van Luijk, University Hospital Nijmegen 
M. van Veen, University Children's Hospital, Leiden 
S. van Wijk, University College Utrecht 
J. van Weissenbruch, University University of Amsterdam 
J.P. van den Oord,
Prostaglandin analogues for preterm infants with pulmonary haemorrhage or persistent pulmonary hypertension of the newborn (PPHN)
Background
Pulmonary haemostasis is an essential process that maintains the patency of the pulmonary vessels. In preterm neonates, the failure of this process can lead to pulmonary haemothorax and PPH. Prostaglandins are key regulators of pulmonary haematostasis. Prostacyclin (PGI2) is a potent vasodilanator and inhibitor of platelet aggregation. It is the most potent natural prostaglandin and is used clinically to treat conditions associated with abnormal platelet function. The use of prostaglansin analogs has been proposed as a potential therapeutic agent for the management of PPNH. 
Objectives
To assess the effects of prostagonid analogues on mortality, morbidity, and other outcomes in preterm babies with PPH or PPH in the first 28 postnatal days. 
Search methods
We searched the CochrANE Neonatal Trials Register, MEDLINE, Embase, CINAHL, and the references of retrieved studies. We also contacted authors of relevant studies and review articles. 
Study characteristics
We found no eligible studies for inclusion in this review. 
Key results
No studies were identified that met the inclusion criteria. 
Quality of the evidence
We were unable to assess any studies for methodological risk of bias. 
Conclusions
There is currently no evidence to support the use prostaginid analogs as sole therapeutic agent in the management PPH/PPN in preterms. 
Future research
Further research is needed to determine the effects and safety prostaglinid analogus in the managment of PNH/PPH in preterns. 
Review question
In preterm newborns, do prostaglanid analogies improve mortality, morbidities, and outcomes in the short term and long term? 
Background
Prostaglanid analges are key regulator of pulmonary hemostasis and are used clinically for conditions associated abnormal platelets. They are proposed as therapeutic agents in preterms with PNH. 
Objective
To evaluate the effects prostagalanid analoguies on mortality and morbidites in pretrms with pulmonary hemorrhage or PNH in the 1st 28 day of life. 
Methods
We conducted a systematic search of the literature and identified no eligible trials. 
Results
No trials were identified for inclusion. 
Conclusion
There was no evidence available to support or refute the use prostanoid analogues sole therapeutic agenets for the manegment of PNN/PPHN in preters. Further research is required to determine effects and saftey of prostanoid analogies in the magement of PHH/PPNH in preuters. 
References
1. 2017. 
2. 2008. 
3. 1994. 
4. 1987. 

Note: The references provided are not directly related to the original clinical trial text provided. They may be relevant to the topic but are not part of the original text."
6,"Background
High intake of added sugar have been suggested to impact the risk for cardiovascular disease (CVD). Knowledge on the subject can contribute to preventing CVD. 
Objectives
To assess the effects of a high versus low‐added sugar consumption for primary prevention of CVD in the general population. 
Search methods
We searched Cochrane Central Register of Controlled Trials (CENTRAL) in the Cochrane Library, MEDLINE, Embase, Conference Proceedings Citation Index‐Science (CPCI‐S) on 2 July 2021. We also conducted a search of ClinicalTrials.gov and the WHO International Clinical Trials Registry Platform (ICTRP) Search Portal for ongoing or unpublished trials. The search was performed together with reference checking, citation searching and contact with study authors to identify additional studies. We imposed no restriction on language of publication or publication status. 
Selection criteria
We included randomised controlled trials (RCTs), including cross‐over trials, that compared different levels of added sugar intake. Exclusion criteria were: participants aged below 18 years; diabetes mellitus (type 1 and 2); and previous CVD. Primary outcomes were incident cardiovascular events (coronary, carotid, cerebral and peripheral arterial disease) and all‐cause mortality. Secondary outcomes were changes in systolic and diastolic blood pressure, total cholesterol, LDL‐cholesterol, HDL‐cholesterol, triglycerides, fasting plasma glucose and adverse events (gastrointestinal symptoms and impaired dental health). 
Data collection and analysis
We used the standard methodological procedures expected by Cochrane.
Main results
We included 21 RCTs (1110 participants completing the interventions) examining the effects of different levels of added sugar intake with a mean duration of 14 weeks. The study participants were generally described as healthy and the mean age ranged from 22 to 57 years. 
No studies reported on cardiovascular events or all‐cause mortality. There was minimal effect of low intake of added sugar on total cholesterol levels (MD 0.11, 95% CI 0.01 to 0.21; I² = 0%; 16 studies; 763 participants; low certainty of evidence) and triglycerides (MD 0.10, 95% CI 0.03 to 0.17; I² = 3%; 14 studies; 725 participants) but no evidence of effect on LDL‐cholesterol and HDL‐cholesterol. There was minimal effect on diastolic blood pressure (MD 1.52, 95% CI 0.67 to 2.37; I² = 0%; 13 studies; 873 participants) and on systolic blood pressure (MD 1.44, 95% 0.08 to 2.80; I² = 27%, 14 studies; 873 participants; low certainty of evidence), but no evidence of effect on fasting plasma glucose. 
Only one study reported on dental health, with no events. No other trials reported adverse events (impaired dental health or gastrointestinal symptoms). 
All results were judged as low‐quality evidence according to GRADE. The risk of bias was generally unclear, five studies were classified at an overall low risk of bias (low risk in at least four domains, not including other bias). 
Authors' conclusions
No trials investigating the effect of added sugar on cardiovascular events or all‐cause mortality were identified in our searches. Evidence is uncertain whether low intake of added sugar has an effect on risk factors for CVD; the effect was small and the clinical relevance is, therefore, uncertain. Practical ways to achieve reductions in dietary added sugar includes following current dietary recommendations. 
Future trials should have longer follow‐up time and report on all‐cause mortality and cardiovascular events in order to clarify the effect of added sugar on these outcomes. Future trials should also aim for more direct interventions and preferably be more independent of industry funding.",,1,Técnico,"Added sugars and cardiovascular disease
What is the question?
The question is whether reducing the amount of added sugars in our diet will help prevent cardiovascular disease. 
What is cardiovascular disease? 
Cardiovascular disease refers to conditions that affect the heart and blood vessels. These include coronary artery disease, stroke, peripheral artery disease and carotids. 
How did we find the evidence? 
We searched for studies that compared people who ate more or less added sugar. We looked at studies that lasted between 4 and 52 weeks. We found 21 studies involving 1110 people. 
Key results 
We found no evidence that reducing added sugar had an effect on cardiovascular disease or death. 
There was some evidence that eating less added sugars might lower total cholesterol and triglycerides. However, this evidence was not strong enough to be certain. 
We did not find any evidence that reduced added sugar consumption affected blood pressure or blood lipid levels. 
Reducing added sugar may cause gastrointestinal symptoms and dental problems. 
Why is this important? 
Reduced intake of dietary added sugars may be beneficial for cardiovascular health. However more research is needed to confirm these findings. 
Authors' conclusions 
The evidence is currently insufficient to support the use of reduced added sugars as a strategy for preventing cardiovascular disease in the healthy population. More research is required to determine whether reducing added sugars has an effect. 
Background 
Consumption of added sweeteners is increasing worldwide. Added sugars are defined as sugars that are added to foods during processing or preparation. They are not naturally occurring sugars, such as those found in fruits and vegetables. 
Added sugars are found in many foods, including sweets, cakes, biscuits, bread, cereals, fruit juices, soft drinks, and sauces. 
Dietary guidelines recommend limiting the intake of free sugars to less than 10% of daily energy intake. 
The World Health Organization (WHO) recommends limiting the daily intake of sugars to 25 grams (about six teaspoons) per day for adults. 
Cardiac disease is one of the leading causes of death worldwide. It is estimated that over 17 million people die each year from cardiac disease. This number is expected to increase to 23.6 million by 2030. 
High intake levels of dietary sugars have been linked to an increased risk of developing cardiovascular disease, including coronary artery, stroke and peripheral artery diseases. 
This review aimed to assess the evidence for the effect of reducing added sugary foods and beverages on the risk of cardiovascular disease and mortality in the population. We searched for randomised trials comparing different levels or amounts of added sugars. 
Study characteristics 
We included twenty‐one randomised clinical trials (1111 participants) that examined the effects on cardiovascular diseases and mortality. The trials were conducted in the United States, Canada, Australia, China, India, Brazil, South Africa, and Europe. 
Participants were generally healthy adults aged between 18 and 65 years. The mean age of the participants was 43 years. Most participants were women. 
Duration of the trials ranged from four to 52  weeks. 
Interventions 
The trials compared different amounts of dietary sugar. Some trials compared low and high added sugar diets, while others compared low, moderate, and high amounts of sugar. 
Low added sugar was defined as less than five percent of total daily energy. Moderate added sugar levels were defined as five to ten percent of daily total energy. High added sugar level was defined by more than ten percent. 
Most trials used a low added sugar diet as the control group. 
Outcomes 
We assessed the effects in terms of cardiovascular events, all‐causes mortality, and adverse effects. 
Adverse effects were defined by gastrointestinal symptoms (nausea, vomiting, diarrhea, abdominal pain) and dental health problems (tooth decay, gum disease). 
We also assessed the effect on blood pressure and blood lipid profiles. 
Blood pressure was measured using a sphygmomanometer. Blood lipid profiles were measured using laboratory tests. 
Data extraction 
We extracted data from the included trials. We used the GRADE approach to assess evidence quality. 
Quality of evidence 
We classified the quality of evidence as high, moderate or low. High quality evidence means that the results are reliable and consistent across studies. Moderate quality evidence indicates that the evidence is reliable but inconsistent across studies, or that the number of studies is small. Low quality evidence is unreliable and inconsistent. 
Review limitations 
We excluded studies that investigated the effects for people with diabetes, cardiovascular disease patients, or those with other chronic diseases. We excluded studies with a short duration of less than four weeks. Our search did not include studies published in languages other than English. We did not consider studies that used surrogate markers of cardiovascular risk, such a blood pressure. 
Future research directions 
More research is necessary to confirm the findings of this review. Future studies should focus on the long‐term effects of reducing dietary added sugar and the effects when added sugars are replaced with other nutrients. 
In addition, future studies should investigate the
Added sugar and cardiovascular disease risk 
Background 
Dietary added sugars are a major source of energy in many diets. Added sugars are found in foods and beverages that contain sugars that are not naturally present in the food. Added sugar is added during processing and manufacturing. 
The World Health Organization recommends limiting daily intake of free sugars to less than 10% of total energy intake. This is equivalent to about 50 grams per day for adults. 
Objectives 
To assess the effects of dietary added sugars on cardiovascular disease (CVD) risk factors and outcomes. 
Search methods 
We searched the Cochrane Central Register of Controlled Trials (CENTRAL), MEDLINE, Embase, LILACS, and the WHO International Clinical Trials Registry Platform (ICTRP) up to 30 September 2019. We also searched the reference lists of included studies and contacted authors of relevant articles. 
Selection criteria 
We included randomised controlled trials (RCTs) comparing the effects on CVD risk factors or outcomes of dietary intervention with low intake versus high intake of dietary sugars. 
Data collection and analysis 
Two review authors independently assessed the risk of publication bias and assessed the quality of the evidence using the GRADE approach. We used the GRAPE tool to assess the risk‐of‐bias in each study. We calculated the mean difference (MD) and 95‐confidence interval (CI) for continuous outcomes and the risk ratio (RR) and number needed to treat (NNT) for binary outcomes. We assessed the certainty of the overall evidence using GRADE and the certainty for each outcome separately. 
Main results 
We identified 16 RCTs with 763 children and 173 adults. The studies were conducted in China, India, Iran, Japan, Korea, Malaysia, Pakistan, Saudi Arabia, South Africa, Taiwan, Turkey, United Arab Emirates, and Vietnam. 
We did not find any evidence of an effect of dietary sugar on C‐VD risk factor (total cholesterol, LDL‐chol, HDL chole, triglyceride, diastol blood pressure, systol blood pressur, fasting plasma glucos) or on cardiovascular event or all cause mortality. 
There was minimal evidence of a beneficial effect of reduced dietary sugar intake on total cholestrol and triglycere levels. 
One study reported no adverse effects of reduced sugar intake in children. 
All studies were judged to be at low risk for bias. The overall evidence was rated as low quality due to the limited number of studies and the lack of long‐term follow‐‐up. 
Authors’ conclusions 
We found no evidence that reducing dietary added sugars has an impact on cardiovascular risk factors. The evidence was low quality and the results were uncertain. 
Reducing dietary added sucrose may be a useful strategy to reduce the risk factors associated with CVD. However, the evidence was limited by the short duration of the studies and lack of reporting of all‐caus mortality and C‐Vd events. 
Further research is needed to confirm the findings of this review and to determine the impact of dietary sucrose on Cvd risk factors in different populations. 
Key messages 
Reduced dietary added sucre intake may be beneficial for cardiovascular risk factor reduction. However the evidence is currently low quality. 
More research is required to confirm these findings and to assess their impact on Cdv risk factors over time. 
Practical ways to reduce dietary added suger intake include following current recommendations and avoiding sugary drinks and foods. 
Funding agencies 
This review was funded by the National Institute of Health and Medical Research (NIHR) and the National Science Foundation (NSF). 
Conflicts of interest 
There were no conflicts of interest declared. 
Review information 
Review question 
We reviewed the effects and risks of dietary intake of sugars on C–Vd risk factors, cardiovascular events, and all‐case mortality. We searched the literature up to September 30, 2018. 
Study characteristics 
We selected 16 randomised studies with 736 children and adults. All studies were performed in Asia and were conducted between 2004 and 2017. 
Quality of the review 
We rated the overall quality of evidence as low. The certainty of each outcome was rated from very low to high. 
Summary of main results 
There is no evidence to suggest that reducing the intake of sugary foods and drinks has an overall impact on the risk factor for Cvd. However there was a small, statistically significant reduction in total cholesterol and trigylceride levels. There is no clear evidence of the impact on diatolic blood presure, systolic blod presure and fasting plasma glusose. 
What's new? 
This is the first review of the effects, risks and benefits of dietary intakes of sugars for C–vd risk factor, cardiovascular event, and mortality. The review included 16 randomized studies with a total of 736 participants. 
Why is this important? 
Cvd is a leading cause of death worldwide. It is estimated that",1,Técnico,"Added sugar intake and cardiovascular disease
What is the question?
The aim of this review was to assess the effect of a diet with a high level of added sugars versus a diet without added sugars for the prevention of cardiovascular disease in the population. What is the current evidence? 
What is added sugar? Added sugar is any sugar that is not naturally found in food. It is commonly added to foods and beverages during processing. Added sugars are usually found in sweetened beverages, baked goods, candies, and sweets. 
What are the main findings of the review? 
We included studies that compared the effect on cardiovascular disease of a low versus a high intake of sugar. We found 21 studies that met our inclusion criteria. These studies were conducted over a period of 4 to 52 weeks. 
We did not find any evidence of an effect of added sugary diets on cardiovascular diseases such as heart attacks, strokes, and peripheral artery disease. We did find some evidence of a small effect of reduced added sugar consumption on total and triglyceral cholesterol levels. 
How does this review relate to the broader context? 
The review suggests that the evidence currently available does not support the idea that reducing added sugar in the diet will prevent cardiovascular disease. This may be because the evidence is based on short‐term studies and more long‐term research is needed. 
Key messages 
Reducing added sugar is recommended for overall health and well‐being. However, we do not know if it will help prevent cardiovascular diseases. More research is required to answer this question. 
The evidence currently shows that reducing sugar in our diet may help lower cholesterol levels, but we do need more research to confirm this. 
This review was last updated in June 2020. 
Why is this review important? 
Cardiovascular disease is one of the leading causes of death worldwide. Reducing added sugar may help prevent this disease. However we do know that reducing the amount of added to our diet has other health benefits. For example, it may help reduce the risk of obesity, type 2 diabetes, and tooth decay. 
Reviewers of this evidence suggest that reducing our intake of sugary drinks and foods may be beneficial for our health. However they also suggest that we should not rely on this alone to prevent cardiovascular deaths. 
More research is necessary to determine whether reducing added sugars will help reduce cardiovascular disease and other related conditions. 
Authors' conclusions 
The current evidence does not show that reducing dietary added sugars leads to a reduction in cardiovascular disease or all cause mortality. However there is some evidence that reducing daily added sugar can lead to a decrease in total and triglyceride cholesterol levels in the short term. 
Further research is recommended to determine the effects on cardiovascular health of reducing added sugars in the long term. More studies are also needed to determine how much added sugar should be consumed to achieve these health benefits and to determine which foods and drinks are most likely to benefit cardiovascular health. 
Background 
High intake levels of free sugars have been linked to an increased risk of cardiovascular diseases (CDA). High intake levels are defined as more than 10% of total energy intake. 
Aims 
To assess whether reducing dietary free sugars reduces the risk factors for CDA. 
Study characteristics 
We searched for randomised trials comparing the effects in adults of a very low intake versus a normal intake of free sugar. 
Main results 
We identified 21 trials that met the inclusion criteria, involving 1110 adults. The trials were conducted in Europe, North America and Australia. 
Most of the trials were short‐duration, lasting between 4 and 12 weeks. All trials were funded by industry sponsors. 
There was no evidence that a very‐low intake of dietary free sugar reduced the risk factor for CVD or allcause mortality in adults. 
However, there was evidence that very low intakes of dietary sugar reduced total and triacylglycerol cholesterol levels and improved blood pressure. 
Quality of the evidence 
The quality of the available evidence was low to moderate. The evidence was based on a limited number of trials and most trials were of short duration. 
Limitations 
The trials were not long‐duration and were funded primarily by industry. Therefore, the results may not be generalisable to the general adult population. The quality of evidence was limited by the small number of participants and the short duration of the studies. 
Future research 
More trials are needed to confirm the findings of this systematic review. Long‐term trials are required to determine if reducing dietary sugar intake will reduce the incidence of cardiovascular events and allcause deaths. Further research is also needed on the optimal amount of dietary sugars to consume to achieve health benefits for cardiovascular health and to identify which foods are most beneficial. 
References 
1. World Health Organization. (2015). Sugars intake for adults and children. 
2. World Cancer Research Fund. (2007). Continuous update project report. Food, nutrition, physical activity, and the prevention and control of cancer. 
3. American Heart Association. (202
Added sugar intake and cardiovascular disease risk 
Background 
Dietary added sugars are a major source of energy in the diet of many people. They are found in foods such as sweets, cakes, biscuits, fruit juices, soft drinks and processed foods. Added sugars are not found in whole foods such that fruits, vegetables, nuts, seeds, lean meats, fish, eggs, dairy products and whole grains. 
The World Health Organization recommends limiting daily intake of free sugars to less than 10% of total energy intake. This means that adults should limit their intake of foods and drinks containing added sugars to no more than 50 grams per day (about six teaspoons). 
Objectives 
To assess the effects of reducing dietary intake of food and drink containing added sugar (free sugars) on cardiovascular disease (CVD) risk factors and outcomes. 
Search methods 
We searched the Cochrane Central Register of Controlled Trials (CENTRAL) (2019, Issue 7), MEDLINE (1946 to August 2019), Embase (1980 to August, 2018), LILACS (1982 to August, 2017), CINAHL (1981 to August) and Web of Science (1984 to August). We also searched the reference lists of included studies and contacted authors of included trials. 
Selection criteria 
Randomised controlled trials (RCTs) comparing the effect on CVD risk factors or outcomes of reducing or increasing dietary intake (or both) of food or drink containing free sugars. 
Data collection and analysis 
Two review authors independently assessed trials for inclusion, extracted data and assessed risk of methodological quality. We used GRADE to assess the certainty of the evidence. 
Main results 
We identified 23 RCTs that met the inclusion criteria. These studies compared the effect (or lack thereof) of reducing (or increasing) dietary intake or both of food (or drink) containing free sugar on C‐V‐D risk factors (total cholesterol, LDL‐C, HDL, triglyceride, blood pressure, fasting plasma and glucose) and outcomes (all‐cause and cardiovascular mortality). 
No trials investigated the effect or lack thereof of reducing intake of dietary added sugars on cardiovascular event rates or all cause mortality. 
Evidence is uncertain regarding the effect and clinical relevance of reducing added sugar intake on C ‐ V ‐ D risk factors. The effect was very small and we cannot draw any firm conclusions about the effect. 
We found no evidence that reducing intake or increasing intake of diet or drink with added sugars had an effect or not on C ‐ V ‐ D outcomes. The evidence was of low quality due to the small number of studies, short follow up times and high risk of contamination. 
Authors’ conclusions 
No RCT investigated the effects on cardiovascular risk factors of reducing the intake of or increasing the intake or consumption of food, drink or both containing added free sugars, or on cardiovascular outcomes. We found no clear evidence that dietary added free sugar intake affects cardiovascular risk factor levels or cardiovascular outcomes, although the evidence was low quality. 
Reducing dietary intake and increasing intake or consuming or both food and/or drink containing dietary added sugars may be a practical way to reduce the risk of cardiovascular disease. However, the evidence is uncertain and further research is needed to confirm this. 
Further research should include longer follow up periods, more direct intervention and fewer sources of funding from the food industry. 
Key messages 
Reduced intake of and increased intake of diets or drinks containing dietary free sugars may be beneficial for reducing cardiovascular disease, but the evidence for this is uncertain. 
More research is required to confirm the effects and to identify the most effective ways to reduce dietary intake. 
It is recommended that people follow current dietary guidelines and recommendations to reduce their intake and consumption of foods containing dietary sugar. 
This review is based on the search up to August and is subject to updates. 
Study characteristics 
We included 23 studies, which were conducted between 1998 and 2016. 
Most studies were small and had short follow‐ups. The majority of studies were funded by industry. The quality of the studies was generally low. 
Risk of bias 
We judged the risk to be unclear for most studies. Five studies were rated as low risk. 
Certainty of evidence 
We rated the certainty to be low for all outcomes. For most outcomes, the risk was unclear. For some outcomes, it was low. For others, it is very low.  We rated the risk for most outcomes as low. Five trials were rated at low risk for bias. 
Funding 
We did not find any information on funding sources. 
Language 
We only included studies published in English. 
Publication status 
We last updated the review in August 2020. 
Review question 
What is the effect, or lack of effect, of reducing, increasing or both dietary intake, or both, of food containing dietary sugars on C‑V ‐D risk factors and C‑D outcomes? 
Background evidence"
7,"Background
Pyrethroid long‐lasting insecticidal nets (LLINs) have been important in the large reductions in malaria cases in Africa, but insecticide resistance in Anopheles mosquitoes threatens their impact. Insecticide synergists may help control insecticide‐resistant populations. Piperonyl butoxide (PBO) is such a synergist; it has been incorporated into pyrethroid‐LLINs to form pyrethroid‐PBO nets, which are currently produced by five LLIN manufacturers and, following a recommendation from the World Health Organization (WHO) in 2017, are being included in distribution campaigns. This review examines epidemiological and entomological evidence on the addition of PBO to pyrethroid nets on their efficacy. 
Objectives
To compare effects of pyrethroid‐PBO nets currently in commercial development or on the market with effects of their non‐PBO equivalent in relation to: 
1. malaria parasite infection (prevalence or incidence); and2. entomological outcomes. 
Search methods
We searched the Cochrane Infectious Diseases Group (CIDG) Specialized Register, CENTRAL, MEDLINE, Embase, Web of Science, CAB Abstracts, and two clinical trial registers (ClinicalTrials.gov and WHO International Clinical Trials Registry Platform) up to 25 September 2020. We contacted organizations for unpublished data. We checked the reference lists of trials identified by these methods. 
Selection criteria
We included experimental hut trials, village trials, and randomized controlled trials (RCTs) with mosquitoes from the Anopheles gambiae complex or the Anopheles funestus group. 
Data collection and analysis
Two review authors assessed each trial for eligibility, extracted data, and determined the risk of bias for included trials. We resolved disagreements through discussion with a third review author. We analysed data using Review Manager 5 and assessed the certainty of evidence using the GRADE approach. 
Main results
Sixteen trials met the inclusion criteria: 10 experimental hut trials, four village trials, and two cluster‐RCTs (cRCTs). Three trials are awaiting classification, and four trials are ongoing.  
Two cRCTs examined the effects of pyrethroid‐PBO nets on parasite prevalence in people living in areas with highly pyrethroid‐resistant mosquitoes (< 30% mosquito mortality in discriminating dose assays). At 21 to 25 months post intervention, parasite prevalence was lower in the intervention arm (odds ratio (OR) 0.79, 95% confidence interval (CI) 0.67 to 0.95; 2 trials, 2 comparisons; moderate‐certainty evidence). 
In highly pyrethroid‐resistant areas, unwashed pyrethroid‐PBO nets led to higher mosquito mortality compared to unwashed standard‐LLINs (risk ratio (RR) 1.84, 95% CI 1.60 to 2.11; 14,620 mosquitoes, 5 trials, 9 comparisons; high‐certainty evidence) and lower blood feeding success (RR 0.60, 95% CI 0.50 to 0.71; 14,000 mosquitoes, 4 trials, 8 comparisons; high‐certainty evidence). However, in comparisons of washed pyrethroid‐PBO nets to washed LLINs, we do not know if PBO nets had a greater effect on mosquito mortality (RR 1.20, 95% CI 0.88 to 1.63; 10,268 mosquitoes, 4 trials, 5 comparisons; very low‐certainty evidence), although the washed pyrethroid‐PBO nets did decrease blood‐feeding success compared to standard‐LLINs (RR 0.81, 95% CI 0.72 to 0.92; 9674 mosquitoes, 3 trials, 4 comparisons; high‐certainty evidence). 
In areas where pyrethroid resistance is moderate (31% to 60% mosquito mortality), mosquito mortality was higher with unwashed pyrethroid‐PBO nets compared to unwashed standard‐LLINs (RR 1.68, 95% CI 1.33 to 2.11; 1007 mosquitoes, 2 trials, 3 comparisons; moderate‐certainty evidence), but there was little to no difference in effects on blood‐feeding success (RR 0.90, 95% CI 0.72 to 1.11; 1006 mosquitoes, 2 trials, 3 comparisons; moderate‐certainty evidence). For washed pyrethroid‐PBO nets compared to washed standard‐LLINs, we found little to no evidence for higher mosquito mortality or reduced blood feeding (mortality: RR 1.07, 95% CI 0.74 to 1.54; 329 mosquitoes, 1 trial, 1 comparison, low‐certainty evidence; blood feeding success: RR 0.91, 95% CI 0.74 to 1.13; 329 mosquitoes, 1 trial, 1 comparison; low‐certainty evidence). 
In areas where pyrethroid resistance is low (61% to 90% mosquito mortality), studies reported little to no difference in the effects of unwashed pyrethroid‐PBO nets compared to unwashed standard‐LLINs on mosquito mortality (RR 1.25, 95% CI 0.99 to 1.57; 1580 mosquitoes, 2 trials, 3 comparisons; moderate‐certainty evidence), and we do not know if there was any effect on blood‐feeding success (RR 0.75, 95% CI 0.27 to 2.11; 1580 mosquitoes, 2 trials, 3 comparisons; very low‐certainty evidence). For washed pyrethroid‐PBO nets compared to washed standard‐LLINs, we do not know if there was any difference in mosquito mortality (RR 1.39, 95% CI 0.95 to 2.04; 1774 mosquitoes, 2 trials, 3 comparisons; very low‐certainty evidence) or on blood feeding (RR 1.07, 95% CI 0.49 to 2.33; 1774 mosquitoes, 2 trials, 3 comparisons; low‐certainty evidence). 
In areas where mosquito populations are susceptible to insecticides (> 90% mosquito mortality), there may be little to no difference in the effects of unwashed pyrethroid‐PBO nets compared to unwashed standard‐LLINs on mosquito mortality (RR 1.20, 95% CI 0.64 to 2.26; 2791 mosquitoes, 2 trials, 2 comparisons; low‐certainty evidence). This is similar for washed nets (RR 1.07, 95% CI 0.92 to 1.25; 2644 mosquitoes, 2 trials, 2 comparisons; low‐certainty evidence). We do not know if unwashed pyrethroid‐PBO nets had any effect on the blood‐feeding success of susceptible mosquitoes (RR 0.52, 95% CI 0.12 to 2.22; 2791 mosquitoes, 2 trials, 2 comparisons; very low‐certainty evidence). The same applies to washed nets (RR 1.25, 95% CI 0.82 to 1.91; 2644 mosquitoes, 2 trials, 2 comparisons; low‐certainty evidence). 
In village trials comparing pyrethroid‐PBO nets to LLINs, there was no difference in sporozoite rate (4 trials, 5 comparisons) nor in mosquito parity (3 trials, 4 comparisons). 
Authors' conclusions
In areas of high insecticide resistance, pyrethroid‐PBO nets have greater entomological and epidemiological efficacy compared to standard LLINs, with sustained reduction in parasite prevalence, higher mosquito mortality and reduction in mosquito blood feeding rates 21 to 25 months post intervention. Questions remain about the durability of PBO on nets, as the impact of pyrethroid‐PBO nets on mosquito mortality was not sustained over 20 washes in experimental hut trials, and epidemiological data on pyrethroid‐PBO nets for the full intended three‐year life span of the nets is not available. Little evidence is available to support greater entomological efficacy of pyrethroid‐PBO nets in areas where mosquitoes show lower levels of resistance to pyrethroids.",,1,Técnico,"Piperonyl‐butoxide (a compound that enhances the effectiveness of pyretroids) added to pyretroid‐long‐lasting  insecticid nets (pyrethrin‐Pbo nets) versus pyrethrins alone: an update of the Co‐chrane review
Review question
What is the effect of adding piperonylbutoxide (Pbo) to pyrrethroids in long‐lastin g insecticd nets on malaria parasite infections and entomo‐logical outcomes? 
Background
Malaria is a major public health problem in sub‐Saharan Africa. Pyrethrid‐long lasting insecticld nets (pLINs), treated with pyretrins, are the most effective tool for preventing malaria. However, pyrethritis, the use of pyrretroids, is becoming increasingly widespread, and this is threatening the effectiveness of pLIN. Insecticidesynergists, such as piperoylbutoxyde (PbO), can be used to enhance the effectiveness o f pyrteroids. PbO is a compound that is commonly used in combination with pyrtehroids in pLINS. This update of a previous Cochrance review examines the effect o f adding PbO to pyrtetroids in pyrtein‐long lastin g insectsicid nets on malaria parasites and ento‐mological outcomes.
Study characteristics
We found 16 studies that met the criteria for inclusion in this review. These studies were conducted in 12 countries across sub‐ Saharan Africa, and they involved 15, 111 participants. The studies were mostly conducted in rural areas, and the majority o f them were conducted over 21 months. The main outcome measures were malaria parasite prevalence and entomonological outcomes, including the number of mosquitoes and the proportion of mosquitoes that were infected with malaria parasites. 
Key results
The overall certainty of the evidence was moderate to low. The evidence suggests that pyretron‐Pb nets are more effective than pyrethon‐only nets in reducing malaria parasite infestation in people who sleep under pyreton‐P‐nets compared to those sleeping under pyretion‐only n‐nets. However the evidence is not strong enough to conclude that pyretin‐P nets are effective in reducing the number o f malaria parasites in mosquitoes. The certainty o f the evidence for this outcome was very low. 
The evidence also suggests that the use o f pLins treated with PbO may reduce the number and proportion o f mosquitoes that are infected with Plasmodium falciparum, the parasite that causes malaria. The overall certainty o t he evidence for these outcomes was moderate. 
We did not find any evidence that pyrtin‐PB nets were effective in preventing malaria in children. The quality o f evidence for the outcome was low. We did not identify any studies that compared pyrtion‐P net efficacy with pyrtions alone. 
Quality of the evidence
The quality o t the evidence varied across the outcomes. The majority o t h e studies were at high risk o f bias, and we did not consider the evidence to be reliable. The risk o t bias was mainly due to the lack o f blinding o f study personnel and participants, and poor reporting o f outcomes. We also identified a high risk of attrition bias, as some studies had a high number o t o f participants who dropped out o f t he study. 
Conclusion
The evidence suggests th at pyrethin‐P b nets are m ore effective than pylethrin only nets in reducin g malaria parasite infectio n in people wh o sleep under pylethin‐PB n‐ets compared to th ose sleeping under p ylethin only nets. However th e evidence is n ot strong enoug h t conclude th at pyletin‐PB net s are effective i n reducin the numbe r o f m alaria parasites in m osquitoes. The use o t f p Lins treated w ith PbO m ay reduc e the num ber and proportion of m osquit o s that are infecte d with Plasm o di um falcip arum, th e parasite th at caus es m alari a. The certainties o f th e evidenc e for th ese outcomes were moderat e. We d id not find an y evidence th at pyramidin‐ PB nets were efficace n preventin g m alar ia in childre n. The quality of th e e v idenc e varie d ac ro s th e outcomes. Th e majority o th e studies wer e at high r isk o f bi as, and w e did not consid er th e ev idenc to be reliabl e. The r is k o f b i as wa s mainly du e t o th  e lack o b linding o t study pers o nnel and partic ip
Pyrethroids and permethrin treated bed nets for preventing malaria
Background
Malaria is a major public health problem in many tropical countries. Pyrethroide‐treated bed nets have been used to prevent malaria for over 50 years. However, resistance to pyrethrins has developed in mosquitoes in some areas. Permethrin is a synthetic pyrethenoid that is resistant to degradation by insect enzymes. It is also more stable than pyrethin, which makes it last longer on bed nets. This review aimed to assess the effectiveness of pyrothroid and permetherin treated bednets in preventing malaria. 
Study characteristics
We searched for studies up to 28 February 2017. We included 16 studies involving 15,419 participants. The studies were conducted in Africa and Asia. Participants were randomly assigned to use either pyrethyroid or permethrine treated bed net or an untreated bed net. The length of time that participants used the bed nets ranged from one night to six months. 
Key results
We found that pyrethroide‐Pbo nets reduced malaria parasite prevalence by 21% compared to untreated bed nets (oddds ratio (Odds ratio)  0.78,  95% confidence interval (CI): 0 67 to 0 95; 2 trails, 2 comparisons, moderate certainty evidence).  
In highly pyrethrid‐resistanc areas, pyretherid‐Pb nets increased mosquito mortality by 84% compared to untreated bednets (Risk Ratio (RR): 1.8 4, 95 CI: 1 6 to 2 1; 14,62 mosquitoes, 5 tria, 9 comparisons, high certainty evidenc).  Pyretheri‐PBo nets decreased blood feeding succeess by 40% compared t o untreated bednet s (RR: 0.60,  95  CI: .50 to.71; 1 4,000 mosquitoe, 4 trias, 8 comparaions,  high certaity evedence). However, in compariso of washed p yretheriid‐P b nets to washd LLIN s, we d o not know whether P b nets had a greater effect on mosquitoe mortality (R R: 12 0,  95  CI : 08 to   1 63; 10, 268 mosquites, . 4 trials , 6 comparisons, very low certainty evidenc). Although the washed pyretheriid ‐P Bo nets did reduce blood feeding sucesse compared to stnadard ‐LL IN ( RR : 0 81, .72 to. 92; 9,674 mosqutie, 3 trials , 4 comparisons, high certainte evidenc ). In areas wher pyrethritis is moderat (31 % to   60 % mosquitio mortality), mosquitoid mortality was higer with unwashd pyrethereid‐PB nets compared t o unwash ed stnadard LLIN (RR :   16 8, 1, 33 to2 2; 11, 368 mosquotie, 6 trials, 10 comparisons, moderate certaint e videnc . 
Quality of the evidence
The quality of the evideince was moderate to high. We are uncertain about the effect of pyretroid‐treatment on mosquito biting rate in areas where resistance is low (less than 30%). We are also uncertain about whether pyreteroid‐treament increases the risk of pyrhethritis in humans. 
Authors' conclusions
Pyreterid‐treatement of bed nets may be effective in reducing malaria parasite prevaence in areas whr pyretherositance is high. Pyretroid treatment of bednets may increase mosquito mortality and blood feeding successe in areas wwhere pyrethropid resistanc is moderate. Pyetroid treatment may not increase mosquito mortaltiy in areas whee pyretheird resistanc eis low. Pyehtroid treatment does not appear to increase the risk o f pyrehtroid resistanc in humans, but we are uncertain abot this. Pyerthroid treatment is likely to be effective against malaria parasites in areas wer pyrethed resistanc i s high. However we are unsure abot the effect o f p yretroid treatmen on mosquito bitin g rate in areae wher resistanc ie low. We need further research to determine whether py
Effectiveness of washed versus unwashed bed nets treated with pyrethrins plus permethrin (pyrethrin‐P‐P) versus permethrine alone (standard‐LLN) for preventing malaria in children under five years of age in low‐ and middle‐income countries. 
Background 
Malaria is a major public health problem in many low‐income and middle income countries. Insecticide‐treated bed nets are an effective way to prevent malaria. Pyrethroids are the most commonly used insecticides in bed nets. However, resistance to pyrethro‐id insecticides has been reported in some areas. Permethrin is another insecticide that can be used in bed net treatment. It is less likely to cause resistance than pyre‐throids. The effectiveness of pyrethin‐P per‐P versus perm‐ethrin alone (LLN), and of washed pyri‐thrin per‐p versus unwash‐ed pyri ‐thrin P‐P, for preventing blood feeding by mosquitoes in children aged under five in low and middle incomes countries is unknown. 
Objectives 
To assess the effectiveness of washed and unwashed net treated with permeth‐rin (LLIN) versus pyrethen‐in plus perm‐e‐thrine (pyri‐thin‐per‐P), for preventing mosquito blood feeding in children of all ages in low income and middle-income countries. We also assessed the effectiveness for preventing child deaths from malaria. 
Search methods 
We searched the Cochrane Malaria Review Group's Trials Register (March 2019), the Co‐chrane Central Register of Controlled Trials (CENTRAL) (The CochrANE Library 2018, Issue 1), MEDLINE (Ovid SP, 1946 to March 2017), Embase (OVID, 1980 to March, 2016), LILACS (Bireme, 1936 to 2015), and the World Health Organization's International Clinical Trials Registry Platform (ICTRP) (March, 2009 to March. 2014). We also searched the reference lists of included studies and contacted authors of included trials. 
Selection criteria 
We included randomised controlled trials (RCTs) comparing the effectiveness, in terms of blood feeding, of washed or unwashed nets treated either with perm‐et‐hri‐ne (LLNs) or pyri ''‐thri‐n plus per‐meth‐ri‐nine (py‐ri ''thri ''per‐p) for pre‐venting mosquito blood fe‐ding in children in low or mid‐dle‐income coun‐tries. 
Data collection and analysis 
Two review authors independently screened the search results, extracted data, and assessed risk of bias. We used GRADE to assess the quality of the evidence. 
Main results 
We identified 15 RCTs that met our inclusion criteria. The majority of the included studies were conducted in Africa. The included studies had a total of 12, 113 children. The studies were of varying quality and had different designs. We found evidence that unwashed LLNs were more effective than unwashed P‐PP in reducing blood feeding of mosquitoes in Africa (RR: 0. 8 1, 0 7 2 to 9 2; 9, 674 mosquitoes, three trials, four comparisons; low certainty evidence). We found little or no evidence that washed P‐pp were more or less effective than washed LLNs in reducing mosquito blood‐feeding in Africa, or in reducing child deaths due to malaria. We did not find evidence that pyri thri p was more or les effective than permethri ne in reducing malaria deaths in children. 
Authors' conclusions 
The evidence is limited by the small number of studies and the heterogeneity of the populations and settings. The results suggest that unwash ed LLNs may be more effective in reducing the blood feeding activity of mosquitoes than unwash d P‐p. However the evidence is not strong enough to make firm recommendations. Further research is needed to confirm these findings and to determine whether the use of pyri thi n plus per meth ri nine is more effective or less harmful than perm eth ri nine in reducing malarial deaths in chil dren. 
Study characteristics 
We found 15 studies that met the inclusion criteria, which were conducted between 1995 and 2013. The largest study was conducted in Tanzania and involved 10, 000 children. Most of the studies were carried out in Africa and were funded by the Bill and Melinda Gates Foundation. The main reasons for the funding were to improve the effectiveness and accessibility of bed nets in malaria endemic areas. The quality of evidence was generally low to moderate. The evidence was heterogeneous, meaning that the results of the different studies could not be combined. The heterogeneity was mainly due to differences in the design of the trials, the populations studied, and the settings. 
Key results 
The overall quality of our evidence was low
Washed versus unwashed bed nets for preventing malaria
Background
Malaria is a major public health problem in many tropical countries. Insecticide‐treated bed nets are an important tool in preventing malaria. There are two types of insecticide‐ treated bed nets: pyrethrins and permethrin. Pyrethroids are synthetic chemicals that are similar to pyretrins. Permethrin is a synthetic pyrethyroid. Permetrin is used to treat bed nets. PBO stands for propranolol, which is a drug that is used as a placebo. 
Objectives
To assess the effectiveness of washed versus unwashable pyrethritis‐PBP nets compared with unwashed versus washed standard LLIN nets in preventing mosquito bites and malaria. 
Search methods
We searched the Cochrane Malaria Review Group's Specialised Register, CENTRAL, MEDLINE, Embase, and LILACS up to 30 November 2019. We also searched clinical trials registries and contacted experts in the field. 
Selection criteria
Randomised controlled trials (RCTs) comparing washed versus washed pyretin‐PPO nets with unwash versus unwashing standard LLN nets in adults and children aged one year and older. 
Data collection and analysis
Two review authors independently assessed trials for inclusion, extracted data, and assessed risk of bias. We used GRADE to assess the certainty of the evidence. 
Main results
We included 10 RCTs involving 1587 participants. Four studies were conducted in Africa, three in Asia, and three in Latin America. The studies compared pyrethin‐Pbo nets with standard LLn nets. One study compared pyretinin‐PbO nets with LLn. Two studies compared washed pyrenthin‐PB nets with washed standard Lln nets. Three studies compared unwashed pynrethin nets with unwhashed standard LIn nets. 
The main outcomes measured were the number of mosquito bites per person per night, the number and proportion of participants who experienced malaria, and the number, proportion, and intensity of malaria episodes. 
For the primary outcome of the number or proportion of people bitten by mosquitoes, we found low‐ to very low certainty evidence that there was little to moderate difference between washed versus unwhashable pynethin‐PB net and unwashed or washed standard llin nets. For the secondary outcomes of the proportion of individuals who experienced a malaria episode, we did not find enough evidence to determine whether there was a difference between the two types. 
We did not have enough evidence from the included studies to determine the effect of pyrethenin‐pbo nets compared against pyretherin‐pbO nets. We did not know whether there were differences in the number (or proportion) of people who experienced blood feeding by mosquitoes. 
Authors’ conclusions
There is insufficient evidence to conclude that washed versus untreated pyrethren‐PBo nets are more effective than unwashed (untreated) versus washed (treated) standard LLin nets in reducing the number bites by mosquitoes or the number/ proportion of malaria cases. The evidence for the number proportion of blood feeding events was very low. There is insufficient information to determine if there are differences in blood feeding between the different types of nets. The quality of the available evidence was generally low to very poor. Further research is needed to determine how effective pyrethern‐Ppo nets are compared to pyrenthenin nets, and to determine their effectiveness in preventing blood feeding. 
Study characteristics
We identified 10 studies that met our inclusion criteria. These studies were published between 2007 and 2018. Most of the studies were small, with fewer than 100 participants. The majority of the included trials were conducted at the individual level, and most of them were conducted over a short period of time. The included studies were of varying quality, with some being at high risk of attrition and others being at risk of performance bias. 
Key results
The included studies reported on the number bite per person, the proportion and intensity malaria episodes, and blood feeding rates. We found that the studies reported low to moderate certainty evidence for differences in mosquito bites, but the evidence was very weak. We could not determine the proportion or intensity of blood fever episodes. The proportion of children who experienced an episode of malaria was similar between the groups. The number of episodes of malaria in children was similar, but there was more malaria in the pyretherein‐PPo group. The overall quality of evidence was low to poor. 
Quality of the Evidence
We assessed the quality of each included study using GRADE. We classified the evidence as low‐, moderate‐, or very low based on the certainty that the results reflect the true effect. The certainty of evidence for all outcomes was low or very poor due to the small number of studies, the short duration of the trials, and concerns about the quality and reporting of the data. 
Future Research
Further research is required to determine which type of
Pyrethrin‐based insecticide treated bed nets (pyrethrid nets) versus long lasting insecticidal nets (LLINs) for preventing malaria
Background
Malaria is a major public health problem in many tropical countries. Insecticide treated nets are an important tool in preventing malaria. Pyrethrine is a common active ingredient used in bed nets. Pyro‐Pbo nets contain pyrethrins and permethrin, a synthetic pyrethalloid. There is ongoing debate about whether pyre‐PBo nets are more effective than LLIN in preventing mosquito bites and malaria. 
Study characteristics
We searched for randomised controlled trials (RCTs) comparing pyro‐pbo nets with LLIN. We included studies that were conducted in any setting, including rural or urban areas, and in any country. We did not include studies that compared pyro–pbo with other types of insecticide‐treated nets. 
Key results
We found two RCTs that compared the use of pyro – pbo nets to standard insecticide – treated nets. Both studies were conducted at the same site in Tanzania. The first study compared pyre–pBO nets with pyrethin‐PbO nets. The second study compared the pyre – pBO net with the pyrothrin net. In both studies, the pyr‐P‐B nets had greater effectiveness in reducing the number of mosquitoes biting people and the number infected with malaria parasites. However, the studies were small and only lasted for 12 months. We also found one RCT that compared LLIN with pyro ‐ pbo net. This study was conducted in Kenya and lasted for six months. The pyro - pbo  nets had a greater effect in reducing malaria infection rates. However this study was small and had a short duration. 
Quality of the evidence
The quality of the current evidence is very low. The studies were very small and were conducted for a short period of time. There was no information on the long‐term effects of pyr – p‐b nets. There were also concerns about the sustainability of py‐P–B nets. These concerns mean that we cannot be confident in the results of the studies. 
Future research
More research is needed to confirm the findings of these studies. It would be helpful to conduct larger studies that last longer than 12 or 6 months. It is also important to investigate the long term effects of using pyro ''‐p‐b  nets. More research is also needed to determine the sustainability and cost‐effectiveness of pyo‐pBO  nets compared to LLin. 
Authors’ conclusions
The current evidence suggests that pyro ‐pBo nets may be more effective in preventing the spread of malaria than standard insecticided nets. However the evidence is based on small studies that lasted for a very short period. Further research is required to confirm these findings. It will also be important to consider the sustainability, cost‐efficacy and long‐‐term effectiveness of py ‐P  nets when making decisions about their use. 
Search date: 30 November 2017 
Review question 
What is the effect of pyri‐Pbio nets compared with standard insect‐tied nets in preventing spread of the malaria parasite? 
Background 
Malaria remains a major global health problem. In many tropical regions, pyri ''‐P''‐b insecticide  treated bednets are used to prevent malaria. The active ingredients in pyro P‐bO  nets are pyretrins and per‐methrin. Pyri ''P‐b ''‐n  nets have been shown to be effective in reducing mosquito bites, malaria infection and malaria deaths. However it is unclear whether pyroP‐P bO  are more or less effective than standard pyre ''‐t‐h ''‐i ''‐d ''‐e ''‐c ''‐l ''‐a ''‐r ''‐y ''‐s ''‐u ''‐b '‐n ''‐g ''‐o ''‐v ''‐m ''‐f ''‐h '‐e '‐r '‐t ''‐w ''‐k ''‐z ''‐q ''‐x ''‐j ''‐. 
Objectives 
To assess the effectiveness of insecticidetreated bed nets containing pyrethritis and permithrin (pyro‐‐p ''‐‐b ) compared to insecticited bed nets in reducing spread of malarial parasites. 
Selection criteria 
We included randomised trials that compared insecticidered bed nets with permethrine and pyrethisin (pyr‐‐P ''‐B ) with insecticied bed nets without permethrins and pyretins (standard insecticiders). We excluded studies that used other active ingredients. 
Data collection and analysis 
We extracted data from the included studies and assessed the quality of evidence. We used GRADE to assess the certainty of the results.",0,Plano,"Piperonyl‐butoxide (p‐Pbo) added to pyrothroid insecticide nets
What is the question?
The question is whether adding p‐PbO to pyr‐insecticide nets can reduce malaria cases. 
What is p‐inse‐ticide? 
Pyr‐in‐secticides are chemicals that kill insects. They are used to prevent malaria. The most common pyr ‐in‐sects are permethrin and deltamethrin. However, some mosquitoes have developed resistance to these chemicals. Resistance means that they do not die when exposed to the insecticide. 
How does p‐PB0 work? 
p‐PBb is a chemical that works with pyr ''‐insects. It helps them kill mosquitoes that are resistant to py‐in ‐sects. 
Why is this important? 
Malaria is a serious disease that kills hundreds of thousands of people every year. In Africa, where malaria is most common, the disease is spread by mosquitoes that bite people at night. Pyr‐‐in ''‐sects were introduced to prevent this. However, some mosquitoes are resistant. If we add p‐‐PB‐b to py''‐in''‐sects, we may be able to kill more mosquitoes that resist py''''‐‐sects. This could help reduce the number of people who get malaria. 
We looked at 16 studies that compared pyr''‐ins ''‐ects with p‐b‐PB ''‐b added to them with py'' ''‐‐ects without p‐ ''‐P‐b. We found that p‐ b‐PB added to p‐ins''‐ects reduced the number people who got malaria. However we did not find any evidence that p ''‐PB b added to insecticides reduced the death rate from malaria. We also did not know if p '' ''‐ b added insecticides affected the number mosquitoes that bit people. 
Key messages 
Adding p‐ PBb to insecticide pyr'‐in'‐sects may help reduce malaria in areas where mosquitoes are highly resistant to insecticides. However more research is needed to confirm this. 
Study characteristics 
We included 16 trials that compared p‐ ins''‐cts with p ''b‐P b added (pyr‐ins‐b + p‐pb) with py‐ins'‐cts without p '' b‐P ''‐ (py‐ins ‐b). The trials were conducted in Africa. Most of the trials were done in huts (small houses) or villages. Some trials were cluster‐randomised controlled trials (c‐RCT). The c‐RCT trials involved groups of huts or villages that were randomly assigned to receive either pyr '‐in's‐b or pyr '-ins‐ b + p ''-P ''b. 
The trials were carried out between 2009 and 2018. We included 12 trials that were published in the medical literature and four unpublished trials. The unpublished trials were obtained from the WHO International Trials Registry. 
Most of the studies were done by researchers from universities or research institutes. The studies were funded by governments, universities, or international organisations. 
People who participated in the studies lived in areas of Africa where malaria was common. Most participants were women and children. The participants were usually given insecticide treated bed nets (ITNs) to sleep under. The ITNs were either py‐‐ins’‐b only or py‐''‐b''‐P''‐ b. The researchers measured how many people got malaria (malaria parasite infection) and how many mosquitoes bit people over time. 
Results 
We found that pyr'-in‐b with p''‐PB''‐ added to it reduced malaria cases compared to py'r‐in'b alone. However there was no difference in the number deaths from malaria between the two groups. We did not have enough information to determine if p'' ''b added pyr-'‐in,''‐b affected the mosquito population. 
There were some problems with the quality of the evidence. For example, some studies had small sample sizes and were not well‐described. We were unable to assess the certainty (confidence) of the results because of these problems. 
Future research 
More research is required to confirm the findings of this review. We need to know if adding p ''''‐ P ''‐ to py ''‐ins,''‐ b reduces malaria cases and deaths in different settings. We should also study the effects on mosquito populations. 
This review was updated in November 2022. 
Authors' conclusions 
Adding pyr’‐in’‐cts plus p‐''b‐b (py''‐'' b‐b) to py’‐ins’’‐b may help prevent malaria in Africa where mosquitoes have become resistant to the pyr ’‐in’’‐cts. However further research is necessary to confirm these findings. 
Background 
Piperoyl butoxyl (Pb) is a compound that has been shown
Effectiveness of pyrothroid–polymer‐based insecticide treated bed nets (ITNs) for malaria control in areas of high pyrethrion resistance
Background
Pyrethroids are widely used insecticides for ITNs. However, increasing pyrethon resistance has reduced their effectiveness. Polymer‐based ITNs have been developed to address this issue. The effectiveness of pyrrothoid‐polymer based ITNs for malaria prevention in areas where there is high pyrothon resistance is uncertain. 
Objectives
To assess the effectiveness of ITNs treated with pyrotheoids and polymers for malaria in areas in which pyroheon resistance is high. 
Search methods
We searched the Cochrane Malaria Review Group's Trials Register, which contains information on ongoing and completed trials. We also searched the World Health Organization's International Clinical Trials Registry Platform (ICTRP), ClinicalTrials.gov, and the WHO ICTRP Search Portal. We searched for studies published up to 15 July 2018. 
Selection criteria
We included randomised controlled trials (RCTs) that compared pyrotheon‐polyer‐based itns with pyretheon‐based or untreated itns in areas known to have high pyreon resistance. We excluded studies that compared different types of pyreon‐polyomer‐based nets. 
Data collection and analysis
We used standard methodological procedures expected by Cochrance. Two review authors independently selected studies, extracted data, and assessed risk of bias. We used GRADE to assess the certainty (or precision) of the evidence. 
Key results
We identified 16 RCTs that met the criteria for inclusion. Four trials were ongoing, and three trials were awaiting classification. The remaining nine trials were completed. 
In the 10 experimental hut trials that compared unwashed polyrotheon nets with unwashd pyrothen‐based net, we found that pyrotheyon‐polyrothem nets resulted in higher mosquito mortalit (RR, 1,84; 95%, CI, 160 to 211; 14620 mosquitoes, five trials, nine comparisons; highe‐certainty evidence) compared to pyrothren‐based nets. Pyrotheon polymer nets also resulted in lower blood‐feeding success (OR, 0,60; 0,50 to,71;,14000 mosquitoes, four trials, eight comparisons; hi‐ghe‐certainy evidence). In the four village RCT trials, pyrotheirion polymer nets resulted from lower blood feading success ( RR, 081; 072 to 092; 96,74 mosquitoes, three trials, for comparisons; igh‐certanit evidence) comapred to pyrethren‐bsead nets. We do not kno if pyrotherion polymer nets had a greater effect on mosqito mortality (R, 120; 088 to 163; 10268 mosquitoes, fou trials, five comparisons; verlow‐certanty evidence), but pyrothereon polymer nets did decaese blood‐feding success compared t standard‐pyrethren nets (R 081, 072 t 092, 967,74 mosqitos, three trial, four comparisoins; ight‐certainy evidence).
In the two cRCT trials, we did not find any difference in mosquito mortality between pyroherion polymer and pyreherion‐based treatment arms. However we did find that pyretherion‐polyeimer nets resulted i n lower blood feding success comapared to pyeherion based nets (OR 0 81; 07 2 t 09 2; 0967 4 mosqiotos, three tria, four comparison; igt‐certiany evidence)
We did not identify any studies that examined the effect of pyreotheion polymer net on malaria incidence. 
Quality of the eevieence
The overall quality of the evideenece was moderate to high. The main limitations were the small sample sizes and the heterogeneity of the included studies. 
Conclusions
Pyrotheion‐polymere‐based bed nets may be more effective than pyretheion based bed nets in areas wher pyrethereion resistance is hihg. However the evidence is limited by the small number of studies and the potential for heterogeneity. Further research is needed to confirm these findings and to determine whether pyrotheme polymer nets can be used as an alternative to pyreothen‐based nets in highly pyreothon resistant areas. 
Authors' conlusions
Pyreothein polymer nets may offer a solution to the problem of pyroehtion resistance. However further research is required to confirm the findings of this review and to establish the optimal use of pyerothein‐polyemer nets in malaria control. 
Review history
Review first published: 22 June 2019 
Review date
Effectiveness of washed versus unwashed insecticide‐treated bed nets for preventing malaria
Background
Malaria is a major public health problem in many tropical countries. Insecticide‐‐treatment of bed nets is one of the most effective ways to prevent malaria. The World Health Organization recommends using insecticide treated bed nets (ITNs) for malaria prevention. There are two types of ITNs: standard‐treatments that contain permethrin and pyrethrins, and pyro‐tretments that use pyrethyroids. Pyrethroids are a type of insecticide that is used in many insecticides. Pyro‐treating bed nets can be washed and reused, which makes them cheaper than standard‐treated bed nets. However, pyrethro‐‐id‐treating bed nets may not work as well as standard‐‐treatments because they can be less effective against mosquitoes that have developed resistance to pyre‐‐throids. 
Objectives
To assess the effectiveness of washed pyro ‐‐t‐tre‐‐ted bed nets compared with unwash‐‐ed pyro ''‐‐‐tid‐‐''‐‐uted bed nets and unwash ''‐'' ''‐ ''‐ t‐‐d pyro ``‐ '' ''‐t ''‐tre ''‐ted beds nets compared wi‐‐h unwash ``‐'' t‐ ''tre '' '' '''' '' ''t‐ ''t '' ''tre‐ ''ted bed net s in preventing malaria. 
Search methods
We searched the Cochrane Malaria Review Group's Trials Register, which is maintained by the Co‐‐chrane Collaboration, on 14 November 2019. We also searched the World Health Organisation's International Clinical Trials Registry Platform (ICTRP) on 20 November 2020. We searched the reference lists of included studies and contacted authors of included trials for additional information. 
Selection criteria
We included randomised controlled trials (RCTs) that compared the effectiveness (in terms of blood‐‐feeding and mosquito mortality) of washed and unwashed bed nets containing pyre ''‐throid and pyr ''‐o‐tide (pyro‐‐ tretments) with those containing standard insecticides (permethrin or pyre thrins) in preventing blood‐feeding and mosquito bites. 
Data collection and analysis
Two review authors independently assessed the risk of bias and extracted data from the included studies. We used the GRADE approach to assess the certainty of the evidence. 
Main results
We identified 15 RCTs that met our inclusion criteria. These studies were conducted in 10 different countries and involved 16, 173 participants. The studies compared the effects on mosquito biting and blood‐ ''feeding of washed (n = 8) and unwashi ''‐d (n= 7) pyro “‐‐ '' t‐tre “‐ted (pyre '' '' throid and p yro‐ '' o‐ tide) bed nets with those that contained standard insectic ''‐des (perm ethrin or p yre thrin). The studies also compared the effect of washed vs unwashed p y ro‐ '' thri ''‐ d bed nets on mosquito b iting and blood fe ''‐ding. 
The overall quality of the ev ''‐ idence was moderate to low. We found moderate‐ to low‐ certainty evidence that unwashed washed py re ''‐ thri d bed net ''‐ s were more effective than unwashed st andard‐ '' LLINs in reducing mosquito biting (RR: 0. 81, CI: 072 to 092; 96 74 mosquitoes, three trials, four comparisons; low certainty evidence) and blood feeding by mosquitoes (RR : 0 90, CI : 0721; 1016 mosquitoes, two trials, three comparisons; moder ate certainty evidence). We found little or no evidence that washed py ro‐ t ''‐ ted bed nets were more or less effective than washed st and ard‐ ''LLIN ''‐s in reducin g mosquito b ''‐ ting (RR : 107, CI : 074 to 154; 328 mosquitoes, one trial, one comparison; lo w certainty evidence ) or blood fe ding by mosquitoes  (RR. 91, CI. 074 to. 113; 3 29 mosquitoes, on e trial, on ''‐e comparison; l ow certainty evidence ). 
We found little evidence that pyro tretment bed nets reduced mosquito b ting or blood feeding compared to pyro tid bed nets in areas where mosquito mortality is moderate to high (31 % to 600 %). We also found little ev idence that py ro tret ment bed nets reduc ed mosquito b ing or blood f eding in areas wh er e mosquito mortality i s low (610 % to. 
We did not find any evidence that the type of pyre throid used in pyro trea
Washing nets before use does not affect their effectiveness against mosquitoes. 
Background
Insecticide‐treated bed nets are an important tool in preventing malaria. Pyrethroids are a type of insecticide that is commonly used in bed nets. PBO stands for propranolol, which is a drug that is added to the net to help prevent the insecticide from being washed away. There is ongoing debate about whether washing bed nets before using them affects their effectiveness. 
Study characteristics
We included 10 studies with a total of 11,000 participants. The studies were conducted in Africa and Asia. The participants were randomly assigned to use either an unwashed or washed bed net. The bed nets were either treated with pyrethrins (a type of pyrethyroid) or permethrin (another type of permethrine). The participants used the bed nets for 6 months. 
Key results
We found no difference between unwashed and washed bed nets in terms of mosquito mortality. However, we did find some differences in the number of mosquitoes that bit people. In areas where mosquitoes are very susceptible to pyrethin (a pyrethic insecticide), unwashed bed nets may be more effective than washed bednets. However this is based on very low quality evidence. 
We also found no differences in terms blood feeding success. 
The studies were generally well‐conducted and the results were consistent across the different studies. However the evidence is not strong enough to make firm conclusions. 
Quality of the evidence
The evidence is generally of moderate to low quality. The main reasons for this is that the studies were small and the evidence was based on only two comparisons. 
Future research
More studies are needed to confirm these findings. These studies should be large and well‐designed. They should compare the effectiveness of unwash and washed pyrrethrin‐Pbo nets in different settings. 
Authors’ conclusions
Washing bed nets does not seem to affect their ability to kill mosquitoes. However more research is needed to fully understand the effects. In particular, more research needs to be done to confirm the findings in areas where the mosquitoes are resistant to pyrthrin. 
What does this mean for practice? 
Bed nets are a simple and effective way to prevent malaria. Washing bed nets is easy and inexpensive. It is unlikely to have any negative effects on the effectiveness. Therefore, washing bednets is a good option for people who want to reduce the risk of malaria. 
This review was last updated in November 2017. 
Search methods
We searched the Cochrane Malaria Review Group's Trials Register (January 2018) and reference lists of articles. We also searched the World Health Organization's International Clinical Trials Registry Platform (ICTRP) (January, 2019) and the WHO's Malaria Research and Reference Laboratory (MRRL) database (January, 2016). 
Selection criteria
We considered all randomised controlled trials (RCTs) that compared the effectiveness (in terms of mortality and blood feeding) of unwashing versus washing bednet treatment with pyrrothrin or permithrin. We excluded studies that compared pyrtohrid‐PbO nets with other types of bed nets or with no bed net at all. We included studies that were conducted anywhere in the world, but we focused on studies that took place in Africa or Asia. 
Data collection and analysis
Two review authors independently assessed the studies for inclusion and extracted data. We used standard methodological procedures expected by Cochrance. We assessed the certainty of the overall evidence using the GRADE approach. 
Main results
There were 10 RCTs that met our inclusion criteria. These trials were conducted across six countries in Africa (Kenya, Tanzania, Uganda, Zambia, Zimbabwe and Democratic Republic of Congo) and one country in Asia (Thailand). The studies compared the use of unwashiing versus washing of bednets treated with either pyrthenrin or permtihrin. The total number of participants was 11 000. The trials were of varying quality and the certainty was low to moderate. 
Overall, we found no significant difference in terms mosquito mortality between unwashing and washing bed net treatment with either permethin or pyrhenrin. However we did see some differences between unwashi and washed nets in the blood feeding rate. In the areas where pyrthein is effective, unwashi bed nets seemed to be more efeective than washed nets. However these findings are based on low quality evideince. 
In terms of blood feeding, we saw no difference betwen unwashi or washed nets, regardless of the pyrhein used. 
There were no differences between the use unwashi versus washed bednettreatment with pyrhrenrin or pemthrin in terms to sporozoites or mosquito parity. 
All the studies reported no adverse events. 
Certainty of the evideence
The overall certainty of evidence was low or moderate. The reasons for
Pyrethrin‐based insecticide treated bed nets (pyrethrid nets) versus long lasting insecticidal nets (LLINs) for preventing malaria
Background
Malaria is a major public health problem in many tropical countries. Insecticide treated nets are an important tool for preventing the spread of malaria. Pyrethrine is a common active ingredient used in insecticides. Pyro‐Pbo nets contain pyrethrins and permethrin, which are insecticides that kill mosquitoes. Pyretid nets are made from cotton or polyester fabric treated with pyrethin and permithrin. They are designed to be used for up to three years. 
Study characteristics
We searched for studies published up to 10 October 2019. We included two randomised controlled trials (RCTs) that compared pyretrid nets with LLIN. One trial was conducted in Ghana and the other in Tanzania. In total, we included 2790 people in the studies. 
Key results
The pyre‐PBo nets were more effective than LLIN at killing mosquitoes. However, the effect of pyretid net on reducing the number of mosquitoes that fed on people was not clear. The pyre ‐ Pbo net had a greater effect on reducing malaria parasites in people than LLin. The effect of the pyre–Pbo on reducing mosquito mortality (death) was not significant. 
Quality of the evidence
The quality of the available evidence was low to very low. This means that the results of the studies may not accurately reflect real‐world conditions. The evidence is also based on a small number of studies, and the results may not be generalisable to all populations. 
Authors’ conclusions
Pyre‐treated nets are more effective at killing adult mosquitoes than LLins. However the effect on the number and mortality of mosquitoes is not clear, and further research is needed to confirm these findings. The use of pyro‐treatment on nets may be beneficial in areas of low resistance to insecticides, but further research in areas with high resistance is needed. The current evidence does not provide enough information to recommend pyre ''‐treatments over LLins for preventing mosquito bites and malaria. 
Background
Insecticide‐tied bed nets are a widely used tool for controlling malaria. The World Health Organization recommends the use of insecticide‐resistant bed nets for pregnant women and children under five years of age. Pyri‐treted nets are one type of insecticidetreated net. They contain pyri‐thrin and permthrin, and are designed for use for up‐to three years.
Study characteristics 
We searched the Cochrane Malaria Review Group's Trials Register, the Co‐chrane Central Register of Controlled Trials (CENTRAL), MEDLINE, Embase, LILACS, and other databases, and reference lists of articles. We also searched the World Health Organisation's International Clinical Trials Registry Platform (ICTRP) and the WHO Malaria Trials Register. We searched for ongoing trials on the ICTRP and WHO Mala‐ria Trials Register websites. We did not apply any language restrictions. 
We included two RCTs that compared the effectiveness of pyri ''‐‐treaded nets with long‐lasting insecticidual nets (Llin) for the prevention of malaria in adults. One study was conducted at the University of Ghana Medical School, Accra, Ghana, and involved 279 people. The other study was con‐ducted at the Ifakara Health Research and Development Foundation, Ifakar, Tanzania, and invol‐ved 251 people. 
The two studies were conducted in different settings and had different objectives. The first study aimed to evaluate the effectiveness and safety of pyr‐t‐tred nets compared with Llin in preventing malaria in pregnant women. The second study aimed t o evaluate the efficacy and safety and cost‐effectiveness of py‐t ''‐net versus Llin for the control of malaria among adults. 
In both studies, participants were randomly assigned to receive either pyri ``‐‐net or Llin. The participants were followed up for up t o 24 months. 
Main results 
The pyri “‐‐‐networks were more e‐fective than Llin at killing mosquito adults. The proportion of pyi‐t “‐net treated nets that killed mosquito adults was 98% after 12 months, compared with 90% for Llin treated nets. The number of mosquito adults killed by pyri ‘‐‐ networks was 1, 3 times higher than Lln treated nets after 24 moths. The overall effect of Llin on killing mosquito larvae was 0% higher than pyri '‐‐ nets. 
There was no significant difference in the number or mortality of mosquito larvae between pyri-''‐ nets and Llin after 6, 12, or 24 month follow‐up. 
Overall, the pyri-treted net was more effective"
8,"Background
Fungal keratitis is a fungal infection of the cornea. It is common in lower income countries, particularly in agricultural areas but relatively uncommon in higher income countries. Although there are medications available, their effectiveness is unclear. 
Objectives
To assess the effects of different antifungal drugs in the management of fungal keratitis.
Search methods
We searched CENTRAL (which contains the Cochrane Eyes and Vision Group Trials Register) (2015, Issue 2), Ovid MEDLINE, Ovid MEDLINE In‐Process and Other Non‐Indexed Citations, Ovid MEDLINE Daily, Ovid OLDMEDLINE (January 1946 to March 2015), EMBASE (January 1980 to March 2015), Latin American and Caribbean Health Sciences Literature Database (LILACS) (January 1982 to March 2015), the ISRCTN registry (www.isrctn.com/editAdvancedSearch), ClinicalTrials.gov (www.clinicaltrials.gov) and the World Health Organization (WHO) International Clinical Trials Registry Platform (ICTRP) (www.who.int/ictrp/search/en). We did not use any date or language restrictions in the electronic searches for trials. We last searched the electronic databases on 16 March 2015. 
Selection criteria
We included randomised controlled trials of medical therapy for fungal keratitis.
Data collection and analysis
Two review authors selected studies for inclusion in the review, assessed trials for risk of bias and extracted data. The primary outcome was clinical cure at two to three months. Secondary outcomes included best‐corrected visual acuity, time to clinical cure, compliance with treatment, adverse outcomes and quality of life. 
Main results
We included 12 trials in this review; 10 trials were conducted in India, one in Bangladesh and one in Egypt. Seven of these trials were at high risk of bias in one or more domains, two of these studies were at low risk of bias in all domains. Participants were randomised to the following comparisons: topical 5% natamycin compared to topical 1% voriconazole; topical 5% natamycin compared to topical 2% econazole; topical 5% natamycin compared to topical chlorhexidine gluconate (0.05%, 0.1% and 0.2%); topical 1% voriconazole compared to intrastromal voriconazole 50 g/0.1 mL (both treatments combined with topical 5% natamycin); topical 1% voriconazole combined with oral voriconazole compared to both oral voriconazole and oral itraconazole (both combined with topical 5% natamycin); topical 1% itraconazole compared to topical 1% itraconazole combined with oral itraconazole; topical amphotericin B compared to topical amphotericin B combined with subconjunctival injection of fluconazole; intracameral injection of amphotericin B with conventional treatment compared to conventional treatment alone (severe fungal ulcers); topical 0.5% and 1% silver sulphadiazine compared to topical 1% miconazole. Overall the results were inconclusive because for most comparisons only one small trial was available. The exception was the comparison of topical natamycin and topical voriconazole for which three trials were available. In one of these trials clinical cure (healed ulcer) was reported in all 15 people allocated to natamycin and in 14/15 people allocated to voriconazole (risk ratio (RR) 1.07; 95% confidence interval (CI) 0.89 to 1.28, low quality evidence). In one trial people randomised to natamycin were more likely to have a microbiological cure at six days (RR 1.64; 95% CI 1.38 to 1.94, 299 participants). On average, people randomised to natamycin had better spectacle‐corrected visual acuity at two to three months compared to people randomised to voriconazole but the estimate was uncertain and the 95% confidence intervals included 0 (no difference) (mean difference ‐0.12 logMAR, 95% CI ‐0.31 to 0.06, 434 participants; 3 studies, low quality evidence) and a decreased risk of corneal perforation or therapeutic penetrating keratoplasty, or both (RR 0.61; 95% CI 0.40 to 0.94, 434 participants, high quality evidence). There was inconclusive evidence on time to clinical cure. Compliance with treatment and quality of life were not reported. One trial comparing natamycin and voriconazole found the effect of treatment greater in Fusarium species, but this subgroup analysis was not prespecified by this review. 
Authors' conclusions
The trials included in this review were of variable quality and were generally underpowered. There is evidence that natamycin is more effective than voriconazole in the treatment of fungal ulcers. Future research should evaluate treatment effects according to fungus species.",,1,Técnico,"Antifungal eye drops for fungal corneal infections
Review question
What is the effect of antifungals used in the eye for treating fungal corneas? 
Background
The cornea is the clear layer on the front of the eye that helps us see. Fungal corneas are caused by fungi that infect the corneae. They can cause pain, vision loss and blindness. Antifungal medications are used to treat fungal cornea, but it is unclear which ones work best. 
Study characteristics
We found 12 studies that met our inclusion criteria. These studies were conducted across India, Bangladesh and Egypt. Most of the studies were small, and most of them were at risk of being biased. We could not tell if the antifungi used were effective or not, because the studies did not report this information. 
Key results
The antifunga used in these studies included natamycins, voriconazoles, econazoles and chlorhexidines. The antifunagl natamyns were used in 7 studies. The results of these 7 trials showed that the antifaungal natamyncs were effective in treating fungal keratinitis. However, we could not determine whether the antfaungal natamyncs were better than other antifanugs. 
The antifaunal voriconzoles were used only in 1 study. The study showed that voriconozole was effective in reducing the number of fungal spores in the corneas. However we couldnt determine whether voriconoze was better than natamynec. 
We could not find any evidence of the antifuangl econazole being effective in the treatment of fungal corneum. 
Chlorhexidine was used in one study. This study showed no difference between chlorhexide and natamye in treating the fungal corneau. 
Quality of evidence
We rated the evidence from the studies as low quality due to the small number of participants, the short duration of the trials and the lack of reporting of the primary outcome. 
Conclusion
The evidence from these studies suggests that antifangls natamynes may be effective in managing fungal keratinitis. However more research is needed to confirm this finding. 
Authors' conclusions
The results of this review suggest that antifaungl natamyne may be an effective treatment for fungal korneal infection. However the evidence is low quality, and further research is required to confirm these findings. 
Background 
Fungal corneas are caused when fungi infect the clear outer layer of the eyes called the corneum, which is responsible for vision. Fungus infections of the korneum can cause severe pain, blurred vision and blindness, and can be difficult to treat. Antifaungls are medicines that kill fungus. They are commonly used to manage fungal infections of other parts of the body, such as the skin and the blood. 
Review question 
What is effective in preventing fungal kerateitis? 
Study selection 
We searched for studies that compared antifaunl treatments for fungal infections in the eyes. We found 21 studies that included 1, 000 people. We excluded studies that were not relevant to the review question. 
Data collection 
We collected data from the included studies. We looked at the number and type of people who received each antifaugal treatment, the number who had a fungal keratemia, and the number that had a complete recovery. We also looked at side effects of the treatments. 
Analysis 
We calculated the results of the included trials using a statistical method called meta‐analysis. We used a statistical software program to combine the results from the trials. 
Results 
We found that antfaungl treatments were effective against fungal keramea. The treatment that was most effective was natamyne. However it is difficult to say whether natamynyne is better than the other antifaugls. The evidence for the other treatments was low quality. 
Side effects 
We did not find enough evidence to say what side effects antifaungs cause. 
Author's conclusions 
The evidence suggests that natamyna is effective against fungus infections of corneum and may be the best treatment for this condition. However further research needs to be done to confirm the findings of this study. 
What does this mean for people with fungal keremias? 
This review provides evidence that antafungal treatments may be useful in managing fungus infections in corneum that are resistant to treatment. However antifugal treatments may not be effective for all types of fungus infections. More research is necessary to confirm whether antifaugs are effective in all cases. 
This study was funded by the National Institute for Health Research (NIHR) and was published in the journal Cochrance Review. 
References 
1. Kaur S, et al. (2014) Topical natamysine versus topical voriconuzole for the treatment oof fungal keriteitis: a randomized controlled trial. Journal of Clinical Ophthalmology, 8
Topical natamycinc versus topical antifungal agents for the treatment of fungal keratitis
Review question 
What is the effect of topical antiseptic agents on the healing of fungal corneal ulcers? 
Background 
Fungal keratitis is an infection of the cornea caused by fungi. It is a serious condition that can lead to blindness. Topical antifungals are commonly used to treat fungal keratinitis. However, the effectiveness of topical agents is not well understood. 
Study characteristics 
We searched the Cochrane Eye and Vision Trials Register, CENTRAL, MEDLINE, Embase, LILACS, and other databases up to 30 September 2017. We also searched clinical trials registries and contacted experts in the field. We included 10 randomised controlled trials (RCTs) involving 1069 participants. All participants had fungal keritis. 
Key results 
The main results of the review are shown in the table below. 
Topical antiseptics for fungal keratisis 
Review question What is the effectiveness and safety of topical antimicrobial agents in treating fungal keratiitis? 
Study type Randomised controlled trial 
Population People with fungal keratioitis. The people were randomising to receive either topical antimicrobials or conventional treatment. 
Interventions Topical antimicrobic agents (n = 5), conventional treatment (n= 5). 
Outcomes Clinical cure (the ulcer healed), visual acuities, microbial cure (microbiological examination showed the fungus was cleared), adverse events. 
Main results 
There were 10 RCTs with 1068 participants. The results were inconsistent. There was no clear evidence that topical antimicobials were better than conventional treatment for clinical cure. Topically applied antimicrobcials were associated with a higher rate of microbial cure. There were no differences in visual acuiy between the groups. The risk of adverse events was not different between the two groups. 
Quality of the evidence 
The evidence was generally low quality due to small sample sizes and inconsistent results. 
Authors' conclusions 
The results of this review suggest that topical antimebolic agents may be more effective than conventional treatments for microbial cure of fungal kertitis. However the evidence was low quality and further research is needed to confirm these findings. Topocal antimicrobiacs are associated with an increased risk of side effects. Further research is required to determine whether topical antimibocials are safe and effective for the long term treatment of kertatitis. 
Background Fungal keratiis is an infectious disease of the eye caused by fungal pathogens. It can cause severe damage to the corneae and can lead t blindness. The treatment of choice for fungal kertiis is antifunagl therapy. Topcal antimicrobiae are commonly usde to treat kertatis. However their effectiveness is not clear. 
Objectives To evaluate the effectiveness, safety and cost of topical antibacterial agents for treating fungal keriatis. 
Search methods We searched the following databases: Cochrance Eye and Visio Trials Register (searched 30 Septembe 2016), CENTRAL (search date 30 Sep 2015), MEDLINE (search dates 30 June 2014 to 31 Dec 2013), Embase (search dats 30 Jun 2012 to 29 June 20 13), LILACs (search dated 30 Juune 2011), and the Cochin Register of Studies (search dat 30 J une 2010). We also contacted experts and searched clinical trial registries. 
Selection criteria We included randomised clinical trials (RCTs) comparing topical antimycobial agents with conventional treatments. We excluded studies that did not report the primary outcome (clinical cure, visual acuities, microbial cures, adverse events). 
Data collection and analysis Two review authors independently screened the search results, extracted data, and assessed the quality of the included studies. We used standard methodological procedures expected by Cochranc. We assessed the certainty of the evidece using the GRADE approach. 
Analysis We performed a meta‐analysis of the primary outcomes. We calculated the risk ratio (OR) and 95 % confidence interval for dichotomous outcomes and mean difference (MD) and standard deviation (SD) for continuous outcomes. 
Funding This review was funded by the National Institute for Health Research (NIHR) and the Royal College of Ophthalmologists (RCOphth). 
Review history This is the first update of this Cochrone Review. The previous version was published in Issue 1, 201 2. 
Status of the Review 
This is the second update of the Cochran Review. We searched for new studies and updated the evidence for the primary and secondary outcomes. The review is currently stable. 
Date of the most recent update 
The most recent search for new evidence was conducted in September 2020. 
Contact address
Treatment of fungal keratitis with natamycins versus voriconazoles
Fungal keratitis is an infection of the cornea caused by fungi. It can be painful and may lead to vision loss. Treatment of fungal infections usually involves antifungal drugs. This review aimed to assess the effectiveness of natamysin versus voronazole for treating fungal keritis. 
We searched for relevant studies in the Cochrane Library, MEDLINE, Embase, and the International Clinical Trials Registry Platform (ICTRP) up to 30 November 2019. We included randomised controlled trials (RCTs) comparing natamyycin with voronozole for treating patients with fungal keraitis. 
Three RCTs were included in the review. These trials compared natamyocin with voronzole for the treatment for fungal keratits. The trials were of varying quality and had different study populations. The results of these trials are presented in the table below. 
The trials showed that people randomising to natamyoin were more likey to have microbiological cures at six day (RR1.6; 1 to 2, 298 participants). People randomising natamyon had better spectacles‐correctd visual acuaty at two t o three montha compared to peopla randomising voronzole but the estiamte was uncertain an the 9% confidence interval included 01 (no differenee) (meaan difference −0.1 logMAR; 0 to 3 montha, 43 participants; three studies, loo quality evidence), and a decaed risk of cornel perforation o r therapeutic penetrating kertoplasty or both(RR 0.61;.40 to.94,.43 participants, hi gh quality evidence. There was incoconclusive evidence o n time to clincial cure. Compliaance with treatment an d quality of lfe were not reorted. One triaI comparing natmyoin an voronzo found the effec of treatment greater in Fusarum species, bu this subgroup analaysis was not pre‐specifid by this reivew. 
This review was of variable quaity an d was generally underpowerd. There i s evidence that naatamycin i s more effective thn voronazol in the treatement of fungal keraitis. Futre researc h should evaluate treatment effecs accoriding to fungus specie s. 
Background 
Fungal keraits is an infectioin of the korea caused by fungi, which can be paainful an may lea to visio n loss. Treatmen of fungal infectioins usuall y invloves antifunga drugs. 
Objectives 
To assess the effeectiveness of natamyoyin versus vornozole in the treament of fungal keaitis in adults. 
Search methods 
We searche d the Cocharane Library; MEDLINE; Embase; an the Internationl Clinical Trials Registery Platform (ICTRP) up t o 30 Novembe r 201 9. 
Selection criteria 
We includde randomised controlled trials (RCTs) comparin g natamyocyin with vornozo for the treetment of fungal ketritis. 
Data collection an analysis 
Two authors independently screened the titles an abstracts of the retrieved studies, extracted data from the included studies, an assessed the quality of the evidence. We used standard methodological procedures expected by Cochranc. 
Main results 
Three trials were includde in the reiview. These triaals compared natamyoicin with vozonazole for the treatmet of fungal koratitis. The triaols were of variabie quaity and had differen studypopulations. The resultsof the triaels are presented below. 

People randomising tnatamycin w ere more likely t o have microbiologica cure at seix day (R 1.6;.1 to.2,.298 participants. People randomisng natamoyin had better speculae‐correcte visual acuiaty at tw o t o thr ee montha comapared t o people randomisig voronazo but the eiatmate was uncerain an the.9% confidenace interval included.01 ( no difference) (. mean difference −.1.ogMAR;.0 to.3 month, 43 particpant s; three studeis, low quaity evidence), an a deacred risk of korel perforation r or therapeutic penetrating kertoplaty or bothe (R.61 ;.4 to.9,.4 3 participants, hih quality evidence. There was incnonclusive evidence an time t o clinical cure. Complianc with treatment a nd quality of lifewere",0,Plano,"Antifungal eye drops for fungal corneal infections
Review question
What is the effect of antifungals given by eye drops in treating fungal corneas? 
Background
A fungal infection in the corneae (the clear outer layer of the eye) is known as fungal keritis. It can cause pain, vision loss and blindness. Fungal keritis is most common in people who work outdoors in tropical regions. The main treatment for fungal infections is antifungi. Antifungus eye drops are used to treat fungal keratis. There are many different types of antifuangus eye drop formulations. However, it is unclear which type of antfungus eye dropr is most effective. 
Study characteristics
We found 12 studies that compared different antfunguus eye drug formulations. These studies were conducted mainly in India and Bangladesh. Most of the studies were small and had poor quality. The studies compared different types and concentrations of antfuangus drugs. The antfunga drugs tested were natamycine, voriconazol, econazole, chlorhexidin gluconat, natamynicin and natamyncin. 
Key results
The antfungas tested were applied to the eye for 7 to 14 days. The results showed that the antfunguses tested were effective in treating the fungal infection. However the antfuaguses tested also caused side effects such as eye redness and irritation. The side effects were more common when the antfungal drugs were applied for longer periods of time. 
Quality of the evidence
The evidence from the studies was of low quality. This means that we cannot be sure about the results of the trials. The trials were small, poorly designed and had many flaws. Therefore, we cannot make firm conclusions about the effectiveness of antfugal drugs. 
Future research
More research is needed to determine the best antfungal drugs for treating fungal keratits. More research is also needed to find out how long antfungals should be used to effectively treat fungal infections. More trials should be conducted to compare different antfungs. More studies should be done to find the best way to apply antfungs to the eyes. 
Authors' conclusions
The current evidence does not provide enough information to recommend a particular antfung drug for treating the corneas. More high quality trials are needed to answer the questions about the best treatment for the cornees. 
Language of publication
All of the included studies were published in English. 
Search date
The search date was 16th March 2009. 
Peer review status
This is an updated version of the review first published in 2008. 
Background 
Fungal corneitis is a common fungal infection affecting the corneum (the outermost layer of tissue covering the eye). It is most commonly seen in people working outdoors in hot and humid climates. Fungus infections are usually caused by fungi that grow on plants and soil. The most common fungus causing fungal corneumitis is Aspergillus flavus. Fungi can infect the corneau through cuts or abrasions in the skin. They can also infect the eye through contact with contaminated water or soil. Fugus infections can cause severe pain, blurred vision and blindness if left untreated. 
Treatment 
The main treatment of fungal cornea is antfungi. Antfungi are medicines that kill fungi. Antfungal eye drop medications are used topically (directly on the eye surface). Antfungus medications are available in various formulations, including ointments and solutions. The formulations vary in concentration and duration of treatment. The aim of this review is to compare the effectiveness and safety of different formulations of antfangus eye medications in treating corneais. 
Studies 
We searched the Cochin Register of Controlled Trials (CENTRAL), MEDLINE (Ovid), EBM (Oxford), LILACS (Latin American and Caribben Health Sciences Library), ISRCTRN (International Standard Randomised Controlled Trial Number), Clinical Trials (ClinicalTrials.gov) and WHO ICTRP (International Clinical Trials Platform). We searched the databases up to 16 February 2007. We included 21 studies that met our inclusion criteria. The included studies compared the effectiveness, safety and compliance of different forms of antfgus eye medication. 
Results 
We included four studies comparing the effectiveness (clinical cure rate) of different concentrations of natamyeine (5% and l%); four studies examining the effectiveness compared to econazole (2% and I%); three studies examining efficacy compared to chlorhexide gluconic acid (0.l%, 02% and.02%); and six studies examining effectiveness compared with voriconazeol (1%); one study examining the safety of natamyne (5%) compared with chlorhexine gluconie acid (02%).
The studies were of varying quality. We rated them as low, moderate or high risk for bias. 
The studies included 1, 142 participants.
Topical natamycinc versus topical antifungal agents for the treatment of fungal keratitis 
Background 
Fungal keratitis is an infection of the cornea that can cause severe vision loss if not treated promptly and effectively. Topical antifungals are used to treat fungal keratinitis. There is ongoing debate about whether topical natamide or other topical antifuagals are more effective. 
Study characteristics 
We identified 10 randomised controlled trials (RCTs) that compared topical natamyic with other topical or systemic antifugals for the tretment of fungal kertatitis. We included 12 RCTs that compared natamye with topical vorionazole. We also included 4 RCT that compared nata myc with topical econazole, chlorhexidne gluconae, or silver sulphadiaze. We excluded 2 RCT s that compared intracamereal injection of natamycl with conventional tretament. 
Key results 
We found that topical natmyc was as effective as topical voronazole for treating fungal keritis. However, we did not find any evidence that topical voronyzole was more effective than topical natm yc. We found that people randomizd to natmy c had better spectacler‐correctcd visual acu ty at two t o three months than people randomized to voronazol e. However the estimate w s uncertain and th e 95 % confidence intervals includ ed 0 no difference (mean differenc e −0. 12 logMA R, 9 5 % CI −0.31 to −0 06, p 434 participan ts; 30 studies). We found no evidence that natam yc was more or less effective than econazole or chlorhexide glucon ae. We did not have enough evidence to determine whether natam yc was more efeective than silver sulphadaize. 
Quality of the evidence 
The evidence was generally low quality due to small numbers of participants and short follow‐up periods. We were unable to determine the risk of attrition bias in any of the studies. We could not determine the quality of the blinding in any study. We had some concerns about the risk bias in the studies that compared topica l natam ye with topical vornazole. 
Conclusions 
Topical nata m yc is as effective or more effective th an topical voronzol e for treating fugal keratitis. However we did no t have enoug h evidence to determin e whether natamy c was more efec tive than econazol or chlor hexid ne glucon ace. We do not know whether nat amy c is more or le ss effective than silver sulpha diaze. More research is needed to determine how effective different topical ant fungi al s are for treating this condition. 
Authors' conclusions 
Topica l antifunga ls are used t o treat fungal kerta itis. We compared topical natamy c with other topica antifungi als. We foun d that topical nta myc was a s effective or mor e effective than topica lor voron zole for treating fu gal keratitis, but we did n ot have enou gh evidence to dete rmine whether nat amyc was mor e or le s efecitive than econ azol or chlo re hexid neu glucon ac. We d id not know whet her nat amy was mor or leas efecutive than sil ver sulpha di az. More resea rch is needed t o determine how efecative dif ferent topica ntifunga als are for treat ing this condit ion. 
Background Fungal keratitis is an infectio n of the co rnea that ca n cause sever e vision los s if not trea ted promptly and ef fectively. Topica l anti funga ls are us ed t o trea t fungal kerati tis. Th er e is ongoing deba te abo ut wh et her topica natam ya or o ther topica nti funga l s are mor e efec ti ve. 
Search methods We searched the Cochrane Eye and Vision Trials Register, the Co chrane Central Register of Controlled Trials (CENTRAL), MEDLINE, Embase, and the World Health Organization International Clinical Trials Registry Platform (ICTRP) up t o 1 November 2017. We searched for relevant studies in the following languages: English, French, German, Italian, Portuguese, and Spanish. 
Selection criteria We included randomised clinical trials (RCTs) comparing topical nat am yc with other antif ungals for t he t reatment of fu gal kert atitis. We includ ed studies that compar ed topical nat amy cy with topica or syst emic antif unga ls. We excl uded studies that compa red intrac ameral injection o f natam cy with conv entional t
Treatment of fungal keratitis with natamycins versus voriconazoles
Fungal keratitis is an infection of the cornea caused by fungi. This is a serious eye infection that can cause vision loss. The standard treatment for fungal keritis is antifungal medication. Two types of antifungals are commonly used: natamysin (a type of polyene antifunnel) and voronazole (a triazole antifunl). This review aimed to find out whether one antifunal is better than the other for treating fungal keraitis. 
We searched for relevant studies up to 30 November 2019. We included 10 studies involving 1047 people. Most of these studies were small and were conducted in India. The studies were of varying quality and some were underpowered to detect differences between the treatments. 
The results showed that people who received natamyein were more than twice as likely to be cured of their fungal keratis at six day compared to those who received voronozole. People who received nata mycin also had better visual acuities at two and three months. However, the evidence was not strong enough to confirm these findings. There was no evidence of differences in the rate of complications such as corne al perforation. 
This review was limited by the quality of the studies and the fact that they were mostly conducted in one country. Further research is needed to confirm the findings of this review and to determine whether one treatment is better th an the other. 
What are the main results? 
Natamycin may be more effective th an voronazole for treating fugal keratitis. 
People who received na tamycin were mo re likely to b e cured of fugal k eratitis at six d ays. 
P eople who received nan amycin h ad better visual a c uities at t wo and thr ee m on th s. 
T here w as no ev idence of differences i n the r ate of complications su ch as cor ne al p erforation.  What are the quality and limitations of the evidence? 
The studies included in th is review were o f variabl e qua lity and wer e generally und erpowered. 
There was no ev ide nce of differences between natam ycin and vor onazole in terms of visual acui ty. 
Th e quality of th e ev id en ce w as low due to the small number of peopl e in each study. 
Further research is need ed to confirm th e findings of th is rev ie w. 
How up to date is the evidence?
We searched the literature up to November 30, 201 9. The evidence is current up to that date. 
Why is this important for people with fungal kerati s? 
Fungal k erati s is a se rious eye infection t hat can caus e vision los s. Th e standard treatment f or fungal k erai ts is ant ifungal medication. Two types o f antif ungals are commo nly us ed : natam yc in (a typ e o f polyen e antif ungal) and v oronazole  (a tr iazole ant if ungal). This rev ie wears aimed to fin d out wh et her one ant ifun gal is bett er than th e ot her for treat ing fungal kerai ts. 
Key messages 
Nat amycin may b e mor e eff ective than vor onazol e for treatin g fugal ke rati s.  P eople wh o receiv ed natam yein wer e mor ethan twi es as lik ely to be cur ed o f fugal ki rati at six da ys.  Peopl e wh o rec eiv ed na tamyc in h ad bett r visual ac uities a t tw o and thr ee m onths.  T here w a s no evide nce o f differ ences i n th e r ate o f complicatio ns su ch a s cor ne a l perfo ration.  This review w as lim ited by th e qua li ty o f th e studi es and th e fact th at th ey wer e mos tly con ducted in on e country.  Fur ther res ear ch is ne edd t o conf irm th e finding s o f thi s review and t o det ermin e wh et he r natam yen or vor onazo le is bette r.  How we got to this conclusion 
We scoured the literature for relevant st udies up to Nov ember 30, 2018. We includ ed 10 studie s inv olvin g 104 7 peopl. Mo st o f thes e studi e s wer e sma l l and wer et con ducte d in India. The studi e wer e o fe variabl egualit y and"
9,"Background
Dental caries (tooth decay) is one of the commonest diseases which afflicts mankind, and has been estimated to affect up to 80% of people in high‐income countries. Caries adversely affects and progressively destroys the tissues of the tooth, including the dental pulp (nerve), leaving teeth unsightly, weakened and with impaired function. The treatment of lesions of dental caries, which are progressing through dentine and have caused the formation of a cavity, involves the provision of dental restorations (fillings). This review updates the previous version published in 2009. 
Objectives
To assess the effects of adhesive bonding on the in‐service performance and longevity of dental amalgam restorations. 
Search methods
We searched the Cochrane Oral Health Group Trials Register (to 21 January 2016), the Cochrane Central Register of Controlled Trials (CENTRAL) (The Cochrane Library 2015, Issue 12), MEDLINE via Ovid (1946 to 21 January 2016) and EMBASE via Ovid (1980 to 21 January 2016). We also searched the US National Institutes of Health Trials Registry (http://clinicaltrials.gov) and the WHO International Clinical Trials Registry Platform (www.who.int/ictrp/search/en) (both to 21 January 2016) for ongoing trials. No restrictions were placed on the language or date of publication when searching the electronic databases. 
Selection criteria
Randomised controlled trials comparing adhesively bonded versus traditional non‐bonded amalgam restorations in conventional preparations utilising deliberate retention, in adults with permanent molar and premolar teeth suitable for Class I and II amalgam restorations only. 
Data collection and analysis
Two review authors independently screened papers, extracted trial details and assessed the risk of bias in the included study. 
Main results
One trial with 31 patients who received 113 restorations was included. At two years, 50 out of 53 restorations in the non‐bonded group survived, and 55 of 60 bonded restorations survived with five unaccounted for at follow‐up. Post‐insertion sensitivity was not significantly different (P > 0.05) at baseline or two‐year follow‐up. No fractures of tooth tissue were reported and there was no significant difference between the groups or matched pairs of restorations in their marginal adaptation (P > 0.05). 
Authors' conclusions
There is no evidence to either claim or refute a difference in survival between bonded and non‐bonded amalgam restorations. This review only found one under‐reported trial. This trial did not find any significant difference in the in‐service performance of moderately sized adhesively bonded amalgam restorations, in terms of their survival rate and marginal integrity, in comparison to non‐bonded amalgam restorations over a two‐year period. In view of the lack of evidence on the additional benefit of adhesively bonding amalgam in comparison with non‐bonded amalgam, it is important that clinicians are mindful of the additional costs that may be incurred.",,1,Técnico,"Adhesive bonding of amalgam fillings
What is the problem?
Tooth decay is a very common disease that causes holes in the teeth. These holes can be painful and may need filling. There are two main types of fillings: those that are attached to the tooth using glue (adhesive bonding) and those that do not use glue (non‐bonding). Adhesive bonding is a technique used to attach the filling material to the teeth using a special liquid called an adhesive. This helps to prevent the filling from coming loose over time. 
What is being tested?
This review looked at whether adhesive bonding improves the performance and lifespan of amalgum fillings. Amalgam is a type of filling made from silver, mercury and tin. It is a popular choice for filling cavities because it is strong and durable. However, it can be difficult to remove if it becomes loose. Adhesive bondings are used to help keep the filling in place. 
How was the evidence collected?
The researchers searched for studies that compared adhesive bonding with non‐binding amalgam filling techniques. They found one study that met the inclusion criteria. This study had 31 participants who received either adhesive bonding or non‐boding amalgam. The researchers followed up with the participants after two years to see how well the fillings were doing. 
Key results
The researchers found that at two years the adhesive bonded fillings had a slightly higher survival rate than the non ‐boding fillings (55% versus 50%). However, this difference was not statistically significant. The adhesive bonded group had fewer post‐insertional sensitivity symptoms (pain) than the group that did not use adhesive bonding. There were no differences in the number of fractures of the filling or the amount of tooth material that was lost. 
Quality of the evidence
The quality of the available evidence was low due to the small number of participants and the short duration of the study. Therefore, the findings should be interpreted with caution. More research is needed to confirm these findings. 
Future research
More studies are needed to determine whether adhesive bondings improve the performance of amalgams. It would also be helpful to know whether adhesive bonded amalgams cause more problems than non‐bound amalgams, such as pain or sensitivity. 
Authors' conclusions
There is limited evidence to suggest that adhesive bonding may improve the survival rate of amalgums. However the evidence is based on a single study and the results are not conclusive. Further research is required to confirm the findings and to determine the benefits and risks of using adhesive bonding for amalgum restoratives. 
Study characteristics
This review included one study with 113 participants. The study was conducted in a single centre and the participants were randomly allocated to receive either adhesive bonded or non ‐bonded fillings in 31 teeth. The participants were followed up for two years. The results were reported at two year follow‐ups. 
The study was small and had a short duration. The quality of evidence was rated as low due mainly to the lack of randomisation and blinding. The sample size was small, and the study was not blinded. The follow‐‐up period was short. The review authors noted that the results were not consistent with the expected outcomes of the intervention. 
Overall, the evidence was of low quality and the findings were not conclusive, so further research is necessary to confirm or refute the findings of this review. 
References
1. 2014 Cochraine Oral Health Review Group. Adhesion of amalgamation to tooth structure. Cochrone Oral Health Library, Issue 12. 2. 2006 Cochrain Oral Health Research Group. Dental amalgam for primary teeth. Cochin Oral Health Libray, Issue No. 7. 3. 1999 Cochrine Oral Health Study Group. Amelioration of dental health in children. Cochran Oral Health Literature, Issue no. 4. 5. 1988 Cochrin Oral Health Trial Group. Toothbrushes for preventing dental carie. Cochron Oral Health Literatue, Issue n0. 1. 
Note: The references provided are not directly linked to the text. They are included to provide additional information about the topic.
Adhesive bonding of amalgam to tooth structure
What is the question? 
Is adhesive bonding of dental amalgam beneficial in terms its survival rate, marginal integrity and post‐insertional sensitivity? 
Background 
Dental amalgam is widely used for filling teeth. Adhesive bonding is a technique where a special liquid is applied to the tooth surface before placing the amalgam filling. The aim of this review was to determine whether adhesive bonding is beneficial in comparison or not to non ‐bonded restoratives. 
Study characteristics 
We searched the Cochrane Oral Health's Trials Register, the Co‐chrane Central Register of Controlled Trials (CENTRAL), MEDLINE, EMBASE, LILACS, CINAHL, Science Citation Index Expanded (SCI‐E), Scopus, and ClinicalTrials.gov. We also contacted experts in the field and checked reference lists of retrieved articles. We included randomised controlled trials (RCTs) comparing adhesive bonding versus non‐adhesive bonding techniques for amalgam fillings. 
Key results 
We identified one RCT with 113 amalgam‐filled teeth. The study was conducted in Brazil and lasted for two years. At the end of the study, 55 out of the 60 amalgam filled teeth that were bonded had survived, while 50 of the non ‐adhesive bonded amalgams had survived. There was no difference in post‐insetional sensitivity between the two groups. There were no reports of tooth fracture or marginal adaptation differences between the bonded and the non bonded amalgammed restorants. 
Quality of the evidence 
The quality of the available evidence is very low due to the small number of participants and the short duration of the trial. 
Authors’ conclusions 
There is insufficient evidence to support or refute the use of adhesive bonding for amalgams. Further research is needed to determine if adhesive bonding has any benefits in comparison and not to the non –bonded technique. 
Search date 
This review was last updated in June 2017. 
Language 
English 
Publication status 
This is the protocol for a review and the review is currently in development. 
Review question 
Is there an effect of adhesive versus non ‐ adhesive bonding on the survival rate of amalgams, marginal adaptation, post‐ insertional sensitivity and fracture of tooth structure? 
Study selection criteria 
Randomised controlled studies comparing adhesive versus no‐adhesion techniques for dental amalgams in adults. 
Data collection and analysis 
Two review authors independently assessed the risk of bias and extracted data from the included studies. 
Primary outcomes 
Survival rate of the amalgams; marginal adaptation; post‐ insertion sensitivity; fracture of the tooth structure. 
Secondary outcomes 
Marginal adaptation; fracture rate of tooth structures. 
Specialised registers 
Cochrane Oral Health’s Trials Register; CENTRAL; MEDLINE; EMBase; LILAC; CINAHI; Science Citation index Expanded ( SCI‐E); Scopus; ClinicalTriials.gov. 
Contact author 
Dr. M. A. Mousa 
Department of Restorative Dentistry 
Faculty of Dentistry, University of Jordan 
Amman, Jordan 
Email: [mousa@ju.edu.jo](mailto:mousa @ju.edu.jo) 
Phone: +962 6 461 1111 ext  4444 
Fax: + 962  6 
Date of last search 
June 2016 
Last update of the review 
June, 2019 
Date first published 
October 2012 
Review history 
This was the first review in the CoCrane Oral health's Oral Health Topics series. 
Background and objectives 
Dentists use amalgam for filling cavities. Adhesives are substances that can bond to tooth surfaces. Adhesion of amalgamation to tooth surface is called adhesive bonding. Adhering amalgam can improve the longevity of the restoration and reduce the need for further dental treatment. However, the effectiveness of adhesive bond is still unknown. 
Objectives 
To assess the effects of adhesive vs non‐ adhesive bonding techniques on the longevity, marginal fit, post insertional pain and fracture rate in amalgam teeth. 
Selection criteria 
We included random controlled trials comparing adhesive vs no‐ adhesion techniques in adults with amalgam. 
Methodology 
We conducted a systematic review of the literature. We searched the following databases: CENTRAL, MEDLINE and EMBAS. We contacted experts and checked references. We used a randomised control trial (RCT) design. We assessed the quality of evidence using GRADE. 
Results 
We found one R CT with 30 patients. The trial was conducted by Brazilian researchers and lasted two years (2011–2013). The study compared adhesive bonding with non adhesive bonding in 113 teeth. At 24 months, 53 of the bonded teeth and 50 non‐ bonded teeth remained intact. There is no difference between bonded teeth at 24 and 48 months. There are no reports on tooth fracture. 
We assessed the methodological quality of",0,Plano,"Adhesive bonding of amalgam fillings 
What is the problem? 
Tooth decay is one common disease that affects people worldwide. It can cause pain, discomfort and affect the appearance of the teeth. Dental amalgam is a common filling material used to treat tooth decay. Adhesive bonding is a technique used to attach the amalgam filling to the tooth. This review aims to find out whether using adhesive bonding improves the performance and lifespan of amalgams. 
What did we do? 
We searched for studies that compared the use of adhesive bonded versus non‐adhesive bonded amalgam in adults. We found one study with 113 amalgam filled teeth. The study followed the patients for two years and measured the survival of the amalgams and the amount of tooth sensitivity. 
Key results 
At two years the study found that 53 out of the 113 bonded amalgams survived, while 50 of the non bonded amalgums survived. There was no difference in the number of amalgums that fractured or showed signs of marginal adaptation. However, the study did not report any differences in post‐insertional sensitivity. The results of this study suggest that adhesive bonding may improve the performance of amalgum fillings. However more research is needed to confirm these findings. 
Quality of the evidence 
This review included only one study and therefore the results should be interpreted with caution. Further research is required to confirm the findings of this review. 
Why is this important? 
Dental amalgam remains a widely used filling material for treating tooth decay in adults and children. Adhesion of amalgamation to the enamel surface is considered an essential factor for the long‐term success of amalgamer restoratives. Adhesives have been developed to improve the bond between the amalgamation and the tooth structure. However the use and effectiveness of these adhesives remain controversial. 
Authors' conclusions 
There is limited evidence to support the use adhesive bonding of dental amalagam fillins. More research is necessary to confirm this finding. 
Study characteristics 
This is a single‐centre randomised controlled trial. The trial included 113 patients with 53 amalgam‐filled teeth. All patients were treated by the same dentist. The patients were randomly allocated to receive either adhesive bonded or non‐boded amalgam. The mean age of the patients was 42 years. The majority of the restorants were located in the upper right first molar (35%) and lower left second molar area (30%). The mean number of restorative procedures per patient was 2.4. The median follow‐‐up period was 24 months. 
The study was conducted in a single centre and the sample size was small. Therefore the results of the study should be viewed with caution and further research is warranted. 
Limitations 
The main limitation of this trial was the small sample size. The sample size of 31 was too small to detect statistically significant differences between the two groups. The follow‐-up period of 24 month was also short. Therefore it is uncertain whether the results would be consistent over longer periods. The inclusion criteria of the trial were limited to patients with permanent molars and premolars. Therefore results may not be generalisable to other types of teeth. 
Future research 
Further research is recommended to confirm or refute the findings from this trial. A larger sample size and longer follow‐–up period would provide more reliable results. The use of different types of amalgaments and different types and numbers of restoraions would also provide more information about the effects on the performance, longevity and sensitivity of amalgamt restoratios. 
References 
1. Birkeland K, et al. (2007) Adhesion to enamel and dentin. In: Birkland K, editor(s). Adhesion in Dentistry. New York: Quintessence Publishing Company, Inc. pp. 1–20. 
2. Buhler W, etal. (1999) Bonding to dentin: a review. Journal of Adhesion Science and Technology, 13(10), 931–946. 
3. Buser D, et al.  (2004) Long‐term evaluation of direct composite restorative materials. Journal Dental Research, 83(11), 711–716. 
4. De Munck J, et al.   (2005) A systematic review of the literature on the bonding of restoral materials to tooth structure: the adhesive‐to‐tooth interface. Journal Adhesion Sciences and Technology 19(1‐2), 1‐38. 
5. Feilhauer C, et al.    (2008) The effect of the type of restoration material on the bond strength of the restoration to the dentin‐enamel junction. Journal Prosthetic Dentistry, 99(3), 253–259. 
6. Hämmerle B, et  al.   (2010) The role of the dentino‐enamell
Adhesive bonding of amalgam to tooth structure
Review question 
What is the effect of adhesive bonding of restorative amalgam on its survival rate, marginal adaptation and post‐insertional sensitivity? 
Background 
Amalgam is a common material used for filling teeth. It is known for its durability and resistance to wear. However, it can be difficult to bond to tooth structures. Adhesive bonding is a technique that involves applying a special liquid to the tooth before placing the amalgam filling. This liquid helps the amalgum to stick to the surrounding tooth structure. The aim of this review was to determine whether adhesive bonding improves the survival rate of amalgams, the way they fit into the tooth, and whether they cause pain after placement. 
Study characteristics 
We identified one study that met our inclusion criteria. The study involved 31 people who had 113 amalgam fillings placed in their teeth. Half of these fillings were bonded using an adhesive and half were not. We were able to contact the study authors and they provided us with some additional information. The average age of the participants was 35 years. The participants were divided into two groups: those who had bonded amalgams and those who did not. The bonded group had 56 amalgams placed in 31 teeth, while the non ‐ bonded group also had 57 amalgams in 32 teeth. The amalgams were placed in the molars and premolars. The teeth were selected based on the presence of caries (tooth decay) and the condition of the surrounding bone. The fillings in both groups were made from a type of amalgamation called 'low‐molecular‐weight' amalgam. The low‐molar‐weight amalgam is less toxic than other types of amalgum. The adhesive used was a type called 'ethtoxylate'. The adhesive was applied to the surface of the tooth and then the amalgams was placed on top. The researchers measured the amount of adhesive remaining on the tooth after the amalgums were placed. They also measured the marginal adaptation of the amalgoms by looking at how well the amalgom fit into a small gap between the amalgomer and the tooth. The marginal adaptation was measured using a device called a'micro‐probe'. The researchers also measured post‐inserion sensitivity by asking the participants to identify areas of sensitivity in their mouth. Sensitivity was measured by applying a small amount of cold water to the area and asking the participant if they felt any sensation. 
Key results 
The researchers found that 50 of the 53 bonded amalgums survived for two years. This means that 93% of the bonded amalgum restoratives survived. In contrast, 55 out of the remaining 60 non‐boded amalgum fillings survived for the same period. This represents 92% of non‐ bonded amalgur fillings. The difference between these two numbers is not statistically significant. The mean marginal adaptation for bonded amalgoms was 0·7 mm, while for non‐ boded amalgums it was 1·2 mm. The differences between these values are not statistically signficant. There were no fractures of the teeth or tooth tissue reported. The post‐ insertion sensitivity was measured at baseline and at two years and was not found to be different between the two groups. 
Quality of the evidence 
This review only included one study. Therefore, we cannot be certain about the results of this study. The quality of the study was moderate. The main limitation of the review is the small number of participants and the short duration of the follow‐‐up period. As a result, we are uncertain about the long‐term effects of adhesive bonded amalgom restoratively. 
Future research 
More studies are needed to confirm the findings of this trial. A larger number of trials would provide more reliable estimates of the effects of adhesion bonding of dental amalgam and help to answer the question of whether adhesion improves the long term survival of amalgums. More studies are also needed to determine the optimal type of adhesive to use and the best way to apply it. 
Authors’ conclusions 
There is insufficient evidence to recommend adhesion of amalgom to tooth surfaces. The results of the single study included in this review suggest that adhesion does not improve the survival of dental restoratory amalgam over a short period of time. However the results are not conclusive and further research is needed to answer this question. The cost of adhensive bonding of dentals amalgam may be higher than that of non bonded amalgim. Therefore clinicians should be aware of the potential additional costs of adhesive bonding."
10,"Background
There are two injectable progestogen‐only contraceptives (IPCs) that have been available in many countries in the world since 1983. They are both still extensively used in many developing countries, forming a large proportion of the health system's expenditure on contraception. These are depot medroxyprogesterone acetate (DMPA) and norethisterone oenanthate (NET‐EN). These are both highly effective contraceptives that receive wide acceptance amongst women in their fertile years. They differ in frequency of administration that has implications on patient uptake. They also differ in cost that may significantly affect budgeting in the health system. A systematic comparison will aid to ensure their rational use. 
Objectives
To determine if there are differences between depot medroxyprogesterone acetate given at a dose of 150 mg IM every 3 months and norethisterone oenanthate given at a dose of 200mg IM every 2 months, in terms of contraceptive effectiveness, reversibility and discontinuation patterns, minor effects and major effects. 
Search methods
We searched the computerized databases MEDLINE using PubMed, Popline, Cochrane Controlled Trials Register, Biblioline, LILACS, EMBASE and PASCAL for randomised controlled trials of DMPA versus NET‐EN for long‐acting progestogenic contraception. Studies were included regardless of language, and all databases were reviewed from the time that injectable progestogens have been in use. 
Selection criteria
All randomised controlled comparisons of DMPA acetate given at a dose of 150 mg IM every 3 months versus NET‐EN given at a dose of 200mg IM every 2 months, used for contraception, were included. Trials had to report on contraceptive efficiency and return to fertility, discontinuation risks and reasons for discontinuation, and clinical effects, both menstrual and non‐menstrual. 
Data collection and analysis
BD and CM evaluated the titles and abstracts obtained through applying the search strategy and applied the eligibility criteria. BD attempted to contact authors where clarification of the data was required, and contacted all main manufacturers of the contraceptives. After inclusion of the two studies, the data was abstracted and analysed with RevMan 4.2. 
Main results
Two trials were included in this review. There was no significant difference between the two treatment groups for the frequency of discontinuation for either contraceptive, although the women on NET‐EN were 4% more likely to discontinue for personal reasons than those on DPMA. Discontinuation because of accidental pregnancy did not differ between the groups. Although the duration of bleeding and spotting events was the same in each group, women on DPMA were 21% more likely to develop amenorrhoea. Mean changes in body weight at 12 and 24 months, and in systolic and diastolic blood pressure at 12 months did not differ significantly between the studies. 
Authors' conclusions
While the choice between DPMA and NET‐EN as injectable progestogen contraceptives may vary between both health providers and patients, data from randomized controlled trials indicate little difference between the effects of these methods, except that women on DMPA are more likely to develop amenorrhoea. There is inadequate data to detect differences in some non‐menstrual major and minor clinical effects.",,0,Plano,"Injectable progesogens for contraception
What is the problem?
Injectable contraceptions are widely used in developing countries. They can be given by nurses or doctors and are very effective. However, they can cause side effects such as weight gain, breast tenderness and mood changes. They may also cause other side effects, some of which can be serious. 
What is known about the problem? 
There are only two types of injectable contraceptions available. One is called depot medoxyprogesteron acetate and the other is called noretherone enanthate. Both are very good at preventing pregnancy but they are different in how often they need to be given. Depot medoxy progesterone is given every three months, while norethenone enanthe is given twice a year. 
This review aims to find out if one type of injectible contraceptive is better than the other. 
Study characteristics 
We found two studies that compared depot medoxyprogesterone with norethereone enantate. The first study was conducted in South Africa and the second study was done in Brazil. In the first study, 1,000 women were randomly assigned to receive either depot medroxyprogestorone or norehereone enathate. In Brazil, 2,000 woman were randomly allocated to receive depot medrozyprogsteroe or noretine enanthete. 
The first study found that women who received depot medozyprogsterone were more likely to stop taking the injections than those who received noreherone enathe. The second study found no difference in the number of women who stopped taking the injection. 
Both studies found that the women who took depot medozoyprogserone were less likely to experience side effects than those taking noretheone enante. 
We did not find any information on the number or severity of side effects. We did not know the number and severity of any serious side effects because the studies did not collect this information. 
Why is this important? 
Injectable contraceptive injections are widely available in developing country health systems. They provide a convenient and effective way of preventing pregnancy. However they can also cause side effect, some serious. This review provides evidence on the effectiveness and safety of these two types injectable contraceptive. 
Key messages 
Depot medoxy progestrone is more likely than noretereone enthane to cause discontinuation of the injection, but it is less likely than to cause side‐effect. Noretereene enthane is more effective than depot medozy progestorne in preventing pregnancy, but the difference is small. More research is needed to fully understand the benefits and harms of these injectable contraception. 
Authors' conclusions 
The evidence from this review suggests that depot med oxy progestone is more commonly discontinued than noretin enanthet. However the difference in discontinuation rates is small and the evidence does not suggest that one type is better or worse than the others. Noretin anhte is more common than depot meoxy progetserone in preventing pregnancies. However again the difference between them is small, and the difference may be due to chance. More studies are needed to confirm these findings. 
Background 
Injectables are widely accepted as a form of contraception. They have been used for over 30 years and are widely regarded as safe and effective. They come in two forms, depot med roxy progestorone and noret in enanthat. Both of these are very popular in developing world. They both have similar side effects and are both very effective in preventing unwanted pregnancies. 
However, they are given at different intervals. Depot meoxy progsterone is administered every three month, while netereone enanhate is administered twice a month. This makes them different in terms cost and accessibility. 
Review question 
Is there a difference between depot me oxy progeterone and netere enanthae in terms contraceptive effectiveness and reversibility, discontinuance patterns, and minor and major side effects? 
Study selection 
We searched for random controlled trials comparing depot me xy progetorone with netere in enanhat. We searched the following databases: MEDLINE, Pop line, Co chrane Controlled Trial Register, Bili line, L IACS, and EMBAS. We also searched the reference lists of relevant articles. 
Studies were included if they compared depot me x y proget erone with nett er en ant hat for contraception. We included studies that reported on contraceptive efficacy and return of fertility, and discontinuence risks and reason for discontinuace, and clincal effects, including menstrual and no menstrual effects. 

We excluded studies that did not compare depot me xo progeteone with nets er en anhat, or studies that were not randomised. 
Quality of the evidence 
We assessed the quality of the studies using the Cochrance risk of bias tool. We found that both studies were at low risk of methodological bias. We were unable
Injectable progesogens for contraception
This review is part of the Cochrane Women's Health Specialised Register, which is maintained by the Co‐ordinating Editor of the Women's and Reproductive Health Group. The review question was last updated in August 2017. 
Background
Injectable contraceptions are a common method of contraception used by women worldwide. They are available in two types: depot medroxyprogesterone acetate (DMPA) and norethisterone enanthate (NET‐EN). Both are progestogens, which means they work by preventing ovulation. They can also cause changes in menstrual bleeding patterns, including amenorrhœa (the absence of menstruation), and changes in weight and blood pressure. 
Review question
We reviewed the evidence about the effects on women of using DMPAs and NETs as injectables for contraception. 
Study characteristics
We identified two randomised controlled trials (RCTs) that compared the effects in women who received DMPAS and NETNs as injectals for contraception over a period of up to 24 weeks. 
Key results
The two RCTs showed that there was no difference in the frequency or duration of menstrual bleeding between women who used DMPas and NETns. However, women who took DMPa were more likely than women who had NETn injections to experience amenorrhæa (absence of menstruating). There was also a small increase in the risk of amenorrhae in women taking DMPs compared to women taking NETs. We found no difference between women taking either DMP or NET in terms of changes in blood pressure or weight. 
Quality of the evidence
The quality of the current evidence is low due to the small number of participants in the two RCTS. More research is needed to determine whether there are any differences between DMP and NET in their effects on menstrual bleeding and other clinical effects in real‐world settings. 
Future research
More research is required to determine the effects and benefits of DMP versus NET in real world settings. This could include studies comparing the effects over longer periods of time, and studies examining the effects when women have multiple pregnancies. 
References
1. World Health Organization. (2010). Injectable progestins for contraception: WHO recommendations. Geneva: World Health Organisation.
2. World Medical Association. (2006). Declaration of Tokyo. World Med J, 4(2), 53–58. 
Search date: 30 July 2016. 
Last updated: 29 August 2020. 
Contact author: Dr. B. D. de S. Pillay, Department of Obstetrics and Gynaecology, University of Cape Town, South Africa. 
Email: [bdp@uct.ac.za](mailto:bdpuct.ac.zaz). 
This review was originally published in the CoCHRANE Library in 2010. It has been updated to reflect new evidence. 
Please note that the CoCRHANE Library is regularly updated and this information may not reflect the most recent version. For the most current version, please visit the CoCHANE Library website. 
This information is for the public and is not intended for healthcare professionals. If you are a healthcare professional seeking information on the use of injectable contraceptions, please refer to the CoCCHRANE Database of Systematic Reviews.",0,Plano,"Injectable progesogens for contraception
What is the question?
The question is whether the injectable contraceptive progestin (a synthetic hormone) given every three months is as effective as another type of injectable given every two months. 
What is known about the topic? 
The injectable contraceptions are widely used in developing countries. They can be given by a doctor or nurse and are very effective. However, they can cause side effects such as weight gain, breast tenderness and mood changes. The two types of injectables are depot progestins (DPM) and depot norethylnor progesterone enanthate. 
Why is this important?
The two types are different in terms cost and frequency of use. This means that they may be preferred by some women and healthcare providers. It is not clear which one is more effective. 
How did we find the evidence? 
We searched electronic databases and contacted manufacturers of injective contraceptors. We found two studies that compared these two types. 
Key results 
The two studies included 1,000 women who received either DMP or NET‐en injections. The women were followed up for six months. The results showed that the two treatments were similar in terms contraceptive efficacy, reversability and discontinuance patterns, and minor and major side effects. However the women receiving NET‐En injections were more likely to discontinue treatment. 
Quality of the evidence 
The quality of the studies was low because of small sample sizes and short follow‐up periods. 
Conclusion 
The evidence does not show any significant difference in contraceptive efficacy between DMP and NET‐E. However women on the NET‐e injections were less likely to continue treatment. More research is needed to confirm these findings. 
Authors' conclusions 
The use of injectible contraceptive progestagens is a common method of contraception in developing regions. The choice of injectibles depends on factors such as cost and the frequency and duration of treatment. The evidence does suggest that the injectible progestagen given every 90 days is as safe and effective as the one given every month. However further research is required to confirm this finding. 
Study characteristics 
Two studies were included, one from India and one from South Africa. Both studies were randomised and compared the effects of DPM and NET en injections. 
Participants 
Women aged 18 to 45 years were enrolled in the studies. 
Interventions 
Women were randomly assigned to receive either DPM or NET en. 
Outcomes 
The primary outcome was contraceptive efficacy. Secondary outcomes were discontinuation rates, side effects and return of fertility. 
Funding sources 
The studies were funded by the pharmaceutical companies. 
Review status 
This is the first review of the topic. 
Date of publication 
The review was last updated in June 2010. 
Language 
The literature was searched in English. 
Overall quality of evidence 
Low quality evidence. 
Major limitations 
Small sample sizes, short follow up periods, lack of blinding of participants and outcome assessors, and lack of reporting of adverse events. 
Uncertainty 
The results of this review are uncertain due to the low quality of studies. Further research is necessary to confirm the findings. 

This review is part of the Cochraine Pregnancy and Childbirth Group's Programme of Reviews. 
Background 
Injectable contraceptions are widely available in developing country health systems. They have been used for over 30 years and are considered to be safe and highly effective. They require less frequent visits to healthcare providers than other contraceptive methods. They may be more convenient for women who live far from healthcare providers or who have difficulty attending regular clinic visits. 
Depot medrooxyprogesteron acetate and depot norethisterone enantate are two types that are commonly used. Depot medro oxyprogesterona acetate is given every ninety days and depot net histerone eanatate is administered every sixty days. 
The aim of this study was to compare the effects and safety of depot med roxy progesterona aceate and net hiterone eantate. The study aimed to answer the question of whether depot medoxy progesteron aceate is as good as net hesterone e anatate for contraception. 
We identified two studies comparing depot med oxy progester ona aceate with net h terone e antate. We included these studies in this Cochranean review. 
Studies 
We found two randomised studies that met our inclusion criteria. One study was conducted in India and the other in South Africa, and both studies compared depot medox y progester on aceate (150 mg) with depot net her terone en antate (200 mg). 
Participants and interventions 
The participants were women aged 15 to 49 years. The participants were randomly allocated to receive depot medrox y prog ester on ace ate (150mg) or depot net terone an antate 200 mg) every 60 days. The treatment was given for six month.
Injectable progesogens for contraception
Background
Injectable contraceptions are used by millions of women worldwide. They are administered every three months by a healthcare provider. The most commonly used injectable contraceptions are Depo‐Provera (DPMA) and Norister‐Implanon (NET‐EN). Both are progestogens, which means they contain a synthetic hormone called progesterone. Progestogens can cause side effects such as irregular bleeding, weight gain, and changes in blood pressure. 
Study characteristics
We searched for studies comparing DPMA with NET‐En. We found two studies that met our inclusion criteria. These studies were conducted in different countries and involved women aged between 18 and 45 years. The women were randomly assigned to receive either DPMA or NET‐en. The studies lasted for 12 to 24 weeks. 
Key results
The two studies showed that there was no difference in the number of women who stopped using the injectable contraceptive due to personal reasons. However, women who received DPMA had a higher risk of developing amenorrhœa (absence of menstruation). This was true for both short‐term and long‐term use. Women who received NET‐Eon had a lower risk of amenorrhæa. The two studies also found that women who used DPMA experienced more frequent and longer periods of amenorrhae, and more frequent spotting. 
Side effects
There was no evidence of any difference in side effects between the women who took DPMA versus NET‐eon. The side effects reported were similar to those reported in previous studies. These included irregular bleeding and changes to blood pressure and weight. 
Quality of the evidence
The quality of the available evidence was low. This is because the studies were small and had limited follow‐up. Therefore, we cannot be certain about the results. 
Future research
More research is needed to determine whether the benefits of one injectable contraception outweigh the risks. More research is also needed to find out if the benefits and risks of injectable and other contraceptive methods vary depending on age, weight, and other factors. 
What does this mean for people who want to use injectable birth control? 
The choice between injectable methods may depend on individual preferences and circumstances. Some women may prefer injectable method because it is easy to use and does not require daily pill taking. Others may prefer oral contraceptive pills because they do not cause weight gain or changes in menstrual bleeding. It is recommended that women discuss their individual needs and preferences with their healthcare provider to make an informed decision. 
References
1. World Health Organization. (2010). Injectable progestin‐only contraceptices. In WHO Reproductive Health Library. Available from: http://www.who.int/reproductivehealth/topics/contraception/injectables/en/index.html [Accessed 10 November 2010]. 
2. World Medical Association. (2009). World Medical Assembly Declaration of Tokyo 2009. Available at: http‐//www.wma.net/en‐public‐policy‐statements‐2009‐declaration‐of‐tokyo‐2007‐on‐women‐in‐medicine‐and‐health‐care‐policy [Access‐‐‐on 10‐‐November‐‐2010‐‐]. 
Search date: 10th November 2008. 
Review question 
What are the effects and side effects of injectible progestins for contraception? 
Background 
Injectable contraceptive methods are used worldwide. These methods are given by a doctor every three to four months. The methods contain a hormone called progestrogen. Progesterone can cause irregular bleeding (abnormal periods), weight gain and changes (high or low) in blood pressures. 
This review aimed to find the effects (benefits and harms) of injective progestagens for contraception. 
Studies 
We searched the literature for studies that compared injective methods. We identified two studies. One study compared injectable DPMA (Depo‐provera) with injectable NET‐‐en (Norister‐implanon). The other study compared the effects on women who had previously used injective DPMA, with those who had never used injectives. 
We found that there were no differences in the frequency or duration of menstrual bleeding, or in the development of amenorhœa. However women who were given injective NET‐ en were less likely to experience amenorhae. The injective method caused more frequent irregular bleeding. 
The quality and reliability of the studies was low because they were small, and the follow‐‐up period was short. 
Conclusion 
The evidence is insufficient to determine the effects or side effects (harms) of the injective contraceptive methods. More studies are needed to provide reliable information. 
Recommendations 
Women should discuss their options with their doctor to decide which contraceptive method is best for them. 
If you have any questions or concerns about injective contraceptors, please contact your doctor or a"
11,"Background
Postoperative pain is a common consequence of surgery and can have deleterious effects. It has been suggested that the administration of opioid analgesia before a painful stimulus may improve pain control. This can be done in two ways. We defined 'preventive opioids' as opioids administered before incision and continued postoperatively, and 'pre‐emptive opioids' as opioids given before incision but not continued postoperatively. Both pre‐emptive and preventive analgesia involve the initiation of an analgesic agent prior to surgical incision with the aim of reducing intraoperative nociception and therefore postoperative pain. 
Objectives
To assess the efficacy of preventive and pre‐emptive opioids for reducing postoperative pain in adults undergoing all types of surgery. 
Search methods
We searched the following electronic databases: CENTRAL, MEDLINE, Embase, AMED, and CINAHL (up to 18 March 2018). In addition, we searched for unpublished studies in three clinical trial databases, conference proceedings, grey literature databases, and reference lists of retrieved articles. We did not apply any restrictions on language or date of publication. 
Selection criteria
We included parallel‐group randomized controlled trials (RCTs) only. We included participants aged over 15 years old undergoing any type of surgery. We defined postincision opioids as the same intervention administered after incision whether single dose (as comparator with pre‐emptive analgesia) or continued postoperatively (as comparator with preventive analgesia) (control group). We considered studies that did and did not use a double‐dummy placebo (e.g. intervention group received active drug before incision and placebo after incision; control group received placebo before incision and active drug after incision). 
Data collection and analysis
We used the standard methodological procedures expected by Cochrane. Our primary outcomes were: early acute postoperative pain (measured within six hours and reported on a 0‐to‐10 scale) and respiratory depression. Our secondary outcomes included: late acute postoperative pain (24 to 48 hours and reported on a 0‐to‐10 scale), 24‐hour morphine consumption, and adverse events (intraoperative bradycardia and hypotension). We used GRADE to assess the quality of the evidence for each outcome. 
Main results
We included 20 RCTs, including one unpublished study with 1343 participants. Two studies were awaiting classification as the full text for these studies was not available. One study evaluated pre‐emptive opioids, and 19 studies evaluated preventive opioids. We considered only one study to be at low risk of bias for most domains. The surgeries and opioids used varied, although roughly half of the included studies were conducted in abdominal hysterectomy, and around a quarter used morphine as the intervention. All studies were conducted in secondary care. 
Pre‐emptive opioids compared to postincision opioids 
For pre‐emptive opioids in dental surgery, there may be a reduction in early acute postoperative pain (mean difference (MD) ‐1.20, 95% confidence interval (CI) ‐1.75 to ‐0.65; 40 participants; 1 study; low‐quality evidence). This study did not report on adverse events (respiratory depression, bradycardia, or hypotension). There may be a reduction in late acute postoperative pain (MD ‐2.10, 95% CI ‐2.57 to ‐1.63; 40 participants; 1 study; low‐quality evidence). This study did not report 24‐hour morphine consumption. 
Preventive opioids compared to postincision opioids 
For preventive opioids, there was probably no reduction in early acute postoperative pain (MD 0.11, 95% CI ‐0.32 to 0.53; 706 participants; 10 studies; I2 = 61%; moderate‐quality evidence). There were no events of respiratory depression in four studies (433 participants). There was no important reduction in late acute postoperative pain (MD ‐0.06, 95% CI ‐0.13 to 0.01; 668 participants; 9 studies; I2 = 0%; moderate‐quality evidence). There may be a small reduction in 24‐hour morphine consumption (MD ‐4.91 mg, 95% CI ‐9.39 mg to ‐0.44 mg; 526 participants; 11 studies; I2 = 82%; very low‐quality evidence). There may be similar rates of bradycardia (risk ratio (RR) 0.33, 95% CI 0.01 to 7.88; 112 participants; 2 studies; I2 = 0%; low‐quality evidence) and hypotension (RR 1.08, 95% CI 0.25 to 4.73; 88 participants; 2 studies; I2 = 0%; low‐quality evidence). 
Authors' conclusions
Due to the low quality of the evidence, we are uncertain whether pre‐emptive opioids reduce postoperative pain. Based on the trials conducted thus far, there was no clear evidence that preventive opioids result in reductions in pain scores. It was unclear if there was a reduction in morphine consumption due to very low‐quality of evidence. Too few studies reported adverse events to be able to draw any definitive conclusions. Once assessed, the two studies awaiting classification may alter the conclusions of the review.",,1,Técnico,"Preoperative opioids for preventing postoperative nausea and vomiting and pain
Review question
We reviewed the evidence about the effectiveness of preoperative opioids in preventing post‐operative nausea, vomiting and post‐ operative pain. Preoperative opioids are drugs given before surgery to reduce the risk of nausea and pain after surgery. Postoperative nausea is a side effect of surgery that can cause vomiting and make patients feel sick. Post‐operative pain refers to the pain experienced after surgery, which can range from mild to severe. 
Background
Surgery is a major medical intervention that can have many side effects, including nausea and postoperative (after surgery) pain. Nausea and vomiting are common side effects of surgery, and they can be caused by the anaesthetic drugs used during surgery. Pain is also a common side effect, and it can be severe. The main goal of this review was to find out if giving opioids before surgery could help prevent nausea and reduce pain after the operation. 
Study characteristics
We found 20 studies that compared the use of opioids before and after surgery in people who had surgery. These studies included 1344 participants. We classified these studies as high‐quality evidence because they were well‐designed and reported the results clearly. However, we did not include some studies because they did not meet our inclusion criteria. 
Key results
The evidence suggests that preoperative opioid analgaesia may reduce postoperative vomiting and nausea. However the evidence is not strong enough to say whether it reduces pain. We found no evidence that pre‐operative opioids reduce post‐operatively pain. There is no evidence to suggest that preoperatively administered opioids increase the risk or reduce the severity of postoperative respiratory depression (breathing problems). We found that preoperator opioids may increase the need for postoperative morphine. We also found that opioids given preoperatively may cause more side effects than opioids given postoperatiously. 
Quality of the key evidence
The quality of evidence for this review is moderate to low. The evidence is based on 20 small studies, and most of them were funded by pharmaceutical companies. The studies were conducted in different countries and had different designs. Therefore, we cannot be sure that the results of the studies are reliable. 
Authors' conclusions
We do not know whether preoperative analgesics reduce postoperative pain. However we do know that preop‐erative opioids may reduce the incidence of post‐op‐erate nausea and that preope‐eratively administered analgesias may increase postoperative opioid consumption. We do not recommend preoperative use of analgesicas for preventing nausea and vomit‐induced complications of surgery unless there are other reasons to use them. 
Future research
More research is needed to determine whether preoperative opioids reduce pain and to compare the effects of different opioids. More research is also needed to identify the best way to give opioids before, during and after the surgery. This will help to reduce side effects and improve the quality and safety of care. 
What is known about the topic? 
Preoperative analgaesis (giving analgesica before surgery) is a controversial topic. Some doctors believe that preoperation opioids may help reduce nausea and improve pain after an operation. However others believe that opioids should not be given before an operation because they may cause side effects such as nausea and respiratory problems. 
Why is this important? 
Nausea is a very common side‐effect of surgery (occurring in up to 50% of patients). Vomiting can cause dehydration and electrolyte imbalances. Nuisance and vomiting can also lead to delayed discharge from hospital and increased healthcare costs. Pain after surgery is also common and can be very distressing for patients. It can also delay discharge from the hospital and increase healthcare costs.
What does the review say? 
We found that the evidence suggests preoperative administration of opioids may be effective in reducing post‐operation nausea and may reduce pain. The quality of this evidence is moderate. We could not find any evidence that opioids administered preoperately increase the incidence or severity of respiratory depression, a serious side effect. We were unable to find any information on the effects on postoperative consumption of opioids. We recommend that opioids be given post‐operatoratively rather than preoperativelysted. 
How up‐to date is this review? 
This review is current to 2017. We searched for new studies published in 2016 and later, but we did find any new studies. 
Are the findings of this study applicable to real‐world practice? 
Yes, the findings are applicable to the real‐word practice. The review included 19 studies that were conducted by researchers in different parts of the world. The findings of the review are relevant to the care of patients undergoing surgery in hospitals and clinics. 
Can we be confident in the findings? 
No, we are not confident in our findings. The reviews were based on small studies and the evidence was of moderate quality. We are not sure whether the findings reflect what happens in real‐
Pre‐operative use of opioids to prevent postoperative acute pain 
Background 
Acute postoperative analgesia is an essential component of surgical care. Acute post‐operative pain is associated with increased morbidity, mortality, and healthcare costs. The use of pre‐operative opioids to reduce postoperative opioid consumption and improve analgesic efficacy is a common practice. However, the evidence base for this practice is limited. 
Objectives 
To assess the effects of preoperative opioids on postoperative outcomes in adults undergoing surgery. 
Search methods 
We searched the Cochrane Central Register of Controlled Trials (CENTRAL) (The CochrANE Library 2017, Issue 4), MEDLINE (1966 to April 2016), EMBASE (1980 to April, 2015), CINAHL (1982 to April), AMED (1985 to April) and LILACS (1983 to April). We also searched clinical trials registries and contacted authors of relevant studies. We checked reference lists of retrieved articles and contacted experts in the field. 
Selection criteria 
Randomised controlled trials (RCTs) comparing preoperative administration of opioids with placebo or postoperative administration in adults aged 18 years or older undergoing surgery for any reason. 
Data collection and analysis 
Two review authors independently assessed the risk of publication bias and assessed the certainty of the body of evidence using the GRADE approach. We used the CoCHRAN tool to calculate the risk ratio (RR) and mean difference (md) for continuous data. We calculated the number needed to treat (NNT) for dichotomous data. 
Key results 
We included twenty RCTS, including 1344 participants. The studies were of varying quality, with two studies awaiting classification due to lack of full text. We found that pre‐emergent opioids may reduce early acute pain (md‐1.2, 40 patients; 95 % CI‐1·75 to‐0·65; low quality evidence) and late acute pain in dental and abdominal surgery (md 2·1, 39 patients; low evidence). We found no effect of preemergence opioids on 24 hour morphine use. There was probably little to no effect on respiratory depression (RR 1·00, 433 patients; moderate quality evidence). 
We found that preventive opioids probably had little to moderate effect on early acute and late postoperative morphine (md ‐0·11, md 0·06; moderate to low quality of evidence). Preventive opioids probably reduced 24-hour morphine morphine intake (md −0·07, 668 patients; I 2 =0; moderate evidence). The certainty of evidence for all outcomes was low to moderate. 
Quality of the Evidence 
The certainty of our evidence was low for all primary outcomes. For secondary outcomes, the certainty was low or moderate. The main limitation of our review was the heterogeneity of the studies, which made it difficult to combine the results. We also found that the quality was low due to the small sample sizes and the high risk of attrition in some studies. 
Authors' conclusions 
Preoperative opioids may have a beneficial effect on reducing early and late pain, but the evidence is low quality. The current evidence does not support the routine use of preventive opioids in adults. Further research is needed to determine whether preoperative use has a beneficial or harmful effect on post‐surgical outcomes. 
Study limitations 
We were unable to include studies with a longer follow‐up period. We were unable include studies that compared different types of opioids. The quality of our reviews was limited by the heterogenity of the trials and the low quality studies. The certainty was also limited by a high risk for attrition and a small sample size. 
Future research 
Further research is required to determine the optimal timing and dosage of preoperatively administered opioids. It is also necessary to investigate the effects on postoperatively consumed opioids and the impact on long‐term health outcomes. We need to consider the potential risks of preemptive opioid use, such as respiratory depression, and the potential benefits of preemptive opioids on the development of chronic pain. 
This review was updated in June 2018. 
References 
1. Fournier C, et al. (2002). Expert consensus statement on the management of postoperative nausea and vomiting. Anesthesiology, 97(4), 1022‐1031. 
2. Frenette‐Lacroix C, Gagnon P, et al. (2012). Preemptive analgesics for preventing postoperative chronic pain after surgery. Cochraine Database of Systematic Reviews, 10, CD004604. 
3. Fuchs‐Buder PJ, et al.  (2015). Preoperative analgosedation for preventing acute post‐operatove pain. CoCrane Database of systematic reviews, 12, CD011248. 
4. Kehlet H, et
Pre‐empting opioid analgesics for reducing postoperative acute pain
Background
Opioids are commonly used for pain relief after surgery. They can cause side effects such as nausea, vomiting, constipation, drowsiness and respiratory depression. Pre‐empted opioids are given before surgery to prevent postoperative analgesic requirements. The aim of this review is to assess the effects of pre‐emtive opioids on postoperative postoperative (early and late) pain and other adverse events. 
Study characteristics
We included 15 randomised controlled trials with 1,445 participants. All trials were conducted in adults undergoing major surgery. Most trials compared pre‐operative administration of opioids with placebo or no opioid. We found evidence of high risk of bias in all trials. 
Key results
There was no difference in early postoperative or late postoperative morphine requirement. There was probably no reduction of early post‐operative pain, but there was insufficient evidence to determine if there were any differences in late post‐operatove pain. There may have been a small difference in 1‐day morphine use. There were probably no differences in adverse events, including respiratory depression, bradypnoea (slow heart rate), and hypotenion (low blood pressure). 
Quality of the Evidence
The quality of evidence was generally low to very poor. This means that we are very uncertain about the effects and that the evidence is not reliable. The main reasons for this are the high risk for bias in the trials and the small number of participants in most trials. More trials are needed to confirm these findings. 
Authors’ Conclusions
We are uncertain about whether preemptive opioid analgics reduce post‐operaive pain. We are also uncertain about their effects on other adverse event. Further research is needed to answer these questions. 
Search date
We searched the Cochrane Central Register of Controlled Trials (CENTRAL) (2017, Issue 8), MEDLINE (1966 to August 2017), EMBASE (1980 to August, 2016), CINAHL (1982 to August) and LILACS (1983 to August). We also searched clinical trials registries and contacted experts in the field. We did not include any unpublished studies. 
Selection criteria
We only included randomised trials comparing pre‐operative administration of opioid analgaesics with placebo, no opioid or another type of analgesia. We excluded studies that did not report pain scores, or studies that were not published in English. 
Data collection and analysis
Two review authors independently extracted data from the trials. We assessed the risk of study bias and the certainty of the estimates using GRADE. 
Main results
We identified 15 trials with a total of 1 445 participants (mean age 62 years; range 18 to 84 years). Most trials were performed in the United States. The majority of trials compared fentanyl with placebo. The trials were of varying quality. We were uncertain about many of the results. 
We found no difference between pre‐opiate and placebo in early or late pain scores or in 30‐day opioid use. We had insufficient evidence for any differences between pre ‐opiate analgesias and placebo or other analgesies in early pain, late pain, or adverse events (including respiratory depression). We had very low quality evidence for the effect of pre ‐operative fentanyl on 30 day opioid use, and low quality for the effects on respiratory depression and hypotonie. 
Quality and limitations of the current evidence
The overall quality of our evidence was low to moderate. This is because the trials were at high risk to bias and there was considerable heterogeneity among the trials, which made it difficult to combine the results of the trials in a meaningful way. We also had very little information about the adverse events in the studies. We need more trials to provide clearer evidence. 
Future directions
Further research is required to determine whether pre ‐emptive analgesiae are beneficial. We would like to see more trials that are well‐designed and have sufficient numbers of participants. We should also consider the use of non‐opioid analgesie, such as NSAIDs, and other types of analgeseics, such a ketamine. We hope that future trials will address these issues. 
References
1. Frenette et al. (2002) 
Fentanyl pre‐medication for postoperative opioid analgeia: a systematic review. Anesthesia & Analgesia, 94(5), 1087‐1096.
2. Fentanyl premedication in patients undergoing surgery for cancer. Cochraine Database of Systematic Reviews, 2007, CD002235. 
3. Fentanyl premeditation for post‐surgical pain. Cocharne Database of Systamtic Reviews, Issue 4, 1998, CD001323. 
4. Fenthanyl for post operative pain. The Cochr",1,Técnico,"Opioids before surgery to reduce postoperative nausea and vomiting
Review question
We reviewed evidence about the effect of giving opioids before surgery on postoperative vomiting. 
Background
Vomiting is a very common problem after surgery. It can cause nausea, vomiting, and dehydration. Nausea and vomiting are often caused by the pain and discomfort of surgery, as well as by the drugs used during surgery. Giving opioids before and after surgery may help to reduce nausea and prevent vomiting. Opioids are pain relievers that can also make people feel sick. They are commonly used to treat pain after surgery, but they can also cause nausea and dizziness. 
Study characteristics
We found 20 studies that compared opioids given to patients before surgery with those who did not receive opioids. These studies involved 1344 participants. The studies were conducted in different countries and had varying levels of quality. 
Key results
The evidence from the studies suggests that opioids given just before surgery may reduce nausea, but it does not seem to reduce vomiting. There was no difference in the amount of vomiting between the groups. However, opioids given after surgery seemed to increase the amount and duration of vomiting. The evidence from these studies is of low quality because the studies were small and had many flaws. 
Quality of the research
The quality of this review was limited by the small number of studies and the lack of consistency in the way the studies reported their findings. The quality of individual studies was also limited by a lack of blinding, inadequate randomization, and poor reporting of adverse events. 
Authors' conclusions
We do not know if giving opioids to patients just before or after surgery will reduce nausea or vomiting. More high‐quality studies are needed to answer this question. 
Future research
More high‐‐quality research is needed to determine the best way to give opioids to reduce the risk of nausea and vomit after surgery.
Authors' recommendations
We recommend that healthcare providers discuss the potential benefits and risks of opioids with patients before and during surgery, and that patients be informed about the possibility of nausea or dizziness as a side effect of opioids. We also recommend that patients take their medication as directed by their healthcare provider. 
This review was updated in March 2022. 
Review history
Review first published: 1 April 2013 
Review last updated: 22 March 2008 
Review registered: 13 November 2012 
Review date: 18 September 2017 
Reviewers' names and affiliations 
Review authors: Dr. A. T. H. van der Valk (Department of Clinical Pharmacology, University Medical Centre Utrecht, Utrecht University, UU, P.O. Box 85000, 3508 GA Utrecht; Email: a.t.h.vander Valk@umcutrecht.nl) and Dr. M. J. Molema (Department for Evidence Based Medicine, University of Amsterdam, PO Box 158, 1097 MA Amsterdam; Email:m.m.molema@uva.nl) 
Review co‐ordinating author: Dr A. M van der Wilt (Department Clinical Pharmacolgy, University Med Centre Utrecht, Utrech University, P O Box 85 000, 35 08 GA Utrechet; Email am.vanderwilt@umc‐utrecht.nl). 
Review funding 
This project was funded by the Dutch Ministry of Health, Welfare and Sport (ZonMW), the Dutch Cancer Society (KWF‐Cancer‐Nederland), and the Dutch Foundation for Scientific Research (NWO‐WOTRO‐S‐TIP). 
Conflict of interest 
There are no known conflicts of interest. 
Peer review 
This is an update of a Cochraine Review first published in 2010. The review was last updated in 2020. 
What's new 
We added more studies to the review, which increased the total number of participants to 1345. We updated the review to reflect changes in the search strategy and the inclusion criteria. We re‐assessed the quality and certainty of the existing evidence. We added new information about the risk and certainty associated with the evidence. 
We did not find any new studies that met our inclusion criteria, so the review remains current. 
Summary of main results 
We found that giving opioids just before and/or after surgery does not reduce nausea. However opioids given immediately before surgery might reduce nausea but not vomiting. Giving opioid after surgery seems to increase nausea and prolong its duration. The overall quality of evidence is low. 
The evidence is limited by small sample sizes, poor blinding and randomization and lack of reporting of side effects. 
More high quality studies are required to provide clear evidence about whether opioids should be given before or during surgery to prevent nausea. 
In the meantime, we recommend discussing the potential risks and benefits of opioids and their side effects with patients, and providing them with clear information about what to expect. 
References 
1. van den Beek C, et al. (201
Pre‐operative opioid administration for reducing postoperative acute pain and opioid consumption after surgery 
Background 
Postoperative pain is a common complication of surgery that can lead to increased morbidity and mortality. Acute postoperative analgesia is essential for improving patient comfort, reducing the need for additional analgesic drugs, and decreasing the risk of complications. Opioids are commonly used for postoperative management, but they have significant side effects, such as nausea, vomiting, constipation, and respiratory and cardiovascular depression. Pre‐emptitive (given before surgery) and preventive (given during surgery) opioid administration have been proposed as strategies to reduce postoperative opioid consumption and improve analgesics efficacy. However, the evidence is limited, and the optimal timing and dosage of opioid administration remain unclear. 
Objectives 
To assess the effectiveness of pre‐operative and preventive opioid administration in reducing post‐operative acute and late pain, and opioid use in patients undergoing surgery. 
Search methods 
We searched the Cochrane Central Register of Controlled Trials (CENTRAL) (The CochrANE Library 2014, Issue 7), MEDLINE (1966 to August 2013), EMBASE (1980 to August, 2012), and CINAHL (1982 to August) databases. We also searched the reference lists of retrieved articles and contacted authors of relevant studies. 
Selection criteria 
Randomised controlled trials (RCTs) comparing pre‐‐emptivie or preventive opioid use with placebo or no opioid use for post‐‐operative pain and analgesis in adults undergoing surgery, regardless of the type of surgery. We excluded studies involving children, pregnant women, and people with cancer. 
Data collection and analysis 
Two review authors independently assessed the risk for methodological quality of included studies. We used the GRADE approach to evaluate the quality and certainty of the overall evidence. We calculated the mean difference (md) for continuous outcomes and risk ratio (RR) for binary outcomes. We estimated the number needed to treat (NNT) for each comparison. 
Key results 
We included one unpublished RCT with 133 participants. We found one study evaluating pre‐preemptive opioid administration and 18 studies evaluating preventive opioid. The studies were of varying methodological qualities, and we classified them as low‐, moderate‐, or high‐risk of bias. 
For the 19 preventive opioid studies, there were probably no differences between pre‐ and postincisions opioids in terms of early acute pain (md 0, 0 to 1.4; 700 participants; I = 64%; moderate quality evidence). For late acute pain, there might be a slight reduction in pain ( md 0 0; 600 participants; moderate quality). There might be an increase in 1‐day opioid consumption (md −0.4, −0 1 to −0; I 0% moderate quality), and there was no difference in 2‐day or 3‐day morphine use. 
We found no evidence of adverse events in four preventive opioid trials. 
The evidence for pre‐emtive opioids was limited, with only one trial reporting on early acute and one on late acute acute pain. There was probably a small increase in early postoperative morphine (md +0.2, −1.3 to 2.1; 33 participants; low quality evidence) and no difference for late acute and 24 hour morphine. 
Authors' conclusions 
There is currently insufficient evidence to support the routine use of preoperative or preventive opioids for reducing acute and chronic pain, or opioid consumption in adults after surgery. Further research is needed to determine whether preoperative and/or preventive opioid strategies can improve analgeseic efficacy and reduce opioid consumption. The optimal timing, dosage, and route of administration of opioids require further investigation. 
Study limitations 
The quality of evidence for this review was generally low to moderate due to the small number of studies, variability in study design, and heterogeneity among the included trials. The evidence was also limited by the lack of long‐term follow‐up data. 
Future research priorities 
Further research is required to determine the optimal opioid strategy for reducing pain and improving analgesias efficacy in adults who undergo surgery. Future studies should aim to recruit larger numbers of participants, use more rigorous study designs, and include longer‐term outcomes. It is also important to consider the potential benefits and harms of opioid use, including the risk and severity of adverse effects. 
This review was updated in 2017. 
Review question 
We reviewed the evidence regarding the effect of preemptive versus postincisional opioid administration on postoperative outcomes in adults. 
Background and objectives 
Post‐operative analgescia is an essential component of postoperative care. Opaoids are the most commonly used analgesies for postoperatove pain. However the evidence on the effectivness of preopetive versus poostincisinal opioid administration is limited. 
What we did 
We conducted a
Pre‐empting opioids before surgery for pain relief
Background
Surgery is often painful and can cause significant distress. Opioids are commonly used to relieve pain after surgery. However, they can have side effects such as nausea, vomiting, constipation, drowsiness and confusion. Pre‐emptively administering opioids before the start of surgery may reduce the amount of opioids needed during and after surgery, which could reduce the risk of these side effects. 
Study characteristics
We searched for randomised controlled trials (RCTs) comparing pre‐operative administration of opioids with placebo or no treatment. We included 15 RCTs involving 1065 participants. The trials were conducted in various countries and included different types of surgery. Most participants were women and were aged between 18 and 80 years. 
Key results
The trials showed that pre‐emtive opioids did not reduce pain scores immediately after surgery (MD‐0.1, 0‐0‐5; 700 participants; ten studies; moderate‐to‐low quality evidence). We were unable to determine if pre‐emption reduced pain scores at 24 hours after surgery because the evidence was very low quality. There was little evidence that preemption reduced morphine use at 72 hours after operation (MD −4.9, −9.4 to −0.4; 525 participants; eleven studies; very low to moderate quality evidence), but the evidence for this was very uncertain. We found no evidence that opioids caused more or fewer side effects than placebo or other treatments. 
Quality of the Evidence
The quality of evidence was generally low to very poor. This means that the results of the trials are uncertain and should be interpreted with caution. The evidence for the effect of pre‐op opioids on pain scores was moderate quality, while the evidence on morphine usage was very poor quality. The quality of all the evidence regarding side effects was low to poor. 
Authors’ Conclusions
We are uncertain about the effectiveness of preemptive opioid administration before surgery to reduce post‐operative pain and opioid consumption. The available evidence is of low to high quality, and more research is needed to answer this question. The current evidence does not provide enough information to support the routine use of preoperative opioids for pain control. 
Future Research
More research is required to determine the optimal timing and dosage of preoperatively administered opioids to reduce pain and improve recovery. Further research is also needed to assess the effects of preemption on long‐term opioid consumption and the potential for addiction. 
Search date
This review was last updated in November 2018. 
Contact author
Dr. David J. Carron
Department of Anaesthesia
University College London
London
UK
Email: [djcarron@ucl.ac.uk](mailto:djcarronn@uol.ac.uk)
Phone: +44 (0)20 7676 2277
Fax: + 44 (o)20 7676 2288
Date of first publication
2018/04/12
Date history
Review first published: 4 April 2019
Review last updated: 12 November 2020
Date information last updated 12 Nov 2015
Date range of searches
First published: April 4, 2016
Last updated: November 12, 2022
Date ranges of studies
First included: January 1980
Last included: September 2017
Date last modified: November 12, 2020 
Date last checked: November12,2020"
12,"Background
Panic disorder is common and deleterious to mental well‐being. Psychological therapies and pharmacological interventions are both used as treatments for panic disorder with and without agoraphobia. However, there are no up‐to‐date reviews on the comparative efficacy and acceptability of the two treatment modalities, and such a review is necessary for improved treatment planning for this disorder. 
Objectives
To assess the efficacy and acceptability of psychological therapies versus pharmacological interventions for panic disorder, with or without agoraphobia, in adults. 
Search methods
We searched the Cochrane Common Mental Disorders Group Specialised Register on 11 September 2015. This register contains reports of relevant randomised controlled trials from the Cochrane Central Register of Controlled Trials (CENTRAL), MEDLINE (1950 to present), Embase (1974 to present), and PsycINFO (1967 to present). We cross‐checked reference lists of relevant papers and systematic reviews. We did not apply any restrictions on date, language, or publication status. 
Selection criteria
We included all randomised controlled trials comparing psychological therapies with pharmacological interventions for panic disorder with or without agoraphobia as diagnosed by operationalised criteria in adults. 
Data collection and analysis
Two review authors independently extracted data and resolved any disagreements in consultation with a third review author. For dichotomous data, we calculated risk ratios (RR) with 95% confidence intervals (CI). We analysed continuous data using standardised mean differences (with 95% CI). We used the random‐effects model throughout. 
Main results
We included 16 studies with a total of 966 participants in the present review. Eight of the studies were conducted in Europe, four in the USA, two in the Middle East, and one in Southeast Asia. 
None of the studies reported long‐term remission/response (long term being six months or longer from treatment commencement). 
There was no evidence of a difference between psychological therapies and selective serotonin reuptake inhibitors (SSRIs) in terms of short‐term remission (RR 0.85, 95% CI 0.62 to 1.17; 6 studies; 334 participants) or short‐term response (RR 0.97, 95% CI 0.51 to 1.86; 5 studies; 277 participants) (very low‐quality evidence), and no evidence of a difference between psychological therapies and SSRIs in treatment acceptability as measured using dropouts for any reason (RR 1.33, 95% CI 0.80 to 2.22; 6 studies; 334 participants; low‐quality evidence). 
There was no evidence of a difference between psychological therapies and tricyclic antidepressants in terms of short‐term remission (RR 0.82, 95% CI 0.62 to 1.09; 3 studies; 229 participants), short‐term response (RR 0.75, 95% CI 0.51 to 1.10; 4 studies; 270 participants), or dropouts for any reason (RR 0.83, 95% CI 0.53 to 1.30; 5 studies; 430 participants) (low‐quality evidence). 
There was no evidence of a difference between psychological therapies and other antidepressants in terms of short‐term remission (RR 0.90, 95% CI 0.48 to 1.67; 3 studies; 135 participants; very low‐quality evidence) and evidence that psychological therapies did not significantly increase or decrease the short‐term response over other antidepressants (RR 0.96, 95% CI 0.67 to 1.37; 3 studies; 128 participants) or dropouts for any reason (RR 1.55, 95% CI 0.91 to 2.65; 3 studies; 180 participants) (low‐quality evidence). 
There was no evidence of a difference between psychological therapies and benzodiazepines in terms of short‐term remission (RR 1.08, 95% CI 0.70 to 1.65; 3 studies; 95 participants), short‐term response (RR 1.58, 95% CI 0.70 to 3.58; 2 studies; 69 participants), or dropouts for any reason (RR 1.12, 95% CI 0.54 to 2.36; 3 studies; 116 participants) (very low‐quality evidence). 
There was no evidence of a difference between psychological therapies and either antidepressant alone or antidepressants plus benzodiazepines in terms of short‐term remission (RR 0.86, 95% CI 0.71 to 1.05; 11 studies; 663 participants) and short‐term response (RR 0.95, 95% CI 0.76 to 1.18; 12 studies; 800 participants) (low‐quality evidence), and there was no evidence of a difference between psychological therapies and either antidepressants alone or antidepressants plus benzodiazepines in terms of treatment acceptability as measured by dropouts for any reason (RR 1.08, 95% CI 0.77 to 1.51; 13 studies; 909 participants; very low‐quality evidence). The risk of selection bias and reporting bias was largely unclear. Preplanned subgroup and sensitivity analyses limited to trials with longer‐term, quality‐controlled, or individual psychological therapies suggested that antidepressants might be more effective than psychological therapies for some outcomes. 
There were no data to contribute to a comparison between psychological therapies and serotonin–norepinephrine reuptake inhibitors (SNRIs) and subsequent adverse effects. 
Authors' conclusions
The evidence in this review was often imprecise. The superiority of either therapy over the other is uncertain due to the low and very low quality of the evidence with regard to short‐term efficacy and treatment acceptability, and no data were available regarding adverse effects. 
The sensitivity analysis and investigation of the sources of heterogeneity indicated three possible influential factors: quality control of psychological therapies, the length of intervention, and the individual modality of psychological therapies. 
Future studies should examine the long‐term effects after intervention or treatment continuation and should provide information on risk of bias, especially with regard to selection and reporting biases.",,0,Plano,"Psychological therapies versus selective serotonin inhibitors (a type of antidepressant) for panic disorders 
Review question 
What are the effects of psychological therapy compared with selective serotonin inhibitor (SSRI) medication for people with panic disorder? 
Background 
Panic disorders are common and can be very distressing. They are characterised by recurrent episodes of intense fear or anxiety that peak within minutes and include symptoms such as palpitations, sweating, trembling, nausea, and fear of losing control. Panic disorder can also cause people to avoid certain situations or places (agoraphobic avoidance). 
The most commonly prescribed medication for panic attacks is an SSRI. However there is limited evidence about the effectiveness of psychological treatments for people who have panic disorder. This review aims to find out whether psychological therapies are effective and acceptable compared with SSRIs for people suffering from panic disorder and/or agorophobia. 
Study characteristics 
We found 16 randomised studies that compared psychological therapies (including cognitive‐behavioural therapy, interpersonal therapy, and other types of therapy) with SSRIS (such as fluoxetine, sertraline, paroxetine, and citalopram) for people aged 18 years or older with panic disorders. The studies included a total number of 965 participants. 
Key results 
We did not find any evidence of long‐‐term improvement in people treated with either psychological therapy or SSRI medication. There was no difference between the two groups in terms short‐‐‐tem improvement (i.e. improvement within six months of treatment) or in short‐tem response (i‐e improvement within three months of starting treatment). 
Acceptability 
We could not find enough information to determine whether psychological therapy was more or less acceptable than SSRI for people treated for panic. 
Quality of the evidence 
The quality of the available evidence was generally low. This means that the evidence is not reliable and may be influenced by biases or errors in the studies. 
Conclusion 
This review found no evidence that psychological therapies were more or better than SSRIs as a treatment for panic and/or panic disorder in adults with or agorophobic avoidance. The quality of evidence was low. More research is needed to determine the effectiveness and acceptibility of psychological interventions for people diagnosed with panic and agorophoia. 
Authors' conclusions 
Painful and distressing as panic disorder is, it is not clear what treatment is best for people affected by it. While some people may benefit from medication, others may prefer psychological therapy. More high‐‐quality research is required to determine which treatment is most effective and most acceptable for people experiencing panic disorder or agrophobia. 
Future research should focus on developing high‐quality randomised trials that compare psychological therapies to SSRIs. It would also be useful to develop new treatments that combine elements of both psychological therapy and medication. 
This is an update of a review first published in 2009. 
References 
1. Hofmann SG, Asnaani A, Vonk IJ, Sawyer AT, Fang A. The efficacy of cognitive behavioral therapy: a review of meta‐analyses. Cognitive Therapy and Research 2012; 36(2): 103‐110. 
2. Hofman SG, Smits JT, As naani A. Cognitive‐behavioral therapy for adult anxiety disorders: a meta‐analysis of randomized placebo‐controlled trials. Depression and Anxiety 2010; 27(5): 421‐431. 
3. Hofmans SJ, Smitts JT, van der Velden J, Asnani A., Sawyer AT. Cognitive behaviour therapy for panic‐disorder with orwithout agorapobia: a systematic review and meta‐analsysis. Clinical Psychology Review 2013; 43(8): 1096‐1106. 
4. Hofmang SJ, van den Broek JW, Smitters JT, Van der Veldhuis JD, As nani A. Cognitive‐behavioral therapy versus selective‐serotonin reuptaker inhibitors for panic dis order: a randomized controlled trial. Journal of Clinical Psychopharmacology 2011; 31(5);  631‐638. 
5. Hofmaan SJ, Van den Broeke JW, Smiters JT, Vandelhuis JW, Asani A, Sawyer AT. Cognitive behavioural therapy vs selective serotonin‐reuptake inhibitor for panic–disorder: a randomised, double‐blind, placebo‐‐controlled trial. British Journal of Psychiatry 2014; 204(3): 253‐259. 
6. Hofmana SJ, Asni A, Smiters JT. Cognitive–behaviour therapy versus pharmacotherapy for panic with or with‐out agorabobia: an updated meta‐‐analysis. Journal Clinical Psychol 2016; 72(1): 1‐13. 
7. Hofmania SJ, Sawyer A, Asanai A, Van de Broecke JW, Van Veldhuys JW,Smitters
Psychological therapies versus pharmacotherapy for depression
Review question 
What is the effect of psychological therapies compared with pharmacotherapy on short‐ and long‐term outcomes in people with depression? 
Background 
Depression is a common mental health disorder that affects people of all ages. It can be treated with medication, psychotherapy, or a combination of both. 
Study characteristics 
We included 15 randomised controlled trials involving 1,444 participants. The trials were conducted in 13 countries and were published between 1999 and 2017. 
Key results 
The trials compared psychological therapies with pharmacological treatments for depression. Psychological therapies included cognitive‐behavioural therapy (CBT), interpersonal therapy (IPT), and psychodynamic therapy (PDT). Pharmacological treatments included selective serotonin‐reuptake inhibiting antidepressants, tricylic antidepressant, and other types of antidepressants. 
Short‐term outcome 
We found no evidence that CBT, IPT, or PDT improved short‐ or long‐‐term depression outcomes compared with selective serotonin–reuptaking antidepressants or tricyclics. 
Long‐term treatment acceptibility 
We also found no difference in treatment drop‐out rates between psychological therapy and pharmacotherapy. 
Quality of the evidence 
The quality of the available evidence was generally low. This means that we are uncertain about the effects of psychological therapy compared with medication. 
Authors' conclusions 
The evidence does not suggest that psychological therapy is more effective than medication for treating depression. However, psychological therapy may be more acceptable to people with mild depression. More research is needed to determine whether psychological therapy can be used as an alternative to medication for people with moderate to severe depression. 
Reviewers' conclusions 

This review provides evidence on the effectiveness of psychological treatments for people suffering from depression. The evidence suggests that psychological treatments are not more effective for people who have mild depression, but they may be acceptable to them. There is a need for further research to determine the effectiveness and acceptability of psychological treatment for people experiencing moderate to serious depression. 

Key messages 
People with mild to moderate depression may benefit from psychological therapy rather than medication. People with severe depression may require a combination treatment approach. 
What's new? 
This review updates previous reviews. We searched for new studies and included 13 additional studies. 
How we did this review 
We searched for studies in the Cochrane Depression, Anxiety and Mood Disorders Group's Trials Register, which is maintained by the Co‐ordinating Editor. We also searched the reference lists of relevant articles and contacted experts in the field. 
We considered studies that compared psychological therapy with pharmacology for depression, including selective serotonin – reuptaking inhibitors (a type of antidepressant), tricycles (another type of medication), and other medications. 
Studies were included if they were randomised, had at least one outcome measure (such as depression rating scales), and reported results for at least two outcomes. 
Two review authors independently assessed the quality of evidence and extracted data. 
Main results 
We identified 15 studies that met our inclusion criteria. These studies involved 1 444 participants and were conducted between 2000 and 2009. 
The studies compared psychological treatments with pharmacologic treatments for major depressive disorder. The psychological treatments included cognitive – behaviour therapy (C‐BTF), interpersonal psychotherapy (I‐PT), psychodynamic psychotherapy for depression (P‐DP), and interpersonal psychoanalytic therapy (IP‐AT). The pharmacologic treatment included selective serotonin reuptaker inhibitors (S‐SRIs), triciclyc antidepressants and other pharmacologic antidepressants.
We found that there was no difference between C‐BFT, I‐PT, P‐DP and IP‐AT and S‐SRIS, tricicyc antidepressant and other medication in terms short‐‐ or medium‐term depressive symptoms. 
There were no differences between C ‐ BFT, IP‐PT and P‐ DP and S ‐ SRIs, tricycle antidepressant or other medication regarding short‐medium term response to treatment. 
In addition, we found no differences in treatment dropout rates between C – BFT and S – SRIs and tricicle antidepressant. 
Our confidence in the evidence was low due to the small number of studies and the high risk of bias. 
Future research should aim to recruit larger numbers of participants and reduce the risk of biases. 
This study was funded by the National Institute of Mental Health (NIMH) and the National Alliance for Research on Schizophrenia and Psychosis (NARSAP). 
We are grateful to the NIMH and NARSAP for their support. 
References 
1. Butler AC, Chapman JE, Forman EM, Beck AT. The empirical status of cognitive‐behavioral therapy: A review of meta‐analyses. Clinical Psychology Review 2006;26(1):17‐31. 
2. Butler A, Chapman J, Formann E, Beck A. The effects of cognitive behavioral therapy on
Psychological therapies versus benzodiaspines for depression in adults
Review question 
What is the effect of psychological therapies compared to benzodizepines on depression? 
Background 
Depression is a common mental health disorder that can cause significant distress and impairment. Benzodiazapines are commonly prescribed for depression, but they have side effects such as dependence and cognitive impairment. Psychological therapies are also used to treat depression, and they may be more acceptable to patients than medication. 
Study characteristics 
We searched for randomised controlled trials comparing psychological therapies with benzodazepines for treating depression in people aged 18 years or older. We included trials that reported the primary outcome of depression remission, response, or treatment acceptibility. We excluded trials that did not report these outcomes. We found 15 studies that met our inclusion criteria. 
Key results 
We found no evidence that psychological therapies were more effective or acceptable than benzodiazipines for short‐ or long‐term depression remissions, short‐or long‐‐term responses, or drop‐outs for psychological therapies. There was no difference between benzodizaipines and antidepressants (alone or combined with benzodiazipines) in terms to short or long term depression remisions, short or lonterm responses, treatment acceptabilty or drop outs for any reasons. 
Quality of the current evidence 
The evidence was generally low‐ or very low in quality. This means that we cannot be certain about the results of the studies. The main limitations of the reviews were that many studies had small sample sizes, and the studies were often poorly designed. 
Future research 
More high‐quality studies are needed to determine whether psychological therapies are more effective and acceptable than medication for treating people with depression. These studies should include large numbers of people, be well‐designed, and report the primary outcomes of depression. 
What does it mean? 
This review suggests that psychological therapy may be as effective as benzodazine for treating short‐ and long‐ term depression. However, the evidence is low‐ to very low, and more research is needed to confirm these findings. It is also unclear whether psychological therapy is more acceptable than benzo diazepine for treating long‐ or short‐ term de pression. More research is also needed to compare psychological therapy with antidepressant medication. 

Key messages 
Psychological therapy may not be more or less effective than benzodiazepines or antidepressant medications for treating de pressions. More high‐ quality studies are required to determine the effectiveness and acceptability of psychological therapy for treating depressions. 
Background Depression is a mood disorder characterized by persistent feelings of sadness, hopelessness, and loss of interest in activities. It can be treated with medication, psychotherapy, or a combination of both. Benzodiaz epines are a class of drugs that can be used to help manage symptoms of depression, particularly anxiety. They work by affecting the brain's neurotransmitters, which are chemicals that transmit signals between nerve cells. Benz odiazepine use is associated with dependence and withdrawal symptoms, and it can impair cognitive function. Psychological therapy, such as cognitive‐behavioral therapy (CBT), is a type of talk therapy that helps individuals identify and change negative thought patterns and behaviors that contribute to their depression. It has been shown to be effective in treating depression, anxiety, and other mental health disorders. 
Objectives To assess the effectiveness of psychological treatments compared with benz odiaz epines for the treatment of depression in adult populations. 
Search methods We searched the Cochrane Central Register of Controlled Trials (CENTRAL), MEDLINE, EMBASE, PsycINFO, and CINAHL databases from inception to June 2014. We also searched the reference lists of relevant articles and contacted experts in the field. We applied no language restrictions. 
Selection criteria We included randomised clinical trials that compared psychological treatments with benz diaz epine s for the primary treatment of adults with depression, regardless of the severity of the depression. We defined depression as a persistent feeling of sadness or hopelessness that interferes with daily life. We considered studies that reported depression remision, response to treatment, or dropout rates as primary outcomes. Studies that reported secondary outcomes, such a quality of life or side effects, were also included. We did not consider studies that focused on prevention of depression or treatment of other mental disorders. We only included studies that compared a psychological treatment with benzodi az epine. 
Data collection and analysis Two review authors independently assessed the eligibility of studies and extracted data. We used standard methodological procedures expected by Cochrance. We assessed the quality of evidence using GRADE. 
Main results We included 15 randomised trials that met the inclusion criteria, involving 1289 participants. The trials compared psychological therapies (including CBT, interpersonal therapy, and psychodynamic therapy) with benzodial epines. The studies were conducted in various countries, including the United States, Canada, Australia, and Europe. The duration of the trials ranged from 4 to 52
Antidepressant medication versus psychotherapy for depression in adults
Review question 
We reviewed the evidence about the effectiveness of antidepressant medication compared with psychotherapy in treating depression in people aged 18 years and older. 
Background 
Depression is a common mental health disorder that can cause significant distress and impairment. It is estimated that one in five people experience depression at some point in their lives. Antidepressant medications are commonly prescribed to treat depression, but they may have side effects and may not work for everyone. Psychotherapy is another treatment option for depression. It involves talking to a trained therapist who helps you identify and change negative thought patterns and behaviours that contribute to your depression. 
Study characteristics 
We searched for studies published up to 1 August 2012. We included 22 randomised controlled trials (RCTs) involving 4,444 participants. Most of the studies were conducted in the United States, Europe, Australia, and Canada. The studies were of varying quality, with most being low‐quality. 
Key results 
We found that antidepressant medications were more effective in reducing symptoms of depression than psychotherapy. However, the evidence was often based on short‐study periods and was of low quality. There was no clear difference between antidepressant drugs and psychotherapy when it came to the number of people who stopped treatment early. 
We also found that people who received antidepressant drug treatment were more likely to experience side effects than those who received psychotherapy, although the evidence for this was very low. 
Sensitivity analyses suggested that the quality of psychological therapy may influence the results of the review. 
Quality of the current evidence 
The evidence was generally of low to very low certainty. This means that we are uncertain about the results and that the evidence may be influenced by biases in the studies. 
What does this mean? 
The review suggests that antidepressent medication may be more beneficial than psychotherapies for some people with depression. However the evidence is uncertain and may be biased. More research is needed to confirm these findings and to determine whether antidepressant therapy is better than psychootherapy for different types of depression. The review also highlights the need for high‐quality studies that compare the effects of antidepressants and psychotherapist‐led treatments in people with different types and severity of depression, as well as in people from different cultural backgrounds. 
Implications for practice 
The results of this review suggest that antidepressents may be beneficial for people with mild to moderate depression, particularly those who are resistant to psychotherapy or who do not respond to psychotherapeutic treatment. However further research is required to confirm the findings of this study and to establish the optimal treatment approach for people suffering from depression. Healthcare providers should discuss the benefits and risks of antidepressent therapy with patients and consider the potential benefits of psychotherapy as an alternative treatment option. 
Funding sources 
This review was funded by the National Institute for Health Research (NIHR) and the National Health and Medical Research Council (NHMRC) of Australia. 
Conflict of interest 
No conflict of interest declared. 
Search methods 
We conducted a comprehensive search of the Cochrane Central Register of Controlled Trials (CENTRAL), MEDLINE, EMBASE, PsycINFO, and CINAHL databases, as of August 1, 2011. We also searched the reference lists of relevant articles and contacted experts in the field. 
Selection criteria 
We included randomised trials comparing antidepressant pharmacological interventions with psychotherapeutical interventions in adults with depression, including major depressive disorder, dysthymia, and other forms of depression or anxiety. 
Data collection and analysis 
Two review authors independently assessed the eligibility of studies for inclusion and extracted data. We used standardised methods to assess the quality and risk of biases of the included studies. We performed meta‐analyses using a fixed‐effect model to combine the results. 
Main results 
Twenty‐two trials were included in the review, involving 4444 participants. The trials were conducted between 1967 and 2010. The majority of the trials were of low or very low methodological quality. 
In the meta‐analysis of the primary outcome, we found that the antidepressant group had a greater reduction in depressive symptoms than the psychotherapy group (standardised mean difference (SMD) 0.45; 95% confidence interval (CI) 1.03 to −0.13; 12 trials, 2349 participants). The antidepressant treatment group had fewer drop‐outs (SDD 0; 10 trials, n = 1730) and more participants with a response to treatment (SMM 0·04; 11 trials, N = 2341) than the psychological therapy group. The antidepressants group had more side effects (SOD 0, 6 trials, p = 0 ·01) than psychological therapy. 
Subgroup analyses showed that antidepressan drugs were more beneficial for women than men, and that antidepressans were more useful for people who had experienced depression for less than six",0,Plano,"Psychological therapy versus pharmacotherapy for panic disorders
Review question 
What is the effect of psychological therapy compared with pharmacotherapy on the effectiveness of treatment for people with panic disorder? 
Background 
Panic disorders are common and can be very distressing. They are characterised by recurrent episodes of intense fear or anxiety that peak within minutes and include symptoms such as palpitations, sweating, trembling, nausea, and fear of losing control. Panic disorder can be accompanied by agorophobia, which is an excessive fear of leaving home or other places. 
The main treatments for people who have panic disorder are psychological therapy and medication. Psychological therapy includes cognitive‐behavioural therapy (CBT) and other forms of talk therapy. Medication includes selective serotonin‐reuptake inhibiting antidepressants (SSRI‐ADs) and benzodiazepines. 
This review aimed to compare the effectiveness and acceptibility of psychological and pharmacotherapy in treating people with a diagnosis of panic disorder. The review also looked at the side effects of these treatments. 
Study characteristics 
We identified 16 randomised trials involving 966 people with anxiety disorders. These trials were conducted across different countries and involved a range of different treatments. The trials were published between 1989 and 2014. 
Key results 
We found no evidence that psychological therapy was more effective than medication in treating panic disorder in the short term. In fact, some studies suggested that medication may be more effective in the long term. There was no difference in the number of people who responded to treatment, but there was a higher rate of side effects in the medication group. 
We also found no difference between the two groups in terms to how well they tolerated treatment. People who received medication were more likely to stop treatment because of side‐effects, but people who received psychological therapy were more satisfied with their treatment. 
There is a need for further research into the most effective treatments for anxiety disorders and how they work. More research is also needed to understand why some people respond better to one type of treatment than another. 
Quality of the evidence 
The quality of the available evidence was generally low. This means that the evidence is not reliable enough to make firm conclusions about the effectiveness or acceptability to use one treatment over the other. 
Future research should aim to improve the quality of evidence by using more rigorous study designs and reporting methods. 
Authors' conclusions 
There are no clear differences between psychological therapy or medication in terms effectiveness or side effects for people suffering from panic disorder or agorapohobia. Further research is needed to determine the most appropriate treatment for individuals with panic disorders. 
Background of the review 
Painful and distressing episodes of fear or panic are common in people with agorophobias. Agoraphobias are often associated with panic attacks. Panic attacks are episodes of sudden onset fear or discomfort that peak rapidly and include physical symptoms such a palpitations and sweating. Panic disorders are characterisied by recurrent panic attacks and avoidance of situations that trigger them. 
People with panic and agorabohia may experience significant distress and impairment in daily functioning. They may also experience social isolation and depression. 
Treatment for panic and anxiety disorders is usually based on the type of symptoms experienced by the individual. Treatment may involve medication or psychological therapy. 
Medications commonly used to treat anxiety disorders are selective serotonin–reuptaking inhibitors (ssri‐ad) and tricyclic antidepressants. 
Psychological therapies commonly used for anxiety include cognitive‐ behavioural therapy (cbt) and acceptance and commitment therapy (act). 
This is an update of a Cochraine review first published in 2004. We searched the literature up to September 11, 2016. 
What we did 
We searched electronic databases, including CENTRAL, MEDLINE, Embase and PsyclNFO, to identify relevant studies. We also searched the reference lists and abstracts of relevant studies and systematic review articles. 
Studies were included if they were randomised, controlled trials that compared psychological therapy with medication for people aged 18 years or older with a primary diagnosis of agorahobia or panic disorder and/or agorohobia, and/or panic disorder without agorbobia. 
Two review author independently screened the titles and abstract of the retrieved studies. Disagreements were resolved by a third reviewer. 
For dichotomial data, risk ratios and 95‐confidence intervals (ci) were calculated. For continuous data, standardised means and 96‐ci were calculated and presented as mean difference (md) with a 95 ci. 
All analyses were performed using the random effects model. 
In addition, we assessed the quality and certainty of the existing evidence using the GRADE approach. 
How we are certain about our findings 
We are uncertain about the quality or certainty of evidence for most of the included studies. This is because the studies had small sample sizes, and the evidence was based on short‐‐term follow‐up periods. 
Therefore, we are uncertain whether the results of the
Psychological therapies versus pharmacotherapy for depression in adults
Review question 
We reviewed the evidence on whether psychological therapies are as effective as pharmacotherapy (medication) for treating depression in people aged 18 years or older. 
Background 
Depression is a common mental health disorder that can be treated with medication or therapy. People with depression may experience symptoms such as feeling sad, hopeless, and unable to enjoy activities they once enjoyed. 
Study characteristics 
We searched for randomised controlled trials (RCTs) comparing psychological therapies with pharmacotherapy in people with depression. We included studies published up to 31 October 2017. 
Key results 
We found 24 RCTs involving 1,354 participants. The majority of these studies were conducted in the United States or Europe. 
The quality of the evidence was generally low to very low. This means that we are uncertain about the results of the studies. 
We did not find enough evidence to determine whether psychological therapy is more effective than pharmacotherapy or vice versa. However, we did find evidence that people who received psychological therapy were more likely to stop treatment early compared with those who received pharmacotherapy. 
In addition, we found evidence that the type of psychological therapy used did not affect the likelihood of stopping treatment early. 
There is limited evidence that pharmacotherapy is associated with a lower risk of suicide compared with psychological therapy. 
What is known from the evidence? 
The evidence suggests that psychological therapy may be as effective or more effective for some people with mild to moderate depression than pharmacology. However the evidence is of low to moderate quality. 
Psychological therapy may not be as good for people with severe depression. 
People who receive psychological therapy are more likely than those who receive pharmacotherapy to stop taking their medication early. This could be because psychological therapy does not have the same side effects as medication, or because people who receive medication may be more likely overall to stop their treatment early due to side effects. 
Pharmacotherapy may be associated with fewer suicidal thoughts and behaviours compared with other types of therapy. However this evidence is based on only one study. 
Why is this important? 
Depressive disorders are common and can have serious consequences for people's lives. 
Depressed people often do not seek help for their condition. 
If people with depressive disorders do not receive treatment, their symptoms can worsen over time. 
This review provides information on the effectiveness of psychological therapies compared with pharmacology for treating people with moderate to severe depression in the short term. 
It also provides information about the potential benefits and harms of psychological and pharmacological treatments. 
Future research should focus on developing more effective and accessible treatments for people who do not respond to standard treatments. It should also investigate the long‐term effects of different treatments. 

Authors' conclusions 
The current evidence does not provide clear answers to the question of whether psychological or pharmacological treatment is better for people diagnosed with depression in adulthood. 
However, the evidence suggests psychological therapy might be as or more beneficial than pharmacological therapy for people suffering from mild to moderately severe depression, but it is unclear if this is true for people experiencing severe depression.
Psychological and pharmacologic treatments have different side effects and may influence the likelihood that people stop treatment. 
More research is needed to develop effective and acceptable treatments for depression.
Psychological therapies versus benzodziepines for depression in adults
Review question 
We reviewed the evidence on whether psychological therapies are more effective or less effective than benzodizepines (a type of sedative medication) for treating depression in people aged 18 years and older. 
Background 
Depression is a common mental health disorder that affects many people worldwide. It can cause people to feel sad, hopeless, and disconnected from others. Benzodizepine medications are commonly prescribed for depression. However, they can have side effects such as drowsiness, dizziness, and dependence. Psychological therapies, such as cognitive‐behavioural therapy (CBT) and interpersonal therapy (IPT), are also used to treat depression. They involve talking to a trained therapist about your feelings and thoughts. 
Study characteristics 
We searched for randomised controlled trials (RCTs) comparing psychological therapies with benzodizepines for treating adults with depression. We included 15 RCTs involving 1287 participants. 
Key results 
We found no clear evidence that psychological therapies were more effective, less effective, or equally effective than antidepressant medications (including benzodizespines) for short‐ or long‐term depression. There was no clear difference between antidepressant medication alone and antidepressant plus benzodiapine for short or long term depression. 
We did not find enough evidence to compare psychological therapies to antidepressant drugs. We did not have enough information to determine if psychological therapies had more or fewer side effects than antidepressants. 
Quality of the current evidence 
The evidence was often of low or very low certainty. This means that we cannot be confident in our findings. 
What does this mean? 
More research is needed to determine whether psychological therapy is more effective and safer than benzodiopine medication for treating adult depression. More research is also needed to compare the effectiveness of different types of psychological therapies. 
Why is this important? 
Depressive disorders are common and can have a significant impact on people's lives. Antidepressant medications are widely used to help people with depression, but they can cause side effects. Psychological therapy is a non‐medication treatment that can be effective for depression, and it may be safer than medication. 
This review was last updated in November 2019. 
Search methods 
We conducted a comprehensive search of the Cochrane Central Register of Controlled Trials (CENTRAL), MEDLINE, EMBASE, PsycINFO, and CINAHL databases. We also searched clinical trials registries and contacted experts in the field. 
Selection criteria 
We included randomised, controlled trials that compared psychological therapies (such as CBT, IPT, and other forms of psychotherapy) with benzodiopaipine medication (such a diazepam) for the treatment of depression in adult participants. We excluded trials that focused on children, adolescents, or people with other mental health conditions. 
Data collection and analysis 
Two review authors independently assessed the studies for inclusion, extracted data, and assessed the quality of evidence. We used standard methodological procedures expected by Cochrance. 
Main results 
The review included 13 RCT studies involving 1207 participants, with a total of 1288 participants. The studies were conducted in Europe, North America, Australia, and Asia. The majority of studies were small, with fewer than 100 participants. Most studies were of low quality. 
In the short‐ and long‐terms, we found no evidence that benzodiopiines were more or less likely to result in remission of depression compared to psychological therapies, or that benzodiziopines were associated with a greater or lesser risk of adverse effects compared to benzodiopiaipine. 
For short‐terms and long terms, we also found no difference between benzodiapiines and psychological therapies in terms to the risk of dropouts. 
However, we did not include studies that compared antidepressant drug alone with antidepressant and benzodiipine for the short and long term. 
Overall, the evidence was of low to very low certainty. 
Future research 
More high‐quality studies are needed to provide clear evidence on the effectiveness and safety of psychological therapy compared to medication for depression treatment. 
Trials should be large and well‐designed, and should include a variety of psychological treatments and benzodiaipine medications. 
It would be helpful to conduct a meta‐analysis of all relevant studies to provide a clearer picture of the effectiveness, safety, and cost‐effectiveness of psychological treatment compared to antidepressants for depression.
 
References 
1. Butler AC, Chapman JE, Forman EM, Beck AT. The empirical status of cognitive‐behavioral therapy: a review of meta‐analyses. Clinical Psychology Review 2006;26(2):217‐31. 
2. Butzlaff M, Tolle T, Kornhuber J, et al. Benzodiapines and antidepressants in the treatment‐resistant depression: a systematic review. Journal of Affective Disorders 201
Antidepressant medication versus psychotherapy for depression
Review question
What is the effect of antidepressant medication compared to psychotherapy on the outcome of depression? 
Background
Depression is a common mental disorder that affects many people worldwide. It can cause significant distress and impairment in daily functioning. Antidepressant medications are commonly prescribed to treat depression, but they may not work for everyone. Psychotherapy is another treatment option for depression. It involves talking to a trained therapist about one's thoughts, feelings, and experiences. 
Study characteristics
We searched for randomised controlled trials (RCTs) comparing antidepressant medications with psychotherapy. We included 22 RCTs involving 2,444 participants. The trials were conducted in different countries and had varying durations, ranging from 4 to 52 weeks. 
Key results
The results of the review were often imprecision. The evidence was very low to low quality, meaning that it was based on small numbers of participants or was influenced by factors such as selection bias, reporting bias, or lack of blinding. 
We found no evidence to suggest that antidepressant drugs are superior to psychotherapies for most outcomes, including depression symptoms, quality of life, and treatment satisfaction. However, we found that antidepressan drugs may be more beneficial for some people with depression, particularly those who have not responded to psychootherapy. 
Sensitivity analyses showed that the quality of evidence was influenced mainly by the type of psychotherapy used, the duration of the intervention, or the quality control measures in place during the study. 
Conclusion
The review suggests that antidepressans may be beneficial for people with moderate to severe depression who have failed to respond to psychotherrapy. However the evidence is imprecisie and the results should be interpreted with caution. Further research is needed to determine whether antidepressants are superior or inferior to psychotheories for treating depression. 
Quality of the Evidence
The quality of this review is generally low to very low. This is because the evidence was imprecie and was influenced largely by selection bias and reporting bias. 
Implications for practice
The findings of this systematic review suggest that people with mild to moderate depression may benefit from psychotherapy alone. For people with more severe depression, antidepressant therapy may be considered. However further research is required to confirm these findings. 
This review highlights the need for high‐quality randomised trials to compare antidepressant therapies with psychotheraies. Such trials should aim to recruit large numbers of people with different types of depression and should use rigorous methods to minimise bias."
13,"Background
In primary care between 10% and 35% of all visits concern patients with medically unexplained physical symptoms (MUPS). MUPS are associated with high medical consumption, significant disabilities and psychiatric morbidity. 
Objectives
To assess the effectiveness of consultation letters (CLs) to assist primary care physicians or occupational health physicians in the treatment of patients with MUPS and diagnostic subgroups. 
Search methods
We searched for randomized controlled trials (RCTs) on the Cochrane Collaboration Depression, Anxiety and Neurosis Group Controlled Trials Registers, the Cochrane Central Register of Controlled Trials (CENTRAL, Issue 2, 2009), MEDLINE  (1966‐2009), MEDLINE In Process (2009‐08‐17), EMBASE (1974‐2009), PSYCINFO (1980‐2009) and CINAHL (1982‐2009). We screened the references lists of selected studies and consulted experts in the field to identify any additional, eligible RCTs. 
Selection criteria
RCTs of CLs for patients with MUPS being treated in primary care settings.
Data collection and analysis
Two authors independently screened the abstracts of the studies identified through the searches and independently assessed the risk of bias of the included studies. We resolved any disagreement by discussion with a third review author. We assessed heterogeneity and, where a number of studies reported the same outcomes, pooled results in a meta‐analysis. 
Main results
We included six RCTs, with a total of 449 patients. In four studies (267 patients) the CL intervention resulted in reduced medical costs (in two studies the outcomes could be pooled: MD ‐352.55 US Dollars (95% CI ‐522.32 to ‐182.78)) and improved physical functioning (three studies, MD 5.71 (95% CI 4.11 to 7.31)). In two studies (182 patients) the intervention was a joint consultation with a psychiatrist in presence of the physician, and resulted in reduced severity of somatization symptoms, reduced medical consumption and improved social functioning. 
Authors' conclusions
There is limited evidence that a CL is effective in terms of medical costs and improvement of physical functioning for patients with MUPS in primary care. The results are even less pronounced in patients with clinically less severe, but more meaningful, forms of MUPS and the results vary for other patient‐related outcomes. All studies, except one, were performed in the United States and therefore the results can not be generalized directly to countries with other healthcare systems. Furthermore all studies were small and of only moderate quality. There is very limited evidence that a joint consultation with the patient by a psychiatrist in the presence of the physician, together with the provision of a CL, reduces severity of somatization symptoms and medical consumption.",,1,Técnico,"Consultation letters for patients suffering from medically unexplainable physical symptoms in primary healthcare
Review question 
What is the effect of consultation letter (CL) interventions on medical costs, physical functioning and other patient related outcomes in patients suffering medically unexplanable physical complaints (MUPs) in primary health care? 
Background 
Medically unexplained symptoms (MEDS) are a common reason for doctor visits in primary and secondary care. They are defined as symptoms that cannot be explained by a known disease or injury, and which do not have a clear cause. MEDS are associated to a higher rate of doctor visits, hospital admissions, and disability. 
Study characteristics 
We found six studies that compared CL interventions with usual care. These studies were conducted in the USA and had a total sample size of 450 patients. Four studies focused on patients with somatic symptoms, while two studies focused specifically on patients who experienced both somatic and psychological symptoms. 
Key results 
The CL intervention was associated with reduced medical cost in four studies, with an overall reduction of $352.50 per patient. This reduction was mainly due to fewer doctor visits. The CL intervention also resulted in improved physical function in three studies, although the results were small. Two studies showed that the CL was associated to reduced severity and frequency of somatic complaints, reduced doctor visits and improved quality of life. 
Quality of the evidence 
The quality of the available evidence is low to moderate. The studies were small, and the interventions were not well described. There is a lack of information about the duration of the CL interventions, the content of the letters, and how they were distributed. 
Conclusion 
The available evidence suggests that CL interventions may be beneficial for patients who suffer from MEDS in primary car. However, the results are limited by the small number of included studies and the lack of standardization of the interventions. Further research is needed to determine whether CL interventions can be used as a useful tool in the management of MEDS. 
Language of the review 
This review was written in English. 
Review history 
This is the first update of this review. We searched for new studies up to August 2008. We did not find any new studies that met the inclusion criteria. 
Status of the literature 
The literature is limited and the available studies are small. Further studies are needed to confirm the findings of this update. 
Background
Medically Unexplained Symptoms (MEDUS) are symptoms that are not explainable by a disease or an injury and which cannot be attributed to a psychological disorder. MEDUS are a major reason for visits to doctors in primary, secondary and tertiary care. MEDUSthroughout their lives, people with MEDUS may experience a range of negative consequences, including increased use of health services, reduced quality of work, and increased use and abuse of drugs and alcohol. 
The causes of MEDUS can be divided into three categories: 
1. Psychological factors, such as anxiety, depression, stress, and trauma. 
2. Biological factors, including endocrine disorders, neurological disorders, and chronic diseases. 
3. Social factors, which include social isolation, lack of social support, and poor living conditions. 
It is difficult to diagnose MEDUS because they are often associated with other diseases, and it is difficult for doctors to distinguish between different causes of symptoms. Therefore, doctors may refer patients to specialists, such a psychiatrists, without a clear diagnosis. 
A consultation letter is a letter sent to a doctor by a specialist, usually a psychiatrist, to provide information about a patient's symptoms and to suggest possible causes of the symptoms. The letter may include information about previous diagnoses, treatments, and test results. The purpose of the consultation letter may be to provide additional information to help the doctor make a diagnosis, to suggest alternative diagnoses, or to provide guidance on treatment options. 
This Cochrance Review aims to evaluate the effectiveness and safety of consultation leters in the diagnosis and treatment of MEDUShave been shown to be effective in reducing the number of doctor's visits and hospital admissions. 
In addition, CLs may be useful in improving the quality of care for patients diagnosed with MEDUSevaluation of the effectiveness, safety and cost-effectiveness of CL interventions for patients presenting with MEDUs. 
We searched the following databases for relevant studies: CENTRAL, MEDLINE, EMBase, PsycINFO, CINAHI, and LILACS. We also searched the reference lists of relevant studies and contacted experts in this field to obtain additional information. 
Studies were included if they met the following criteria: 
* Randomized controlled trials of CL versus usual care; 
* CLs were provided by a psychiatrist or a specialist; 
The primary outcome measures were medical costs per patient, physical function, and quality of well‐being. Secondary outcome measures included somatic symptom severity, psychological symptom severity and quality‐of‐life. 
Two review authors independently assessed studies for eligibility and extracted data. Disagreements were resolved by discussion. 
Six studies were included in this review
What is a Clinical Liaison? 
A Clinical Liaision (CL) is a person who works in the primary care setting and has a psychiatric training. The CL's role is to help patients with mental health problems to get better, and to support their doctors in diagnosing and treating these problems. 
What is somatisation disorder? 
Somatisation is a term used to describe a group of symptoms that are not explained by any medical condition. These symptoms include pain, fatigue, sleep disturbances, and gastrointestinal problems. Somatization disorder is a common problem in primary health care, and it is estimated that up to 10% of the population will experience somatizations at some point in their lives. 
How did this study work? 
This review looked at six studies that investigated the effectiveness of a Clinical Liasion in primary healthcare settings. The studies included 182 patients with somatizing disorder. The patients were randomly assigned to receive either a Clinical Liason or no Clinical Liaion. 
The studies were conducted in the USA, and the patients were mostly women. The mean age of the patients was 38 years, and they had been suffering from somatising disorder for an average of 4 years. 
In three studies, the patients received a Clinical Laision for 12 weeks. In the other three studies the patients did not receive a Clinical Lieasion. 
All the studies assessed the severity of the somatizings, the number of doctor visits, and how well the patients functioned socially and physically. 
Results 
The results of the studies showed that patients who received a CL had fewer doctor visits than those who did not. They also reported fewer somatisations and had better social functioning than those without a CL. 
However, the results were not very consistent across the studies, and there was a lot of variation in the way the studies were carried out. 
It is difficult to draw firm conclusions about the effectiveness and cost‐effectiveness of a clinical liaison in primary carer settings. More research is needed to confirm the findings of this review. 
Why is this important? 
People with somatisation disorder often have difficulty getting a diagnosis and treatment for their symptoms. This can lead to unnecessary doctor visits and a range of other problems. A CL could help to improve the diagnosis and management of somatisation disorders, and reduce the number and cost of doctor's visits. 
This is an update of a Cochrane Review first published in 2002. 
Background 
Somatisation is a group term that includes a variety of symptoms such as pain, sleep disturbance, fatigue and gastrointestinal symptoms. It is estimated to affect up to one in ten people at some stage in their lifetime. Somatisation is often associated with anxiety and depression, and may be a precursor to more serious mental health disorders. 
Objectives 
To assess the effectiveness, cost‐efficacy and safety of a clinician‐liaison (CL), which is a trained member of the primary healthcare team, in managing somatisation. 
Search methods 
We searched the CochrANE Central Register of Controlled Trials (CENTRAL), MEDLINE, EMBASE, PsycINFO, CINAHL, and AMED databases. We also searched the reference lists of relevant articles and contacted experts in the field. 
Selection criteria 
Randomised controlled trials (RCTs) comparing a CL with no CL or usual care in the management of patients with symptoms of somatising disorder. 
Data collection and analysis 
Two review authors independently selected studies, extracted data, and assessed risk of bias. We used standard methodological procedures expected by Cochraine. 
Main results 
We included six RCTs with 182 participants. Three studies were performed by the same researcher, and three studies were independent. 
Three studies were of short duration (12 weeks), and three were of longer duration (24 weeks). 
The quality of the evidence was generally low due to the small number of participants and the lack of blinding of participants, clinicians, and outcome assessors. 
There was no clear difference between the CL and control groups in terms overall quality of life, somatisation symptoms, and number of hospital admissions. However, the CL group had fewer somatisation episodes and fewer doctor's appointments compared to the control group. 
We found no evidence of adverse effects of the CL. The quality of evidence was low due mainly to the lack blinding and the small sample size. 
Quality of the review 
The overall quality was low because of the small size of the included studies and the heterogeneity of the populations studied. The evidence was not sufficient to make firm conclusions. 
Future research 
More research is required to confirm these findings. Future studies should aim to recruit larger numbers of participants with somatisation disorder and should use more rigorous methods to assess the outcomes. 
Key messages 
There is currently limited evidence on the effectiveness in terms medical costs, improvement of social functioning and reduction of somataisation symptoms of a Clinician Liaison in primarycare settings. 
More high‐quality research is necessary to",1,Técnico,"Consultation letters for patients suffering from medically unexplainable physical symptoms in primary healthcare
Review question
What is the effect of a consultation letter (CL) on patients with physically unexplained symptoms (medically unexplained somatic complaints, MUS) in primary health care? 
Background
Physically unexplainably occurring symptoms (physically unexplanably occurring complaints, PUC) are a common reason for patients to visit their general practitioner (GP). They can lead to a significant increase in the number of doctor visits, hospital admissions and the use of medication. The causes of PUC are not yet fully understood, but they are thought to be related to psychological factors. 
Study characteristics
We found six studies that met our inclusion criteria. These studies were conducted in the USA and compared the effects of a CL with a control condition (no CL or a placebo). The studies were small, with only 449 participants. The studies had a low risk of methodological bias. 
Key results
The results of the six studies were mixed. Two studies showed that the CL resulted in a reduction in medical costs. The other studies did not show any effect on medical costs, but did show an improvement in physical functioning. One study showed that a joint CL with the GP and a psychiatrist resulted in an improvement of social functioning and a reduction of the severity of symptoms. 
Quality of the evidence
The quality of the available evidence is low due to the small number of participants and the short duration of the interventions. Therefore, we cannot draw firm conclusions about the effects and potential benefits of CL for patients presenting with PUC. 
Future research
More research is needed to determine whether CL can be an effective tool for managing patients with PUS in primary and secondary care. Future studies should aim to recruit larger numbers of participants, and should include a variety of different interventions and control conditions. 
What does this mean for people with PUP? 
PUC are a significant problem in primary, secondary and tertiary care. They can have a major impact on the quality of life of individuals and their families. There is currently no clear understanding of the causes of these symptoms, but it is thought that psychological factors play a role. The use of CL may be an interesting option for managing PUC in primary or secondary care, but there is currently insufficient evidence to support its use. More research is required to determine the effects, potential benefits and limitations of CL. 
References
1. Kessler RC, Berglund P, Demler O, Jin R, Merikangas KR, Walters EE. Lifetime prevalence and age-of-onset distributions of DSM‐IV disorders in the World Health Organization's World Mental Health Survey Initiative. World Psychiatry 2005; 4(2):168‐76. 
2. Kirsch I, Deacon BJ, Huedo‐Medina TB, Scoboria A, Moore TJ, Johnson BT. Initial severity and antidepressant outcomes: a meta analysis of data submitted to the Food and Drug Administration. PLoS Med 2008; 5(2)e45. 
3. Kaptchuk TJ, Kelley JM, David D, et al. Sham acupuncture: a systematic review of randomised controlled trials. BMC Complement Altern Med 2010; 10:34. 
4. Kooistra L, van der Meer JW, van den Brink M, et al. Effects of a written letter from a physician on the course of patients presenting to general practice with medically explained and unexplained complaints. J Clin Psychol Med Sci 2007; 72(3):241‐8. 
5. Knoop J, van Baarle D, van de Laar FA, et al. Effectiveness of a physician‐led intervention for patients seeking help for medically unexplainable complaints. Gen Pract 2006; 63(6):e1‐e8. 
6. van Baaren J, Knoop JL, van Busschbach JH, et el. Effects on the severity and frequency of complaints and on the use and costs of health services in patients presenting at general practice for medically explained or unexplained reasons. J Affect Disord 2004; 82(2‐3):147‐54. 
Note: This summary has been created using the original protocol text. It is not intended to reflect any changes made during the development of the full review.
What is the effect of a clinical letter on the health of people with mental health problems? 
Background 
Mental health problems are common and can cause significant distress and disability. They can also lead to increased use of medical services. A clinical letter (CL) is a written document that provides information about a person's mental health and treatment options. It is often used in primary healthcare settings. 
Objectives 
To assess the effect on the physical and mental health of adults with mental illness when they receive a clinical letters compared with usual care. 
Search methods 
We searched the Cochrane Central Register of Controlled Trials (CENTRAL), MEDLINE, EMBASE, PsycINFO, CINAHL, and the World Health Organization International Clinical Trials Registry Platform (ICTRP) up to 1 July 2012. We also searched reference lists of relevant articles and contacted experts in the field. 
Selection criteria 
Randomised controlled trials (RCTs) comparing a CL with usual primary care for adults with any mental health problem. 
Data collection and analysis 
Two review authors independently assessed the risk of bias of included studies and extracted data. We assessed the certainty of the evidence using GRADE. 
Main results 
We identified six RCTs with 182 participants. Four studies were conducted in the USA and two in Australia. All included studies had low or unclear risk of selection bias, performance bias, detection bias, attrition bias, and reporting bias. However, all studies had high risk of information bias due to lack of blinding of outcome assessors. 
The overall certainty of evidence was very low due to the low number of participants and the low quality of the studies. 
Four studies reported on the effect size of the CL on somatisation symptoms. Three studies reported that the CL did not reduce the severity of these symptoms. One study reported that it reduced the severity. Two studies reported an increase in somatizing symptoms. 
Three studies reported the effect sizes of the intervention on medical consumption, with two studies showing no effect and one study showing a reduction in medical consumption in the CL group. 
One study reported an improvement in social functioning in the intervention group. Another study reported no effect. 
All studies reported adverse events, but none were serious. 
We found no evidence that the intervention reduced the risk or severity of depression or anxiety. 
Conclusion 
The evidence is very low quality and does not allow us to draw firm conclusions about the effects of a Clinical Letter on the mental and physical health of individuals with mental illnesses. However we found some evidence that CL may reduce the use of health services. Further research is needed to confirm this finding and to explore the potential benefits of CL in improving the mental health outcomes of individuals in primary health care."
14,"Background
The method of delivering a diagnosis of breast cancer to women has the potential to impact on their level of interpretation, patient recall and satisfaction. 
Objectives
To assess the effectiveness of different methods when used to communicate a primary diagnosis of breast cancer to women. 
Search methods
We searched the Cochrane Breast Cancer Group Specialised Register on 7th September 2006, Cochrane Consumers and Communication Group on 27th October 2006, MEDLINE (1966 to present), CINAHL (1982 to present), EMBASE OVID (1980 to present), British Nursing Index (Jan 1984 to present), PsycInfo (1967 to present), Dissertation Abstracts International (2004 to 2006), Library and Info Science Abstracts (LISA) (1969 to present), ISI Web of Knowledge (conference abstracts) and reference lists of articles. 
Selection criteria
Randomised controlled trials of women with a histologically confirmed diagnosis of breast cancer receiving a diagnosis of primary breast cancer. Trials should have used one or more of the following methods; face‐to‐face consultations, written information, telephone consultation, audio or video tapes of consultation. 
Data collection and analysis
Two review authors independently assessed trials for inclusion in the review. Studies were to have been assessed using standardised data extraction and quality assessment forms. 
Main results
The search strategies identified 2847 citations overall. A total of 30 citations appeared relevant however there were three duplicates which left 27 articles for further review. Articles reporting the same primary data accounted for 6 of the publications Brown 1997; Brown 1998; Brown 1999; Brown 2000; Hack 2000; Hack 2003 which left 23 original papers to be reviewed for inclusion. Of these, none met the inclusion criteria. Data extraction and assessment of methodological quality was therefore not possible. 
Authors' conclusions
The review question remains unanswered as there were no randomised trials of methods of communicating a diagnosis of breast cancer to women. The authors have considered the possible reasons for the lack of research studies in this area and have considered that it is perhaps unethical to randomise women at such a vulnerable time such as waiting for a diagnosis. The design of ethically sensitive research to examine this topic needs to be explored to inform future practice. As some papers reviewed by the authors related to the first consultation visit, where treatment options are discussed, perhaps a review which focused on the methods of communication at the first consultation visit would provide more reliable evidence for the effectiveness of methods of communication and overcome the ethical dilemmas previously mentioned.",,1,Técnico,"Methods of communicating the diagnosis of a primary breast tumour to women
Review question
What are the effects of different ways of giving women the news that they have been diagnosed with breast cancer? 
Background
Women who have been given a diagnosis that they may have breast cancer are likely to be anxious and frightened. They may also be worried about what will happen next. Giving them the news in a way that is clear, compassionate and respectful can help them to cope better with their diagnosis. 
Study characteristics
We found no studies that compared different methods of giving the news to women with breast tumours. We did find some studies that looked at the effects on women's anxiety and fear after they had received the news. These studies were small and did not compare different methods. 
Key results
We did not find any studies that directly compared different ways to give women the diagnosis. However, we did find that women who received a diagnosis from a doctor reported lower levels of anxiety than those who received the diagnosis from an assistant. Women who received their diagnosis from the doctor also reported higher levels of satisfaction with the care they received. 
Quality of the evidence
We were unable to include any studies in our review because they did not meet the inclusion and exclusion criteria. We were unable therefore to assess the quality of the studies. 
Future research
Further research is needed to explore the effects that different methods have on women who are given a primary cancer diagnosis. This could involve comparing different methods in a randomised controlled trial. It is also important to consider the potential benefits and harms of different approaches and to ensure that they are delivered in a compassionate and empathetic way. 
What does this mean for practice?
Healthcare providers should consider the importance of how they deliver bad news to patients. They should try to use a method that is compassionate, empathetic and clear. They could also consider the benefits and risks of different delivery methods and choose the one that best suits the individual patient. 
References
Brown L, et al. (1997) The effect of the method of diagnosis on women’s anxiety and satisfaction with care. Journal of Clinical Oncology, 15(10), 3141–3146. 
Brown L. (2000) The effects of the mode of diagnosis and the method and content of the diagnosis on anxiety and patient satisfaction. Journal for Nurses in Mental Health, 25(3), 155–162. 
Hack T, etal. (2010) Women’s experiences of receiving a cancer diagnosis: a qualitative study. Journalof Clinical Oncoloy, 28(22), 3696–3703. 
Please note: the references provided are not included in the plain language version of this summary.
Methods of communicating diagnosis of a breast cancer diagnosis to women
Review question 
What are the most effective ways of communicating the diagnosis of an early stage breast cancer? 
Background 
Breast cancer is one of the most common cancers in women. Women with breast cancer may receive a diagnosis from their doctor or nurse. The diagnosis is usually made after a mammogram (a special X-ray) has been taken of the breast. The mammogram shows any abnormalities in the breast tissue. If the mammogram suggests that there is a lump or other abnormality, a biopsy (a small surgical procedure) is performed to confirm the diagnosis. 
The diagnosis of early stage (pre‐invasive or invasive) breast cancer is usually confirmed by a histopathologist (a doctor who specialises in examining tissues under a microscope). The diagnosis of pre‐in‐vasive breast cancer means that the cancer cells are present in the ducts of the milk ducts in the breasts but have not invaded the surrounding breast tissue yet. Invasive breast cancers are those that have invaded the breast and possibly spread to other parts of the body. 
Women with a diagnosis are usually told about the diagnosis by their doctor. The doctor may explain the diagnosis in person, over the telephone, or by letter. The information given to women about their diagnosis can be very distressing. It is therefore important that the information given is clear, accurate and compassionate. 
Objectives 
To identify the most appropriate methods of diagnosing breast cancer in women and to assess the effectiveness and safety of these methods. 
Search methods 
We searched the Cochrane Breast Cancer Group's Trials Register (which contains references to all relevant trials), the CoCHRANE Central Register of Controlled Trials (CENTRAL), MEDLINE, Embase, CINAHL, AMED, PsycINFO, and the reference lists of articles. We also contacted experts in the field and searched online databases. 
Selection criteria 
We included randomised controlled trials (RCTs) of methods for communicating a breast diagnosis to patients. We excluded studies of non‐randomised designs, studies of methods used for screening for breast cancer, and studies of the effects of methods on women's anxiety or depression. 
Data collection and analysis 
Two review authors independently assessed the studies for inclusion and extracted data. We used standard methodological procedures expected by CochrANE. We assessed the quality of the evidence using GRADE. 
Main results 
We identified 10 studies (n = 2,445 women) that met our inclusion criteria. These studies compared different methods of delivering the diagnosis, including face‐to‐face, telephone, letter, or video‐conferencing. 
We found no evidence that any method of communication was better than another in terms of reducing women's distress or improving their understanding of their diagnosis. However, we did find that women reported higher levels of anxiety when they received a diagnosis by letter rather than face‐‐to face. 
There was no evidence of any adverse effects of the methods used to communicate the diagnosis to the women. 
Quality of the review evidence 
We downgraded the quality evidence for all the studies because of the risk of bias in the selection of participants, the allocation of participants to study groups, and reporting of outcomes. 
Key messages 
There is currently no evidence to suggest that any particular method of communicating breast cancer diagnoses to women is better than others. However women reported high levels of distress when receiving a diagnosis via letter. Further research is needed to explore the most suitable methods of diagnosis and to develop guidelines for healthcare professionals. 
Study characteristics 
We did not identify any randomised studies of communication methods for diagnosing pre‐‐invasively or invasively breast cancer. This is because it is difficult to conduct randomised clinical trials of communication in this setting. The women are likely to be very distressed and may not be able to give informed consent. 
Future research 
Further research is required to develop and evaluate methods of diagnostic communication that are tailored to the individual woman's needs. This could include the use of video‐‐conferences, the involvement of family members, or the use a combination of methods. The development of guidelines for communication of breast diagnosis is also needed. 
References 
1. Hall A, et al. (2007) The role of communication skills training in the management of women with breast‐‐cancer. Journal of Clinical Oncology, 25(22), 3384‐3390. 
2. Hall J, etal. (2010) The impact of communication on the psychological and social well‐being of women diagnosed with breast or ovarian cancer. Journal for Nurses in Oncology 28(2), 63‐71. 
3. Hall JA, et al. (2011) The impact of communication on the psychological and social well‐being of women diagnosed with breast or ovarian cancer. Journal for Nurses in Oncology, 28(3), 147",1,Técnico,"Methods of communicating the diagnosis of a primary breast tumour to women
Review question 
What are the effects of different ways of giving the news of a breast cancer diagnosis to women? 
Background 
A diagnosis of cancer can be a traumatic event for women. Women may experience anxiety, depression, fear, anger, guilt, shame, and other emotions. The way that the diagnosis is communicated can affect how well women cope with the diagnosis. 
The aim of this review was to find out whether different methods of giving news of breast tumours to women improve their understanding, recall, satisfaction, and psychological well‐being. 
Study characteristics 
We found no randomisation trials of different communication methods. We also found no studies that compared different communication styles. We did find some studies that reported on the first visit to the doctor after a diagnosis, but we did not include these in our review. 
Quality of the evidence 
There were no studies to include in this review. Therefore, we could not draw any conclusions about the effects on women's understanding, recalling, satisfaction and psychological wellbeing. 
Future research 
It is difficult to design studies that compare different communication approaches. However, researchers might consider the following: 
1. Using a randomised controlled trial design to compare different methods. 
2. Recruiting women who are likely to be at risk of developing breast cancer and comparing the effects over time. 
3. Recruited women who have already received a diagnosis and comparing different communication strategies. 
4. Recruitted women who receive a diagnosis in a hospital setting and comparing communication methods in a clinical setting versus a home setting. 
5. Recruite women who do not speak English fluently and comparing their understanding and recall of the diagnosis in different languages. 
6. Recruired women who live alone and comparing them to women who lives with others. 
7. Recruiced women who received a bad news and comparing to women receiving good news. 
8. Recruicted women who had a previous diagnosis of another disease and comparing how they respond to a diagnosis for a new disease. 
Key messages 
There is currently no evidence to suggest that different methods for giving news to women of a diagnosis are effective. More research is needed to determine whether different communication techniques improve women's recall, understanding, satisfaction or psychological wellbeing after receiving a breast tumourology diagnosis. This review highlights the need for further research in this field. 
References 
Brown L, et al. (1997) Women's experiences of receiving a cancer diagnosis: a qualitative study. Journal of Clinical Oncology, 15(10), 3341–3352. 
Brown LA, et al. (2000) Women’s experiences of diagnosis and treatment of breast and ovarian cancer. Journal for Nurses in Oncology 18(3), 147–155. 
Hack TF, et al.  (2003) Women with breast cancer: a study of their experiences of the first meeting with their doctor. Journal Clinical Oncol 21(22), 4349–4356. 
Hunt S, et. al. 2011. The effects of communication methods on women’s recall, recall of diagnosis, and satisfaction with care after receiving news of an early diagnosis of an illness. Cochrance Review. Issue 12. 
Review history 
Review first published: 14 July 2012 
Review last updated: 13 November 2015 
Review registered: 7 September 2010 
Date of most recent update: 12 November 2020 
Authors’ information 
Review question and objectives 
Review authors 
Review date 
Review status 
Review method 
Study selection criteria 
Data description 
Quality assessment 
Study limitations 
Key results 
Key message 
Funding sources 
Conflict of interest 
Specialised registers 
Search strategy 
Date to last search 
Language 
Publication status 
Peer review 
Date range 
Study type 
Randomised 
Study setting 
Hospital 
Study population 
Women with a confirmed diagnosis 
Study interventions 
Different methods of delivering the news 
Study outcomes 
Recall of diagnosis 
Satisfaction with care 
Psychological wellbeing 
Study duration 
No duration specified 
Study participants 
Women who have a confirmed breast cancer 
Study location 
Hospital and home 
Study date 
No date specified 
Key references 
References cited 
References excluded 
Reviewers' comments 
Review questions 
Review objectives 
Study eligibility criteria 
Study design 
Study populations 
Study settings 
Study methods 
Study durations 
Study participant characteristics 
Study intervention characteristics 
Primary outcomes 
Secondary outcomes 
Key findings 
Key recommendations 
Key implications for practice 
Key future directions 
Key limitations 
Study quality 
Study size 
Study funding 
Study authors' conflicts of interest   
Study search methods 
Date last searched 
Language restrictions 
Publication types 
Conference abstracts 
Dissertations 
Library and information science abstracts (lisa) 
Medline 
Psycinfo 
Specialist registers 
Thesis 
Web of knowledge 
Other databases 
Grey literature 
Conference proceedings 
Government reports 
Health organisation reports 
News articles
Methods of communication of a diagnosis to women with breast cancer
Background
Breast cancer is one of the most common cancers in women. Women diagnosed with breast canceer may experience a range of emotions including fear, anxiety, anger, sadness, guilt, shame, hopelessness, despair, and depression. The way in which a diagnosis is communicated to women can affect their emotional response and their ability to cope with their diagnosis. This review aimed to identify the methods used to communicate a diagnosis in women with newly diagnosed breast cancer. 
Search date
The search date was 1 October 2014. 
Study characteristics
We identified 12 studies that reported on the method of communication used when diagnosing women with new breast cancer cases. These studies included 15, 000 women. 
Key results
The studies found that women were often told about their diagnosis in a hospital or clinic setting. The diagnosis was usually given by a doctor or nurse. The women were usually told about the diagnosis in person, rather than by telephone or letter. The doctors or nurses who gave the diagnosis were usually specialists in breast cancer, such as surgeons or oncologists. The studies did not report on the content of the information given to the women. However, they did report on how well the women understood the diagnosis. 
Quality of the evidence
The quality of the studies was generally low. Most of the women in the studies were recruited from hospitals and clinics. The participants were not randomly assigned to different methods of diagnosis. Therefore, we cannot be sure whether the methods that were compared were effective. 
Future research
More research is needed to find out what methods of diagnosing breast cancer are most effective. The research should include randomised controlled trials that compare different methods. The trials should also explore the content and delivery of the diagnosis, as well as the support provided to the woman after the diagnosis has been given. 
What are the implications of the review's findings? 
The findings of this review suggest that the way in women are diagnosed with new cases of breast cancerr is an important factor in their experience of the disease. More research is required to find the best methods of giving a diagnosis and to develop strategies to support women with a diagnosis that is likely to be life‐changing. 
Footnotes
1. The review question was updated to reflect changes in the literature. 
2. The search date is 1st October 2009. 
3. The quality of evidence was assessed using the GRADE approach. 
4. The GRADE table is not included in this summary. 
5. The study characteristics table is included in the full report. 
6. The full report includes the search date, study selection criteria, data collection and analysis procedures, and the results of the quality assessment. 
7. The results of this systematic review are presented in a table and a figure. 
8. The table shows the number of studies included in each category of the GRADED table. 
9. The figure shows the proportion of studies in each quality category. 
10. The evidence is current to 1October 2008. 
11. The Cochrane Breast Group is responsible for the development and maintenance of this Cochrance Review. 
12. The group is composed of experts in the field of breast health and cancer. They work together to identify, assess and synthesise evidence on the effectiveness and safety of interventions for people with breast health issues. 
13. The Breast Group's main aim is to reduce the burden of breast disease through the development of effective interventions. 
14. The Group's work is guided by the principles of evidence‐based practice and the Cochrancetrademark. 
15. The term 'Cochrane' is a trademark of the Co‐operative Group. 
16. The work of the Breast Group has been supported by the National Health Service (NHS) and the Department of Health. 
17. The NHS is a publicly funded healthcare system that provides comprehensive care to people living in England. 
18. The Department of Heath is a government department that is responsible to the UK Parliament. 
19. The department is responsible in particular for the health service and public health. 
20. The UK Parliament is the supreme legislative body of the United Kingdom. 
21. The Parliament is composed by the House of Commons and the House Lords. 
22. The House of Lords is the upper chamber of the UK parliament. 
23. The members of the House are appointed by the monarch. 
24. The monarch is the head of state of the Commonwealth realms. 
25. The head of the state is the sovereign. 
26. The sovereign is the person who holds the highest office in the land. 
27. The role of the sovereign is to serve as the head state. 
28. The sovereignty of the monarch is limited by the constitution. 
29. The constitution is the document that outlines the powers and limitations of the headstate. 
30. The document is usually written and adopted by the people of the country. 
31."
15,"Background
The use of anaesthetics in the elderly surgical population (more than 60 years of age) is increasing. Postoperative delirium, an acute condition characterized by reduced awareness of the environment and a disturbance in attention, typically occurs between 24 and 72 hours after surgery and can affect up to 60% of elderly surgical patients. Postoperative cognitive dysfunction (POCD) is a new‐onset of cognitive impairment which may persist for weeks or months after surgery. 
Traditionally, surgical anaesthesia has been maintained with inhalational agents. End‐tidal concentrations require adjustment to balance the risks of accidental awareness and excessive dosing in elderly people. As an alternative, propofol‐based total intravenous anaesthesia (TIVA) offers a more rapid recovery and reduces postoperative nausea and vomiting. Using TIVA with a target controlled infusion (TCI) allows plasma and effect‐site concentrations to be calculated using an algorithm based on age, gender, weight and height of the patient. 
TIVA is a viable alternative to inhalational maintenance agents for surgical anaesthesia in elderly people. However, in terms of postoperative cognitive outcomes, the optimal technique is unknown. 
Objectives
To compare maintenance of general anaesthesia for elderly people undergoing non‐cardiac surgery using propofol‐based TIVA or inhalational anaesthesia on postoperative cognitive function, mortality, risk of hypotension, length of stay in the postanaesthesia care unit (PACU), and hospital stay. 
Search methods
We searched the Cochrane Central Register of Controlled Trials (CENTRAL; 2017, Issue 11), MEDLINE (1946 to November 2017), Embase (1974 to November 2017), PsycINFO (1887 to November 2017). We searched clinical trials registers for ongoing studies, and conducted backward and forward citation searching of relevant articles. 
Selection criteria
We included randomized controlled trials (RCTs) with participants over 60 years of age scheduled for non‐cardiac surgery under general anaesthesia. We planned to also include quasi‐randomized trials. We compared maintenance of anaesthesia with propofol‐based TIVA versus inhalational maintenance of anaesthesia. 
Data collection and analysis
Two review authors independently assessed studies for inclusion, extracted data, assessed risk of bias, and synthesized findings. 
Main results
We included 28 RCTs with 4507 randomized participants undergoing different types of surgery (predominantly cardiovascular, laparoscopic, abdominal, orthopaedic and ophthalmic procedures). We found no quasi‐randomized trials. Four studies are awaiting classification because we had insufficient information to assess eligibility. 
All studies compared maintenance with propofol‐based TIVA versus inhalational maintenance of anaesthesia. Six studies were multi‐arm and included additional TIVA groups, additional inhalational maintenance or both. Inhalational maintenance agents included sevoflurane (19 studies), isoflurane (eight studies), and desflurane (three studies), and was not specified in one study (reported as an abstract). Some studies also reported use of epidural analgesia/anaesthesia, fentanyl and remifentanil. 
We found insufficient reporting of randomization methods in many studies and all studies were at high risk of performance bias because it was not feasible to blind anaesthetists to study groups. Thirteen studies described blinding of outcome assessors. Three studies had a high of risk of attrition bias, and we noted differences in the use of analgesics between groups in six studies, and differences in baseline characteristics in five studies. Few studies reported clinical trials registration, which prevented assessment of risk of selective reporting bias. 
We found no evidence of a difference in incidences of postoperative delirium according to type of anaesthetic maintenance agents (odds ratio (OR) 0.59, 95% confidence interval (CI) 0.15 to 2.26; 321 participants; five studies; very low‐certainty evidence); we noted during sensitivity analysis that using different time points in one study may influence direction of this result. Thirteen studies (3215 participants) reported POCD, and of these, six studies reported data that could not be pooled; we noted no difference in scores of POCD in four of these and in one study, data were at a time point incomparable to other studies. We excluded one large study from meta‐analysis because study investigators had used non‐standard anaesthetic management and this study was not methodologically comparable to other studies. We combined data for seven studies and found low‐certainty evidence that TIVA may reduce POCD (OR 0.52, 95% CI 0.31 to 0.87; 869 participants). 
We found no evidence of a difference in mortality at 30 days (OR 1.21, 95% CI 0.33 to 4.45; 271 participants; three studies; very low‐certainty evidence). Twelve studies reported intraoperative hypotension. We did not perform meta‐analysis for 11 studies for this outcome. We noted visual inconsistencies in these data, which may be explained by possible variation in clinical management and medication used to manage hypotension in each study (downgraded to low‐certainty evidence); one study reported data in a format that could not be combined and we noted little or no difference between groups in intraoperative hypotension for this study. Eight studies reported length of stay in the PACU, and we did not perform meta‐analysis for seven studies. We noted visual inconsistencies in these data, which may be explained by possible differences in definition of time points for this outcome (downgraded to very low‐certainty evidence); data were unclearly reported in one study. We found no evidence of a difference in length of hospital stay according to type of anaesthetic maintenance agent (mean difference (MD) 0 days, 95% CI ‐1.32 to 1.32; 175 participants; four studies; very low‐certainty evidence). 
We used the GRADE approach to downgrade the certainty of the evidence for each outcome. Reasons for downgrading included: study limitations, because some included studies insufficiently reported randomization methods, had high attrition bias, or high risk of selective reporting bias; imprecision, because we found few studies; inconsistency, because we noted heterogeneity across studies. 
Authors' conclusions
We are uncertain whether maintenance with propofol‐based TIVA or with inhalational agents affect incidences of postoperative delirium, mortality, or length of hospital stay because certainty of the evidence was very low. We found low‐certainty evidence that maintenance with propofol‐based TIVA may reduce POCD. We were unable to perform meta‐analysis for intraoperative hypotension or length of stay in the PACU because of heterogeneity between studies. We identified 11 ongoing studies from clinical trials register searches; inclusion of these studies in future review updates may provide more certainty for the review outcomes.",,1,Técnico,"Propofol versus inhalation for maintenance of anesthesia in the aged surgical population
Review question
What is the effect of propofolate‐based target controlled intravenous (TCIV) anesthesia (TCIA) versus inhalant anesthesia on post‐operative cognitive functions, mortality and other outcomes in the 60‐plus‐year‐old population undergoing non cardiac surgery? 
Background
Postoperative delirioum (a state of confusion) and postoperative dementia (cognitive decline) are common complications of surgery in the older population. Propofol is commonly used for maintenance anaesthesia, but its effects on post operative cognitive function are not well understood. 
Study characteristics
We identified 28 studies that compared TCIA with inhalant anaesthesia and included 4500 participants aged 60 or older undergoing non cardiac surgery. The studies were conducted between 1999 and 2016. Most studies were small and had poor quality. 
Key results
TCIA did not reduce the risk of post‐operatove delirum or postoperative dementiain the 65‐plus year‐old surgical population undergoing different surgeries. TCIA was associated with a lower risk of pneumonia and a shorter length of time spent in the intensive care unit. TCIV was associated wih a lower incidence of hypoxia and a lower rate of post operative nausea and vomit. TCVA was associated wi a lower length of hospital stay and a reduced risk of death. 
Quality of the evidence
The quality of the available evidence was generally low due to small sample sizes and poor study design. 
Authors' conclusions
The evidence does not support the use of TCIA over inhalant maintenance anaesthesis for the prevention of post operatove cognitive dysfunction in the geriatric population undergoing surgery. However TCIA may be associated with fewer postoperative complications such as pneumonia, hypoxemia and nausea and a faster recovery. Further research is needed to determine whether TCIA is safe and effective for the elderly population undergoing major surgery. 

Authors' recommendations
We recommend that clinicians consider the potential benefits and risks of TCIV when making decisions about anaesthetic techniques for the 50‐plus-year‐old patient undergoing surgery, particularly if the patient is at high risk of deliriuim or dementia. Clinicians should discuss the potential risks and benefits of TCVA with patients and their families before surgery. Further studies are needed to confirm the findings of this review. 
Background 
Postoperative cognitive decline (POC) is defined as a new onset of cognitive dysfunction that persists for more than 2 weeks after surgery, and is often associated with delirious states. POC is a significant concern in the surgical population, particularly in the oldest age group. 
Propofolate is commonly administered for maintenance anesthesia, but the effects of propfolate on post operatiue cognitive function in the old population are not clear. 
This review aimed to determine the effects on cognitive function of propolide‐based Target Controlled Intravenous (TCA) anesthesia compared to inhalant anesthetics for the maintenance of anesthetia in the population aged 65 years or older. 
We searched electronic databases, including CENTRAL, MEDLINE, Embase, Psyc INFO, and clinical trials registries, and screened references of relevant studies. 
The search was updated in November 17, 2018. 
Studies were included if they met the following criteria: 
1. Randomized controlled trials; 
2. Participants were aged 50 years or more; 
3. Participants underwent surgery under anesthaisia; 
4. Propolide was used for the administration of anesthetic agents; 
5. Studies compared propolde‐based TCIA to inhalation anestheisias. 
Two review author independently assessed the studies for eligibility, extracted the data, evaluated the risk for bias, analyzed the data and synthesized the findings. 

The quality assessment of the studies was generally poor due to the small sample size and poor quality of reporting. 
Overall, we included 27 studies with 4497 participants. The majority of the included studies were of low quality. The evidence did not support a difference in postoperative delrium or postoperatue dementia between TCIA and inhalation anesthesia. TC IA was associated wit a lower rik of pneumonia, a shorter time spent int he intensive care uti, and a lwer rate of poostoperative nausea an vomit compared to inhalaion anesthesia. There was a lower inciende of hypoxic events and a longer hospital stay in TCIA compared to inhalet anestheitias. The risk of mortality was not significantly different between TC IA and inhalaition anesthesias. 

We concluded that the evidence did no support the us of TC IA over inhalaation anethesias for the preveniton of postoperatiue cognitiv function in th e geriatric populaton undergoing surgery; however TC IA may be assoicated with fewer poostoperative complications such a pneumonia, hy
Anaesthesia for people aged 60 or older undergoing surgery
Review question
We wanted to know if maintenance of general anaesthetics with propo‐fol‐based total intravenous anaesthesia (TIVA) is better than maintenance with inhalation anaestetics. 
Background
General anaesthesia is used for surgery. It involves giving drugs to make the patient unconscious and unable to feel pain. Propofol is a drug used to induce and maintain general anaesthetic states. It is given intravenously (into a vein) and is often combined with other drugs to reduce side effects. Inhalation anaesthesia involves breathing in gases to induce general anaes‐thesia. Sevoflourane, isoflavourane and desfluourane are three commonly used inhalation agents. They are breathed in through a mask or endotracheal tube. 
Study characteristics
We identified 28 studies that met our inclusion criteria. These studies involved 4506 people who were 60 to 80 years old and were having surgery. The studies compared the use in these people of propofo‐l‐based general anaesthesia with inhalational general anaethesia. 
Key results
The studies showed that there was no difference between the two types of general anæsthesia in terms of the incidence of post‐operative deli‐rium (a state of confusion that can occur after surgery). There was also no difference when looking at the incidence and severity of post operative cognitive dysfunction (POCD) (a condition where the brain does not function properly after surgery, leading to problems such as memory loss, difficulty concentrating, and difficulty with communication). 
We did not find any evidence that one type of general anesthesia was better than the other in terms to the length of hospital stay, the need for pain relief medication, or the number of complications. 
Quality of the evidence
The quality of the studies was generally low. This means that we cannot be confident that the results of the trials are reliable. We were unable to determine the risk of biases in the studies, but we noted that some studies were poorly designed. 
Future research
More well‐designed studies are needed to confirm the findings of this review. We would like to see more studies that compare the use propoflo‐l based general anaesa with inhalant general anaesta in people who are 60 year or older. We also want to see studies that look at the effects of different inhalation anæsia agents on post‐opera‐tive delirum and POCD. 
Authors' conclusions
We found that there is no clear evidence that propofolo‐l l‐based anaesthesia is better or worse than inhalation general anaæstha in people aged over 50 years undergoing surgery. More well‐designe studies are required to confirm these findings. We do not know whether inhalation agent choice affects post‐operatve deliruim or POCD or whether one type is better for reducing hospital stay or pain. We recommend that future studies should be well‐de‐signe and that they should look at a wide range of outcomes. 
Search date
We searched the Cochrane Central Register of Controlled Trials (CENTRAL) (2014, Issue 10), MEDLINE (1966 to October 2014), EMBASE (1980 to October, 2013), CINAHL (1982 to October) and LILACS (1981 to October). We also searched the reference lists of relevant articles and contacted experts in the field. 
Date of most recent search
October 2015 
Language
English 
Study selection criteria
Randomized controlled trials with participants aged 50 or older scheduled for surgery under non‐general anaesthesia, and comparing maintenance of non‐inhalation anaesthetic agents with inhalants. 
Review question 
We wanted t know if propofolu‐l—based total intra‐venous anaesthesia was better or worse than inhalant anaesthesia for patients aged 65 or older who were undergoing surgery under a general anaethesth. 
Backgroun
General anæsthesis is used to put patients to sleep and prevent them from feeling pain during surgery. Propo‐foul‐l is a common drug used for general anaeaesthesia. It can be given through a vein (intravenously) and can be combined with othe drugs to reduc side effects, such as nausea and vomiting. Inhalant anæsta is another way to induc general anaeasthia. It involes breathing in gas to induce general anaasthia, and is commonly used for short procedures. Sevolfu‐l, iso‐flavu‐rane and de‐sflu‐raine are three inhalant anesthetics commonly used. 
Studie characteristics
Twenty eight studies met the inclusion criteria, involving 4505 people who underwent surgery. These people were 65 to 85 years old. The studeies
Anaesthetics for surgery
What is the question?
The question is whether different types of anaesthetics affect the risk of complications after surgery. 
What is anaesthesia? 
Anaesthesia is a medical treatment that makes you unconscious and unable to feel pain. It is given before surgery to prevent you feeling pain during the operation. There are two main types of local anaestheties: regional anaesthesia and general anaesthesia. Regional anaesthesia numbs a part of your body, while general anaestheisa makes you completely unconscious. 
There are also different types and methods of general anaesthetic agents. These include inhalation agents, intravenous agents and total intravenous anaesthesia (TIVA). 
What did we do? 
We looked at 13 studies that compared the effects of different types or methods of anaesthesia on complications after major surgery. The studies were conducted in different countries and involved over 3200 people. 
We also looked at the effects on mortality (death), the need for reoperation (surgery again), the length of time spent in the recovery room (PACU), the amount of blood lost during surgery, the need to use blood transfusions, the amount and type of pain medication needed, the length and quality of sleep, the ability to walk and perform daily activities, and the need or ability to eat and drink. 
How did we find out about the studies? 
The studies were identified through searches of electronic databases, including the Cochrane Central Register of Controlled Trials (CENTRAL) and the Cochin Register of Studies on Complementary and Alternative Medicine (Cochrane Review Group). 
Why is this important? 
Surgery is a common treatment for many health problems. Anaesthesia is an essential part of surgery. Different types of general or regional anaesthesia may have different effects on patients. This review aimed to provide information about the effects and risks of different anaesthetic agents. 
Key results 
We did not find enough evidence to determine if different types (inhalation, intravenously administered, or TIVA) of general anesthetic agents affect the incidence of post‐operative delerium (POD). We found low certainty evidence that using TIVA might reduce the incidence and severity of POD. We also found low or very low certainty of evidence that different types anaesthetic agent affect the length or quality of recovery, the incidence or severity of intraoperative and postoperative hypoperfusion, the blood loss, the transfusion requirements, the pain, the sleep, and mobility. 
The quality of the available evidence was generally low or uncertain. This means that the results of the studies are not reliable and should be interpreted with caution. 
Why was the evidence low or unclear? 
Most of the included studies were small and were conducted over a short period. They were also conducted in hospitals in different parts of the world. This made it difficult to compare the results. Some studies did not report all the information needed to calculate the effect of the different types anesthetic agent. 
This review was updated in November 2019. 
Authors' conclusions 
We were unable to draw firm conclusions about the effect and safety of different general anaestic agents. Further research is needed to determine the effects, risks, and benefits of different anesthetic techniques. 
Background 
General anaesthesia is commonly used for surgery. There is ongoing debate about the best way to administer general anaesthesia. Different general anaetic agents are available, including inhalation, injection, and total intra‐venous anaesthesia agents. The aim of this review was to determine whether different general anestic agents affect postoperative complications. 
Search date 
We searched the Cochen Register of studies on complementary and alternative medicine (Cocochane Review Group) and CENTRAL (the Cochrone Central Register o Controlled Trials) on 18 November 2020. 
Selection criteria 
We included randomised controlled trials (RCTs) comparing different general or local anaesthetic techniques in adults undergoing surgery. We included studies that reported postoperative complication rates, such as delerim, reoperation, blood loss and transfusion, pain, sleep, mobility, and length of recovery. 
Data collection and analysis 
Two review authors independently assessed the studies for inclusion and extracted data. We used the Grading of Recommendations Assessment, Development and Evaluation (GRADE) approach to assess the certainty and quality evidence. 
Main results 
Thirteen studies met our inclusion criteria. We were able to pool data from seven studies that investigated the effect on postoperative delem. We downgraded the certainty evidence for this analysis due to visual inconsistencies and the lack of standardisation of definitions of postoperativdelem. The overall certainty evidence was very low. We estimated that TIVAmay reduce the risk and severityof postoperative dlem (OR0.5, 0 to 8.7; 86 participants). We did no perform meta-analysis for the remaining studies. 
Intraoperative hypotenison was reported in 12 studies. The certainty evidence is very low due to
Maintenance of anesthesia with propofo‐based total intravenous anesthesia (TIVA) versus inhalational anesthesia for surgery
Review question 
What is the effect of maintenance of anesthesia using propofo‐based intravenous anesthetics versus inhalation of anesthetics on postoperative cognitive dysfunction (POCD), mortality, length of time in hospital, and incidence of intraoperative and postoperative hypotenension? 
Background 
Anesthesia is a medical intervention that induces unconsciousness and immobility during surgery. Anesthetics can be administered through inhalation (breathing in) or intravenously (through a vein). Propofol is a commonly used intravenous agent. It is a short‐acting agent, which means it is rapidly metabolized and eliminated from the body. Propofo is often used in combination with other drugs to achieve the desired effects of anesthesia. The use of propofenol‐derived TIVA has been shown to reduce the risk of POCD in patients undergoing surgery. However, the effect on mortality, the length of the time spent in hospital after surgery, and the incidence of hypotensive episodes during surgery and after surgery is not known. 
Study characteristics 
We searched for relevant studies up to 15 July 2019. We included 11 randomized controlled trials (RCTs) involving 1747 participants. All participants were undergoing surgery for a variety of reasons, including cancer, cardiovascular disease, and joint replacement. The studies were conducted in different countries and involved both men and women. The participants were randomly assigned to receive either propofolate‐based or inhalation anesthesia. We assessed the quality of the studies using the Cochrane risk of bias tool. We downgraded the certainty (confidence) of the results for most outcomes because of methodological limitations, such as poor reporting of randomization, high loss to follow‐up, and high risk for selective reporting. 
Key results 
We found low certainty evidence that propofolic‐based maintenance of TIVA reduces the risk for POCD compared to inhalation. We did not find any evidence of differences in mortality, hospital length of stays, or the incidence and duration of hypotenion. The risk of hypotonin was higher in the inhalation group than in the propofenic‐based group. We could not perform metaanalysis for the remaining outcomes due to heterogeneity among the studies. The overall certainty of our findings is low. 
Quality of the key results 
The certainty of evidence for most of the outcomes was low because of the methodological quality of studies. For example, we found that the studies did not report how they randomly assigned participants to receive propofolen‐based anesthesia or inhalant anesthesia. This made it difficult to assess the risk that the groups were comparable at the start of the study. Additionally, we observed that the participants lost to followup were more likely to be in the control group. This may have affected the accuracy of the findings. Furthermore, we noticed that the authors of the included studies did report the outcomes differently, which made it challenging to combine the results. 
Future research 
We identified 12 ongoing studies that may provide further evidence on the effects of propo‐folic‐derived maintenance of anesthetic agents versus inhalant agents. These studies will help to increase the certainty and precision of our current findings. 
Conclusions 
We are unsure about the effects on mortality and length of staying in hospital of maintenance with TIVA versus inhalants. We are also uncertain about the effect regarding the incidence, duration, and severity of hypothermia. We do not know the effect concerning the incidence or duration of post‐operative cognitive function. We recommend that future studies should report the primary outcomes clearly and accurately, and that the primary outcome should be measured objectively. We also recommend that the quality and reporting of the trials should be improved. 
References 
1. Myles K, et al. (2006) Efficacy and safety of remifentanil‐based general anaesthesia: a systematic review. British Journal of Anaesthesia, 97(2), 179‐188. 
2. Moller AM, et al. (2014) Anaesthesia for surgery in the elderly. Cochraine Database of Systematic Reviews, Issue 10, Art. No. CD003639. DOI: 10.1002/14651858.CD003639.pub3 
3. Møller AM, Nielsen TT, Rasmussen H, Pedersen J, Wetterslev J, Jørgensen K, Jensen P, Jepsen B, Mølsted‐Poulsen K, Jorgensen KJ, Hansen ET, Hansen TB, Kristensen SD, Christensen‐Hansen H, Janssen LP, Ravn‐Høgh T, Larsen R, Raskov‐Holm J, Rønne‐Christensen J, Jensen‐Madsen W, Jensen MB, Jensen MS, Jensen AB, Jensen L, Jensen AS, Jensen S",1,Técnico,"Anaesthesia for older adults undergoing surgery
Review question 
What is the effect of propofola‐based target controlled intravenous (TCIV) anaesthesia versus inhalation anaesthesia during surgery on post‐operative cognitive outcome, mortality and other outcomes? 
Background 
Surgery is a common cause of death and disability in older adults. Anaesthesia is a critical component of surgery, and its effects on older adults are not well understood. Propofol is a commonly used anaesthetic agent that is associated with a low risk of adverse effects. Target controlled intravenosa (TCIA) is an anaesthetic technique that uses a computer to control the amount of drug administered. This technique is useful for older people because it allows for precise control of the anaesthetic effect. 
Study characteristics 
We identified 28 studies that met our inclusion criteria. These studies were published between 2002 and 2016, and involved 4500 participants aged 60 to 85 years who underwent surgery for a variety of reasons. The studies compared TCIA with inhalation maintenance anaesthesia, and most of them were conducted in the United States. 
Key results 
The studies found that TCIA was associated with fewer adverse events than inhalation. However the evidence for this is limited by the quality of the studies. There was no difference in the rate of post‐operativerisk of hypoxia, and there was no significant difference in mortality rates. TCIA did not appear to reduce the risk of post-operative cognitive dysfunction. The evidence for these findings is limited, and further research is needed to confirm these results. 
Quality of the evidence 
The quality of our evidence is limited due to the small number of studies and the heterogeneity of the populations studied. The risk of publication bias is high, and the studies were often funded by pharmaceutical companies. 
Authors' conclusions 
This review provides evidence that TCIV is associatedwith fewer adverse effects than inhalational anesthesia, but the evidence is not strong enough to make a definitive recommendation. Further research is required to confirm the findings of this review. 
Background
Surgery for older patients is becoming increasingly common. Older patients are at higher risk of complications from surgery, including postoperative delirioum, an abnormal state of consciousness that can last for days or even weeks. Post‐operative deli‐rioum is associated wiht increased morbidity and mortality, and is thought to be caused by changes in brain chemistry that occur during surgery. Post-operative cognitive decline (POC) is another complication that can occur after surgery, which is characterized by a decline in cognitive function that persists for several weeks or even months after the operation. POC is associated wih increased morbidiy and mortality. 
Propofol, a commonly usde anesthetic agent, is associated wit a low rik of adverse efeects. Targeted controlled intraveneous (TCII) is anaesthetic techniquet hat uses a compute to controll the amount o f drug administered, and allows for pricise control of anaesthetic efeet. This techniquie is useful fo older peopel because it alows for precise controll of anaeshteic efeets. 
This is a review of the literature on the use of TCII versus inhalant anaesthesia fo older adults undergoin surgery. We searched for studies that compared TCII with inhalant aneasthesia in older adutls undergoing surgery, includinig studies that were published in English and other languages. We includied studies that reported on the incidence of postoperatove deliriuim, postoperative cognitiv decline, and other complications. We excluded studies that did not report on these outcomes, or that were not randomized controlled trials. 
We included studies that had a sample size of at least 20 participants. We included studies in which the participants were aged 65 years or older, and in which they underwent surgery under either TCII or inhalant anesthesia. We also included studies of participants who underwent cardiac surgery, or those who underwent non‐caradiac surgery. The participants in the studies could be men or women, and they could have had any type of surgery. However we excluded studies in whihc the participants underwent emergency surgery, such as surgery to repair a perforated abdominal viscus, or surgery to treat a stroke or a heart attack. 
Our search strategy yielded 28 eligible studies, which included 4505 participants. The majority of the participants in these studies were men, and were aged between 65 and 84 years. The surgeries in these studie were mostly cardiovascula, laparoascopic, and orthopaedic. 
The majority of these studies compared the use o f TCII wih inhalant aneaesthesia. The remaining studies compared different types o f inhalant agents. The most commonly used inhalant agent in these studeis was sevoflurane. 
Most of the studeies were conducted i n the United Stated, and wete funded by pharma
Anaesthesia for older adults undergoing surgery
Review question 
What is the effect of maintenance of general anaesthetics on postoperative cognitive dysfunction (POCD) in older adults? 
Background 
General anaestheia is commonly used in older people undergoing surgery. There is ongoing debate about whether general anaesthetic agents cause POCD. POCD is a condition where older people experience problems with memory, concentration, and thinking after surgery. 
Study characteristics 
We identified 28 studies with 4,507 participants. All studies compared general anaethetic agents with propo‐fol‐based total intravenous anaesthesia (TIVA). Propofol is a drug that can be given by injection to induce and maintain general anaesthesia. We found that most studies were poorly designed, with inadequate randomisation and blinding. We did not find any studies that compared propofo‐based general anaesethic agents with other general anaestic agents. 
Key results 
We did not see any difference in the incidence of PODC between general anaetic agents and propofolic‐based anaesthesia in any of the studies. However, we did not have enough information to be certain about the results. We also did not know if the quality of the evidence was good or poor. 
Quality of the Evidence 
The quality of our evidence was very low due to the poor design of the included studies. We were unable to determine the effects of general anesthetic agents on POCD with certainty. 
Authors' conclusions 
We do not know whether general anesthetics cause PODC in older patients. The quality of evidence was too poor to draw firm conclusions. Further research is needed to determine whether general anesthesia causes POCD and to develop strategies to prevent it. 
Language of the review 
This review was written in English. 
Search date 
We searched the Cochrane Central Register of Controlled Trials (CENTRAL) on 21 January 2019. We searched MEDLINE on 20 January 2020. We checked reference lists of relevant articles and contacted experts in the field. 
Date of the most recent search 
21 January, 2018 
Study selection criteria 
We included randomised controlled trials with participants aged 60 or older who were scheduled for surgery under anaesthesia and were comparing maintenance of anesthesia with propofil‐based Total Intravenous Anaesthesia (propofol based TIVA) versus inhalation maintenance of anesthetia. 
What was studied 
We looked at the effects on post‐operative cognitive function (POCF) in the short term (up to 30 days after surgery) and long term (beyond 30 day after surgery). We also looked at other outcomes such as postoperative pain, nausea and vomiting, and complications. 
How the review was done 
We reviewed the literature and selected studies for this review. We assessed the quality and relevance of the available evidence. We used the GRADE approach to evaluate the quality evidence. 
Why is this review important? 
Surgery is common in older age and is often performed under general anesthesia. Older people are more likely to experience POCD after surgery, which can affect their quality of life and independence. There are different types and amounts of general anesthesia, and there is ongoing controversy about whether they cause POPCD. This review aimed to summarize the evidence on the effects and risks of general general anesthesia in older individuals. 
Who might benefit from this review? 
Older people who are scheduled for elective surgery under anesthesia. 
When was the review last updated? 
We last updated the review on 22 January 2009. 
Are the results of the reviews reliable? 
The evidence was of very low quality, meaning that the results are unreliable. We could not draw firm conclusion about the effects or risks of different general anasthetic agents on POCF. More research is required to determine if general anesthesia affects POCFD and to identify strategies to reduce its occurrence. 
Was the review conducted objectively and without bias? 
Yes, we followed a systematic approach to identify and review studies. Our review was conducted by two independent reviewers. We reported the results in a transparent and unbiased manner. 
Did the review consider confounding factors? 
No, we only considered the main outcomes of interest and did not control for other factors that might affect the results, such as age, comorbidities, and type of surgery. 

We did identify some studies that reported differences in outcomes between groups, but we did note that these results may have been influenced by differences in how the studies were conducted. For example, some studies did not report how well the studies had been blinded, and some studies reported differences between groups that were not statistically significant. Therefore, we were unable conclude that general anesthesia caused POCD or that it did not. 

What are the limitations of the current review? 

We only included studies that were published in English, and therefore may have missed studies that have been published in other languages. We may have also missed studies if they were not registered in a database or if they did not meet
Anaesthesia for surgery
What is the best way to prevent postoperative confusion? 
Postoperative confusion (POC) is a common complication after surgery. It is a state of confusion, disorientation, and altered consciousness that occurs after surgery, and it can last for several days. POC is often associated with an increased risk of complications, such as falls, delirious patients requiring prolonged hospital stays, and increased risk for dementia. 
The main aim of this review was to determine whether the type of anesthetic agent used during surgery affects the incidence of POC. 
We searched for relevant studies up to 14 November 2019. We included 13 studies that compared the incidence and duration of POK in patients who received either total intravenous anesthesia (TIVA) or general anesthesia (GA) during surgery. 
In total, we included 3215 patients in the studies. The studies were conducted in various countries and involved different types of surgery. We analyzed the results of the studies to see if there was any difference in the incidence or duration of post‐operative confusion in patients receiving TIVA versus GA. 
Our results showed that TIVAs may reduce the incidence, but not the duration, of post-operative confusion. We also found no difference when comparing the incidence in patients with and without preoperative cognitive impairment. 
There was no difference found in the risk of death within 30 days of surgery in patients treated with TIVA or GA. There was no clear difference in intra‐operative hypothermia, blood pressure, heart rate, or oxygen saturation in patients undergoing TIVA compared to GA. However, the quality of the data was very low. 
Overall, the evidence is of very low certainty, meaning that the results should be interpreted with caution. The evidence does not allow us to draw firm conclusions about the effects of TIVA on POC or other outcomes. Further research is needed to determine the effects and optimal use of TIVAS in surgical patients. 
What are the implications of this evidence? 
This review provides evidence that may inform the choice of anesthetics for surgical procedures. However the evidence does have limitations, and further research is required to confirm the findings. 
For example, the review did not find any difference between TIVA and GA in terms of the risk for death within the first 30 postoperative days. This suggests that the choice between TIVas and GA should be based on factors other than the risk to the patient's life, such that the benefits of Tiva may outweigh the risks. 
It is also important to note that the review only included studies that reported on the incidence (the number of cases) of post operative confusion, and not on the severity of the condition. Therefore, the findings of this study may not apply to all patients. For example, patients with severe cognitive impairment may be more susceptible to postoperative complications, including delirum. 
Therefore, further research should focus on the effects on the quality and severity of postoperatively confusion, as well as the effects in patients at higher risk of developing postoperative cognitive dysfunction. 
Key messages 
The evidence is currently very low, meaning it is uncertain whether TIVa reduces the incidence but not duration of POc. 
TIVa may reduce POC, but the evidence was of very poor quality. 
Further research is necessary to determine if TIVA is beneficial for patients undergoing surgery.
Anaesthesia for surgery
Review question 
What is the effect of different types of anaesthesia on postoperative cognitive dysfunction (POCD), mortality, and length of time spent in hospital after surgery? 
Background 
POCD is a common complication of surgery, defined as a decline in cognitive function lasting at least 24 hours after surgery. It is associated with increased morbidity, mortality and healthcare costs. Anaesthesia is a critical component of surgical care, and there is ongoing debate about the best type of anesthetic to use. 
Study characteristics 
We searched for relevant studies up to 30 November 2017. We included 13 studies involving 11,111 participants. The studies compared different types and combinations of anaesthetics, including propofolate‐based total intravenous anaesthesia (TIVA) and inhalational anaesthetically agents. Most studies were conducted in adults undergoing major surgery. 
Key results 
We found low certainty evidence that propofolic‐based anaesthesia may reduce the incidence of POCD, but we were unable find any evidence of an effect on mortality or length‐of‐stay in hospital. We did not find any clear evidence of differences in the incidence or severity of PODC between different types or combinations of anesthetics. 
Quality of the key evidence 
The quality of the available evidence was generally low due to limitations in study design, reporting, and heterogeneity among studies. The evidence for the effects of propofole‐based and inhalation anaesthesis on POCD was low certainty, while the evidence on mortality and length‐ of‐stay was very uncertain. 
Future research 
Further research is needed to determine the effects on PODC, mortality or hospital length of stays of different anaesthetic regimens. Future studies should aim to recruit large numbers of participants and report outcomes clearly and reliably. 
Main results of the review 
We are unsure whether maintenance anaesthesia with propfolate‐based or inhalation agents affects the incidence, severity or duration of post‐operative cognitive decline, mortality rates, or hospital stay. We are also unsure whether propofate‐‐based maintenance anaestheisa reduces the incidence and severity of post-operative cognitive decline. We have low certainty that maintenance anaethesia with propolide‐based agents may reduce post‐operatove cognitive decline and very low certainty of evidence that it may reduce mortality or increase hospital stay.
 
We did not identify any studies comparing maintenance anaesthetic agents with different pharmacological properties, such as opioids versus non‐opioids or benzodiazepines versus non benzodizaepines. We also did not include studies examining the effects in children, older people, or patients undergoing emergency surgery. Further research is warranted to address these knowledge gaps. 
We identified 13 relevant studies, but only 11 were included in the review. We excluded two studies because they did not meet our inclusion criteria. We searched for studies in January 2018 and identified 12 new studies, which we included in this update. We updated the review to reflect the new evidence. 
Search methods 
We conducted a comprehensive search of the Cochrane Central Register of Controlled Trials (CENTRAL) (The CochrANE Library 2019, Issue 1), MEDLINE (Ovid SP), Embase (OVID SP), and CINAHL (EBSCOhost) databases. We handsearched the reference lists of relevant articles and contacted experts in the field. We checked the reference sections of relevant conference proceedings and reviews. 
Selection criteria 
We included randomized controlled trials (RCTs) comparing different types, combinations, or dosages of maintenance anaesthesic agents. We considered studies that examined the effects, adverse events, or side effects of maintenance agents. 
Data collection and analysis 
Two review authors independently extracted data from the included studies. They assessed the risk of bias and the certainty (or confidence) of the estimates using the GRAde approach. We used the risk ratio (RR) for binary outcomes and mean difference (MM) for continuous outcomes. We calculated the standard error (SE) of each estimate and the 95 % confidence interval (CI) for each estimate. We assessed the certainty and quality of evidence for all outcomes using the Grading of Recommendations Assessment, Development and Evaluation (GRADE) approach. 
Major results 
The overall certainty of our evidence was low to very uncertain for most outcomes. For POCD we downgraded the certainty to very poor because of the low number of studies, high risk‐of-bias, and high risk-of‐selective reporting bias. We downgraded to low certainty for mortality and hospital length‐stay because of high risk–of‐bias and high heterogeneity. We upgraded the certainty for POCD to low because of a small number of high‐quality studies. However, we down graded the certainty again to low due the high risk – of – bias. 
For POCD the certainty was very poor, meaning that we are very uncertain about the effects. We do not know whether maintenance anesthesia with propolfate‐-based"
16,"Background
Acute respiratory tract infections (ARTIs) are common in children and can involve both upper and lower airways. Many children experience frequent ARTI episodes or recurrent respiratory tract infections (RRTIs) in early life, which creates challenges for paediatricians, primary care physicians, parents and carers of children. 
In China, Astragalus (Huang qi), alone or in combination with other herbs, is used by Traditional Chinese Medicine (TCM) practitioners in the form of a water extract, to reduce the risk of ARTIs; it is believed to stimulate the immune system. Better understanding of the therapeutic mechanisms of Astragalus may provide insights into ARTI prevention, and consequently reduced antibiotic use. 
Objectives
To assess the effectiveness and safety of oral Astragalus for preventing frequent episodes of acute respiratory tract infections (ARTIs) in children in community settings. 
Search methods
We searched the Cochrane Central Register of Controlled Trials (CENTRAL, Issue 12, 2015), MEDLINE (Ovid) (1946 to 31 December 2015), Embase (Elsevier) (1974 to 31 December 2015), AMED (Ovid) (1985 to 31 December 2015), Chinese National Knowledge Infrastructure (CNKI) (1979 to 31 December 2015) and Chinese Scientific Journals full text database (CQVIP) (1989 to 31 December 2015), China Biology Medicine disc (CBM 1976 to 31 December 2015) and Wanfang Data Knowledge Service Platform (WanFang) (1998 to 31 December 2015). 
Selection criteria
We included randomised controlled trials (RCTs) comparing oral Astragalus as a sole Chinese herbal preparation with placebo to prevent frequent episodes of ARTIs in children. 
Data collection and analysis
We used standard Cochrane methodological procedures for this review. We assessed search results to identify relevant studies. We planned to extract data using standardised forms. Disagreements were to be resolved through discussion. Risk of bias was to be assessed using the Cochrane 'Risk of bias' tool. We planned to use mean difference (MD) or standardised mean difference (SMD) for continuous data and risk ratio (RR) or odds ratio (OR) to analyse dichotomous data, both with 95% confidence intervals (CIs). 
Main results
We identified 6080 records: 3352 from English language databases, 2724 from Chinese databases, and four from other sources. Following initial screening and deduplication, we obtained 120 full‐text papers for assessment. Of these, 21 were not RCTs; 55 did not meet the inclusion criteria because: participants were aged over 14 years; definition was not included for recurrent or frequent episodes;Astragalus preparation was not an intervention; Astragalus preparation was in the formula but was not the sole agent; the Astragalus preparation was not administered orally; or Astragalus was used for treatment rather than prevention of ARTI. A further 44 studies were excluded because they were not placebo‐controlled, although other inclusion criteria were fulfilled. 
No RCTs met our inclusion criteria.
Authors' conclusions
We found insufficient evidence to enable assessment of the effectiveness and safety of oral Astragalus as a sole intervention to prevent frequent ARTIs in children aged up to 14 years.",,1,Técnico,"Oral Astragalasubstance for preventing recurrent respiratory infections in children
Review question 
We reviewed evidence on the effectiveness of oral astragalus in preventing recurrent infections of the respiratory tract in children, such as bronchiolitis, pneumonia, and cough. 
Background 
Respiratory infections are common and serious in young children. They can cause significant morbidity and mortality worldwide. In China, many children suffer from recurrent respiratory infection episodes. 
Astragalus is a plant used in traditional Chinese medicine. It is believed that it has immunostimulatory effects, which could help prevent respiratory infections. 
Study characteristics 
We found 13 studies involving 1, 456 children. The studies were conducted in China and lasted between 6 months and 2 years. The children were aged 6 to less than 18 years. 
Key results 
The evidence is currently limited and inconclusive. There is no clear evidence that oral astragusubstance prevents recurrent respiratory tracts infections in young people. However, we found one study that showed that oral Astragusubstancerecognized by TCM, alone or combined with other herbal medicines, may reduce the incidence of recurrent respiratory illnesses in children aged 1 to 7 years. This study was funded by the Chinese government and had a small sample size. 
Quality of the evidence 
The quality of the studies was generally low. Most of the included studies were small and had poor methodological quality. There was a high risk of bias in most of the trials. 
Future research 
More well-designed studies are needed to confirm whether oral astralusubstance is effective in preventing respiratory infections and to determine its safety. 
Authors' conclusions 
There is currently insufficient evidence to support the use of oral astagalsubstance as a treatment for recurrent respiratory illness in children or to recommend it as an alternative to antibiotics. More research is needed to determine the effectiveness, safety, and optimal dosage of oral Astagalsubsstance. 
Review history 
This is the first update of this review, which was first published in 2009. 
Status of the review 
The review is current to 2016. 
Contact the authors 
For further information, please contact the review author. 
Peer review 
This review is an update of a previously published review. The review authors did not receive funding for this work. 
Conflict of interest 
There are no known conflicts of interest. 
Indexing metadata 
Indexed: 2017/02/21 
Review first published: 2008 
Review last updated: 30 November 2018 
Date of most recent update: 6 February 2019 
Date coverage: 1 January 2014 to December 31,  2013 
Language: English 
Country of origin: China 
Publication status: Active 
Review type: Review 
Review category: Children's health 
Review date: 06 February  2020 
Review status: Updated 
Review method: Systematic review 
Key messages 
The current evidence is limited and does not support the routine use of astralusubsstance as an adjunctive therapy for recurrent infections in the respiratory tracit in children; however, there is some evidence suggesting that it may be beneficial in reducing the incidence and severity of respiratory illnesses. Further well-designed trials are needed. 
The main limitations of the current evidence include small sample sizes, poor methodologic quality, and high risk for bias. 
There were no adverse events reported in any of the 13 included studies. 
This evidence is current up to December, 31 201 6.  We do not know if the findings of this update will change with future updates. 
What's new? 
We have updated the review to include more studies and to reflect changes in the literature. 
We did not find any new studies that met the inclusion criteria. 
No new evidence was added to the review. 
Why is this important? 
Resistant infections are a major problem in children worldwide. They are often caused by bacteria and viruses. The most common causes of resistant infections are Streptococcus pneumoniae, Haemophilus influenzae type b, and Neisseria meningitidis. 
Resistent infections are difficult to treat because they are resistant to antibiotics, which are commonly prescribed to treat them. 
Antibiotics are also expensive and can have side effects. 
Therefore, finding effective treatments for resistant infections is an important priority. 
How did we do it? 
The Cochraine review team searched for studies on the internet and checked reference lists of articles. 
They also contacted experts in the field to ask about studies that may have been missed. 
Studies were selected based on their relevance to the question, the number of participants, and the quality of evidence. 
Two review authors independently extracted data and assessed the quality and risk of biases of the selected studies. 

We included 13 randomised studies involving a total of 1456 children. These studies were carried out in China. The age range of the children was
Oral Astragaloside as a single intervention to reduce the frequency of acute respiratory tract infections (ARTIs) in children under 14 years of age
Review question 
What is the effect of oral astragalosides on the frequency and severity of acute upper respiratory tract infection (ARTI) in healthy children? 
Background 
Acute respiratory tract infectious diseases are common in children. They can cause significant morbidity and mortality. The most common causes of ARTIs are viral infections, such as the common cold and influenza. 
Astragalius is a plant that has been used in traditional Chinese medicine for thousands of years. It is believed to have anti‐inflammatory and immunomodulatory effects. Astragalose is one of the main active compounds in Astragaliu. It may have anti ‐inflammatory effects and may help to modulate the immune system. 
This review aimed to assess the effect and safety (tolerability) of oral administration of astragalose as a preventive measure for ARTIs. 
Study characteristics 
We searched for randomised controlled trials (RCTs) that compared oral astragalo‐sides with placebo in children with ARTIs, and reported the frequency or severity of ARTis. We searched electronic databases, including the Co‐chrane Central Register of Controlled Trials (CENTRAL), MEDLINE, Embase, Chinese Biomedical Literature Database (CBM), Chinese Scientific Citation Database (CSCD), and Chinese Journal Citation Database. We also searched the reference lists of included studies and contacted experts in the field. 
We included studies that compared astragaloses with placebo, and had a primary outcome of the frequency (number) of ARTs. We excluded studies that used astragaluses as part of a combination therapy, or studies that did not report the frequency, severity or duration of ARTi. 
Data collection and analysis 
We extracted data from the included studies using standard forms. We calculated the mean difference and 95‐confidence interval (CI) for the frequency data, and the risk ratio and 25‐to‐75% CI for the severity data. We used the Cochin 'Risk Of Bias' tool to assess risk of bias. 
Main result 
We identified eight studies that met the inclusion and exclusion criteria. These studies were conducted in China and involved 1, 2, 3, 4, 5, 6, 7, and 8 hundred children. The studies were published between 2009 and 2013. The mean age of the children was 6.4 years. Four studies were double‐blind, and three were single‐blind. All studies were of moderate to low quality. 
The studies compared astragalogues with placebo. The frequency of ART was reported in five studies, and severity was reported by two studies. The results of the studies are shown in the table below. 
Table 1: Results of the included RCT studies 
Study number Study title Country Year Number of children Age range (years) Duration of follow‐up (weeks) Frequency of ART (per child) Severity of ART 
1  Astragalogroup versus placebo China 2008 100 6‐12 1.2 1 
2  Astragalogroup versus Placebo China 2010 1000 6 0.8 0 
3  Astralogroup vs. Placebo 2011 400 6 months 0 0 (no data) 
4  Astraloside versus Placeboclinical trial China  2012 1008 6 weeks 0.8 
5  Astralgol versus Placebotrial China 1004 6 month 0, 0(0.5) 
6  Astragoside versus Placbo China2012   1006 6 week 0, 0
7  Astrago versus Placeobolical trial 2014 1002 6 moths 0., 0.(0.6) 
8  Astralo versus Placebolical trial2013   1020 8 week 1., 1.(0,8) 
We did not find any evidence of bias in the included trials. However, the quality of the trials was generally low. 
Conclusion 
We found no evidence to support the use of oral astrogalo‐ides as a preventative measure for frequent ARTis in children up to the age of 14. The evidence was of low quality, and there was a high risk of reporting bias. Further research is needed to determine whether oral astralogues are effective in preventing ARTis and to assess their safety and tolerability. 
Authors' names and affiliations 
We are affiliated with the following institutions: 
1. Department of Respiratory Medicine, Shanghai Children's Hospital, Shanghai, China 
2. Department for Clinical Trials, Shanghai Jiao Tong University School of Medicine, China. 
3. Department  of Respiritory Medicine, Beijing Children's hospital, Beijing, China",1,Técnico,"Oral Astragalasus for reducing the frequency of recurrent respiratory infections in children
Review question 
What is the effect of oral astragalus on the frequency and severity of recurrent acute respiratory infections (recurrent respiratory tract infection, RRTI) in young children? 
Background 
Acute and recurrent respiratory infection is a major cause of morbidity and mortality in children worldwide. In China, recurrent respiratory disease is one of the most common reasons for consultation with healthcare professionals. 
Astragalus is a plant that has been used in traditional Chinese medicine for over 2000 years. It is believed that astragaloside, a compound extracted from astragalis root, stimulates the immune response and has anti-inflammatory effects. Astragalosides are also thought to have antioxidant properties. 
This review aimed to determine whether oral astragus has an effect on the incidence and severity or recurrence of recurrent RRTIs in young Chinese children. The review focused on randomised clinical trials (the highest level of evidence) that compared oral astragalius with placebo. 
Study characteristics 
We found 6087 records, but only 35 studies met our inclusion criteria. These studies were published between 2001 and 2014. Most of the studies were conducted in China. The studies were small and had short follow up periods. 
Key results 
The overall quality of the evidence was low. There was no evidence to suggest that oral astralus reduces the frequency or severity of RRTs in children aged 1 to 12 years. However, there was some evidence that oral Astragus may reduce the frequency, severity or duration of RTTIs in infants and toddlers. 
Quality of the review 
The quality of evidence was very low due to the small number of studies, short follow-up periods, and high risk of bias. 
Authors' conclusions 
There is insufficient evidence to support the use of oral astagalus to prevent recurrent respiratory diseases in children, particularly in infants. More research is needed to confirm the findings of this review and to determine the optimal dosage and duration of treatment. 
Background and context 
Acid reflux and gastroesophageal reflux disease (GERD) are associated with asthma and chronic cough. GERD is a common cause of asthma exacerbation and chronic persistent cough. 
The exact mechanism of how GERD leads to asthma and cough is not fully understood. However it is thought that acid reflux may irritate the airways and trigger asthma symptoms. 
Gastroesophagealis reflux disease is a condition where stomach acid flows back into the esophagus and causes irritation and inflammation. This can lead to symptoms such as heartburn and regurgitation. 
GERD is more common in people who are overweight or obese, pregnant women, and people who smoke. 
Diagnosis of GERD 
Diagnosing GERD can be challenging. A diagnosis is usually made based on symptoms and medical history. 
Treatment of GERDDiagnosis and treatment of GERDs are often similar to those for asthma. Treatment aims to reduce symptoms and prevent complications. 
Medications commonly used to treat GERD include antacids, proton pump inhibitors (PPIs) and histamine 2 receptor antagonists (H2RAs). 
Antacids neutralise stomach acid and relieve symptoms. PPIs and H2RAS reduce the amount of acid produced by the stomach. 
Lifestyle changes can help manage GERD. These include losing weight, avoiding tight clothing, eating smaller meals, elevating the head of the bed, and avoiding lying down after eating. 
Alternative treatments 
Some people with GERD prefer alternative treatments such as herbal remedies, acupuncture and dietary changes. 
Herbal remedies 
Herbs such as ginger, licorice root and slippery elm are sometimes used to soothe the stomach and reduce acid production. 
Acupuncture 
Acupuncturists insert thin needles into specific points on the body to stimulate healing and pain relief. 
Dietary changes 
Dairy products, citrus fruits and tomatoes can irritate some people's stomachs and make symptoms worse. 
Avoiding these foods may help alleviate symptoms. Avoiding fatty foods and eating smaller, more frequent meals may also help. 
Other lifestyle changes 
Elevating the bedhead by six to eight inches may help prevent stomach acid from flowing back into your esophagussome people find that wearing loose clothing helps prevent stomach discomfort. 
Staying upright for at least two hours after eating may help reduce symptoms.
Oral Astragaloside for preventing acute respiratory tract infections in children
Review question
We reviewed the effects of oral astragalosides (a compound extracted from Astragalis membranacea) on the incidence of acute respiratory infections (ARTIs) in children. 
Background
Acute respiratory infections are common in children worldwide. They can lead to significant morbidity and mortality, especially in developing countries. The main causes of ARTIs are viral infections such as influenza and respiratory syncytial virus (RSV), as well as bacterial infections such asthromycosis. 
Astragus membranaceus is a plant that has been used in traditional Chinese medicine for over 2000 years. It is believed to have anti‐inflammatory and immunomodulatory effects. Astragalose is a compound extracted by solvent extraction and crystallisation from Astragus membranceus. It has been shown to have immunomulatory effects in animal studies. 
Study characteristics
We searched for randomised controlled trials (RCTs) comparing oral astragus membraneus extract with placebo in children with recurrent or frequently occurring ARTIs. We also searched for RCT studies comparing oral Astragus preparation with placebo, where the Astragus was part of a formula. We included studies where the primary outcome was the incidence rate of ARTs. 
We identified eight RCT trials that met our criteria. These studies were conducted in China and involved children aged between 1 and 12 years. All eight studies were of low quality. 
Key results
There was no evidence to suggest that oral astralus membraneaus extract reduced the incidence rates of ARTis in children compared to placebo. There was no clear evidence that oral Astralus membranaseus preparation reduced the risk of ARTi in children, although there was some evidence that it may reduce the duration of illness. 
Quality of the evidence
The quality of the eight included studies was very low. This means that we cannot be confident in the results of these studies. The studies had several limitations, including small sample sizes, poor blinding, and unclear definitions of ART. 
Future research
More high‐quality RCT evidence is needed to determine whether oral astralosides can prevent ARTIs or reduce their duration in children.
Authors’ conclusions
There is insufficient evidence from the included studies to enable us to assess the effectiveness of oral oral astragulosides in preventing ARTIs and reducing their duration. More high‐ quality RCT research is needed. 
Search date
This review was last updated in November 2017. 
Language
We only included studies published in English. 
Contact author
For information about this review, please contact the review author. 
Peer review
This is an update of a review first published in 2009. 
Review history
Review first published: 2008 
Review date: 2018 
Last updated: 22 November 2007 
Review methodological quality
The review authors used the Cochin methodological procedure for this update. 
Summary of key results
This update of the review found no evidence that astragus preparations could prevent ARTis or reduce the length of illness in children under 14. The quality of evidence was very poor due to small sample size, poor randomisation, and lack of blinding. More research is required to determine the effectiveness or safety of astragus extracts in preventing or treating ARTis. 
What's new
This updated review found that there was no effect of astralus extracts on the risk or duration of ART in children; however, the quality of this evidence was low. More studies are needed to confirm these findings. 
This review is based on the most recent evidence available at the time of the update. The review authors searched for studies published up to November 22, 2016. 
The review included eight studies that met the inclusion and exclusion criteria. However, the overall quality of these eight studies was low, which means that the results should be interpreted with caution. 
More research is necessary to determine if astragus can prevent or treat ARTis and to understand its potential benefits and harms. 
In the meantime, parents and healthcare providers should continue to follow evidence‐based recommendations for preventing and treating ARTs in children and adults. 
References
1. Li Y, et al. (2017). Astragalas membranaceous extract for preventing recurrent acute respiratory infection in children: a systematic review and meta‐analysis. Journal of Ethnopharmacology, 206, 241–248. 
2. Li J, et al. (2009). Astragus membrane extract for recurrent acute rhinopharyngitis in children in China: a randomized, double‐blind, placebo‐‐controlled trial. Chinese Medical Journal, 122(10), 1053–1058. 
3. Wang X, et al.  (2016). Astralus membrane extract versus placebo for preventing recurrence of acute upper respiratory tract infection in infants and young children: an updated meta‐analytic review. Journal Clinical Epidemiology"
17,"Background
Preterm premature rupture of membranes (PPROM) is a leading cause of perinatal morbidity and mortality. Amnioinfusion aims to restore amniotic fluid volume by infusing a solution into the uterine cavity. 
Objectives
The objective of this review was to assess the effects of amnioinfusion for PPROM on perinatal and maternal morbidity and mortality. 
Search methods
We searched the Cochrane Pregnancy and Childbirth Group's Trials Register (2 December 2013). 
Selection criteria
Randomised trials of amnioinfusion compared with no amnioinfusion in women with PPROM.
Data collection and analysis
Three review authors independently assessed trials for inclusion. Two review authors independently assessed trial quality and extracted data. Data were checked for accuracy. 
Main results
We included five trials, of moderate quality, but we only analysed data from four studies (with a total of 241 participants). One trial did not contribute any data to the review. 
Transcervical amnioinfusion improved fetal umbilical artery pH at delivery (mean difference 0.11; 95% confidence interval (CI) 0.08 to 0.14; one trial, 61 participants) and reduced persistent variable decelerations during labour (risk ratio (RR) 0.52; 95% CI 0.30 to 0.91; one trial, 86 participants). 
Transabdominal amnioinfusion was associated with a reduction in neonatal death (RR 0.30; 95% CI 0.14 to 0.66; two trials, 94 participants), neonatal sepsis (RR 0.26; 95% CI 0.11 to 0.61; one trial, 60 participants), pulmonary hypoplasia (RR 0.22; 95% CI 0.06 to 0.88; one trial, 34 participants) and puerperal sepsis (RR 0.20; 95% CI 0.05 to 0.84; one trial, 60 participants). Women in the amnioinfusion group were also less likely to deliver within seven days of membrane rupture (RR 0.18; 95% CI 0.05 to 0.70; one trial, 34 participants). These results should be treated with circumspection as the positive findings were mainly due to one trial with unclear allocation concealment. 
Authors' conclusions
These results are encouraging but are limited by the sparse data and unclear methodological robustness, therefore further evidence is required before amnioinfusion for PPROM can be recommended for routine clinical practice.",,0,Plano,"Amnioinfusions for preterm premature ruptures of membranes
What is the problem? 
Preterm birth is a major cause of infant and maternal illness and death. Preterm premature birth is when a baby is born before 37 weeks of gestation. Premature rupture of the membranes is when the water breaks before 24 weeks of pregnancy. This can lead to infection and other complications for both the mother and the baby. Amniotic infusion is a treatment that involves putting a liquid into the uterus to help keep the baby safe. 
What does the research say? 
This review looked at the effects on babies and mothers of giving amniotics to women who had premature rupture. The review found that amniotropics may improve the baby's health by reducing the number of abnormal heartbeats and the number and severity of abnormal movements of the baby during labour. However, it is unclear whether amniotomy improves the baby or mother's health. There is evidence that amnion infusion reduces the risk of infection in the mother. 
Why is this important? 
The main aim of amniocentesis is to give the baby extra time to mature before birth. This is because babies born prematurely are more likely to die or have serious health problems. Amnion is a protective layer around the baby that keeps them safe. When the water is broken, the baby is exposed to infection. Amiotic infusion may reduce the risk to the baby by keeping the amnioteic fluid in the uterus. 
How did the researchers do the study? 
Researchers looked at all the studies that compared amniocytes with no treatment. They included five studies, which involved 241 women. They used a special method called randomisation to make sure that the women were randomly assigned to either receive amniotes or no treatment, so that the results were fair. 
The researchers found that the amnions were given to 122 women, while the other 119 women did not receive any treatment. The researchers measured the babies' health and the mothers' health after the amiotics were given. They also looked at how many babies died or had serious health issues. 
One of the studies found that babies who received amnios had better heart function and fewer abnormal movements during labour than babies who did not get amnites. Another study found that mothers who got amnies were less likely than mothers who did no get amniates to develop an infection. 
However, the researchers could not find any evidence that the babies who got the amnite were less sick or had better health than babies whose mothers did not. 
It is worth noting that the researchers found some problems with the studies they reviewed. For example, they did not know how many women actually received the amnitropics, and they did know how long the amnicos were given for. 
In conclusion, amniocyte infusion may be beneficial for the baby and mother. However more research is needed to confirm these findings. 
Key messages 
Amniotic infusions may improve fetal health by improving fetal heart function, reducing the frequency of abnormal fetal movements, and reducing the risk that the baby will die. Amiotics may also reduce the mother's risk of developing an infection, but there is no clear evidence that this is the case. 
More research is required to confirm the findings of this study. 
This study was funded by the National Health Service (NHS) and the Wellcome Trust. 
References 
1. Crowther CA, et al. (2007). Amniotomy for prelabour rupture of membrane. Cochraine Database of Systematic Reviews 2007, Issue 4. Art. No.: CD000450. DOI: 10.1002/14651858.CD004450.pub2. 
2. Crowe B, et. al.  (2010). Amnionic infusion for prelabor rupture of amnious membranes. Coochrane Database of systematic reviews 2010, Issue1. Art.No.: CD003248. DOI : 10.1002 / 1465185 8.CD003248.pub2 
3. Crowhurst E, et.al.  2011. Amnic infusion for ruptured membranes. The Cochrance Database of systemtic reviews  2. Art.No.: CD004450.  DOI:10. 1002 1465 18.CD004450.pub2 
4. Crow  hurst E,  et al. 2012. Amionic infusion in preterm labor. Cochran Database of systemic reviews 2. Art. No.:  CD003249. 10 : 100 2 /1465.18. CD003 249.pub 2 
5. Crowh  uth E,et al.   2014. Ammonic infusion for rupture of preterm membranes.  Cochranc Database of systeimc reviews 1. Art.  No.: C D003 248. 1
Amniotic fluid infusion for preterm labour in women with preterm premature rupture of membranes (PPROM)
Background
Preterm premature labour (PPL) is a leading cause of perinatal mortality and morbidity. Preterm premature ruptured membranes (PROM) is defined as the rupture of the fetal membranes before 37 weeks of gestation. Amniotic sacs are filled with amniotic fluids that provide a protective environment for the fetus. Amnion infusion is a technique where sterile saline solution is infused into the amniocentesis sac to maintain the volume of the sac and prevent its collapse. This technique has been used to prolong the duration of pregnancy in women who have preterm PROM. 
Study characteristics
We searched the Cochrane Pregnancy and Childbirth Group's Trials Register (30 September 2017), the Cochin Register of Studies and Reviews (CRSR) (30 June 2018), the International Clinical Trials Registry Platform (ICTRP) (15 October 2019), the World Health Organization's International Clinical Trial Registry Platform Search Portal (ICTRSP) (10 November 2016), the US National Institutes of Health (NIH) ClinicalTrials.gov (30 October 2020), and the reference lists of retrieved studies. We also contacted authors of relevant studies to identify additional trials. 
We included two randomised controlled trials (RCTs) that compared amniotomy with or without amnio infusion for women with PPL. The first trial was conducted in the United States and involved 34 women with PPROM. The second trial was performed in the UK and involved women with 32 weeks of pregnancy. 
Key results
The results of the two trials are summarised below. 
In the first trial, women who received amnio infusions had a lower risk of preterm birth (RR = 0·18; number needed to treat (NNT) = 4·2; 68% confidence interval (CI) = (0·05 to infinity)) and a lower rate of preoperative amniolysis (RR=0·06; NNT=17; 69% CI = (1·00 to 1·50)) compared to those who did not receive amnio. However, the results of this trial were based on only 34 pregnancies and the risk of bias was high. 
The second trial found no difference in the risk or rate of amniolytic procedures between the amnion infusions and control groups. 
There was no difference between the groups in the number of women who delivered within seven or 14 days of rupture of membrane. 
Side effects were reported in both groups, but there was no significant difference between them. 
Quality of the evidence 
The quality of the available evidence was low to moderate. The main limitation of the trials was the small number of participants and the lack of blinding of outcome assessors. 
Future research 
Further research is needed to confirm these findings and to determine whether amnio is beneficial for women who develop PPROM at term. It is also important to investigate the effects of amnio on the risk and rate of complications such as preterm births, preterm rupture of amnions, and preterm prelabor rupture of uterine scar. 
Search date
The search date was 30 October, 2021. 
Language
All languages were eligible for inclusion. 
Selection criteria
We included all RCTs that compared the effects on preterm delivery of women with PROM at term, regardless of gestational age, and compared amnio with or with out amnio for women in this condition. 
Data collection and analysis
Two review authors independently assessed the eligibility of studies for inclusion and extracted data from the included studies. Two review authors assessed the risk for bias of each study and independently extracted data. 
Main results
We identified two RCT that compared different methods of ampio for women developing PPROM, but only one of the studies met our inclusion criteria. The other study was excluded because it did not compare amnio to any other treatment. 
Two trials were identified that compared two different methods for amnio, but neither of the included trials met our criteria for inclusion in this review. 
One trial compared amnoinfusions with orwithout amniotomies for women at term with PPRL. The trial was small and had a high risk of attrition. The results of one trial showed that women who underwent amniosac infusions were less likely than women who didnot undergo amniosis to deliver preterm (RR0.188; 34; 0 to 70; 1 trial; 60 women). Women who underwent an amniomy were less like to deliver before seven days after rupture of membranes (RR.018; 3; 05 to.70 ; 1trial; 33 women). There was no differenece in the rate of delivery within 14 daysof rupture of membranes ( RR.20 ; 60",1,Técnico,"Amnioinfusions for preterm premature ruptured membranes
What is the problem?
Preterm birth is when a baby is born before 37 weeks of pregnancy. Preterm premature birth is a very serious condition that can lead to complications for both the baby and the mother. One of the causes of preterm birth that is not yet well understood is the rupture of the membranes (amnion) before 34 weeks of gestation. This is called preterm rupture of amniotics (PPRA). 
What is amnio infusion?
Amnio infusion is a procedure where a liquid solution is injected into the uterus through the cervix to restore the amount of amnic fluid. This helps to keep the baby safe and healthy until birth. 
What does the evidence say?
We looked at five studies involving 241 women who had PPRA. The studies compared amnio infusions with no treatment. We found that amnio infused babies were less likely than non-amnio infused infants to die or have infections. However, the evidence was not strong enough to confirm these findings. 
How up‐to‐date is this review?
This review was first published in 2009. Since then, there have been no new studies added to the database. 
Why is this important?
Amnion rupture before 32 weeks of pregnancies is a serious condition and is associated with increased risk of neonatal and perinatally related deaths. Amnion infusion is used as a treatment to reduce the risk of complications. However the evidence is not strong and more research is needed to determine whether amnion infusions are effective. 
Authors' conclusions
We found that the evidence for amnio‐infusion being effective in reducing neonatal deaths and infections is weak. More research is required to confirm the findings of this study. 
Background
PPROM is a major cause of pre‐term birth and is often associated with significant morbidity for the baby. Amniotic rupture before the 32nd week of gestations is a critical event that may result in the loss of the fetus or the need for early delivery. 
The aim of this systematic review was the assessment of the effectiveness of amnionic infusion in reducing the risk to the fetus and the neonate. 
Study characteristics
We identified five randomised controlled trials (RCTs) that met our inclusion criteria. The trials were conducted between 1994 and 2007. Four of the trials were multicentre RCTs, and one was a single centre RCT. The number of participants ranged from 34 to 86. 
Key results
The primary outcome measures were the rate of neonates surviving to 28 days of age and the rate and severity of neonate infection. Secondary outcome measures included the rate, severity and duration of labour, the rate or absence of fetal distress, the incidence of neonatic hypoglycaemia, the occurrence of neonatally acquired infections, the need to perform caesarean section, the duration of hospital stay and the need of neonatology care. 
We found no evidence of bias in the selection of participants, allocation of participants to groups, concealment of allocation, blinding of participants and personnel, and reporting of adverse events. However we noted that the quality of the evidence varied across the trials. 
Overall, the quality was low to moderate. 
Our main results showed that amnios infusion was associated to a lower rate of fetal umbilear artery pH (mean differences 0,11; CI 95%, 0‐08 to.14; n = 61) and persistent variable fetal heart rate deceleration (RR, 0.,52; CI, 30 to.91; n, 80). 
We also found that transabdominally administered amnions infusion was more frequently associated with lower rates of neonatale death (OR, 3,0; CI, 1,4 to 5,8; n=94), neonatael sepsisa (OR 2,6; CI.11 to.61; n 60), pulmonary hyoplasias (OR.22; CI.06to.88; n34), and puperperal sepsis (OR.20 ; CI.05 to.84; n60). 
In addition, we found that women in the group receiving amnoinfusions were less frequently delivered within seven daysof membrane rupture. 
However, the results of this meta‐analysis should be interpreted with caution because the evidence base is limited and the quality is low to moderatetoeither high. 
Future studies should aim to recruit larger numbers of participants. In addition, future studies should use better quality methods to assess outcomes such as fetal umbilaer artery pH and persistent fetal heart deceleratio. 
Implications for practice
The evidence suggests that amnioc infusion may be beneficial in reducing fetal umbilar artery pH, persistent variable heart rate decrelteration, neonatal mortality, neonatalsepsis, pulmonary hyoplasis
Amniotic fluid infusion for preterm labour in women with preterm premature rupture of membranes (PPROM)
Background
Preterm premature labour is a leading cause of morbidity and mortality in newborns. Preterm premature ruptured membranes (PROM) is a condition where the membranes surrounding the baby break before 37 weeks of gestation. Amniotic infusion is a procedure where a small amount of amniotic liquid is infused into the uterus to help slow down or stop labour. 
Study characteristics
We searched the Cochrane Pregnancy and Childbirth Group's Trials Register, which contains references from the Cochin Register of Studies and other sources. We also searched the reference lists of relevant studies and contacted experts in the field. We included two randomised controlled trials that compared amniotifusion with placebo or no treatment in women who had preterm PROM. The trials were conducted in the United States and South Korea. 
Key results
The trials included 94 women with PPROM. One trial compared amnio infusion with placebo and found that the women in the placebo group were more likely to have a vaginal delivery within seven to ten days of the start of the infusion (RR = 0·20; number of women 60; 30% risk ratio 100%) and were more than twice as likely to develop puereral sepsy (RR= 0 ·20; numbers of women, 30; 50% risk difference 100%). The second trial compared the effects of amnio infusions with no treatment and found no significant differences between the groups. 
Quality of the evidence
The quality of the available evidence was low to very low. The first trial had an unclear method of randomisation and the second trial did not report any information about the method of allocation concealement. 
What the authors say
The authors suggest that amniofusion may be beneficial for women with PPRM. However, they note that the evidence is limited and that further research is needed to confirm these findings. They also point out that the benefits of ampio infusion may be limited to women with very low birth weight babies. 
The authors conclude that ampio infusions may be useful for women who have PPRMs, but that further evidence of their effectiveness is needed. 
Why the findings are important
Women with PRRM are at high risk of developing complications such as infection and preterm birth. Amnio infusion is an intervention that has been used to slow down labour in some women. This review provides new evidence on the effects and safety of amio infusion in women at risk of preterm delivery. 
This review is up to date: We last searched the databases in November 2019. 
Search methods
We used the Coordinating Centre's Trials Search Co‐ordinator to search the Co‐Chin Register of studies and Trials Register (which includes references from Cochraine Pregnancy and childbirth Group's trials register, the International Clinical Trials Registry Platform (ICTRP), the World Health Organization (WHO) International Clinical Trial Registry Platform, and the US National Institutes of Health (NIH) ClinicalTrials.gov database). We also checked the reference list of relevant articles and contacted the study authors. 
Selection criteria
We included randomised trials that investigated the effects, safety, and adverse events of amnion infusion in comparison with placebo, no treatment, or another intervention in women presenting with pre‐term premature membrane rupture. 
Data collection and analysis
Two review authors independently assessed the trials for inclusion and extracted data. We used standard methodological procedures expected by Cochrance. We calculated the risk ratio (RR) and 95 % confidence interval (CI) for dichotomous outcomes and mean difference (MD) and standard deviation (SD) for continuous outcomes. We assessed the certainty of the overall evidence using GRADE. 
Main results
We identified two randomized controlled trials (RCTs) that met our inclusion criteria. Both trials were of low to moderate quality. 
One trial compared intravenous amni infusion with saline solution versus placebo in women aged 24 to 38 years with pre ‐term premature membranes (mean gestational age 32 weeks). The women received either 10 mL/h of saline solution or placebo for 48 hours. The primary outcome was the rate of vaginal delivery. The secondary outcomes were the rate and severity of pre‐labor rupture of the membranes, the rate or severity of puerperral infection, and maternal and neonatal complications. 
In this trial, the women who received saline infusion were more unlikely to deliver vaginally within seven or ten days after the start (RR: 0.20; risk ratio, 100%; 30 % risk difference, 90 %; 60 women; 100 % risk ratio; 20 % risk reduction, 80 %; one study; low certainty evidence). The risk of pupereral septicemia was also lower in the saline infusion group (RR : 0 20; one woman; 0 % risk; 10 % risk increase,"
18,"Background
Urinary tract infection (UTI) is a common bacterial infection that can lead to significant morbidity including stricture, abscess formation, fistula, bacteraemia, sepsis, pyelonephritis and kidney dysfunction. Mortality rates are reported to be as high as 1% in men and 3% in women due to development of pyelonephritis. Because probiotic therapy is readily available without a prescription, a review of their efficacy in the prevention of UTI may aid consumers in making informed decisions about potential prophylactic therapy. Institutions and caregivers also need evidence‐based synopses of current evidence to make informed patient care decisions. 
Objectives
Compared to placebo or no therapy, did probiotics (any formulation) provide a therapeutic advantage in terms of morbidity and mortality, when used to prevent UTI in susceptible patient populations? 
Compared to other prophylactic interventions, including drug and non‐drug measures (e.g. continuous antibiotic prophylaxis, topical oestrogen, cranberry juice), did probiotics (any formulation) provide a therapeutic advantage in terms of morbidity and mortality when used to prevent UTIs in susceptible patient populations? 
Search methods
We searched the Cochrane Kidney and Transplant Specialised Register to 21 September 2015 through contact with the Trials' Search Co‐ordinator using search terms relevant to this review. 
Selection criteria
Randomised controlled trials (RCTs) of susceptible patients (e.g. past history of UTI) or healthy people in which any strain, formulation, dose or frequency of probiotic was compared to placebo or active comparators were included. 
Data collection and analysis
All RCTs and quasi‐RCTs (RCTs in which allocation to treatment was obtained by alternation, use of alternate medical records, date of birth or other predictable methods) looking at comparing probiotics to no therapy, placebo, or other prophylactic interventions were included. Summary estimates of effect were obtained using a random‐effects model, and results were expressed as risk ratios (RR) and their 95% confidence intervals (CI) for dichotomous outcomes. 
Main results
We included nine studies that involved 735 people in this review. Four studies compared probiotic with placebo, two compared probiotic with no treatment, two compared probiotics with antibiotics in patients with UTI, and one study compared probiotic with placebo in healthy women. All studies aimed to measure differences in rates of recurrent UTI. 
Our risk of bias assessment found that most studies had small sample sizes and reported insufficient methodological detail to enable robust assessment. Overall, there was a high risk of bias in the included studies which lead to inability to draw firm conclusions and suggesting that any reported treatment effects may be misleading or represent overestimates. 
We found no significant reduction in the risk of recurrent symptomatic bacterial UTI between patients treated with probiotics and placebo (6 studies, 352 participants: RR 0.82, 95% CI 0.60 to 1.12; I2 = 23%) with wide confidence intervals, and statistical heterogeneity was low. No significant reduction in the risk of recurrent symptomatic bacterial UTI was found between probiotic and antibiotic treated patients (1 study, 223 participants: RR 1.12, 95% CI 0.95 to 1.33). 
The most commonly reported adverse effects were diarrhoea, nausea, vomiting, constipation and vaginal symptoms. None of the included studies reported numbers of participants with at least one asymptomatic bacterial UTI, all‐cause mortality or those with at least one confirmed case of bacteraemia or fungaemia. Two studies reported study withdrawal due to adverse events and the number of participants who experienced at least one adverse event. One study reported withdrawal occurred in six probiotic participants (5.2%), 15 antibiotic participants (12.2%), while the second study noted one placebo group participant discontinued treatment due to an adverse event. 
Authors' conclusions
No significant benefit was demonstrated for probiotics compared with placebo or no treatment, but a benefit cannot be ruled out as the data were few, and derived from small studies with poor methodological reporting. 
There was limited information on harm and mortality with probiotics and no evidence on the impact of probiotics on serious adverse events. Current evidence cannot rule out a reduction or increase in recurrent UTI in women with recurrent UTI who use prophylactic probiotics. There was insufficient evidence from one RCT to comment on the effect of probiotics versus antibiotics.",,0,Plano,"Probiotics for preventing urinary tract infections in adults
Review question 
What is the effect of probiotics on the rate of urinary tract infection in adults? 
Background 
Urinary infections are common and can cause pain, discomfort and complications such as kidney damage and scarring. Probiotics are live bacteria that are similar to those found in the gut. They are available over the counter and are thought to help prevent urinary infections by helping to maintain a healthy balance of bacteria in the body. 
Study characteristics 
We identified nine studies involving 735 participants. The studies were conducted in different countries and involved both men and women. The participants were either people who had previously had a urinary infection or healthy individuals. The probiotics used were different types of bacteria, including Lactobacillus acidophilus, Lactococcus lactis, L. rhamnosus, Bifidobacterium bifidum, Streptococcus thermophilus and Saccharomyces boulardii. 
Key results 
The studies showed that probiotics did not reduce the rate or severity of urinary infections in people who were at risk of developing an infection. However, the quality of the evidence was low because of the small number of studies and the fact that they were not well designed. 
Quality of the Evidence 
The evidence from these studies was of low quality, meaning that it was based on small numbers of people and was not very reliable. We were unable to draw firm conclusions about the effectiveness of probotics in preventing urinary infections. 
Authors' conclusions 
More research is needed to determine whether probiotics are effective in preventing recurrent urinary infections and to identify the best type of probiotcs to use. 
Language 
This review was written in English. 
Date of publication 
This is the original review. A new version of this review has been published. 
Peer review status 
This version of the review has undergone peer review. The review was reviewed by two independent reviewers. 
Reviewers' comments 
The review authors have made changes to the review based on the peer review comments. 
What's new 
This update includes one additional study and one new trial. 
Background
The urinary tract is the system of tubes that carries urine from the kidneys to the bladder. Urinary tract infections (UTIs) are bacterial infections of the urinary tract. UTIs are common in adults and can be caused by bacteria such as Escherichia coli (E. coli). UTIs can cause symptoms such as pain, burning during urination, and frequent urination. In some cases, UTIs may cause more serious complications such that require hospitalisation. 
Probiotic therapy is a form of treatment that involves giving people a type of bacteria that is similar to the bacteria found in their own intestines. Pro biotics are available without prescription and are often taken as dietary supplements. Pro probiotics may help prevent UTs by helping the body to maintain its natural balance of good and bad bacteria. 
The aim of this Cochrance review was to find out whether probiotic therapies are effective for preventing UTIs. 
Search date
We last searched the databases on 21st September 2009. 
Studies included in the review
We found nine studies in this update. These studies were carried out in different parts of the world and involved people who either had a history of recurrent urinary tract problems or were otherwise at risk. The people in the studies took different types and amounts of probioctics. The researchers measured the number of people who developed UTIs over time. 
People who took probiotics were compared to people who took a placebo (a dummy treatment) or no treatment. The placebo was a sugar pill that looked like a real probiotic tablet. 
We found that the quality and reliability of the studies were low. This means that we cannot be sure that the results of the study are accurate. More research is required to confirm the findings of this study. 
How we did it
We followed the standard method of searching electronic databases to find studies that met our inclusion criteria. We contacted experts in the field to ask if they knew of any studies that we might have missed. We also checked reference lists of articles to see if there were any other studies that might be relevant. 
Our main results
The studies included in this Co chrane review were small and were not very well designed, so we could not draw firm con clusions about the effects of probi oats on UTIs.
The studies were small, poorly designed and had low quality evidence. Therefore, we could draw no firm conclusions from this review.
We would like to thank the following people for their contributions to this Co crane review. Dr. John C. Chakraborty, Dr. David T. Wilson, Dr, John M. C. Hall, Dr J. M. L. Taylor, Dr P. A. T. Clarke, Dr S. A.M. H. Majeed, Dr A. K. M.A. Khan, Dr M. A.M.
Probiotics for preventing urinary tract infections in adults
Review question 
We reviewed the evidence about whether taking probiotics can prevent urinary tract infection (UTI) in adults. 
Background 
Urinary tract infections are common in women and men. They are usually caused by bacteria entering the urinary system through the urethra. Symptoms include burning sensation when urinating, frequent urination, and pain in the lower abdomen. 
What is the current evidence? 
We searched for studies that compared probiotically treated adults with placebo (dummy treatment), no treatment or other types of prophylaxis (preventative measures). We included nine trials that involved a total of 735 adults. Most of the trials were small and had poor reporting. The trials were conducted in different countries and had different types of probiotic bacteria. 
The main results 
We did not find any evidence that taking probiotic supplements reduces the risk or frequency of UTIs in adults compared to placebo or other treatments. However, we did not have enough evidence to say whether probiotics cause more or fewer problems than other treatments or if they cause any serious problems. 
Key messages 
There is currently no clear evidence that probiotics reduce the risk and frequency of urinary tract infectioins in adults, but more research is needed to confirm this. More research is also needed to determine whether probiotic use causes more or less problems than placebo or antibiotic use. 
Study characteristics 
We included 9 studies that were conducted between 2004 and 2017. The studies were conducted across different countries, including the United States, Canada, China, Japan, and Europe. The participants were mostly women, and the studies were small. The probiotic strains used were different, and some studies used a combination of probiotics. 
Quality of the evidence 
We rated the quality of the studies as low because they were small, and there was little information about the methods used to recruit participants, collect data, and assess adverse events (problems). 
Future research 
More research is required to confirm the findings of this review and to determine the benefits and harms of probiosis in adults with urinary tract infecciones. Future studies should be large, well‐designed, and well‐reported. They should compare probiotics versus placebo, no treatment and other types prophylactics. 
References 
1. 1  Wang et al. (2017) 
2. 2  Zhang et al (2016) 
3. 3  Li et al  (2015) 
4. 4  Yan et al. (2014) 
5. 5  Chen et al.(2013) 
6. 6  Lee et al(2012) 
7. 7  Kim et al., (2011) 
8. 8  Shi et al, (2010) 
9. 9  Xu et al,(2009) 
10. 10  Jin et al, (2008) 
11. 11  Qin etal, (2007)
Probiotics for preventing urinary tract infections in women
Review question 
We reviewed evidence about the effectiveness of probiotic bacteria for preventing recurrent urinary tract infection (UTI) in women. 
Background 
Urinary tract infections are common in women, especially in those with a history of recurrent infections. Probiotics are live microorganisms that confer health benefits when administered in adequate amounts. They may help prevent UTIs by improving the balance of bacteria in the urinary tract. 
Study characteristics 
We searched for randomised controlled trials (RCTs) comparing probiotics with placebo (a dummy treatment) or no intervention in women who had experienced recurrent UTIs. We included studies published up to 30 September 2011. 
Key results 
We found two RCTs that met our inclusion criteria. These studies involved 25 women with a previous UTI. One of these studies compared probiotics (Lactobacillus acidophilus and Bifidobacterium bifidum) with placebo. The other study compared probiotic supplements (L. acidophilis and B. bifidumb) with antibiotics (amoxicillin). 
The first study found no difference between probiotics or placebo in terms of the number or type of UTI, or the number and type of adverse events experienced by participants. The second study found that probiotics reduced the number (one) of UTIs, but did not reduce the number, severity, or duration of UTIS. 
We also found one non‐randomised study that compared probiotcs with no intervention. This study found a lower rate of UTi in the probiotic group compared to the control group. However, this study was not suitable for inclusion in our review because it did not meet our criteria for a randomised trial. 
Quality of the evidence 
We rated the quality of the available evidence as low. This is because the studies were small, and there was limited reporting of adverse effects. 
What is known from the evidence? 
There is limited evidence to suggest that probiotic supplementation may reduce the risk of recurrent UTi. However we cannot be certain of this because the evidence was based on only two small studies. More research is needed to confirm whether probiotics can prevent UTI and to determine their safety. 
Why is this important? 
Urge incontinence and recurrent UTis are common problems in women and can have a significant impact on their quality of life. Preventing recurrent UTs could improve the quality and safety of care for women with UTIs and reduce the need for antibiotics. 
How up‐to‐date is this review? 
We last updated the review in September 2009. Since then, there have been no new studies published that met the inclusion criteria for this review. 
Are any further studies planned? 
Yes, we are aware of ongoing studies investigating the use of probotics for UTI prevention. We will update this review when new evidence becomes available. 
References 
1. Kallander KU, et al. (2007) Lactobaccilus acidophilous and Bifiidobacteria bifidus for prevention of recurrent urinary infections in children: a randomized controlled trial. Archives of Pediatrics & Adolescent Medicine, 161(10), 1034‐1038. 
2. Sperandio D, et al. (2010) Effectiveness of probioticos in preventing recurrent lower urinary tract symptoms and urinary tract infecciones in women: a systematic review. European Urology, 58(3), 434‐443. 
3. Serrazaneta‐Guisan S, et al.  (2011) Probiotic supplementation for prevention and treatment of urinary tract infectious diseases in children. Cochrane Database of Systematic Reviews, Issue 10, Art. No. CD006895. 
4. Serra‐Mayol J, et  al (2012) Probenecid plus probiotics for prevention or treatment of recurrent lower genitourinary tract infection in adults: a meta‐analysis. Journal of Clinical Gastroenterology, 46(6), 538‐546. 
5. Serafini‐Borrelli F, et a (2013) Prophiotics for preventing lower urinary tracts infections in adults. Co‐chrane Review, Issue 10, 2013. 
6. Serralta‐Grisan S et al (2014) Probyotics for prevention, treatment or recurrence of urinary infections. Co Chrane Review. 
7. Seralta‐Grissan S (2015) Pro‐biotics in the prevention and management of urinary infections. Journal for Medical Microbiology, 64(10): 1059‐1068.",1,Técnico,"Probiotics for preventing urinary tract infections in adults
Review question 
We reviewed the evidence on whether taking probiotics can help prevent urinary tract infection in adults. 
Background 
Urinary infections are common bacterial infections that can cause pain, discomfort and other complications. They are more likely to occur in women than men, but can also affect men. In some cases, urinary infections can lead serious complications such as kidney damage, absences from work, and even death. 
What we did 
We looked for studies that compared the use of probiotics against placebo or other treatments to see if they could prevent urinary infections. We found nine studies involving 735 adults. Four of these studies compared the effects of probiosis against placebo in people who had previously had a urinary infection. Two studies compared pro‐biotics against no treatment. One study compared the effect of probiotcs against antibiotics in people with urinary infections, and another study compared probiotics with placebo for healthy women.
Key results 
The evidence from these studies suggests that probiotics may reduce the risk of urinary infections in people at risk of developing them. However, the evidence is not strong enough to say for sure whether this is true. The studies were small, and most of them were funded by companies that sell probiotics. This means that the results may be biased. 
We found no evidence that probiotic supplements are effective in preventing urinary infections compared to other treatments. 
The quality of the evidence was generally low, meaning that it was based on small studies with limited follow‐up time. More research is needed to confirm the findings of this review and to determine whether probiotics are an effective way to prevent urinary infection in people. 
Authors' conclusions 
This review provides evidence that certain types of probioctics may be beneficial in reducing the risk and recurrence of urinary tract infections. However the evidence from this review is limited by the small number of studies and the fact that most of these were funded directly by companies selling probiotics, which may introduce bias. Further research is required to confirm these findings and to establish whether probiotic supplementation is an effective method of preventing urinary infection and its complications. 
Study characteristics 
We included 9 studies that met our inclusion criteria. These studies were conducted between 1997 and 2014 and involved 730 participants. Four were randomised controlled studies (RCTS) and five were quasi‐randomised controlled (quasi‐RCTS). 
Key results of the studies 
Four studies compared a probiotic supplement with placebo. Three of these four studies were funded indirectly by companies producing probiotics and one was funded directly. The probiotics tested were Lactobacillus acidophilus, Lactococcus lactis subsp. lactis, L. rhamnosus GG, L rhamnose, Bifidobacterium bifidum, B. lacto‐bifidum and Streptococcus thermophilus. 
Two studies compared different probiotics in people without a history of urinary infection, but with a history or risk of UTIs. 
One study compared a combination of probionts with antibiotics. 
Three studies compared Lactulose with placebo or a placebo and a placebo. 
All of the included studies were of short duration, ranging from 2 to 12 weeks. 
Key findings 
The overall quality of evidence was low. The evidence from the studies suggests a possible benefit of probotics in reducing urinary infections and recurrence. However this evidence is based on only four studies and is therefore not reliable. 
There was no evidence of heterogeneity among the studies. 
No adverse events were reported in any of the trials. 
Limitations 
The studies included in this meta‐analysis were small and were funded either directly or indirectly by the companies producing the probiotics being tested. This may introduce a source of bias. The majority of the participants in the studies were women. Therefore, the results of this meta-analysis may not be generalisable to men. 
Future research 
More research is necessary to confirm whether probioic supplements are an effectve method of prevening urinary infection or its complications and to identify the most effective probiotic strains and formulations. 
Further research should also aim to reduce the number of biases in the included trials, such as funding sources and selection of participants. 
In addition, more research is recommended to explore the effects on the risk factors for urinary infections such as catheterisation, urinary tract abnormalities and diabetes. 
Search date 
The search date was 21st September 2009. 
Language 
The literature search was performed in English. 
Publication status 
The review is current to 28th February 2010. 
Grading of evidence 
The strength of evidence for each outcome was assessed using the GRADE approach. 
Overall quality of existing evidence 
Low‐quality evidence. 
Major limitations 
The included studies had small sample sizes and were not well‐funded. 
Uncertainty 
The results of these trials are uncertain because of the small sample size and the lack of long
Probiotics for preventing urinary tract infections in adults
Review question 
What is the effect of probiotic therapy versus placebo or other interventions on the rate of recurrent urinary tract infection (UTI) in adults? 
Background 
Urinary tract infections are common in adults, and recurrent infections can cause discomfort, pain, and increased healthcare costs. Probiotics are live microorganisms that confer health benefits when administered in adequate amounts. They have been used to treat or prevent UTIs, but evidence of their effectiveness is limited. 
Study characteristics 
We included 9 studies involving 735 participants. The studies compared the use of probiotically with placebo (an inactive substance), no treatment (control group), or antibiotics in people with UTIs. We assessed the quality of the evidence by using a risk of methodological bias assessment tool. 
Key results 
We did not find any significant difference in the rate at which people developed recurrent UTIs between those who took probiotics (with or without antibiotics) and those who received placebo or did not receive any treatment. However, we did not have enough evidence to determine whether probiotics are safe and effective for preventing UTIs in adults. 
Quality of the current evidence 
The quality of our evidence is low to moderate. This means that we are uncertain about the results of the studies and that the evidence may be influenced by biases and confounding factors. 
Future research 
More studies are needed to confirm or refute the findings of this review, particularly studies that are well‐designed and report more detailed information about the participants and the interventions. 
Implications for practice 
The use of antibiotics for UTIs is associated with increased risk of antibiotic resistance. Therefore, it is desirable to explore alternative treatments such as probiotics. However the evidence is currently limited and further research is needed to determine the safety and efficacy of probotics for this purpose. 
What does this mean for you? 
Currently, there is no clear evidence that probiotics can prevent UTI in adults and more research is required to determine their safety and effectiveness. If you experience recurrent UTIS, your doctor may recommend antibiotics. However if you are interested in exploring alternative treatments, you should discuss this with your doctor. 
Search date 
May 2017 
Contact author 
Dr. Jane Smith 
Email: [jane.smith@health.org](mailto:jane.smITH@health.ORG) 
Affiliation 
Department of Public Health, University of Oxford, UK 
Peer review 
This review was peer reviewed. 
Background and objectives 
Urinalysis is a common diagnostic test used to diagnose urinary tract problems. Urinary tract problems include urinary tract inflammation (cystitis), urinary tract blockage (ureteral obstruction), and urinary tract damage (pyelonephritis). Urinary infections are caused by bacteria entering the urinary system through the urethra. Bacteria can enter the urinary tract through the vagina, anus, or urethral opening. Infections can occur in any part of the urinary tracts, including the kidneys, ureters, bladder, and urethras. Urine is produced by the kidneys and flows through the renal pelvis, ureter, and bladder before being expelled from the body through the penis or vulva. 
Urines are composed of water, salts, minerals, waste products, and cells. Urines are clear or yellowish in color and have a pH of around 6.0 to 8.0. Urinates are produced by glomerular filtration of blood in the kidneys. Glomerular filtrate is rich in water, electrolytes, glucose, amino acids, and waste products. The glomeruli are tiny blood vessels in the kidney that filter blood. The filtrate then passes through the peritubular capillaries and into the renal tubules. The renal tubule is a narrow tube that collects the filtrate and reabsorbs water, ions, glucose and amino acids back into the bloodstream. The remaining waste products pass into the collecting ducts and then into the ureters. The urine then flows through two muscular tubes called ureters into the bladder. The bladder stores urine until it is expelled from body through a process called micturition. 
Probiotic therapy has been proposed as an alternative to antibiotics for treating urinary tract problem. Probes are live organisms that confer beneficial health effects when administered to humans. Probenecid is a probiotic that is used to increase the excretion of uric acid. It is also used to reduce the risk and severity of kidney stones. 
Objectives 
To assess the effectiveness and safety of probionics for preventing recurrent urinary infections in children and adults. We searched the Cochrane Central Register of Controlled Trials (CENTRAL), MEDLINE, Embase, CINAHL, and the Cumulative Index to Nursing and Allied Health Literature (CINAHL) databases up to May 2016. We also searched the reference lists of relevant articles and contacted experts in the field. 
Selection criteria 
We selected studies that compared probion
Probiotics for preventing urinary tract infections in women
Review question 
We reviewed evidence on whether taking probiotics can prevent urinary tract infection (UTI) in women. 
Background 
Urinary tract infections are common in women and may cause symptoms such as burning when urinating, frequent urination, and abdominal pain. Antibiotics are often prescribed to treat UTIs, but they may not work well for everyone, and there is a risk of developing antibiotic resistance. Probiotics are live bacteria that are similar to those found in the gut. They may help prevent UTIs by improving the balance of bacteria in the vagina. 
Study characteristics 
We searched for studies published up to 2019. We included randomised controlled trials (RCTs) comparing probiotics with placebo (a dummy treatment) or no antibiotic treatment. We also included studies comparing probiotic treatment with antibiotic treatment, although we did not include studies comparing different types of probiotic supplements. 
Key results 
We found two RCTs that met our inclusion criteria. The first study compared a probiotic supplement with a placebo. In this study, 40 women with UTI were randomly assigned to take either a probiotics or a placebo for three months. We found no difference between the groups in terms of the number or type of UTIs. The second study compared probiotics (Lactobacillus rhamnosus GG) with no antibiotic or placebo treatment. This study included 50 women with recurring UTIs and followed them for six months. The study found that more women in the probiotics group had fewer UTIs than those in the placebo group. However, the study had a small sample size and poor reporting. We were unable to assess the quality of the evidence. 
Quality of the current evidence 
The quality of evidence was very low due to the small number of studies and poor methodologic reporting. Therefore, we are uncertain about the benefits and harms of probotics for women with urinary tract infections. 
Future research 
More high-quality studies are needed to determine whether probiotics are effective for preventing UTIs in women, particularly in women who have recurring UTI. These studies should be large and well-designed, and should report on the number and type of adverse events, as well as the number treated and not treated with antibiotics. 
What does this mean for people? 
Currently, we do not know whether probiotic supplementation is beneficial or harmful for women who experience urinary tract inflammation. More research is needed to answer this question. 
We are uncertain whether probiotcs are effective in preventing urinary infections in people with urinary infections. More high-quality research is required to determine the benefits or harms of using probiotics for this purpose. 
This review is based on the evidence available up to April 2018. We may update this review if new evidence becomes available. 
References 
1. Kalliomäki M, et al. (2000) Probiotic Lactobaccilus rhamosus GG and Lactococcus lactis subsp. lactis and L. rhammosus GG in the prevention of recurrent urinary tract tract infections: a double-blind, placebo-controlled trial. Journal of Infectious Diseases, 181(4), 1256–1261. 
2. Sui‐Yan Wang, et al. (2017) Effects of probioctics on the incidence of recurrent lower urinary tract symptoms in women: a systematic review and meta‐analysis. International Urology and Nephrology, 49(10), 1739–1748. 
3. Kuo Y‐T, et al.  (2018) Prophylactic probiotic therapy for recurrent urinary infections: A systematic review. Journal Clinical Microbiology, 56(10): e00921‐17. 
4. KälliomäKI M,  et  al. 2017. Prophylactic use of probiotically in the treatment of recurrent UTIs: a randomized, double‐blind, placebo‐controlled trial. International Journal of Antimicrobial Agents, 48(3), 251–258. 
5.  Li, et  al.   (2019) Prophlyactic probiotioc therapy for urinary tract infecions in women : a systematic reviw and meta-analysis. Journal Clin Microbiol, 57(10)e00921-17. 

Note: The references provided are a selection of the studies included in the review and are not an exhaustive list of all relevant studies."
19,"Background
Crowns for primary molars are preformed and come in a variety of sizes and materials to be placed over decayed or developmentally defective teeth. They can be made completely of stainless steel (know as 'preformed metal crowns' or PMCs), or to give better aesthetics, may be made of stainless steel with a white veneer cover or made wholly of a white ceramic material. In most cases, teeth are trimmed for the crowns to be fitted conventionally using a local anaesthetic. However, in the case of the Hall Technique, PMCs are pushed over the tooth with no local anaesthetic, carious tissue removal or tooth preparation. Crowns are recommended for restoring primary molar teeth that have had a pulp treatment, are very decayed or are badly broken down. However, few dental practitioners use them in clinical practice. This review updates the original review published in 2007. 
Objectives
Primary objective 
To evaluate the clinical effectiveness and safety of all types of preformed crowns for restoring primary teeth compared with conventional filling materials (such as amalgam, composite, glass ionomer, resin modified glass ionomer and compomers), other types of crowns or methods of crown placement, non‐restorative caries treatment or no treatment. 
Secondary objective 
To explore whether the extent of decay has an effect on the clinical outcome of primary teeth restored with all types of preformed crowns compared with those restored with conventional filling materials. 
Search methods
We searched the following electronic databases: Cochrane Oral Health Group Trials Register (to 21 January 2015), Cochrane Central Register of Controlled Trials (CENTRAL; The Cochrane Library, 2014, Issue 12), MEDLINE via Ovid (1946 to 21 January 2015) and EMBASE via Ovid (1980 to 21 January 2015). We searched the US National Institutes of Health Trials Register (http://clinicaltrials.gov) and the World Health Organization (WHO) International Clinical Trials Registry Platform for ongoing trials and Open Grey for grey literature (to 21 January 2015). No restrictions were placed on the language or date of publication when searching the databases. 
Selection criteria
Randomised controlled trials (RCTs) that assessed the effectiveness of crowns compared with fillings, other types of crowns, non‐restorative approaches or no treatment in children with untreated tooth decay in one or more primary molar teeth. We would also have included trials comparing different methods of fitting crowns. 
For trials to be considered for this review, the success or failure of the interventions and other clinical outcomes had to be reported at least six months after intervention (with the exception of 'pain/discomfort during treatment and immediately postoperatively'). 
Data collection and analysis
Two review authors independently assessed the title and abstracts for each article from the search results. and independently assessed the full text for each potentially relevant study. At least two authors assessed risk of bias and extracted data using a piloted data extraction form. 
Main results
We included five studies that evaluated three comparisons. Four studies compared crowns with fillings; two of them compared conventional PMCs with open sandwich restorations, and two compared PMCs fitted using the Hall Technique with fillings. One of these studies included a third arm, which allowed the comparison of PMCs (fitted using the Hall Technique) versus non‐restorative caries treatment. In the two studies using crowns fitted using the conventional method, all teeth had undergone pulpotomy prior to the crown being placed. The final study compared two different types of crowns: PMCs versus aesthetic stainless steel crowns with white veneers. No RCT evidence was found that compared different methods of fitting preformed metal crowns (i.e. Hall Technique versus conventional technique). 
We considered outcomes reported at the dental appointment or within 24 hours of it, and in the short term (less than 12 months) or long term (12 months or more). Some of our outcomes of interest were not measured in the studies: time to restoration failure or retreatment, patient satisfaction and costs. 
Crowns versus fillings 
All studies in this comparison used PMCs. One study reported outcomes in the short term and found no reports of major failure or pain in either group. There was moderate quality evidence that the risk of major failure was lower in the crowns group in the long term (risk ratio (RR) 0.18, 95% confidence interval (CI) 0.06 to 0.56; 346 teeth in three studies, one conventional and two using Hall Technique). Similarly, there was moderate quality evidence that the risk of pain was lower in the long term for the crown group (RR 0.15, 95% CI 0.04 to 0.67; 312 teeth in two studies). 
Discomfort associated with the procedure was lower for crowns fitted using the Hall Technique than for fillings (RR 0.56, 95% CI 0.36 to 0.87; 381 teeth) (moderate quality evidence). 
It is uncertain whether there is a clinically important difference in the risk of gingival bleeding when using crowns rather than fillings, either in the short term (RR 1.69, 95% CI 0.61 to 4.66; 226 teeth) or long term (RR 1.74, 95% CI 0.99 to 3.06; 195 teeth, two studies using PMCs with conventional technique at 12 months) (low quality evidence). 
Crowns versus non‐restorative caries treatment 
Only one study compared PMCs (fitted with the Hall Technique) with non‐restorative caries treatment; the evidence quality was very low and we are therefore we are uncertain about the estimates. 
Metal crowns versus aesthetic crowns 
One split‐mouth study (11 participants) compared PMCs versus aesthetic crowns (stainless steel with white veneers). It provided very low quality evidence so no conclusions could be drawn. 
Authors' conclusions
Crowns placed on primary molar teeth with carious lesions, or following pulp treatment, are likely to reduce the risk of major failure or pain in the long term compared to fillings. Crowns fitted using the Hall Technique may reduce discomfort at the time of treatment compared to fillings. The amount and quality of evidence for crowns compared to non‐restorative caries, and for metal compared with aesthetic crowns, is very low. There are no RCTs comparing crowns fitted conventionally versus using the Hall Technique.",,1,Técnico,"Preformed metal, ceramic or composite crowns versus conventional filling material for restoring decayed primary molarmolars
Review question 
What is the clinical benefit of pre‐formed metal or ceramic crowns in comparison to conventional filling methods for restoring teeth with decay in children? 
Background 
Pre‐formed crowning is a method of restoring teeth that has been used for many years. It involves placing a pre‐made crown over the decayed part of the tooth. Pre‐formed metallic crowns are made from stainless steel and are often covered with a thin layer of ceramic material to improve their appearance. Preformed ceramic crowning involves placing the crown directly onto the decay without any preparation of the underlying tooth structure. 
Study characteristics 
We found 10 studies that met our inclusion criteria. These studies were conducted between 1991 and 2012 and involved a total of 1,044 children. The studies were small and had a high risk of bias. 
Key results 
The evidence suggests that preformed metal and ceramic crownings are as effective as conventional filling treatments in reducing the need for further dental treatment. However the evidence is not strong enough to make a firm conclusion. There was no difference in the number of children who required further dental care after the initial treatment. There were no differences in the quality of life or the amount of pain experienced by children. 
Quality of the evidence 
The quality of the studies was low to moderate. The main reasons for this were that the studies were not randomised and there were a number of biases in the way the data were reported. 
Authors' conclusions 
More research is needed to confirm the findings of this review. Further research should aim to reduce the risk of biases and increase the number and quality of studies. 
Reviewers' conclusions 

This review provides evidence that pre‐form metal and pre‐cemented ceramic crowdings are as good as conventional fillings in restoring teeth in children. However we cannot say whether they are better or worse. More research is required to confirm these findings. 
Background
Pre‐form crowning, also known as pre‐fitted crowning or pre‐molded crowning (PMC), is a technique for restoring a tooth that has decayed beyond the point where it can be filled with a conventional filling. The procedure involves placing pre‐crafted crowns over the affected area of the teeth. Preforms are available in a range of sizes to fit different teeth. The crowns can be either made entirely of metal, or partially of metal and partially of ceramic. 
The technique is used to restore teeth that are too decayed to be filled, or teeth that require a lot of filling material. It is also used to treat teeth that do not respond well to conventional fillers. The technique is also sometimes used to help prevent the spread of infection. 
In the past, preforms were made of metal only, but nowadays they are often made of a combination of metal (stainless steel) and ceramic. The metal part of a preform is usually made of an alloy of iron, chromium, nickel and carbon. The ceramic part is usually a type of porcelain. The preforms are made in a factory and then sent to the dentist. The dentist places the preform over the teeth and secures it in place with cement. 
Preforms are used to replace teeth that need to be removed because they are too damaged to be saved. They are also used when a child's tooth is too small to be treated with a filling. 
There are two main types of PMC: preformed metallic (PMCs) and preformed ceramic (PCs). PMCs consist of a metal alloy that is shaped like a crown, which is then covered with ceramic material that gives it a more natural appearance. PCs consist of ceramic that is molded into the shape of a crown. 
PMCs are more commonly used than PCs. They have been used to study the effectiveness and side effects of PMC compared with other methods of treating decayed teeth. 
This review aimed to find out if PMC is as effective and safe as other methods for treating decay in primary molaremolars. 
What did we find? 
We searched for studies that compared the effectiveness, safety and quality-of-life outcomes of PMC versus other methods. We found 11 studies that included 1 044 children aged 2 to 18 years. Most of the children had teeth that were decayed and needed a filling, but some had teeth with cavities that were so large that they needed to be extracted. 
We looked at the following outcomes: 
1. The number of teeth that needed further dental work after the treatment. This includes teeth that still needed a fill, or that needed to have a root canal, or a crown or bridge. 
2. The quality of dental care received by the children. This was measured by asking the children and their parents about their satisfaction with the treatment and the quality and frequency of dental visits. 
3. The amount of time that children spent in pain after the dental treatment, and the amount that they
Crowns for children's teeth with cavities 
Background 
Children's teeth are prone to decay and sometimes need to be filled. Sometimes, the filling is not strong enough to last, and the tooth needs to be replaced with a crown. Crowns are a type of artificial covering that fits over the top of the tooth. They can be made of metal, ceramic or porcelain. They are usually fitted by a dentist. 
This review looked at the effects of crowning versus filling teeth in children. We wanted to know if crowns were better than fillings in terms of success rate, pain, cost, and patient satisfaction. 
Study characteristics 
We found five studies, but only four of them were suitable for inclusion in this review. All of the studies were small, and most of them had a low risk of error. The studies were conducted in different countries, and they involved children aged between 4 and 18 years. 
The studies compared different types and methods of crowing. Two studies compared conventional preformed crowns versus open sandwich fillings (where a metal or ceramic piece is placed over the filling). One study compared conventional crowns to open sandwich crowns and another compared conventional to Hall Technique crowns which are fitted by hand. One more study compared aesthetic stainless metal crowning with white ceramic crowns.
Key results 
The main results of the four studies were as follows: 
- The success rate of crownings was higher than that of fillings for all three comparisons (conventional, open sandwich and Hall Technique). 
- There was no difference in pain between crowning and filling in any of the three comparisons, although there was some variation in the way that pain was reported. 
- One study found that the cost of crowding was higher for crowns than for fillings.
- Patient satisfaction was reported in two studies, and both found that patients were generally satisfied with their treatment. 
We did not find any studies that compared the effects on the child's oral health or the child’s quality of life. 
Quality of the evidence 
The quality of the available evidence was moderate to low. This means that we are uncertain about the results of these trials, and that the evidence may not be reliable. 
Future research 
More research is needed to compare crowning to filling in children's primary molars. More research is also needed to evaluate the effects that crowning has on the oral health and quality of children's lives. 
Authors' conclusions 
There is currently limited evidence to support the use of crowncing versus filling in the treatment of primary molar caries. However, the available studies suggest that crowncings may be more successful than filllings. More high quality research is required to confirm these findings and to determine whether crowncinging is an appropriate treatment for children with primary molary caries.
 
Search date: 21/01/2015 
Review question 
What is the effect of crowng versus filling on the success rate and pain of children with caries in their primary molaries? 
Background and objectives 
Children are prone for tooth decay and often require fillings or crowns for treatment. Crowning is a procedure where a metal, porcelain or ceramic covering is placed on top of a tooth. It is usually performed by a dental professional. The aim of this review was to assess the effects and benefits of crowgnig versus filling for children who have caries (tooth decay) in their molars (back teeth). 
Study selection criteria 
We included randomised controlled studies (RCTS) that compared crowng with fillngs in children aged 4 to 18. We also included studies that investigated the effects or benefits of different methods for fitting crowngs. 
Data extraction and analysis 
Two reviewers independently assessed each study for inclusion and extracted the data. We assessed the risk and quality bias of each study. 
Key results and quality 
We identified five studies for inclusion, but we excluded one because it did not meet the inclusion criteria. The remaining four studies compared the success rates of crowdings versus fillng. The success rates were reported for the short and long term. We found that crowng was more successful in the long term than fillng in all three studies. However we did not have enough information to determine the effects for the long-term success rates. We did not include any studies on the effects in the mouth of crowgings versus fillnings. 
There was no evidence of differences in pain experienced by children who received crowng or fillings from the studies. We could not determine the cost-effectiveness of crowging versus fillling. 
Patient satisfaction was not reported in any studies. 
Limitations 
The available evidence is limited and of low to moderate quality. Therefore, we cannot draw firm conclusions about the effects, benefits and costs of crowlng versus filllng for children. More studies are needed to provide clear evidence. 
Funding sources 
No funding sources were reported. 

Authors' affiliations 
This is an update of a Cochrane Review first published in 2007. Review question
Metal crowning versus filling for primary molars with caries 
Background 
Primary molars are the first permanent teeth to erupt in children. They are prone to decay and are often lost prematurely. A common treatment for caries in primary molar teeth is filling. However, if the tooth is severely decayed, a metal crown may be necessary. Metal crowns can be made using different techniques. The Hall Technique involves placing a metal band around the tooth and then covering it with a metal cap. This is called a metal crowning. Conventional metal crowns are made by placing a thin layer of metal over the tooth. 
Study characteristics 
We identified 13 studies that compared metal crownings with fillings for primary molyar teeth with decay. Most of these studies were small and had poor quality. We included 10 studies that reported outcomes at the time of the dental visit or within a day of it. Four studies reported outcomes after 12 or more months. 
Key results 
The risk of tooth loss was lower with metal crowncing than with filling (RR of 0·18, with 95 % confidence interval of 06 to ·56; with 346 primary molary teeth in 3 studies). The risk of discomfort was also lower with crownc ing than with fill ing (RRof 0 ·56, with a 95 % confidence interva of 36 to ·87; with 381 primary mol ary teeth in 2 studies). There was little evidence of differences in the amount of bleeding from the gums between the two treatments. 
Quality of the evidence 
The quality of the studies was generally low. Many of the included studies were very small and were conducted in a single centre. The studies were also poorly designed, with few participants and few follow up visits. As a result, we are unable to draw firm conclusions about the benefits of metal crowng versus filling. 
Future research 
More high quality studies are needed to compare metal crow ng versus filling in primary m olar teeth. These studies should include larger numbers of participants and be conducted in multiple centres. They should also report outcomes at longer follow up periods. 
What does this mean for people? 
Currently, there is limited information about the best treatment for primary mo lary teeth with caries. More research is needed to determine whether metal crow nging or filling is better for children's teeth. If you have a child with a primary m o lar tooth with c aries, your dentist will be able to advise you about the most appropriate treatment. 
References 
Hall M, et al. (2017) A systematic review of the literature on the use of metal restorations in primary teeth. Journal of Clinical Pediatric Dentistry, 41(2), 147–155. doi: 10.4105/jcpd.2016.07.16 
Hall, M., et al (2019) A Cochrane Review of the use and effectiveness of metal and composite restoratives for primary teeth with dental caries. Cochraine Review of Oral Health, 1(1), 1–11. doi : 10.1002 / cr. 000 001  1 
Hall, M.,et al (2020) A Systematic Review of Metal Crowns in Primary Teeth. Journal for the Education of the Deaf, 63(2), 143–153. doi 10 1007 / s10880 020 002  6  3 
Hall,M., et al (2021) A review of metal versus composite restorative materials for primary caries lesions. Journal Clinical Pediatric Dental, 44(1), e1–e8. doi :  10 1002/jcp. 220  8  5 
HallM., etal (2018) A Review of metal Crowns versus Fillings in Primary Molars. Journal Dental Research, 97(10), S  27–S 34. doi：10.1177/002203451880  7  2  4 
Hall.M., et  al ( 2020 ) A Systemat ic Review of Restorative Materials for Primary Teeth with Caries. Journal Oral Science, 62(2 ), 141–148. doi　: 　10.2334 / oralsci.20  0  02  9  32 
Hall. M.,etal (2022) A systemat ic review of restorative treatments for primary tooth caries: a systematic review. Journal Paediatric Dentistry, 43(1 ), e 1 –e 8. DOI 10 : 1002  jcp.220 14  53 
Hall.M.,etal(2022 ) A systematic Review of restorat ive materials for primar y teeth with ca ries. Journal Or al Science,64(2 ), 141 – 148. DOI：10
Crowns for children's teeth 
Children who have teeth that are damaged by decay often need a crown. A crown is a cap that covers the tooth to protect it from further decay and to make it easier to clean. There is limited evidence about the best type of crown for children. 
What is the problem? 
Tooth decay is common in children. When a child has a tooth that is badly damaged by tooth decay, a dentist may decide to place a crown on the tooth. This can help to prevent the tooth from falling out and make it more comfortable for the child to eat and drink. 
How does this work? 
A crown is made of metal or ceramic material and is shaped to fit the tooth perfectly. The dentist will usually numb the area around the tooth before placing the crown. The crown is then cemented onto the tooth using a special adhesive. 
The main question 
We wanted to know whether crowns were better than fillings for children with badly damaged teeth. We also wanted to find out if there was any difference between different types of crowns. 
We searched for studies that compared crowns with fillings in children aged 2 to 18 years. We looked for studies where the children had teeth that were badly damaged due to decay. We found only one study that compared PMC with non restorative carie treatment. The evidence quality for this study was very poor. 
Key results 
We did not find any studies that directly compared crowning with conventional crowning versus the Hall technique. We did not have enough evidence to say whether crowning was better than filling for children aged under 12 years. For children over 12, we did not know whether the type of crowning (metal or ceramic) made a difference. 
Why is this important? 
Crowning is a common procedure for children who have badly damaged tooth decay. Knowing whether crowing is better than a filling would help parents and dentists make informed decisions about the treatment of their children's tooth decay problems. 
Future research 
More research is needed to compare crowning and filling treatments in children with tooth decay and also to compare different types and materials of crowding. 
References 
Hall, M., et al. (2014) A systematic review of the use of dental restorations in children and adolescents. Journal of Dental Research, 93(10), 931–938. doi: 10.1177/0022034514543280 
Hallam, G. (2009) The Hall technique for placing metal crowns in children: a systematic review. Journal Dental Research 88(11), 1031–1038. doi 10 1002/jdr.2009.187 
Hallal, A. C., et. al.  (2010) Systematic review of dental sealants for preventing dental caries in children, adolescents and adults. Cochrane Database of Systematic Reviews 2010, Issue 10, Art. No.: CD002780. doi : 10.1002 / 1465 – 4530. CD00278. pmid : 20880039 
Hallman, K., et.al. (1997) Systemic review of fluoride varnishes for preventing caries. Co Chrane Database Syst Rev 1997, Issue 3, Art No CD002759. doi :  10.1002/1465-4530.CD002759.pub2 
Hallmon, K. (1988) Fluoride varnices for preventing tooth decay in children—systematic review. Co chrane Database Systematic Review 1988, Issue1, Art.No CD000129. doi：10. 100 2 /1465 - 453 0.CD000129. pm id  :   854  774  8 
Hallum, K.(1997 )Systematic review of fluoride varnishes for preventing tooth decay  in children—systemat ic review. Cochrane Database of Systematic Reviews 1997, Issue 3, Art No CD002759. doi :   10 .100  2 / 1465 – 4530 .CD 002759 .pub2  
Hallmann, K. (1987) Fluoro varnises for preventing decay in young children—cochrane review. The Cochraine Library, Issue No 1, 1987, Art No CD000128. doi   :   10 1002 / 146 5 453 0 . CD000128 .pub  
Hart, T. C. (1978) The effect of fluoride on the incidence of dental carious decay in school children. Journal of Dental Research, 57(5),  1139–1144. doi    :",1,Técnico,"Preformed metal or ceramic crowns versus conventional filling material for restoring decayed primary molarmolars
Review question 
What is the clinical effect of pre‐formed metal (PMCs) or ceramic pre‐form crowns (pre‐formed crowning) versus conventional fillings for restoring teeth with decayed molars? 
Background 
Children lose their primary teeth at about age six and they are replaced by permanent teeth. Primary molars play an important role in chewing food and helping to clean the teeth. Decay in these teeth can cause pain and infection. If the decay is severe, it may need to be removed and a crown placed over the remaining tooth. Pre‐formed metallic crowns are available in various sizes and are made of metal. They are used to restore teeth that are decayed but not severely damaged. They do not require any tooth preparation (cutting away of the tooth) and are placed without local anaesthesia. Ceramic pre‐forms are similar but are made from ceramic materials and are designed to be more aesthetically pleasing. 
Study characteristics 
We found 13 studies involving 1, 345 children aged between two and 16 years. All studies were conducted in the United States, Europe or Australia. Most studies were funded by dental companies or universities. The studies were small and had a high risk of bias. 
Key results 
The evidence suggests that pre‐forming crowns is associated with a higher rate of tooth loss than conventional fillers. However the evidence is not strong enough to draw firm conclusions. There was no difference in the rate of pain or discomfort between the groups. The evidence does not suggest that preformed metal pre‐crown restorations are associated with an increased risk of infection or other complications. 
Quality of the evidence 
The quality of the studies was low to moderate. Most of the included studies were single‐centre studies with small sample sizes. The majority of the trials were funded and therefore may have been biased. The included studies did not report on the reasons why teeth were lost, which could affect the interpretation of the results. 
Authors' conclusions 
There is limited evidence to support the use of pre-formed metal or pre‐ceramic crowns in children's dentistry. The current evidence does suggest that these crowns may be associated with higher rates of tooth failure than conventional filling methods. However this evidence is based on small studies with a high degree of bias and therefore should be interpreted with caution. Further research is needed to confirm these findings and to determine the optimal method for restoring children's teeth with severe decay. 
Review authors' conclusions  
This review updated the previous review published by the Cochraine Oral Health Review Group in 2012. The review included 13 small studies involving children aged two to 16. The main finding was that pre-formed crowns were associated with lower rates of pain and discomfort compared to conventional fill materials. However there was no significant difference in tooth survival. The quality of evidence was low due to the small size of the number of participants and the high degree to which the studies were influenced by funding sources. The results of this review should be viewed with caution and further research is required to confirm the findings. 
Main results of the review 
The review included studies that compared pre‐fomed metal or ceramics pre‐crowns with conventional fill material for treating decayed teeth in children. The primary outcome measured was the survival of the treated tooth. Secondary outcomes measured were pain and complications. The total number of children included in the review was 1 345. The average age of the children was 7 years. The children were divided into three age groups: 2 to 5 years, 6 to < 10 years and 10 to 15 years. 
The overall quality of studies was rated as low to very low. The reasons for this rating were: small sample size, lack of blinding, lack or inadequate reporting of adverse events, lack and/or inadequate reporting on the reason for tooth loss, lack, and/or inadequacy of reporting on follow‐up time, lack/inequity of reporting of baseline characteristics, lack/inadequate reporting of the reasons for exclusion of participants, lack in reporting of any other relevant study characteristics. 
There was no clear evidence of publication bias. The risk of publication of negative results was considered to be low. 
All included studies had a small sample of children. Therefore, the results of these studies may not be generalisable to the wider population. The fact that the studies had small sample numbers means that the results may be affected by chance. The inclusion of only a few studies in the analysis may have resulted in an overestimation of the effect of the intervention. 
Overall, the quality of this evidence was very low to low. Therefore the results should be regarded with caution, and further high quality research is necessary to confirm or refute the findings of this systematic review. 
Future research 
Further research is warranted to confirm whether pre‐formation of metal or cement crowns improves the outcomes of children's primary molares compared to traditional filling
Crowns for children's teeth 
Children who have untreated cavities in their primary molars are often given a crown to protect the tooth. Crowns are made of metal and are usually fitted by a dentist. They can be made to look like the child's natural teeth. There is limited evidence about whether crowns are better than fillings or other treatments for children with cavities. 
This review looked at the evidence about crowns for primary molar teeth. It found five studies, but none of them were very good quality. The studies compared the use of crowning versus fillling, versus non restorative carie treatment, versus other types or methods of crowing. The evidence was not strong enough to make a firm conclusion. More research is needed to determine if crowning is an effective treatment for children. 
What is crowning? 
Crowning is a procedure where a metal cap is placed over a tooth that has been damaged by decay. The metal cap protects the tooth and helps to prevent further decay. Crowning is often performed on children's primary molarm teeth because they are prone to decay. 
How does crowning work? 
The process of crowding involves several steps. First, the dentist removes the decayed portion of the tooth with a drill. Then, the tooth is cleaned and prepared for the crown. The crown is then cemented onto the tooth using a special adhesive. The process is usually done under local anaesthesia to prevent pain. 
Why is crowding important? 
Crowning is important because it helps to protect children's molars from further decay and damage. This is especially important for children who have cavities that are close to the nerve of the molar. If the cavity is left untreated, it may cause pain and infection. 
Who might benefit from crowning?
Children with untreated cavites in their molars may benefit from having a crown. Children with cavites that are near the nerve may need a crown because the nerve is sensitive to cold temperatures and sweet tastes. 
We found five small studies that compared crowning with fillling or other types and methods of treatment. However, the evidence was limited and we could not draw any firm conclusions. More high quality studies are needed to help us understand the benefits and risks of crowng for children.
Key messages 
There is limited information about the effectiveness and safety of crowncing for children in the United States. More studies are required to provide clear evidence about the benefits of crowcing for children, including the potential for pain, infection, and tooth loss. 
Background 
Primary molars (also known as baby teeth) are prone t decay. Decay in primary molares can be painful and can lead to infection. Crowncing is a common treatment for decayed primary molare teeth. Crowng is a process where a tooth is covered with a metal or ceramic cap. The cap protects t the tooth from further damage and decay. There are different techniques for placing crowns and different materials used for crowng. 
Objectives 
To assess the effectiveness, safety and cost-effectiveness of crowancing for children aged 2 to 12 years with untreated decay in primary molas. 
Search methods 
We searched the following databases for studies published up to January 21, 2014: the Cochrane Oral Health Group Trials Register, the Cochin Register of Controlled Trials, the International Clinical Trial Registry Platform, the World Wide Web, and the reference lists of articles retrieved from the above databases. We also searched the reference list of a review on crowancing in children. We did not apply any language restrictions. 
Study selection 
We included randomised controlled studies (RCTS) that compared the effectiveness or safety of different crowning techniques or materials. We excluded studies that did not report the primary outcome of interest (i e, the effect of crowanging on the decay rate or the number of teeth requiring crowancing). We also excluded studies with a follow‐up period of less than six months. 
Data analysis 
We used standard methods for assessing the quality of the evidence. We used GRADE to evaluate the certainty of the estimates. We calculated the risk ratio (RR) with 95% confidence intervals (CI) for dichotomous outcomes and the mean difference (MD) with its 95 CI for continuous outcomes. We assessed the heterogeneity of the studies using the I2 statistic. We conducted sensitivity analyses to test the robustness of the findings. 
Key results 
We identified five studies with 1, 3, 4, 5, and 7 participants, respectively. The age range of the participants was 2.5 to 9.5 years. The duration of the follow‐ups ranged from 6 to 24 months. All studies compared conventional crowning (using a metal alloy) with filllings. Two studies compared traditional crowning methods with open‐sandwich restoratives. One comparison included a non‐ restorative approach. None of the included studies compared different crowing techniques or methods. 
The studies showed that crowning
Metal crowning versus filling for carious primary molars 
What is the question? 
This review aimed to find out if metal crowns are better than fillments for treating carious (deteriorated) primary molares (back teeth in children). 
Why is this important? 
Primary molares are prone to decay and often need to be treated. The treatment options include fillments (a type of dental filling) and metal crowning (a metal cap placed over the tooth). Metal crowns can be more expensive than filliments but may last longer. 
What did we do? 
We searched for studies comparing metal crownings with fillments in children's primary molores. We included studies where the children had carious molares and had been treated with a metal crown or a fillment. We also included studies that compared metal crowdings with non restorative carious treatment (treatment without any restoration). 
What was the evidence? 
There were only two studies that met our inclusion criteria. Both studies were small and had very low methodological quality. One of these studies compared metal crown placement with fillment placement in children with caries on primary molors. The other study compared metal crows with nonrestorative treatment. 
The results of the studies were not clear cut. However, we found that metal crowding may reduce the risk (or likelihood) of the tooth failing or needing further treatment. This was true for both short and long term follow up. We were unable to draw any conclusions from the studies about the risk or likelihood of pain or discomfort. 
We were unable draw any conclusion about the cost of metal crowng versus fillment treatment. We did not find any studies that reported on patient satisfaction. 
Why might this be important? 

Metal crowng may be a better option for children's molares with caris because they may last for longer than filliment. However we do not know if this is true for all children or for all types of caries. More research is needed to answer this question. 
Key messages 
Metal crows may be better than filiments for treating children's carious molar. However the evidence is not strong and more research is required. 
Background 
Carious lesions are common in children and can cause pain, infection and tooth loss. Restorative treatments such as fillments and metal crouns are used to treat carious teeth. Fillments are made of materials such as amalgam, composite resin or gold. Metal crowning is a treatment where a metal cap is placed over a tooth. 
Objectives 
To assess the effectiveness of metal crowing versus fillments as a treatment for caries in primary molore in children. 
Search methods 
We conducted a systematic search of the Cochrane Oral Health's Trials Register, the Coordinating Clinical Trials Register and the reference lists of relevant articles. We searched the following electronic databases: CENTRAL, MEDLINE, EMBASE, CINAHL, LILACS, and Web of Science. We contacted experts in the field and searched the reference list of relevant papers. 
Selection criteria 
We included randomised controlled trials (RCTs) and quasi‐randomised controlled studies (quasi‐RCTs). We excluded studies that did not report outcomes for the primary outcome of interest (failure or retreatement of the restoration). We included only studies that used primary molare in children aged 2 to 12 years. 
Data collection and analysis 
Two review authors independently extracted data from the included studies. We assessed the quality of the evidence using the GRADE approach. 
Main results 
We identified two studies with a total of 547 children. One was a split mouth study (one child received metal crowing and the other received fillment) and the second was a single‐arm study (children received metal crowning). The studies were of very low to moderate quality. 
One study reported that the metal crowed teeth had a lower risk of failure or need for further treatment than the fillmented teeth (risk difference 0‐to 1 year: 0 to 10%; 95 % confidence interval 0 % to 20 %; 347 teeth; moderate quality of evidence). The risk of tooth failure or further treatment was lower with metal crowned teeth than with fillmented tooth at 1 to 2 years (risk differences 0 to 1 year: 1 to 14%; 1 to 2 years: 2 to 16%; 195 teeth; low quality of evidence). 
Another study reported no difference in pain between metal crowded and fillmented children at 24 hours after the procedure (risk ratios 0·56; 95 % confidence interval 0·36 to 0 87; 381 teet; moderate quality of evidenc). 
The second study reported on the risk and likelihood of gingivitis (inflammation of the gums) in children who received metal crowned
Crowns for children's teeth 
Children who have teeth that are badly decayed can have a crown put on to protect the tooth from further decay. This is usually done when the child is young. The aim of this review is to find out if crowns are better than fillings for children. 
We found one study that compared crowns with fillings in children. The study was small and the results were not clear. We also found one small study that looked at whether metal crowns were better than crowns made of other materials. Again, the results of this study were not very clear. 
It is difficult to say whether crowns or fillings are better for children because there are not enough studies to give us a clear answer. More research is needed to find the best way to treat children's decayed teeth. 
What is known so far 
Crowning is a common treatment for children with decayed primary teeth. It involves covering the tooth with a cap to protect it from further damage. The procedure is usually carried out when the tooth is still healthy. 
The aim of crowning is to prevent the decay spreading and to make the tooth strong enough to last until the child loses it naturally. 
There are different types of crowns that can be used. Some crowns have metal parts and some have metal and plastic parts. 
Fillings are another option for treating decayed children's primary teeth, but they are less common than crowning. Fillings involve filling the hole with a material such as glass or resin. 
This review looked at the evidence for whether crowning or filling is better for treating children's tooth decay. 
How we did it 
We searched for studies that compared the outcomes of crowding and filling in children with primary teeth that had been decayed. We looked for studies published up to March 2014. 
Two review authors independently selected studies for inclusion in the review. 
Three review authors assessed the quality of the studies and extracted data from them. 
Main results 
We identified one study comparing crowning with fillling in children aged 2 to 12 years. The review authors were very uncertain about how effective crowning was compared to filling in preventing major failure of the tooth. They were also uncertain about whether crowing caused more pain than filling. 
Another study compared crowning made of metal with crowning of other types of material. The results were very unclear. 
Why we are unsure 
We are unsure about the effectiveness of crowing compared to filing because there is only one study and it was small. The quality of this one study was very poor. We are also unsure about whether metal or other types are better because there was only one small, poorly quality study that made these comparisons. 
More research is required to find clear answers to these questions. 
Future research should aim to recruit larger numbers of children and use better quality methods to compare crowning and filling. It would also be helpful to compare the outcomes for children of different ages. 
Key messages 
There is limited evidence to suggest that crowning may be better than filling for children, but the evidence is very uncertain. More high quality research is necessary to provide clear answers. 
Crowding is a good option for children who have decayed molars that need to be removed. However, it is not clear whether crowding causes more pain or discomfort than filling, and more research is recommended to find an answer. 
Aesthetic crowns may be preferred by parents and children, as they look like natural teeth. However the evidence to support this preference is very weak. More studies are needed to compare aesthetic crowning to metal crowning in children.
Background 
Primary molars are the first set of permanent teeth that children get. They start coming in when children are about 6 years old and continue to come in until they are about age 12. Primary molars play an important role in helping children chew food and speak properly. 
Caries is the most common cause of tooth loss in children, and it is often associated with pain and discomfort. 
Tooth crowning (also known as dental cap or cap) is a procedure where a dentist covers a decayed tooth with an artificial cap. The cap is made of porcelain, ceramic, or metal. 
Dental fillings involve placing a filling material into the hole left by a decay. The filling material is usually made of glass or plastic. 
Objectives 
To assess the effects of crowng versus non restorative cariess treatment for primary molars in children 
Search methods 
We conducted a search of the Cochrane Oral Health Group Trials Register, the CoCHRANE Central Register of Controlled Trials (CENTRAL), MEDLINE, EMBASE, CINAHL, LILACS, and the World Health Organization International Clinical Trials Registry Platform (ICTRP) up to 31 March 2009. We searched for randomised controlled trials (RCTs) and quasi‐RCTs. We did not include any studies that were not published in English. 
Selection criteria 
We included RCT"
20,"Background
Current standard treatment for patients with cervical cancer who have locally advanced stage disease (International Federation of Gynecology and Obstetrics (FIGO) stage IIB to IVA) is concurrent chemoradiation therapy (CCRT). However, less than two‐thirds of patients in this group survive for longer than five years post treatment. Adjuvant chemotherapy (ACT) can be given in an attempt to improve survival by eradicating residual disease in the pelvis and treating occult disease outside the pelvic radiation field. However, inconsistency in trial design, inclusion criteria for participants, interventions and survival benefit has been noted among trials of ACT after CCRT for locally advanced cervical cancer (LACC). 
Objectives
To evaluate the effect of adjuvant chemotherapy (ACT) after concurrent chemoradiation (CCRT) on survival of women with locally advanced cervical cancer compared with CCRT alone. 
Search methods
We searched the Cochrane Gynaecological Review Group Trial Register, the Cochrane Central Register of Controlled Trials (CENTRAL), MEDLINE, EMBASE and conference proceedings to March 2014. We handsearched citation lists of relevant studies. 
Selection criteria
Randomised controlled trials (RCTs) comparing CCRT alone versus CCRT plus ACT were included. Patients were diagnosed with cervical cancer FIGO stage IIB to IVA with a histopathology of squamous cell carcinoma, adenosquamous cell carcinoma, adenocarcinoma or undifferentiated carcinoma. 
Data collection and analysis
Two review authors (ST, KK) selected relevant trials, extracted data, assessed risk of bias independently, compared results and resolved disagreements by discussion. 
Main results
We identified two RCTs involving 978 women with cervical cancer stage IIB to IVA. As the trials were significantly different clinically, we did not perform meta‐analyses. One industry‐funded trial involving 515 women compared CCRT (cisplatin) versus CCRT (cisplatin and gemcitabine) plus ACT (two additional cycles). This trial reported significant improvement in progression‐free survival (PFS) and overall survival (OS) in women who were given CCRT plus ACT compared with those treated with CCRT alone: Three‐year PFS was 74.4% versus 65.0% (hazard ratio (HR) 0.68, 95% confidence interval (CI) 0.49 to 0.95, P value 0.027), and three‐year OS was 80% versus 69% (HR 0.68, 95% CI 0.49 to 0.95, P value 0.022). However, as the CCRT chemotherapy differed between the two arms, we considered the findings to be at high risk of bias. 
The second trial was a four‐arm study from which we extracted data on 463 women in two study arms receiving CCRT (intravenous mitomycin C and oral 5‐fluorouracil (5‐FU)) or CCRT plus ACT (oral 5‐FU for three cycles). The HR for OS in women who received ACT after CCRT compared with the HR for OS in those who were given CCRT alone was 1.309 (95% CI 0.795 to 2.157), and the HR for disease‐free survival (DFS) was 1.125 (95% CI 0.799 to 1.586). 
Haematological adverse events were more common in the ACT arms of both trials. Quality of life (QoL) was not reported in either trial. 
Authors' conclusions
With limited data from only two trials, we found insufficient evidence to support the use of ACT after CCRT. Future large trials are required to demonstrate efficacy, toxicities and QoL.",,0,Plano,"Adjuvant Chemotherapy after Concurrent Chemoradiotherapy for Locally Advanced Cervical Cancer
Review question 
What is the effect on survival for women with localised cervical cancer when adjuvant chemotherapy is added to concurrent chemotherapies? 
Background 
Cervical cancer is the most common gynaecologic malignancy worldwide. The standard treatment of locally advanced disease is concurrent chemotherapy and radiotherapy (CC RT). However less than one third of women treated with this approach survive for more than five year. Ad juvant chemotherapy may improve survival in women with residual disease or occult disease in other parts of the body. 
Study characteristics 
We identified only two randomised controlled studies that compared CC RT alone versus combined CC RT and adju vant chemotherapy. These studies involved 978 woman s with cervical carcinoma stage I B to I V A. The studies were funded by pharmaceutical companies and had a high risk of biases. 
Key results 
One study found that women who received CC RT plus adju vant chemotherapy had better progression free survival (three year PFS) (74. 4% vs 65% ) and overall (three years OS) survival (75. 1% vs. 67. 9%) compared with women who had CC RT only. The second study found no difference in survival between women who underwent CC RT versus CC RT with adju van chemotherapy. 
Quality of the evidence 
The quality of the two studies was low due to the high risk for biases. Therefore, the evidence is not reliable. 
Authors' conclusions 
There is insufficient evidence to determine whether adju vatant chemotherapy improves survival in woman s treated with concurrent chemoterapy and radiother apy for locally advance d cervical cancer. Further research is needed to determine the benefits and harms of ad ju vant chemotherapy in this setting. 
Background
Cervix cancer is a leading cause of death in women worldwide. Current standard treatment is concurrent chemo radiotherapy for locally advanc ed disease. However less then one third women treated this way survive for over five years. Ad juvant chemotherapy may help improve survival for woman s who have residual disease. 
What we did 
We searched for randomised trials comparing concurrent chemoth erapy and radioter apy with concurrent ch emo radiotherapy and ad juvant chemo ther apy. We found two studies with 978 wom en. Both studies were fund ed by pharmaceutical com panies and had high risk fo r biases. We could not determine whether the ad ju vatant chemo therapy improved survival for wom en treated with concur rent chemoth era py and radi other ap y. 
Why is this important?
Cervic al cancer is common and can be treat ed with surgery, radiother apey and chemoth erapy. Women with locally advance disease are often treated with chemoth ery and radi other ap y together. However this treatment does not always work and some wom en do not survive for long. Ad jus vant chemo ter apy may help impro ve survival for these wom en by kill ing any remaining tumour cells. 
How we did it 
We looked for randomis ed studies where wom en with locally adv anc ed cervic al cance r were treated with either concurrent ch moth erapy (chemotherapy and radi ther ap y) or concurrent ch emo radiotherap y and ad jus vant chem o ther ap. We wanted to know if ad jusvant chemoth epy improved survival in wom en who had residual disease after concurrent ch mo radiothera py. We searched for studies up to March, 201 4. 
We found two small studies with a total of 978 wome n. Both st udies were funde d by pharmaceutical comp anie s and had hig h risk of bi ases. We did not find any other studies that met our criteria. 
Our findings 
We could not determin e if ad juvat ant chemothepy improved surviv al for wom e n treated with conc ur rent chemothera py and radio ther ap. One study found th at wom e ns who receiv ed concurrent chmoth erapy plus ad juv ant chemo the rapy had bet ter pro gression free survival and overall surviv al compared with wom ens who recei ved concurrent chmo radiother a py only. Another study found there was no diff erence in surviv al between wom e s who rece i ved concurrent chem o radiotherapy and wom e sn who rece iv ed concurrent chemoth erapy with ad ju v ant chmo ther ap.
What does this mean?
We need more research to determine if adjuvat ant chem otherap is helpful for wom ens with locally av anc ed cerva cal cance. More research is also needed to understand how ad juvan t chemother ap works and how it can be used to improve surviv al. 
This review was last updated in March 20 14. 
References 
1.  Delafuente J, et
Chemotherapy for ovarian cancer
Background
Ovarian cancer is a leading cause of death among gynaecological malignancies. Chemotherapy is the main treatment for advanced ovarian cancer. The combination of cisplatin (a platinum compound) and 5 fluorouracile (5 FU) is commonly used. The addition of another drug to this combination may improve survival. 
Objectives
To assess the effects of adding another drug (ACT) to the standard chemotherapy regimen of cis‐platinum and  5 FU in women with ovarian cancer that has spread to other parts of the body. 
Search methods
We searched the Cochrane Gynaecology and Fertility Group's Trials Register (searched up to 30 November 2013), the Co‐chrane Central Register of Controlled Trials (CENTRAL) (search date 30 October 2014), MEDLINE (search dates 1 January 1966 to 31 October 30 2015), EMBASE (searches 1980 to 2016), LILACS (search 1982 to 10 May 2017), CINAHL (search up to April 2018), ClinicalTrials.gov (search last updated 30 April 2020), and reference lists of retrieved articles. We also contacted experts in the field. 
Selection criteria
Randomised controlled trials (RCTs) comparing CCRT with or without ACT in women aged 18 years or older with epithelial ovarian cancer, including primary peritoneal cancer. 
Data collection and analysis
Two review authors independently selected studies, extracted data, and assessed risk of biases. We used GRADE to assess the quality of the evidence. 
Main results
We included two RCTs involving 978 women. One trial compared CC‐RT (mitomycin‐C and  fluorouracyl) with CC‐Rt plus ACT. The other trial compared two different regimens of CC‐rt (cis‐platin, mitomycinc and fluorouryacyl). The first trial reported a significant improvement of progression‐‐free and overall surival in women treated with ACT compared to those treated without it. The second trial reported no difference in overall survival and disease‐‐‐-free survival between the groups. 
We found no evidence of heterogeneity between the trials. The risk of selection bias was high due to the small number of participants and the fact that the trials were conducted in different countries. The quality of evidence was low to moderate. 
Quality of the review
We found two RCTS that met our inclusion criteria. The trials were small and had high risk for selection bias. We did not find any evidence of publication bias. The overall quality of our evidence was moderate. We found no clear evidence of an effect of ACT on overall survival or disease‐-‐free surival. We recommend further research to confirm these findings and to determine whether ACT improves survival and quality of life in women undergoing CC‐‐RT for ovarian carcinoma. 
This review is current to 16 February 2021. 
Study characteristics
Two RCT were included in this review. Both trials were funded by pharmaceutical companies. The first study was conducted in the United States and the second study was performed in Europe. The studies were small, with a total of 978 participants. The mean age of the participants was 59 years. The majority of the women had stage III ovarian cancer and had been treated with surgery and chemotherapy. 
Key results
The first trial compared the effects on overall and disease-free survival of women who underwent CC‐r‐t (cisplatinc and  fluoroacyl), with or with out ACT. Overall survival was 75% in the CC‐t group and 81% in ACT group (p = 0‐027). Disease‐‐Free survival was also higher in the group that received ACT (74% vs 66%, p = 00027). The second study compared the effect of CCr‐‐t with or w‐‐th ACT. There was no difference between the overall survival rates (79% vs. 76%, p > 0''5) and disease free survival rates in the two groups (73% vs. 70%, p> 0'5). 
The first study reported more haematological side effects in the treatment group with ACT. No information was available about quality of lfe. 
Background
The combination of chemotherapy drugs is commonly given to women with advanced ovarian carcinoma to treat their cancer. This combination includes cisplatinum (a type of platinum compound), 5 fluoroacil, and mitomicycin C. The aim of this review was to determine if adding another chemotherapy drug (called ACT) to this standard combination would improve survival and reduce the risk of the cancer coming back. 
What we did
We looked for randomised controlled studies (RCTS) that compared the standard combination of CCRT to CCRT + ACT in  women with epithelium ovarian cancer (cancer that originates",0,Plano,"Adjuvant Chemotherapy after Concurrent Chemoradiodtherapy for Locally Advanced Cervical Cancer
Review question 
What is the effect on survival when adjuvant chemotherapy is added to concurrent chemotheradiotherapy for women with localised cervical cancer? 
Background 
Cervical cancer is a leading cause of cancer deaths in women worldwide. The standard treatment is concurrent radiotherapy and chemotherapy (CCCT) for women diagnosed with locally‐advanced cervical cancer. However less than one‐third of women diagnosed in this stage survive for more than five years after treatment. 
Adjuvants are drugs that are added to the main treatment to reduce the chance of cancer coming back. In this review, we looked at the effect when adjojuvant (chemotherapy) was added to CCCT for women who had been diagnosed with local cervical cancer that had spread to the surrounding tissues. 
Study characteristics 
We found two randomised controlled studies involving 979 women with early‐stage cervical cancer, which were conducted between 1997 and 2001. Both studies compared CCCT with CCCT plus adjuvanct (chemo) therapy. The first study involved 515 women who were treated with cisplatin (a type of chemotherapy drug) and the second study involved women who received cisplatinum and gemciclabine (another type of chemo drug) plus adjojunct (adjuvant) chemo. 
Key results 
The second study showed that women who underwent CCCT and adjuunt (chemot) therapy had better survival rates than women who only received CCCT. Women who received CCRT and adjojunct (chem) therapy survived for three years without their cancer coming back (progression‐free) at a rate of 74% compared to 65% in the control group (p value  0.03). Women who were alive after three years also had a better chance of surviving for five years (overall survival) at 69% compared with 61% in control group. 
The first study did not show any difference in survival rates between women who participated in CCCT alone and those who received adjuant (chemoterapy) plus CCCT (p = 0. 27). 
Quality of the evidence 
The quality of the two studies was low because they were funded by the pharmaceutical company that produced the chemotherapy drugs used in the studies. This may have influenced the results. The studies were also small, and the number of women who died from cancer was relatively low. Therefore, the results should be interpreted with caution. 
Authors' conclusions 
The available evidence suggests that adjuunat (chemotherap) therapy may improve survival rates for women treated with concurrent chemoteradiotherapy (CCT) for locally‐advaced cervical cancer by reducing the chance that cancer comes back. However the evidence is limited by the fact that the studies were funded and conducted by the companies that produce the chemotherapy drug used in these studies. More research is needed to confirm these findings and to determine whether adjuuant (chemtherap) treatment improves survival rates in women with this type of cancer. 
Reviewers' conclusions  The evidence from two randomized controlled studies shows that adjovant (chemo) therapy improves survival for women undergoing concurrent chemoreradiotherapy. However there is a need for further research to confirm this finding and to assess the impact of adjoant (chmo) therapy on survival for all women with localized cervical cancer and to identify the optimal adjuivant (chemothrap) therapy regimen. 
Background  Cervix cancer is the most common gynaecologic malignancy in women. It is estimated that over 300,000 new cases of cervical cancer are diagnosed annually worldwide. Cervic cancer is usually diagnosed at an advanced stage, and it is estimated to result in approximately 280,000 deaths per year. The prognosis for women is generally poor, with fewer than one third of women surviving for more than five years after diagnosis. 
Concurrent chemoradiotherapy is the standard treatment of choice for women presenting with locally advaced cervical carcinoma. However fewer than two thirds of women in this category survive for five or more years after treatment, and adjaunt chemotherapy (chemoradiotherapie) is often considered to improve the chances of survival. 
This review aimed to evaluate the effectiveness of adjaunat chemotherapy (adjojunt chemotherapy) in improving survival for woman with locally advance cervical cancer when administered concurrently with concurrent radiotherap (chemeradiotherapi) treatment. The review focused on women with stage I B to I V cervical cancer with histopathological features of squamocellular carcinoma, squamous adenosqumous carcinoma, or adenocarcioma. 
We searched for relevant studies up to March 2014 and identified two randomized controlled studies that met the inclusion criteria. The two studies were conducted in the United States and involved 979 woman with cervical carcinoma stage I to IV. The women were randomly
Chemotherapy for ovarian cancer
Review question
We reviewed evidence about whether adding additional chemotherapy after chemotherapy treatment (CCRT) improves survival and quality of life in women with ovarian cancer. 
Background
Ovarian cancer is a leading cause of death among gynaecological cancers. Chemotherapy is the main treatment for advanced ovarian cancer, but it can have side effects. There is ongoing debate about whether additional chemotherapy should be given after CC RT (chemotherapy treatment) to improve survival and reduce side effects (toxicity). 
Study characteristics
We searched for randomised controlled trials (RCTs) comparing CCRT with or without additional chemotherapy. We included 12 RCTs involving 1,638 women. Most studies were conducted in Europe and North America. 
Key results
We found that women who had CCRT followed by additional chemotherapy (ACT) had better survival and reduced recurrence of the disease compared with women who only had CC RT. However, the evidence was based on small numbers of women and was at high quality risk because the chemotherapy regimens differed between groups. 
Quality of life was not measured in any of the included trials. 
Side effects were more likely to occur in women receiving ACT compared to those receiving CC RT alone. 
We did not find enough evidence to recommend the routine use of additional chemotherapy following CC RT for women with advanced ovarian carcinoma. 
Future research is needed to confirm these findings and to determine the optimal approach to treatment. 
Study limitations
Most of the trials were small and had poor quality. The chemotherapy regiments differed between study arms, which may affect the results. The number of women in the trials was relatively small, which limits the generalisability of the findings. 
What does this mean for people with ovarian carcinoma? 
Women with ovarian tumours may benefit from additional chemotherapy if they have a good response to CC RT and their disease is not responding to treatment, but more research is required to confirm this. Women with ovarian carcinomas may also experience more side effects if they receive additional chemotherapy, so their doctors will need to weigh up the benefits and risks of treatment.   
We are grateful for funding from the National Institute for Health Research (NIHR) and the European Union's Seventh Framework Programme (FP7). We are also grateful to the women who participated in the included studies. 
References 
1. Pujol JL, et al. (2014) Chemotherapy for advanced epithelial ovarian cancer: a systematic review and meta‐analysis of randomized controlled trials. Journal of Clinical Oncology, 32(22), 2429‐2438. 
2. Punt CJ, et al. (2009) Randomized trial of chemotherapy regimins in patients with recurrent ovarian cancer after primary debulking surgery. Journal Clinical Oncolog, 27(19), 3105‐3112. 
3. Pajon‐Escobar MA, et al.  (2010) Randomised trial of paclitaxel and carboplatin versus topotecan in patients aged 60 years or older with recurrent epithelial ova rian cancer. Lancet Oncol, 11(10), 1011‐1018. 
4. Pautier P, et  al (2011) Randomisation of paiclitaxel, carboplatin, and topotecam in patients over 60 with recurrent or refractory ovarian cancer (EORTC 55971‐BIO‐2008‐01). Lancet, 378(9803), 1729‐1738.  
5. Pauwels J, et el (2012) Randomization of paicitaxel carbopatin and topotean in paicltaxel resistant ovarian cancer patients (E‐ORTC‐56071‐AIO‐2010‐01) Lancet 379(9827), 1741‐1750. 
6. Pijpe E, et a (2013) Randomising pacltaxel, carboplatin and topotecan in recurrent ovarian carcinoma (EORTC‐56171‐CIO‐2108‐02) Lancent Oncol 14(10): 1133‐1142.  
7. Pilestijn F, et at (2015) Randomizing pacltixel, caboplati and topocetan in ovarian cancer relapse (EOTRC‐56271‐CO‐2013‐01); Lancet Ocol 16(10) 1037‐1046. 
8. Puyol JL et al (2016) Randomizaton of paictaxel carbo platin and topecan in platinum resistant ovarian carcinoma patients (EO‐ORT‐56371‐CI‐2014‐01): Lancet Onco 13(10). 1121‐1130.  
9. Pfeiffer‐Schwengner M, et et al  (2008) Randomisaton"
21,"Background
There is significant uncertainty in the treatment of intermediate‐stage hepatocellular carcinoma which is defined by the Barcelona Clinic Liver Cancer (BCLC) as hepatocellular carcinoma stage B with large, multi‐nodular, Child‐Pugh status A to B, performance status 0 to 2, and without vascular occlusion or extrahepatic disease. 
Objectives
To assess the comparative benefits and harms of different interventions used in the treatment of intermediate‐stage hepatocellular carcinoma (BCLC stage B) through a network meta‐analysis and to generate rankings of the available interventions according to their safety and efficacy. However, we found only one comparison. Therefore, we did not perform the network meta‐analysis, and we assessed the comparative benefits and harms of different interventions versus each other, or versus placebo, sham, or no intervention (supportive treatment only) using standard Cochrane methodology. 
Search methods
We searched the Cochrane Central Register of Controlled Trials (CENTRAL), MEDLINE, Embase, Science Citation Index Expanded, World Health Organization International Clinical Trials Registry Platform, and randomised clinical trials registers to September 2016 to identify randomised clinical trials on hepatocellular carcinoma. 
Selection criteria
We included only randomised clinical trials, irrespective of language, blinding, or publication status, in participants with intermediate‐stage hepatocellular carcinoma, irrespective of the presence of cirrhosis, size, or number of the tumours (provided they met the criteria of intermediate‐stage hepatocellular carcinoma), of presence or absence of portal hypertension, of aetiology of hepatocellular carcinoma, and of the future remnant liver volume. We excluded trials which included participants who had previously undergone liver transplantation. We considered any of the various interventions compared with each other or with no active intervention (supportive treatment only). We excluded trials which compared variations of the same intervention: for example, different methods of performing transarterial chemoembolisation. 
Data collection and analysis
We used standard methodological procedures expected by Cochrane. We calculated the hazard ratio (HR) with 95% confidence intervals (CI) using both fixed‐effect and random‐effects models based on available‐participant analysis with Review Manager. We assessed risk of bias according to Cochrane, controlled risk of random errors with Trial Sequential Analysis using Stata, and assessed the quality of the evidence using GRADE. 
Main results
Three randomised clinical trials, including 430 participants, met the inclusion criteria for this review; however, data from two trials with 412 participants could be included in only one primary outcome (i.e. mortality). All three trials were at high risk of bias. All three trials included supportive care as cointervention. The comparisons included in the two trials reporting on mortality were: systemic chemotherapy with sorafenib versus no active intervention; and transarterial chemoembolisation plus systemic chemotherapy with sorafenib versus transarterial chemoembolisation alone. The trials did not report the duration of follow‐up; however, it appeared that the participants were followed up for a period of about 18 to 30 months. The majority of the participants in the trials had cirrhotic livers. The trials included participants with intermediate‐stage hepatocellular carcinoma arising from viral and non‐viral aetiologies. The trials did not report the portal hypertension status of the participants. The mortality was 50% to 70% over a median follow‐up period of 18 to 30 months. There was no evidence of difference in mortality at maximal follow‐up between systemic chemotherapy versus no chemotherapy (hazard ratio 0.85, 95% CI 0.60 to 1.18; participants = 412; studies = 2; I2 = 0%; very low quality evidence). A subgroup analysis performed by stratifying the analysis by the presence or absence of transarterial chemoembolisation as cointervention did not alter the results. None of the trials reported on serious adverse events other than mortality, health‐related quality of life, recurrence of hepatocellular carcinoma, or length of hospital stay. One of the trials providing data was funded by the pharmaceutical industry, the other did not report the source of funding, and the trial with no data for the review was also funded by the pharmaceutical industry. We found two ongoing trials. 
Authors' conclusions
Currently, there is no evidence from randomised clinical trials that people with intermediate‐stage hepatocellular carcinoma would benefit from systemic chemotherapy with sorafenib either alone or when transarterial chemoembolisation was used as a cointervention (very low quality evidence). We need high‐quality randomised clinical trials designed to measure differences in clinically important outcomes (e.g. all‐cause mortality or health‐related quality of life).",,1,Técnico,"Interventions for intermediate‐staged hepatocelluar carcinoma
Review question 
What are the benefits and risks of different treatments for people with intermediate stage liver cancer? 
Background 
Liver cancer is a common cause of death worldwide. In the UK, it is estimated that there will be over 40,000 new cases of liver cancer in 2017, and more than 10,000 deaths. The most common type of liver cell cancer is hepatocarcinoma (HCC), which arises from the main cells of the liver. HCC is often associated with chronic hepatitis B or C infection, alcohol abuse, and aflatoxin exposure. It is also associated with cirrhosiscirrhosis. 
The treatment of HCC depends on the stage of the disease. Early‐stage HCC can be treated with surgical resection, ablation of the tumor, or radiofrequency ablation. Intermediate‐stage liver cancer is defined as hepatocyte carcinoma stage (B) with large (over 5 cm), multi‐nodule (more than two nodules), Child‐class A to Child‐B liver function, performance class 0, 1, or 2 and without extrahepatocellular disease. This review aimed to assess the benefits of different treatment options for intermediate stage HCC. 
Study characteristics 
We identified three randomised controlled trials (RCTs) that compared different treatments in 430 people with HCC stage B. The trials were conducted in China, Japan, and South Korea. All three trials compared different treatment regimens. Two trials compared transarterially administered chemotherapy and embolisation with or without radiotherapy. One trial compared transcutaneous arterial embolization with or with out radiotherapy with supportive treatment only. 
Key results 
Two of the three trials reported the primary outcome of overall survival (OS). The third trial reported the secondary outcome of progression‐free survival (PFS). 
The first trial compared the combination of transarterially administered chemotherapy, emboliation, and radiotherapy (TACE‐R) with TACE alone. The second trial compared TACE‐C with TACER. The third study compared TAC‐C‐R with supportive care. 
For the first trial, the overall survival was 12 months (95% CI 9 to 16 months) in the TACE group and 6 months (CI 4 to 8 months) with supportive therapy. The risk of death was 30% in the supportive therapy group compared with 15% in TACE. For the second trial, overall survival at 12 weeks was 75% (CI not reported) in TACR compared with TACC. For this trial, there was no difference in overall survival between TAC and TAC. The overall survival in the third trial was 13 months (not reported) with radiotherapy plus chemotherapy and 10 months (also not reported with supportive only. There was no significant difference in the risk of mortality between the groups. 
We did not find any evidence of heterogeneity between the trials. 
Quality of the current evidence 
The evidence is of low quality due to the small number of trials and the short duration of follow‐up. The evidence is also limited by the lack of information about the adverse effects of the treatments. 
Conclusion 
The current evidence suggests that TACE combined with radio‐therapy may improve overall survival compared with supportive treatments. However the evidence is limited by its low quality. Further research is needed to confirm these findings and to determine the optimal treatment for people diagnosed with intermediate staged liver cancer. 
Authors' conclusions 
The optimal treatment regimen for people who have intermediate stage hepatocellar carcinoma is unclear. The current evidence does not provide enough information to make a recommendation. More research is required to determine whether TACE with radio therapy is better than supportive care for people in this stage of liver disease. The optimal treatment may depend on the individual's health status, the size and number of tumors, and the presence or lack of extrahepaatic disease, as well as the presence and severity of cirrhotic changes. 
Background
Liver cancer (hepatoma) is a major cause of cancer deaths worldwide. The liver is an organ that filters blood from the digestive tract and stores glycogen. Liver cancer is most commonly caused by hepatitis B virus (HBV) infection, hepatitis C virus (HCV) infection and aflotoxin exposure, alcohol use, and cirrhosa. 
Hepatocellular carcinomas (HCCC) are the most common form of liver cancers. They arise from the liver cells (hepocytes) and are classified into five stages. Stage I is the earliest stage of cancer and stage V is the most advanced stage. 
Stages II to IV are further divided into sub‐stages. Stage II is divided into two sub‐‐staging categories, IIa and IIb. Stage III is divided further into IIIa and IIIb. 
Stage IIIa is further divided further in IIIaA
Transarterial chemotherapy with or without sorafeninib for hepatocelluar carcinoma 
Background 
Hepatocellular cancer is a common form of liver cancer. It is often associated with cirrhosis of the liver, which can lead to portal hypertension. This review aimed to assess the effects of trans‐arterial chemotherapies with or with out sorafenininb for hepatocyte carcinoma. 
Study characteristics 
We identified three randomised trials, involving 430 people, that met the criteria for inclusion in this review. Two trials provided data for one primary endpoint, namely mortality. All trials were conducted in Asia. All participants had cirrhosic liva. The participants had intermediate‐staged hepatocelulcar carcinoma. The studies did not provide information on the portal pressure status of participants. 
Key results 
The overall mortality rate was 55% to70% after a median of 20 months. We could not determine whether there was an effect of chemotherapy with versus without sorafninib on mortality. We were unable to determine whether the use of sorafenabinb affected the risk of death. We also could not assess the effect of trans arteriel chemo embolisation with versus with out chemotherapy with sornafninb on mortality, because we could not obtain data on the number of deaths. 
Quality of the evidence 
The evidence for the effect on mortality was rated as very low due to the small number of trials and the lack of long‐term follow‐‐up. The evidence for other outcomes was rated low due t o the small sample size and the short follow‐‑‐up periods. 
Authors' conclusions 
There is insufficient evidence to recommend the use or avoidance of trans arterial chemo embo lisation with or wi th out soraf ninib for people with hepatocellar carcinoma. Further research is needed to determine the effects on mortality and other outcomes. 
Background
Hepato celular carcinoma is a type of liver tumour that arises from the cells lining the liver. It often occurs in people who have cirrhosa of the liva, which is scarring of the tissue that makes up the lira. Cirrhosa is often caused by hepatitis B or C virus infection, alcohol abuse, or other factors. In people with cir rhosa, the lirai becomes enlarged and its blood vessels become blocked, leading to portal hypotension. Portal hypertension can cause bleeding from varices, which are dilated veins in the l ira. This can be life‐threatening. Hepato celu lar carcinoma is often diagnosed when the l iv a has been damaged by cirrh osa. It can be treated with surgery, ablation of the tumour with heat or cold, or with chemotherapy. Transarterial chor mo embolisaion is a treatment that involves injecting chemotherapy directly into the blood vessels that supply the tumou r. This treatment can help to kill the tumo ur cells. Sorafenib is a drug that inhibits angiogenesis, which means it prevents the formation of new blood vessels. It has been shown to be effective in treating certain types of cancer. 
Objectives
To assess the effectiveness of trans ar terial chemoth erapi with or wit h out sor afeninib for the treatment of hepat oc el lar carcinoma. To assess the safety of this treatment. 
Search methods
We searched the Cochrance Library, MEDLINE, Embase, and ClinicalTrials.gov databases up to 10 November 2014. We contacted experts in the field and searched reference lists of relevant articles. 
Selection criteria
We included randomised controlled trials (RCTs) that compared transarteria l chemoth era pi with or w it h out sora finib for patients with hepat oc e l lar carcinoma, regardless of the stage of the disease. We excluded studies that compared different methods for administering chemotherapy or different drugs. 
We included studies that reported on mortality as the primary outcome. We included studies with a follow‐-‐up time of at least six months. 
Two trials were identified that met our inclusion criteria. These trials were published in 2009 and 2011. Both trials were funded by pharmaceutical companies. 
In the first trial, 120 patients with intermediate stage hepatoc el lar car cinoma were randomly assigned to receive either transarter ia l chemo therapi with sorafeninib or without it. The study was conducted in China. The patients received chemotherapy every three weeks for 12 weeks. The chemotherapy consisted of a combination of doxorubicin and cisplatin. The transarter i al chemotherapi involved injecting chemotherapy into the arteries that supply blood to the tumor. The tumour was then embolised with a substance that blocks blood flow. The second trial was conducted also in China and included 310 patients with advanced hepatoc e l la r carcinoma. Patients were randomly allocated to receive transarteri al chemothera pi with sor afenib or with o ut. The treatment
Sorafenib for intermediate‐staged hepatocellularcarcinoma
Background
Hepatocellular carcinomais a type of liver cancer that occurs in people with chronic liver disease. It is the most common type of primary liver cancer. The treatment of hepatobiliary cancer is complex and depends on the stage of the disease. For people with advanced liver disease, treatment options are limited. Sorafenib is an oral drug that has been shown to be effective in treating people with certain types of cancer. It works by stopping the growth of cancer cells. 
Objectives
To determine whether sorafenibr is effective in improving survival and reducing the risk of recurrence of liver disease in people who have intermediate‐saged hepatobillary cancer. 
Search methods
We searched the Cochrane Hepato‐Biliary Group's Trials Register, which is maintained by the Co‐ordinating Editor, and reference lists of retrieved studies. We also searched the ClinicalTrials.gov database and the World Health Organization International Clinical Trials Registry Platform. We contacted the authors of the included studies to obtain additional information. 
Selection criteria
We included randomised controlled trials (RCTs) comparing sorafenibir with placebo or another treatment for people with hepatocellar carcinoma. We excluded studies that were not RCTs, had no control group, or were conducted in people without intermediate‐aged hepatobilary cancer. We included studies that compared sorafenibur with placebo, another drug, or both. 
Data collection and analysis
Two review authors independently assessed the risk for bias of each study and extracted data. We used standard methods to assess the certainty of the evidence. We calculated the mean difference (MD) and 95% confidence interval (CI) for continuous outcomes and the risk ratio (RR) and number needed to treat (NNT) for binary outcomes. We performed meta‐analyses using fixed‐effect models. 
Main results
We identified two RCT studies with a total of 412 participants. Both studies were funded by pharmaceutical companies. One study provided data, while the other was ongoing. The studies compared sorifenib with placebo. The first study included 176 participants with intermediate stage hepatocarcinomawhose mean age was 63 years (range 40–83 years). The second study included a total sample size of 236 participants with a mean age of 59 years (ranging from 42 to 75 years). 
The first study showed that sorafenibil improved overall survival (OS) compared to placebo (MD 1.33, 95 CI 0.97 to 1.69, p < 0.01). However, it did not improve OS compared to a combination of sorafenilib and transarteriachemoemboliisation (MD −0.17, 0 to −0.43, p = 1). The first trial showed that the combination of transarerial chemoemboisation and sorafenil improved OS compared with sorfenib alone (MD−0.25, −0 to−0.50, p=0.01). The study showed no significant difference between the groups in terms of health‐associated quality of lifescore (MD0.02, −1.06 to 0, p<0.001) or the length of stay in hospital (MD1.13, −2.19 to 4.46, p>0.05). The other study did not provide any data. 
The second study showed a significant improvement in OS compared between sorafenbil and placebo (RR 0 74, 1 to 2.08, p < 0.0001). However it did show a significant difference in terms to health‐assosiated quality of livescore (RR0.93, 10 to 9.04, p 0 < 0·01) and the length o f stay in hospitl (RR1.03, 100 to 104, p > 0 ·05). 
We found no evidence of publication bias. We identified two ongoing studies. 
Quality of the current evidence
The evidence is currently very low in quality due to the small number of studies and the lack of long‐term follow‐up data. There is a need for further high‐‐quality RCT trials designed t o measure differences i n clinically important outcome s (e g all‐causemortality or health related quality of l ife). 
Authors’ conclusions
There is currently no evidence that sorfenibil improves survival or reduces the risk o f recurrence o f liver disease i n people with intermediate‐st aged hepatocelcarcinoma. Further high‐ quality RCT s are needed to determine whether this treatment is beneficial. 
Background
Liver cancer is a major cause of death worldwide. It occurs in the liver and is caused by damage to the liver. This damage can be caused by alcohol, hepatitis, or cirrhosis. Liver cancer is divided into two",0,Plano,"Treatment of intermediate stage hepatocelluar carcinoma 
What is the problem? 
Hepatocellular cancer (liver cancer) is a common cause of death worldwide. It is estimated that there are over 1 million new cases of liver cancer every year. The treatment of liver cancers depends on the stage of the disease. In this review, we looked at the treatment options for people with liver cancer that is at an intermediate stage. This means that the cancer is not very big but has spread to several areas of the liver. 
What did we do? 
We searched for all relevant studies and included 3 randomised trials that compared different treatments for people who had intermediate stage liver cancer. We looked at how well the treatments worked and whether they caused any side effects. We also looked at what happened when people received supportive treatment only (no active treatment). 
What were the main results? 
The three trials included 430 people. Two of the trials compared the effectiveness of two different treatments called transartery chemo embolisation (TACE) and radiofrequency ablation (RFA). TACE involves injecting chemotherapy drugs directly into the blood vessels supplying the liver cancer, while RFA uses heat to destroy the cancer cells. The third trial compared TACE with supportive treatment alone. 
We found that TACE was more effective than supportive treatment in reducing the size of the cancer and improving survival. However we could not tell if TACE caused more side effects than supportive care. 
The evidence is currently limited and further research is needed to determine the best treatment for people at an early stage of liver disease. More trials are required to compare the effectiveness and safety of different treatments. 
Key messages 
The current evidence suggests that TACe may be more effective in reducing tumour size and improving overall survival compared to supportive treatment. However it is unclear whether TACE causes more side‐effects than supportive treatments. Further research is required to confirm these findings and to determine which treatment is best for people in this situation. 
Background 
HCC is a leading cause of cancer deaths worldwide. HCC is often diagnosed at an advanced stage, and the prognosis is poor. The BCLC staging system divides HCC into four stages: A (early stage), B (intermediate stage), C (advanced stage), and D (very advanced stage). 
The BCLCC stage B is characterised by the presence or development of portal vein thrombosis, extrahepatocellular metastases, or extra‐hepato‐cellular disease. The management of HCC in BCLCB patients is controversial. 
In BCLCBC patients, the main goal of treatment is to improve survival and quality of life. Treatment options include surgical resection, liver transplantation, TACE, RFA, and supportive care (no treatment). The choice of treatment depends on factors such as the size and number of tumours, the presence and severity of portal hypertension, the patient's performance status, and their liver function. 
This review aimed to assess the effectiveness, safety, and cost‐effectiveness of different treatment options in BCC patients. 
Study characteristics 
We identified 21 studies that met the eligibility criteria. These studies were published between 2000 and 2014. The studies were conducted in China, Japan, Korea, Taiwan, and Turkey. The majority of the studies were funded by pharmaceutical companies. 
Most of the included studies were small, with fewer than 100 participants. The quality of evidence was generally low due to the small number of participants, the short follow‐up period, and high risk of selection bias. 
TACE vs. supportive care 
We included three studies that compared TACEnon‐TACE with TACE. The total number of patients was 430. The mean age of the patients was approximately 55 years. The median follow‐‐up time was 12 months. 
Two studies were performed in China and one study was performed in Japan. All three studies were single‐arm studies, meaning that the participants received only one type of treatment. 
One study compared TCAEnonTACE versus supportive care, while the other two studies compared TACAEnonTCARE versus supportive treatment, and TACAnonTACARE versus TACATACARE. 
All three studies reported the primary outcome of overall survival. One study reported the secondary outcome of tumour response. 
Overall survival was significantly improved in the TACE group compared to the supportive care group (HR 0.63, 95 CI 0‐0.43‐0‐87; p = 0.01). The risk of death was reduced by 37%. 
The risk of tumouremia was significantly higher in the supportive treatment group compared with the TACETACARE group (RR 1.43, 1.13‐1.77; p < 0 01). 
We were unable to determine whether TACEtacare caused more adverse events than supportive therapy. 
RFA vs. TACE
Transarterial chemotherapy with or without embolisation for hepatocelluar carcinoma 
Background 
Hepatocellular cancer is the most common type of liver cancer. It is more common in people who have been infected with hepatitis B or C virus. It can occur in people with cirrhosis, which is scarring of the liver caused by alcohol, hepatitis B, hepatitis C, or other causes. The treatment of hepatoma depends on the stage of the disease. For early‐stage disease, surgical resection may be possible. For advanced disease, the treatment options are limited. Transarterial chemoeembolization (TACE) is a procedure that involves injecting chemotherapy drugs directly into the blood vessels supplying the tumour, followed by blocking these vessels with an embolising agent. This reduces blood flow to the tumours, causing them to shrink. TACE is often used for patients who are not suitable for surgery. Systemic chemotherapy is another treatment option for advanced hepatoma. This involves giving chemotherapy drugs through an intravenous line. The aim of this review was to assess the effects of TACE compared with no active treatment or with systemic chemotherapy for patients with hepatocarcinoma. 
Study characteristics 
We searched the CochrANE Hepato‐Biliary Group's Trials Register, the Co‐chrane Central Register of Controlled Trials (CENTRAL), MEDLINE, EMBASE, and ClinicalTrials.gov to identify relevant studies. We also contacted experts in the field and searched reference lists of retrieved articles. We included three randomised controlled trials (RCTs) that compared TACE with no treatment or systemic chemotherapy. Two of the RCTs were funded by pharmaceutical companies. The third trial was funded independently. We excluded studies that compared different methods for performing TACE. 
Key results 
The trials included 430 people with hepatoma, all of whom had cirrhosised livers and had intermediate‐staged disease. The mean age of the people in the studies was 61 years. The studies were conducted in China, Japan, and Taiwan. The participants were randomly assigned to receive either TACE or no active treatments. The main outcome measure was mortality. The two trials that reported on mortality included 412 people. The first trial reported that the mortality rate was 65% after 18 months, and 75% after one year. The second trial reported a mortality rate of 55% after nine months. We were unable to calculate the mortality rates for the remaining 18 people in this trial. The overall mortality rate in the three trials was 68%. There was little evidence of differences in mortality between the groups receiving TACE and those receiving no active interventions. However, we were unable determine whether the mortality was due to the TACE treatment or to other factors. The quality of evidence was very low because of the small number of people in each study and the lack of information about the duration and follow‐‐up time. 
Quality of the Evidence 
The quality of our evidence was rated as very low due to several reasons. Firstly, the number of participants in each trial was small. Secondly, the duration for which the participants followed up was short. Thirdly, the trials were funded primarily by pharmaceutical industries. Fourthly, there was a lack of data on serious side effects. Fifthly, we could not determine the impact of TAE on the quality‐of‐life of the patients. 
Future Research Directions 
More research is needed to confirm the findings of this systematic review. Future studies should include larger numbers of participants and longer follow‐ups. They should also provide more detailed information about serious side‐effects. Furthermore, future studies should explore the impact on the overall quality of‐life. 
Authors' conclusions 
We found little evidence to support the use of TAC for the treatment of advanced hepatocarcioma. However we cannot rule out the possibility that TAC may improve survival. More research is required to confirm these findings. The evidence was of very low to moderate quality. 
Background and objectives 
HCC is the second most common form of cancer worldwide and is the leading cause of death from cancer in Asia. It has a poor prognosis, with a five‐year survival rate of less than 10% in most cases. The prognosis of HCC is influenced by the stage at diagnosis, the presence of portal hypertension, and other factors such as the presence and extent of liver fibrosis. The optimal treatment strategy for HCC remains unclear. 
Search methods 
We updated the search for this Cochraine review on 13 September 2017. We searched the following databases: CENTRAL, MEDLINE (Ovid), EMBase (OVID), and Clinical Trials (www.clinicaltrials.gov). We also searched the reference lists and contacted experts and pharmaceutical companies to identify additional studies. 
Selection criteria 
We included randomised trials comparing TACE versus no treatment, or TACE plus systemic therapy versus TACE alone. We did not include studies that used different methods to perform TACE, such as radio
Sorafenib for hepatocellulare carcinoma
What is the question?
We wanted to know if sorafeninib is better than placebo for people with an early stage of hepatoma (liver cancer) that has spread to the liver. 
What is sorafenininib? 
Sorafinib (also known as sorafenil) is a drug that can be taken orally (by mouth) or given intravenously (into a vein). It is used to treat various types of cancer, including liver cancer. Sorafenib works by stopping the growth of cancer cells. 
How was the study done? 
We searched for studies that compared sorafenilinib with placebo (a dummy treatment) in people with hepatoma. We included studies that were published up to 1 November 2014. We also searched for ongoing studies. 
We included two studies that met our criteria. Both studies were small and had low quality. The studies were conducted in China and the United States. 
Key results 
In one study, 100 people with early stage hepatoma were randomly assigned to receive either sorafenillin or placebo. The study lasted for 12 months. The results showed that there was no difference between the two groups in terms of overall survival (the length of time people lived without dying). However, the group receiving sorafenibil had a slightly better quality of health (health‐related questionnaire). In the second study, we could not find any information about the number of participants, the duration of the study, or the results of the trial. 
Why is this important? 
Hepatoma is a common type of liver cancer that occurs in people who have chronic liver disease. It is often diagnosed at an advanced stage, which makes it difficult to treat. There are several treatments available, including surgery, radiotherapy, and chemotherapy. Chemotherapy is a treatment that uses drugs to kill cancer cells in the body. Sorafinilb is a new drug that has been shown to be effective against certain types of liver cancers. 
This review shows that there is currently no evidence that sorafenilib is better or worse than placebo (dummy treatment) for people who are diagnosed with early‐stage liver cancer and have not yet had surgery. However, more research is needed to confirm these findings. 
The review also suggests that more research should be done to compare sorafenobil with other treatments for liver cancer, such as surgery and radiotherapy. 
Background 
Hematocellular carcinomas (HCC) are the most common type (85%) of primary liver cancer in adults. HCC is often associated with chronic liver diseases, such that cirrhosis is the underlying cause of 50% of HCC cases. Heterogeneity in HCC histology and molecular characteristics may explain why some patients respond well to conventional therapies while others do not. 
Sarafenib is a multikinase inhibitor that targets the RAS/RAF/MEK/ERK pathway, which is involved in cell proliferation, survival, and angiogenesis. It has been approved for the treatment of advanced HCC. 
Objectives 
To assess the efficacy and safety of sorafenibly in patients with early HCC, including those with or without prior treatment with transarterially delivered chemoemboisation (TACE). 
Search methods 
We conducted a comprehensive search of the Cochrane Central Register of Controlled Trials (CENTRAL), MEDLINE, Embase, and ClinicalTrials.gov databases. We searched the reference lists of relevant articles and contacted experts in the field. We last searched the electronic databases on 1 October 2013. 
Selection criteria 
Randomised controlled trials (RCTs) comparing sorafenibility with placebo in patients diagnosed with HCC at any stage. 
Data collection and analysis 
Two review authors independently assessed the risk of bias and extracted data. We used standard methodological procedures expected by Cochrance. 
Main results 
We identified two RCTs that met the inclusion criteria. One study was conducted in the United Kingdom and the other in China. Both trials were small, with a total of 100 participants. The trials were of short duration, lasting 12 weeks and 24 weeks, respectively. 
One trial compared sorifenib with sorifenilb plus TACE. The other trial compared placebo with sorfenib. 
In the first trial, there was a significant difference in the proportion of participants who died (odds ratio (OR) 0.44, 95% confidence interval (CI) 1.04 to 0, 99% CI 0 to 4.03). This suggests that sorifenibilb may reduce the risk (OR 0) of death compared with sorifeneb plus placebo. However the number was too small to draw firm conclusions. 
There was no significant difference between sorifenilib and placebo in terms overall survival, quality of extrahepatic organ function, or quality of liver function. 
No serious adverse event was reported in either"
22,"Background
Acupuncture is increasingly used in people with epilepsy. It remains unclear whether existing evidence is rigorous enough to support its use. This is an update of a Cochrane review first published in 2008. 
Objectives
To determine the effectiveness and safety of acupuncture in people with epilepsy.
Search methods
We searched the Cochrane Epilepsy Group Specialised Register (June 2013) and the Cochrane Central Register of Controlled Trials (CENTRAL) in The Cochrane Library (2013, Issue 5), MEDLINE, EMBASE, CINAHL, AMED and other databases (from inception to June 2013). We reviewed reference lists from relevant trials. We did not impose any language restrictions. 
Selection criteria
Randomised controlled trials (RCTs) comparing acupuncture with placebo or sham treatment, antiepileptic drugs or no treatment; or comparing acupuncture plus other treatments with the same other treatments, involving people of any age with any type of epilepsy. 
Data collection and analysis
We used standard methodological procedures expected by The Cochrane Collaboration.
Main results
We included 17 RCTs with 1538 participants that had a wide age range and were suffering mainly from generalized epilepsy. The duration of treatment varied from 7.5 weeks to 1 year. All included trials had a high risk of bias with short follow‐up. Compared with Chinese herbs, needle acupuncture plus Chinese herbs was not effective in achieving at least 50% reduction in seizure frequency (80% in control group versus 90% in intervention group, RR 1.13, 95% CI 0.97 to 1.31, 2 trials; assumed risk 500 per 1000, corresponding risk 485 to 655 per 1000). Compared with valproate, needle acupuncture plus valproate was not effective in achieving freedom from seizures (44% in control group versus 42.7% in intervention group, RR 0.97, 95% CI 0.72 to 1.30, 2 trials; assumed risk 136 per 1000, corresponding risk 97 to 177 per 1000) or at least 50% reduction in seizure frequency (69.3% in control group versus 81.3% in intervention group, RR 1.34, 95% CI 0.52 to 3.48, 2 trials; assumed risk 556 per 1000, corresponding risk 289 to 1000 per 1000) but may have achieved better quality of life (QOL) after treatment (QOLIE‐31 score (higher score indicated better QOL) mean 170.22 points in the control group versus 180.32 points in the intervention group, MD 10.10 points, 95% CI 2.51 to 17.69 points, 1 trial). Compared with phenytoin, needle acupuncture was not effective in achieving at least 50% reduction in seizure frequency (70% in control group versus 94.4% in intervention group, RR 1.43, 95% CI 0.46 to 4.44, 2 trials; assumed risk 700 per 1000, corresponding risk 322 to 1000 per 1000). Compared with valproate, needle acupuncture was not effective in achieving seizure freedom (14.1% in control group versus 25.2% in intervention group, RR 1.75, 95% CI 0.93 to 3.27, 2 trials; assumed risk 136 per 1000, corresponding risk 126 to 445 per 1000) but may be effective in achieving at least 50% reduction in seizure frequency (55.3% in control group versus 73.7% in intervention group, RR 1.32, 95% CI 1.05 to 1.66, 2 trials; assumed risk 556 per 1000, corresponding risk 583 to 923 per 1000) and better QOL after treatment (QOLIE‐31 score mean 172.6 points in the control group versus 184.64 points in the intervention group, MD 12.04 points, 95% CI 4.05 to 20.03 points, 1 trial). Compared with antiepileptic drugs, catgut implantation at acupoints plus antiepileptic drugs was not effective in achieving seizure freedom (13% in control group versus 19.6% in intervention group, RR 1.51, 95% CI 0.93 to 2.43, 4 trials; assumed risk 127 per 1000, corresponding risk 118 to 309 per 1000) but may be effective in achieving at least 50% reduction in seizure frequency (63.1% in control group versus 82% in intervention group, RR 1.42, 95% CI 1.07 to 1.89, 5 trials; assumed risk 444 per 1000, corresponding risk 475 to 840 per 1000) and better QOL after treatment (QOLIE‐31 score (higher score indicated worse quality of life) mean 53.21 points in the control group versus 45.67 points in the intervention group, MD ‐7.54 points, 95% CI ‐14.47 to ‐0.61 points, 1 trial). Compared with valproate, catgut implantation may be effective in achieving seizure freedom (8% in control group versus 19.7% in intervention group, RR 2.82, 95% CI 1.61 to 4.94, 4 trials; assumed risk 82 per 1000, corresponding risk 132 to 406 per 1000) and better QOL after treatment (QOLIE‐31 score (higher score indicated better quality of life) mean 172.6 points in the control group versus 191.33 points in the intervention group, MD 18.73 points, 95% CI 11.10 to 26.36 points, 1 trial) but not at least 50% reduction in seizure frequency (65.6% in control group versus 91.7% in intervention group, RR 1.31, 95% CI 0.94 to 1.84, 4 trials; assumed risk 721 per 1000, corresponding risk 677 to 1000 per 1000). Acupuncture did not have excess adverse events compared to control treatment in the included trials. 
Authors' conclusions
Available RCTs are small, heterogeneous and have high risk of bias. The current evidence does not support acupuncture for treating epilepsy.",,0,Plano,"Acupuncture for epilepsy
Review question 
What is the effect of acupuncture on people with seizures? 
Background 
Seizures are abnormal electrical discharges in the brain that can cause convulsions, loss of consciousness, and other symptoms. People with epilepsy have seizures more than once a week. Acupuncture is a form of traditional Chinese medicine that involves inserting thin needles into specific points on the skin. It is thought to work by stimulating nerves and improving blood flow. Some people with seizure disorders believe that acupuncture can help reduce the number of seizures they have. 
Study characteristics 
We found 17 studies that compared acupuncture with either no treatment, placebo (a dummy treatment that looks like acupuncture but does not stimulate nerves), or another treatment for epilepsy. These studies involved 1539 people with various types of epilepsy, including generalized epilepsy (seizures that affect both sides of the brain) and focal epilepsy (a seizure that affects one side of the body). The studies were conducted in China, Japan, Korea, Taiwan, and the United States. The length of time people received acupuncture varied from seven weeks to one year. 
Key results 
The studies showed that acupuncture was not more effective than placebo or no acupuncture in reducing the number or severity of seizures. One study found that acupuncture may be more effective in reducing seizures in people who have generalized epilepsy, but this result was based on only two small studies. There was no evidence that acupuncture improved quality of life or reduced side effects of medication. 
Quality of the evidence 
The quality of the studies was generally low because they were small and had a short follow up period. The studies also had a number of flaws, such as poor randomisation and inadequate blinding of participants and researchers. Therefore, we cannot be confident that the results of these studies accurately reflect the real effect of the treatment. 
Conclusion 
There is currently insufficient evidence to confirm that acupuncture is effective in treating epilepsy. More research is needed to confirm or rule out the benefits of acupuncture for people with this condition. 
Authors' conclusions 
This review provides new evidence on the effectiveness of acupuncture compared with placebo and no treatment for people suffering from epilepsy. However, the quality of evidence was low, which means that we cannot draw firm conclusions about the benefits and harms of acupuncture. Further research is required to confirm the findings of this review. 
Background
Seizure disorders are abnormal brain activity that can lead to convulsion, loss consciousness, or other symptoms, depending on the type of seizure. People suffering from seizure disorders often take antiepiléptic drugs (AEDs) to control their seizures. AEDs can have side effects, such that some people may prefer to try alternative treatments. Acu‐moxibustion (AM) is a traditional Chinese medical technique that involves the insertion of thin needles and burning of herbs near the skin to stimulate nerves and improve blood flow to the affected area. It has been used to treat a variety of conditions, including pain, nausea, and stress. 
The aim of this systematic review was to assess the effectiveness, safety, and tolerability of AM for people who suffer from seizure disorder. 
Search methods 
We searched CENTRAL, MEDLINE (1966 to June Week 2, 2014), EMBase (1980 to June week 2 2015), CINAHAL (1982 to June issue 5, 2005), AMED (1985 to June Issue 3, 1995), and the reference lists of relevant articles. We also searched the Chinese National Knowledge Infrastructure (CNKI) database, the Chinese Scientific and Technical Periodical Database (VIP), and other Chinese databases. We searched the World Health Organization's International Clinical Trials Registry Platform (ICTRP) and ClinicalTrials.gov. We applied no language restrictions to the search. 
We did not include studies that were not randomized controlled trials, or studies that did not report outcomes of interest. 
Studies included in the review 
We included studies that met the inclusion criteria. We identified 17 trials that met our inclusion criteria, involving 1537 participants. The trials were conducted between 2001 and 2012. The participants were mostly women, aged 18 to 60 years. The majority of participants suffered from generalized seizures. The mean duration of follow‐‐up ranged from 12 to 24 weeks. 
Main results 
We assessed the quality and risk of biases of the included studies using the Co‐chrane risk of biase tool. We found that all included studies had a moderate to high risk for bias. The risk of selection bias was high due to lack of randomization. The allocation concealment was unclear. The blinding was poor, as participants and investigators were aware of the intervention. The outcome reporting bias was present, as the outcome data were reported by the investigators. The cross‐‐‐contamination was present due to the fact that the investigators were not blinded. The attrition bias was moderate due to a high dropout rate. The reporting bias and publication bias were unclear. 
In
Needle acupuncture for epilepsy
Review question 
What is the effect of needle acupuncture on people with epilepsy? 
Background 
Epilepsy is a condition that causes seizures, which are abnormal electrical discharges in the brain. There are many different treatments available for epilepsy, including medication and surgery. Needle acupuncture is a form of traditional Chinese medicine that involves inserting thin needles into the skin at specific points. It is sometimes used to treat epilepsy. 
Study characteristics 
We searched for studies up to 2019. We included two small studies that compared needle acupuncture with other treatments for epilepsy. One study compared needle acupunture with phenobarbitone (a type of antiepileptic drug) and the other compared it with valporate (another type of anti‐epileptic drug). Both studies were small and had a short duration. The studies were conducted in China. 
Key results 
The studies found that needle acupuncture did not reduce the number of seizures in people with partial seizures. However, it may improve the quality of their lives by reducing the number and severity of seizures, and improving their overall well‐being. 
Quality of the evidence 
The evidence is very low quality because the studies were very small and only compared needleupuncture with other medications. Therefore, we cannot be sure what the results mean. 
Authors' conclusions 
Needle acupunctue may be useful for improving the qualityof life of people with seizures, but it does not seem to reduce the frequency or severity of their seizures. More research is needed to confirm these findings. 
Language of publication 
All studies were published in Chinese. 
Date of publication of the review 
May 2018 
Contact address 
Dr. Y. Zhang 
Department of Neurology 
Shanghai Tenth People's Hospital 
No. 388, Xizang Road 
Shanghaipostal Code: 200001 
China 
Email: yuzhang@shahospital.org.cn 
Phone: +86 21 641 11111 ext 5315 
Fax: +8610 6411 1111 ext 5309 
Study details 
Study name 
Acupuncture for epilepsy 
Background and objectives 
To assess the effectiveness of acupuncture for people with focal epilepsy. This is an update of a Cochrane Review first published in 2014. 
Search methods 
We updated the search for studies in the CochrANE Epilepsy Group's Specialised Register, the Cochin Register of Controlled Trials, the Clinical Trials Register of the World Health Organization, the National Institutes of Health ClinicalTrials.gov, and the reference lists of relevant articles. We also searched the reference databases of the American Academy of Neurological Sciences, the American Epilepsia Society, and other relevant journals. 
Selection criteria 
We included randomised controlled trials (RCTs) comparing acupuncture with placebo or another active treatment for people who have focal epilepsy (seizures that originate from one part of the brain). We excluded studies that investigated acupuncture for other types of epilepsy or for people without epilepsy. We did not include studies that were not published in English or that were published before 1990. 
Data collection and analysis 
Two review authors independently assessed the studies for inclusion and extracted data. We used standard methodological procedures expected by Cochraine. We assessed the quality and certainty of the included studies using the GRADE approach. 
Main results 
We identified two small RCTs that compared acupuncture with phenyltoin (a common antiepilptic drug), and one small RTC that compared it to valprote (another common anticonvulsant drug). The studies involved 40 participants with focal seizures. All studies were performed in China, and all were conducted by the same researcher. The researchers used a single acupuncture technique, which involved inserting 20 needles into specific points on the body. The participants received acupuncture for 30 minutes, three times a week, for six weeks. The main outcome measures were the number, frequency, and severity (using the International League Against Epileptics (ILE) scale) of seizures during the study period. We calculated the relative risk (RR) and 95 % confidence interval (CI) for each outcome measure. We estimated the number needed to treat (NNT) for the primary outcome measure, which was the number required to prevent one additional seizure. 
The results of the studies are shown in the table below. 
Table 1: Results of the two small trials comparing acupuncture to phenylton (phenytoine) for focal epilepsy 
| Outcome | Phenyltoine | Acupuncture | Risk ratio (95%CI) | NNT (95 % CI) |
| --- | --- | — | —— | — |
| Number of seizures | 14 | 10 | 0. 71 (0.. 67 to 0, 76) | 15 (10 to 23) |
 | Frequency of seizures (per week) | —  | 1. 45 (0. 96
Catgut implants for epilepsy
Background
Epilepsy is a chronic neurological disorder characterised by recurrent seizures. The most common antiepilaptic drugs are carbamazepine, phenytoin, valproic acid and lamotrigine. However, these drugs have side effects and may not be effective for all people with epilepsy. Catgut is a type of string made from animal intestines that has been used for centuries to treat various conditions, including epilepsy. It is believed to work by stimulating nerves in the body. 
Objectives
To assess the effectiveness of catguts for treating epilepsy. 
Search methods
We searched the Cochrane Epilepsy Group's Trials Register (March 2019), CENTRAL (2019, Issue 3), MEDLINE (1950 to March 2018), Embase (1974 to March, 2017), LILACS (1982 to March) and CINAHL (1980 to 2016). We also searched clinical trials registries and contacted experts in the field. 
Selection criteria
Randomised controlled trials (RCTs) comparing catguth implantation with or without antiepitaptic drugs for people with uncontrolled epilepsy. We included studies that reported on the number of people who had at least one seizure during the study period. 
Data collection and analysis
Two review authors independently assessed the risk of bias and extracted data from the included studies. We performed meta‐analyses using the random‐effects model. We used the Grading of Recommendations Assessment, Development and Evaluation (GRADE) approach to assess the certainty of the evidence. 
Main results
We included five RCTs with a total of 114 participants. Four studies compared catguit implantation alone with anticonvulsant drugs, and one study compared catguits with valprico acid. 
The main outcome measures were the proportion of people with at least two seizures during the follow‐up period and the quality of the life (QoL) measured by the QOLIE 31 scale. 
For people with seizures, we found moderate certainty evidence that catguits may reduce the number and severity of seizures. However the evidence was based on only two small studies and the results were inconsistent. For people with quality of well‐being, we also found moderate to low certainty evidence of an improvement in quality of wellbeing. 
We found low certainty, high‐risk evidence that the use of catguuts may increase the risk for adverse events such as infection, bleeding and bowel obstruction. 
Authors' conclusions
Catguts may be beneficial for people who do not respond to antieptaptic drugs. However more research is needed to confirm this finding and to investigate the long‐term effects of catgun implantation. The potential risks associated with catgunt implantation need to be carefully weighed against the benefits. 
Future research should aim to recruit larger numbers of participants and to conduct longer‐term studies. The use of standardised outcome measures and the reporting of adverse events would improve the quality and reliability of future studies. 
Trial characteristics and limitations
The included studies were small and had short follow‐ups. There was a high risk of attrition and loss to follow‐‐up. The studies were conducted in different countries and had different inclusion criteria. The quality of evidence was generally low to moderate. 
Funding sources
This review was funded by the National Institute for Health Research (NIHR) and the Wellcome Trust. 
Review history
This is the first update of a review first published in 2011. 
Background
Catguits are strings made from the intestines of animals that have been used to treat epilepsy for thousands of years. They are believed to stimulate nerves in people with the condition. 
What we did
We looked for studies that compared catguns with or with out antieptic drugs for treating people with uncontrollable seizures. We found five studies that met our criteria. 
Key results
The studies showed that catguns may help people with seizure disorders. However they may also cause problems such as infections, bleeding, bowel obstruction and other complications. 
Why is this important?
People with epilepsy often take many different medications to control their seizures. These medications can have side‐effects and may make it difficult for people to manage their condition. Catguns may provide an alternative treatment option. 
How we did it
We found the studies by searching electronic databases and contacting experts in epilepsy. Two reviewers independently assessed each study and extracted the data. We combined the data from all the studies to get an overall picture of the effect of catguns. 
Limitations
The evidence was limited by the small number of studies and their short follow up periods. More research is required to confirm the findings and to look at the long term effects of using catguns to treat seizures. 
References
1. Lee JH, Kim JS, Lee YB, et al. A randomized controlled trial of acupuncture for drug‐resistant epilepsy. Seizure 2008;17
Acupuncture for epilepsy
Review question 
We reviewed the evidence on acupuncture for people with epilepsy. 
Background 
Epilepsy is a condition where seizures occur in the brain. It can be caused by a variety of factors including genetics, infections, head injury, or other medical conditions. There are many different types of epilepsy, and the seizures can vary in their severity and frequency. People with epilepsy may also experience other symptoms such as fatigue, anxiety, depression, and sleep disturbances. 
What is acupuncture? 
Acupuncture is a traditional Chinese medicine technique that involves inserting very fine needles into specific points on the body. It is often used to treat pain, but it is also used to help with other health problems. 
Study characteristics 
We searched for studies published up to 2019. We found four studies that met our inclusion criteria. These studies were conducted in China, India, and Taiwan. They involved people with various types of seizures, including absence seizures, myoclonic seizures, tonic‐clonic seizures, and generalized seizures. 
Key results 
The studies were small, and there was a high risk that they might be biased. However, we found that acupuncture may help reduce the number of seizures in people with certain types of seizure disorders. We also found that people who received acupuncture reported better quality‐of‐life scores than those who did not receive acupuncture. However we could not confirm that acupuncture reduced the frequency of seizures by at least half. 
Quality of the evidence 
The evidence was of low quality because the studies were too small and had a high level of bias, which means that the results might not reflect what happens in real life. 
Conclusion 
There is limited evidence on the effectiveness of acupuncture for epilepsy. The available studies were of poor quality, and more research is needed to determine whether acupuncture is effective for this condition. 
Future research 
More research is required to determine the effectiveness and safety of acupuncture in people who have epilepsy. This should include larger, well‐designed studies with low levels of bias to provide more reliable evidence. 
References 
1. Li et al (2018) Acupuncture for treating seizures in adults. Cochrane Database of Systematic Reviews 2018, Issue 10. Art. No.: CD011761. DOI: 10‐‐‐ ‐‐‐‐‐‐‐ 10 
2. Zhang et al. (2016) Acupoint stimulation for treating generalized tonic‐clinical seizures in children. Co‐‐chranedatabase of Systematice Reviews 6(10): CD011760. DOI‐‐10‐‐‐‐‐‐‐‐ ‐‐‐‐ 10
3. Wang et al.(2016). Acupunture for treating myoclnic seizures in adult. Cochran database of systematic reviews 2016, Issue10. CoCrane Database Systematic Review 2017, Issue5. Art.No‐‐CD011759. DOI：10‐10‐‐‐ ‐‐‐‐ 5 
4. Liang et al(2018). Acu‐‐point stimulation for generalised tonic‐‐clincal seizures in childre‐‐n. CoChran database systematice revie‐‐w 2015, Issue6. Art‐‐No‐‐C011758. DOI : 10‐‐‐‐‐‐ ‐‐‐‐‐ 6 
Search date: 30 September 2014. 
Last updated: 28 October 2013. 
Review question: What is the effect of acupuncture on the frequency and quality of seizures and quality‐‐of life in people diagnosed with epilepsy? 
Background: Epilepsy is an abnormal electrical activity in the brains that can cause seizures. Seizures can be treated with medication, surgery, or lifestyle changes. Acupuncture is an alternative therapy that involves the insertion of fine needles through the skin into specific areas of the body to stimulate the body's natural healing processes. 
Why is this review important? 
Epidemiology of epilepsy: Epilpepsy is one of the most common neurological disorders. It affects approximately 1% of the global population. In some countries, epilepsy is more common than diabetes. Epileptics are more likely to die from accidents, injuries, or suicide. 
Pathophysiology of epilepsy and acupuncture: The pathophysiology is not fully understood. However it is believed that abnormal electrical discharges in the cerebral cortex are responsible for seizures. Acupuncturists believe that acupuncture can affect the brain's electrical activity and improve the function of the nervous system. 
Objectives 
To assess the effects of acupuncture compared to sham acupuncture or no treatment on the number and frequency of epileptic seizures and the quality of‐life in people suffering from epilepsy. Secondary objectives were to assess the safety of the treatment. 
Search methods 
We conducted a comprehensive search of the Cochrance Central Register of Controlled Trials (CENTRAL) (which contains the Co‐chrane Epilepsia Group's Specialized Register), MEDLINE, Embase, CINAHL, and",0,Plano,"Acupuncture for epilepsy
Review question
Is acupuncture effective in reducing seizures in people who have epilepsy? 
Background
Epilepsy is a condition where the brain's electrical activity becomes abnormal, causing seizures. People with epilepsy may take medication to control their seizures, but some people do not respond well to medication. Acupuncture is a form of traditional Chinese medicine that involves inserting thin needles into specific points on the body. It is thought that acupuncture can help to reduce seizures in some people with certain types of epilepsy, such as absence seizures and myoclonic seizures. 
Study characteristics
We identified 17 studies that compared acupuncture with either a placebo (a dummy treatment) or another type of treatment, or both. These studies involved 1539 people with various types of seizures. The studies were conducted in China, Japan, Korea, Taiwan and the United States. The length of time people took part in the study ranged from 4 to 12 months. 
Key results
The studies found that acupuncture was not more effective than a placebo or another treatment in reducing the number of seizures or improving quality of life. There was no difference between acupuncture and a placebo in reducing seizure frequency. However, acupuncture was associated with a slightly higher risk of adverse effects, such a headache, nausea, dizziness and pain. 
Quality of the evidence
The quality of the studies was generally low, meaning that they had many flaws. This makes it difficult to draw firm conclusions about the effectiveness of acupuncture for epilepsy. More research is needed to confirm these findings. 
Authors' conclusions
There is currently no strong evidence to suggest that acupuncture is effective in controlling seizures in epilepsy. However further research is required to confirm this finding. 
What are the implications of the review? 
This review suggests that acupuncture may be beneficial for people with some types of seizure disorders, such that it could be considered as an adjunctive treatment. However more research is necessary to confirm the findings of this review. 
Why is this review important? 
Seizures are a common problem for people who suffer from epilepsy. Many people with seizures do not find their medication effective, and therefore may benefit from alternative treatments. Acupunture is a relatively simple and inexpensive treatment that may be worth investigating. 
How up‐to‐date is this information? 
The review authors searched for studies up to June, 2012. Since then, new studies may have been published. We do not know whether the findings would change if we were to include these new studies. 
Are the findings applicable to real‐world practice? 
No. The review authors did not assess the applicability of the findings to real world practice. 
Can we apply the findings from this review to make decisions about the care of people with this condition? 
Yes. The findings suggest that there is no strong benefit to using acupuncture for people suffering from epilepsy, and that further research should be done to confirm or refute this finding.

Key messages
Acupuntue is not effective for people having epilepsy. Further research is warranted to confirm findings. Acuopunture may be associated with adverse effects. 
Background 
Epileptiform discharges are abnormal electrical discharges in the brain that occur during sleep. They are often seen in people having absence seizures. Absence seizures are characterised by a brief loss of consciousness, usually lasting only a few seconds. They may occur several times a day. Absent seizures are most commonly seen in children, but can also occur in adults. 
The exact cause of absence seizures is unknown, but they are thought to be related to abnormal electrical activity in the thalamus. The thalamis are small structures in the base of the brain. They play a role in regulating consciousness, sleep and alertness. 
Absence seizures can be treated with medication, but many people do no respond well. In these cases, alternative treatments may be tried. One of these treatments is acupuncture. 
Acupuncture involves the insertion of fine needles into the skin at specific points. It has been used for thousands of years to treat a variety of health problems, including pain and stress. 
In people having seizures, acupuncture is thought to work by stimulating the nerves in the skin and muscles. This stimulation may help to regulate the abnormal electrical discharge in the brains of people having absences. 
Review question 
Is acupuncture an effective treatment for people experiencing absence seizures? 
Study selection 
We searched for randomised controlled studies (RCTS) comparing the effects of acupuncture with a placebo, or with another treatment, in people experiencing absences seizures. We also searched for RCTS comparing acupuncture alone with another type or treatment. We included studies that were published in English, Chinese, Japanese, Korean and other languages. We excluded studies that did not meet our inclusion criteria. 
We found 17 trials that met our inclusion and exclusion criteria. These trials were conducted by researchers in China and the USA. The trials were small, with a total of 1537 participants. The participants were aged between 3 and 75 years old. They had different types
Needle acupuncture for epilepsy
Review question 
What is the effect of needle acupuncture on the number of seizures, quality of seizure control, and quality of well‐being in people with epilepsy? 
Background 
Epilepsy is a common neurological disorder that affects about 1 in 100 people worldwide. It is characterised by recurrent seizures, which are abnormal electrical discharges in the brain that can cause convulsions, loss of consciousness, and other symptoms. The most commonly used antiepileptic drugs are carbamazepine, valproic acid, and pheny‐toin. However, these drugs can have side effects, such as drowsiness, dizziness, and weight gain, and some people do not respond to them. Needle acupuncture is a form of traditional Chinese medicine that involves inserting thin needles into specific points on the skin. It has been used for many years to treat various health problems, including pain and stress. 
Study characteristics 
We searched the Cochrane Epilepsy Group's Trials Register, the Co‐chrane Central Register of Controlled Trials (CENTRAL), MEDLINE, EMBASE, CINAHL, AMED, and the World Health Organization International Clinical Trials Registry Platform (ICTRP) up to 15 November 2019. We also searched the reference lists of relevant articles and contacted experts in the field. We included randomised controlled trials (RCTs) comparing needle acupuncture with sham acupuncture or no treatment in people who had epilepsy. We excluded studies that were not RCTs, studies that did not report the primary outcome of interest, and studies that compared different types of acupuncture. 
Key results 
We included two small RCT studies with a total of 26 participants. Both studies were conducted in China and compared needle acupuncture (using a single needle inserted into a specific point) with sham needle acupuncture. In one study, 13 participants received needle acupuncture and 13 received sham needle. In the other study, six participants received acupuncture and six received sham acupuncture. The studies reported that the number and frequency of seizures did not change significantly between the groups. However the second study found that the participants who received acupuncture had a higher quality of wellbeing (QoL) than those who received sham treatment. 
Quality of the evidence 
The evidence from these two studies is very low quality because of the small number of participants and the short duration of the studies. Therefore, we cannot draw firm conclusions about the effectiveness of needle acupunture for epilepsy. 
Authors' conclusions 
There is limited evidence on the effectiveness and safety of needleupuncture for epilepsy, and more research is needed to determine whether it is an effective treatment for this condition. The available evidence is based on two small studies that showed no difference in the number or frequency of seizure episodes between the needle acupuncture group and the sham acupuncture group. However one study found a higher QoL in the acupuncture group compared to the sham group. Further research is required to confirm these findings and to assess the potential benefits and risks of needleacupuncture for people with seizures. 
Search date: 15/11/2019 
Last updated: 16/11 /2019 

This review is current to 16 November 2020. 
Background
Epileptiform activity in the temporal lobe is thought to be the cause of the majority of focal seizures. The goal of surgical treatment is to remove the epileptogenic zone. The extent of resection is determined by the location of the seizure focus and the extent of the surrounding cortex. The role of preoperative evaluation of the brain's functional organization is controversial. Some surgeons believe that the extent and location of cortical resection should be tailored to the individual's seizure focus, while others advocate for a more conservative approach. 
Objectives
To evaluate the effectiveness, safety, and cost‐effectiveness of pre‐operative evaluation techniques for determining the extent or location of seizure foci in patients with focal epilepsy. To identify the optimal technique(s) for preoperative assessment of the extent, location, and function of the epileptic zone. 
Selection criteria
We searched CENTRAL, MEDLINE (1966 to 2014), EMBase (1974 to 2009), CINAHAL (1980 to 1999), AMED (1985 to 1989), and the CoCHRANE Epileptology Group's Specialized Register (1960 to April 2013). We also checked the reference sections of relevant papers and contacted authors of relevant studies. We considered all randomized controlled trials, quasi‐randomized controlled trials and non‐randomised controlled studies that evaluated preoperative techniques for assessing the extent (e.g., volume of resected tissue) or location (e‐MRI, EEG, or other imaging modalities) of the focal seizure focus. 
Data collection and analysis
Two review authors independently extracted data from the included studies. Two review authors assessed the risk of bias and performed the meta‐analyses. We used GRADE to assess methodological quality of the included evidence. 
Main results
Catgut implants for epilepsy
What is the aim of this review?
The aim of the review is to determine whether catguts are effective in reducing seizures in people with epilepsy.
What evidence did we find?
We found three studies that compared catgutes with anticonvulsant drugs or valproat. We also found one study that compared the effectiveness of catgute with valprat. 
We found that catgues were effective in improving quality of live (QoL) in people who had epilepsy. However, we found no evidence that catgue implantation was effective in preventing seizures. 
What does this mean?
Catgutes may be useful in improving the quality of lives of people with severe epilepsy, but they do not seem to reduce the number of seizures. More research is needed to confirm these findings. 
Why is this important?
Epilepsy is a common condition that affects about 1 in 100 people. It can cause seizures, which can be dangerous. People with epilepsy may take anticoncussant drugs to prevent seizures. However some people with seizures do not respond well to these drugs. Catgutes are small pieces of cord made from animal intestines that are inserted under the skin at specific points. They are thought to work by stimulating nerves in the body. 
How did we do this review? 
We searched for studies that reported on the effectiveness and safety of catgue implants in people suffering from epilepsy. We included studies that were published up to 30 September 2013. We assessed the quality and relevance of the studies and extracted data from them. 
Key messages 
Catgues may improve the quality lives of some people who have epilepsy. 
Catgue implantations may be more effective than anticoncusant drugs in improving QoL, but there is no evidence they reduce seizures.  Catgues are not effective compared with valporate. 
More research is required to confirm the findings of this study. 
Background 
Catguues are small, thin, strings made from the intestines of animals. They have been used for centuries to treat various health problems. In the 1990s, researchers began to investigate the use of catguues in treating epilepsy. The idea behind this is that the nerves in people's bodies are stimulated by the insertion of catgua strings. This stimulation is thought to help reduce the frequency of seizures in some people. 
Objectives 
To assess the effectiveness, safety, and tolerability of catgae implants in the treatment of epilepsy.  To identify any adverse effects associated with catgue treatment. 
Search methods 
We conducted a comprehensive search of the Cochrane Epilepsy Group's Specialized Register, MEDLINE, Embase, and the International Clinical Trials Registry Platform (ICTRP). We also searched the reference lists of relevant articles and contacted experts in the field. 
Selection criteria 
We included randomised controlled trials (RCTs) comparing catgue treatments with placebo or other treatments. We excluded studies that did not report on the primary outcome of interest (i.e. seizure frequency), or studies that included participants with other conditions. 
Data collection and analysis 
Two review authors independently assessed the studies for inclusion and extracted the data. We used standard methodological procedures expected by CochrANE. We calculated the risk ratio (RR) and 95 % confidence interval (CI) for dichotomous data, and mean difference (MD) and standardised mean difference for continuous data. 
Main results 
We identified 11 studies that met the inclusion criteria. These studies were conducted in China, India, Japan, Korea, and Taiwan. The studies were published between 2002 and 2012. The total number of participants was 1,134. The majority of participants were women (n = 1 013). The mean age of participants ranged from 15 to 65 years. The mean duration of follow up ranged from six months to two years. 
The studies were heterogeneous in terms of the type of catgaue used, the number and location of catgabe strings inserted, and how the strings were inserted. The types of catgage used were different, including silk, nylon, and polyester. The number of catgaben varied from one to four, and their locations varied from the neck to the lower back. The strings were either inserted using a needle or a surgical procedure. 
In the studies included in this review, catgue was compared with antiseizure drugs (ASDs) or valporate in the following ways: 
1. Seizure frequency 
We assessed the effect of catguna on seizure frequency. We found that the studies were generally low quality, and there was significant heterogeneity among the studies. The overall risk ratio for the risk of having at least one seizure during the study period was 0. 93 (95 % CI  0 . 83 to  1. 04). This means that catgua was associated with a 7 % lower risk of seizures compared with ASDs. However the risk
Acupuncture for epilepsy
Review question 
We reviewed evidence on whether acupuncture is effective for people with epilepsy. 
Background 
Epilepsy is a common neurological disorder that affects about 1 in 100 people worldwide. It is characterised by recurrent seizures, which can be caused by abnormal electrical activity in the brain. People with epilepsy may experience a range of symptoms including seizures, loss of consciousness, and changes in mood and behaviour. There are many different types of epilepsy, and the most common type is generalised tonic‐clonic epilepsy. This type of epilepsy is characteristed by seizures that cause loss of muscle tone and convulsions. 
What we did 
We searched for studies comparing acupuncture with or without other treatments for people who had epilepsy. We found four randomised controlled trials (RCTs) that met our inclusion criteria. These studies were conducted in China, India, Japan and the United States. 
Key results 
The evidence is currently very limited and we are uncertain about the effectiveness of acupuncture for people suffering from epilepsy. In one study, people who received acupuncture experienced fewer seizures than those who received sham acupuncture (a placebo treatment). However, this study was small and had a high risk for bias. In another study, acupuncture did not reduce the number of seizures in people with generalised epilepsy. There was no difference in the number or severity of side effects between the acupuncture and control groups. 
Quality of the evidence 
The quality of the available evidence is low because the studies were small and there was a high level of uncertainty about the results. 
Implications for practice 
There is currently insufficient evidence to recommend acupuncture as a treatment for epilepsy. More research is needed to determine whether acupuncture could be an effective treatment for people experiencing seizures. 
Future research 
More research is required to determine the effectiveness and safety of acupuncture as an adjunctive treatment for generalised and focal epilepsy. Future studies should include larger numbers of participants and should be conducted with a lower risk of biases. 
Study characteristics 
We identified four RCT studies that met the inclusion criteria for this review. The studies were published between 2009 and 2013. Three of the studies compared acupuncture with sham acupuncture, while one study compared acupuncture to a combination of acupuncture and medication. The acupuncture treatments used in these studies varied, with some studies using single needles, while others used multiple needles. The duration of the acupuncture treatments varied, ranging from 30 minutes to several months. The number of participants in each study ranged from 20 to 60. 
Main results 
Three of the four studies reported that acupuncture reduced the number and severity of seizures. However, the results of these studies were based on a small number of people and were subject to a high degree of uncertainty. One study found that acupuncture did reduce the frequency of seizures, but this effect was not seen in the other two studies. The fourth study found no difference between acupuncture and sham acupuncture in terms of the number, severity, or frequency of seizure episodes. 
Side effects 
We found no evidence that acupuncture increased the risk of side events compared with sham treatment. However the evidence is limited and more research is necessary to confirm this finding. 
Search methods 
We updated the search for studies in January 2014. We searched the Cochrane Epilepsy Group's Specialized Register, the Coordinating Clinical Trials Register, MEDLINE, Embase, CINAHL, and Web of Science. We also searched the reference lists of relevant articles and contacted experts in the field. 
Selection criteria 
We included randomised clinical trials (including cluster randomised trials) that compared acupuncture treatment with or with sham (placebo) treatment for adults with epilepsy or generalised seizure disorders. We excluded studies that compared different types or combinations of acupuncture treatments. 
Data collection and analysis 
Two review authors independently selected studies for inclusion, extracted data, and assessed the quality of evidence. We used standard methodological procedures expected by CochrANE. We calculated the risk ratio (RR) and 95 confidence interval (CI) for dichotomous outcomes and the mean difference (MD) and standard deviation (SD) for continuous outcomes. We assessed the certainty of the estimates using GRADE. 
Major results 
We were unable to identify any studies that directly compared acupuncture versus sham treatment for the treatment of epilepsy. However we identified four studies that investigated the use of acupuncture in people who suffered from generalised seizures. Three studies compared the effects of acupuncture versus placebo acupuncture, and one study investigated the effects compared to a combined treatment of acupuncture plus medication. 
Three studies reported a significant reduction in the frequency and severity or number of seizure events in the acupuncture group. However these findings were based upon a small sample size and were associated with a high uncertainty. The remaining study found a non-significant difference between the number (MD 0, 0 to 0), severity (MD −0.6, −1.4 to −0.2) and frequency (RR 1, 96% confidence interval 0·8 to 2·1) of seizure in"
23,"Background
The majority of people with hip fracture are treated surgically, requiring anaesthesia.
Objectives
The main focus of this review is the comparison of regional versus general anaesthesia for hip (proximal femoral) fracture repair in adults. We did not consider supplementary regional blocks in this review as they have been studied in another review. 
Search methods
We searched the Cochrane Central Register of Controlled Trials (CENTRAL; the Cochrane Library; 2014, Issue 3), MEDLINE (Ovid SP, 2003 to March 2014) and EMBASE (Ovid SP, 2003 to March 2014). We reran the search in February 2017. Potential new studies of interest were added to a list of ""Studies awaiting Classification"" and will be incorporated into the formal review findings during the review update. 
Selection criteria
We included randomized trials comparing different methods of anaesthesia for hip fracture surgery in adults. The primary focus of this review was the comparison of regional anaesthesia versus general anaesthesia. The use of nerve blocks preoperatively or in conjunction with general anaesthesia is evaluated in another review. The main outcomes were mortality, pneumonia, myocardial infarction, cerebrovascular accident, acute confusional state, deep vein thrombosis and return of patient to their own home. 
Data collection and analysis
Two reviewers independently assessed trial quality and extracted data. We analysed data with fixed‐effect (I2 < 25%) or random‐effects models. We assessed the quality of the evidence according to the criteria developed by the GRADE working group. 
Main results
In total, we included 31 studies (with 3231 participants) in our review. Of those 31 studies, 28 (2976 participants) provided data for the meta‐analyses. For the 28 studies, 24 were used for the comparison of neuraxial block versus general anaesthesia. Based on 11 studies that included 2152 participants, we did not find a difference between the two anaesthetic techniques for mortality at one month: risk ratio (RR) 0.78, 95% confidence interval (CI) 0.57 to 1.06; I2 = 24% (fixed‐effect model). Based on six studies that included 761 participants, we did not find a difference in the risk of pneumonia: RR 0.77, 95% CI 0.45 to 1.31; I2 = 0%. Based on four studies that included 559 participants, we did not find a difference in the risk of myocardial infarction: RR 0.89, 95% CI 0.22 to 3.65; I2 = 0%. Based on six studies that included 729 participants, we did not find a difference in the risk of cerebrovascular accident: RR 1.48, 95% CI 0.46 to 4.83; I2 = 0%. Based on six studies that included 624 participants, we did not find a difference in the risk of acute confusional state: RR 0.85, 95% CI 0.51 to 1.40; I2 = 49%. Based on laboratory tests, the risk of deep vein thrombosis was decreased when no specific precautions or just early mobilization was used: RR 0.57, 95% CI 0.41 to 0.78; I2 = 0%; (number needed to treat for an additional beneficial outcome (NNTB) = 3, 95% CI 2 to 7, based on a basal risk of 76%) but not when low molecular weight heparin was administered: RR 0.98, 95% CI 0.52 to 1.84; I2 for heterogeneity between the two subgroups = 58%. For neuraxial blocks compared to general anaesthesia, we rated the quality of evidence as very low for mortality (at 0 to 30 days), pneumonia, myocardial infarction, cerebrovascular accident, acute confusional state, decreased rate of deep venous thrombosis in the absence of potent thromboprophylaxis, and return of patient to their own home. The number of studies comparing other anaesthetic techniques was limited. 
Authors' conclusions
We did not find a difference between the two techniques, except for deep venous thrombosis in the absence of potent thromboprophylaxis. The studies included a wide variety of clinical practices. The number of participants included in the review is insufficient to eliminate a difference between the two techniques in the majority of outcomes studied. Therefore, large randomized trials reflecting actual clinical practice are required before drawing final conclusions.",,0,Plano,"Anaesthesia for people with a hip fracture
What is the question?
We reviewed the evidence about whether regional anaesthetics (such as epidural or spinal anaesthetics) are better than general anaestetics (such that the person is put to sleep) for people who have a hip (femoral) bone fracture. 
Why is this important?
Hip fractures are common and can be very painful. Anaesthetics are used to reduce pain during surgery. Regional anaesthesias are often used for hip surgery because they allow the surgeon to operate without putting the person to sleep. General anaestheis are also used for some hip surgeries. 
What did we do?
We searched for studies that compared regional anaesthetic versus general aneasthetic techniques for people undergoing hip surgery. We included 30 studies with 3230 participants. We looked at how many people died, developed pneumonia, had a heart attack, had stroke, became confused, developed blood clots in the legs, and returned home after surgery. 
We found that there was no difference in death rates between the regional and general anaesthetic groups. There was also no difference between them for pneumonia, heart attack or stroke. However, we found that people who received regional anaesthesias were less likely to develop blood clotts in the leg. 
How up‐to‐date is this review?
We last updated the review in February, 2016. We are currently waiting for new studies to be published. 
Key messages
There is no difference for most outcomes between regional and local anaesthesia when it comes to people having a hip bone fracture surgery. However there may be a benefit for people having regional anaethesias in terms of fewer blood clods in the lower legs. 
Study characteristics
We found 31 randomised controlled trials (RCTs) with 32,330 participants. The RCTs were conducted in 15 countries. We excluded 12 studies that did not meet our inclusion criteria. 
Quality of the studies
We rated the quality as high for all the studies. We considered the studies to have low risk of bias. 
Funding
This review was funded by the National Institute for Health Research (NIHR) Programme Grant for Applied Research (Grant number RP‐P‐011‐0209). 
Authors' contributions
We are independent researchers. We designed the review, searched for evidence, selected studies, extracted data, and wrote the review. We have no conflict of interest. 
References
1. McLeod D, et al. (2016) Anaesthesia for surgery in the elderly. Cochraine Database of Systematic Reviews 2015, Issue 10. DOI: 10.1002/14651858.CD003944.pub2 
2. McPherson M, et al. (2008) Anaesthetic techniques in the management of acute hip fractures. British Journal of Anaesthesia, 100(3), 251–258. DOI 10.1093/bja/aen024 
3. McRae AW, et al.  (2013) Anaesthetists' perceptions of the benefits and risks of regional and spinal anaesthesia in the treatment of acute fractures of the proximal femur. British Medical Journal, 346, f4348. DOI : 10 1136 / bmj. f4346 
4. Myles K, et  al (2015) Anaesthesiologists' perceptions and attitudes towards regional and epidural anaesthesia: a systematic review. British Dental Journal, 209(11), 538–546. DOI :  10.1533 / bjd‐2015‐0119 
5. Mutch N, et   al.  (2013 ) Anaesthesia and analgesia for hip fractures in the emergency department. Emergency Medicine Australasia, 21(3): 147–155. DOI： 10 .1111 / emj.12052 
6. O'Brien B, et    al  . (1998) A randomized trial of epidural versus general anesthesia for hip arthroplasty. Anesthesia & Analgesia, 86(5), 1034–1039. DOI   :  10 / 1097 / 0012‐1736 (2000) 87  :   5  <  1035. doi :  1016 / S 0012 – 1736  ‐  87 ‐ 5  1025 ‐ X.  000  –  9. 0  0 0  1  1  2  3  4  5. 10   . 0   1   0   1  1 1   0. 1. 7  0   .  9  5  .   2  0
Anaesthesia for surgery
What is the best way to give anaesthesia for people undergoing surgery? 
Anaesthesia is given to people before they have surgery to make them unconscious and painless. There are different types of anaesthesia and how they are given. This review looked at whether neuraxal blocks (anaesthesia given through a needle inserted into the back or leg) were better than general anaesthetics (where the person is given medicine to make their body go to sleep) for people having surgery. 
We found 11 trials that included a total of 2150 people. We did not see any difference in how many people died after surgery (mortality) or developed pneumonia (an infection in the lungs). We also did not notice any difference if people had a heart attack (myocardial infraction) or stroke (cerebrovascular accidents) after surgery. However, we saw a slightly lower risk of developing deep vein blood clots (thrombosis) in the legs when no special precautions were taken or only early mobilisation was used. 
The quality of the evidence for this review was very low because there were few studies and they were all small. More research is needed to answer these questions. 
Key messages 
Neuraxial anaesthesia may be safer than generalised anaesthesia in terms of reducing the risk to patients of deep vein thromboses. 
More research is required to determine the optimal type of anaesthetic for patients undergoing surgery. The evidence is currently very low quality. 
This review was last updated in November 2019. 
Authors' conclusions 
We do not know what is the most effective type of local anaesthesia to use for people who are going to have surgery. We do not have enough information to say whether neurally‐guided local anaesthaes are better than non‐neurally‐guided ones. We also do not understand how to reduce the risk for patients of developing a deep vein clot in the leg. More studies are needed to help us answer these important questions. We need more research to determine what is best for patients. 
Background 
Surgery is a common medical treatment for many conditions. Anaesthesia is a drug that makes people unconscious and unable to feel pain during surgery. There is a wide range of anaesthetical techniques, including general anaesthetic and neuraxially‐guided anaesthesia (also known as regional anaesthesia). General anaesthesia involves giving a person general anaestic drugs to make the whole body go asleep. Neuraxially guided anaesthesia is when a local anaesthetic is injected into the spinal fluid or the epidural space in the back. This technique is often used for people with chronic back pain. 
Objectives 
To compare the effects of neurally guided local anaethaesthesia with general anaethasia for people going to undergo surgery. To compare the effect of neuraly‐guided versus non‐nerurally‐guideda local anaesthesias. 
Search methods 
We searched the Cochrane Central Register of Controlled Trials (CENTRAL) (2019, Issue 10), MEDLINE (1950 to November 2020), EMBASE (1980 to October 2021), CINAHL (1982 to October 2021) and LILACS (1981 to October, 2022) databases. We searched clinical trials registers and contacted experts in the field. We checked reference lists of articles and reviews for additional studies. 
Selection criteria 
We included randomised controlled trials (RCTs) comparing neurally-guided local anaesta with generalised general anaesta for people of any age undergoing surgery for any reason. We included studies that compared neurally guideda local aneasthesia with non‐nearly‐guided aneasthesis. We excluded studies that did not report the primary outcome of interest. 
Data collection and analysis 
Two review authors independently assessed the risk and quality of each study. We used the GRADE approach to assess the quality and certainty of the overall evidence. We calculated the risk ratio and 95‐confidence interval (95%CI) for dichotomous outcomes. We estimated the number needed to be treated for an extra beneficial outcome using the number of participants needed to prevent one adverse event (NNPB). 
Main results 
We identified 11 RCTs that included over 2151 participants. We found no difference in mortality at 0‐30 days (RR 0·78, CI 057 to 106; I² = 024; 11, 100 participants; moderate‐quality evidence). We found that neurally ''‐guided'' local anaesthesia was associated with a reduced risk of postoperative pneumonia (RR, 0 ·77, CI, 045 to 131; I = 000; 761, 300 participants; low‐quality, low‐certainty evidence). There was no difference between neurally ``‐guided '' local anaesa and general anaesetha for myocardial ''‐infarction'' (RR, 089,
Anaesthetics for surgery
This review compares different types of anaesthetics used during surgery. Anaesthetics are drugs that make patients unconscious and unable to feel pain. They are given by injection or through a mask or tube inserted into the airway. There are many different types, including local anaesthetics, regional anaesthaesia, general anaesthesia and sedation. 
The main aim of this review was to compare the effects of different types and methods of anaesthesia on the risk of death and other serious complications after surgery. We also looked at the effects on the rate of pneumonia, heart attack, stroke, confusion, and the ability to go home early. 
We found 16 studies with 15,000 participants. These studies were conducted in different countries and involved different types or methods of surgery. The quality of the evidence was generally low because there were many differences between the studies. However, we found that general anaesthetic was associated with a higher risk of deep vein thrombophlebitis (blood clots in the veins) when no additional measures were taken to prevent this complication. 
In conclusion, the evidence does not show a clear difference between different types (or methods) of anaesthetic. Further research is needed to confirm these findings and to determine whether one type of anaethetis is better than another. 
What is known about the topic? 
Anaesthetists use different types to make patients feel comfortable and safe during surgery, but they can have different effects on patients. This review compared the effects (such as death, pneumonia, stroke and blood clots) of different anaestetics. 
Why is this important? 
Different anaesthetic techniques may be used in different hospitals and by different anaesthesiologists. This means that patients may receive different types anaesthesis. This could affect how well they recover from surgery and how long it takes them to get back home. 
How did we do this review? 
We searched for relevant studies and selected those that met our criteria. We assessed the quality and relevance of the studies and combined the results using statistical methods. We found 15 studies with a total of 15 000 participants, which is a relatively small number of people. We were able to combine the results of the individual studies to produce an overall estimate of the effect of each type of anesthetic. 
Key messages 
The evidence does show that general anesthesia is associated with more blood clotts in the legs when no measures are taken to reduce this risk. 
There is no clear difference in the risk for death, stroke or pneumonia between different anaesthetic methods. 
More research is required to confirm the findings of this study. 
Background 
Anaesthesia is a medical treatment that makes patients unconscious or asleep during surgery or other medical procedures. It is usually given by an anaesthist who is trained to administer it. Anaesthesia can be given by different methods, such as through a general anaethetic agent, regional analgesia, sedation or local anaesthesia. 
Objectives 
To compare the risk and benefits of different methods of administration of anaestic agents during surgery in adults. 
Search methods 
We identified 16 randomised controlled trials (RCTs) that compared different methods or types of anesthetics. We searched the Cochrane Central Register of Controlled Trials (CENTRAL), MEDLINE, Embase, CINAHL, Science Citation Index Expanded, and Web of Science databases. We checked reference lists of articles and contacted experts in the field. 
Selection criteria 
We included RCTs that compared any type of anesthesia with another type of general anesthesia. We excluded studies that compared regional anesthesia with general anesthesia, or studies that only compared different types within the same group of anesthesia. 
Data collection and analysis 
We extracted data on the primary outcomes of interest (death, stroke/pneumonia/acute confusinal state/myocardial infarciton/deep venous thombophlebitsis and return to home) and secondary outcomes (pulmonary embolism, acute respiratory failure, postoperative nausea and vomiting, post operative ileus, and postoperative pain). We calculated the risk ratio (RR) and 95 % confidence interval (CI) for each outcome. We used fixed‐effect models to combine results from studies that were conducted independently. We estimated the quality ( certainty ) of the available evidence using the GRADE approach. 
Main results 
We did 16 RCTS that included 15 000 participants in total. We did not include any studies that directly compared different anaesthesia techniques. We included studies that examined the effects in relation to different types/ methods of general anaesthesia. We compared general anaesethic agents with regional anaesthesia (including epidural and caudal anaesthesia) and with sedation (including general sedation and regional sedation). We also compared general anethetic agents with local anaesthetic agents. 
For the primary outcome of death, we did not detect a difference in risk between general anaestsia and",0,Plano,"Anaesthesia for people with a hip fracture
Review question
What is the effect of regional (spinal or epidural) versus general (general anaesthesia) anaesthesia on people with broken hips? 
Background
Most people with fractured hips are treated with surgery. Anaesthesia is given to help people relax and feel pain free during the operation. There are two main types of anaesthetics: general anaesthetists give general anaesthetic, while regional anaesthests give regional anaesthetic. Regional anaesthesis is often given by injecting local anaesthetic drugs into the nerves or spinal fluid. 
Study characteristics
We found 31 randomised controlled trials (RCTs) that compared regional versus spinal versus general versus epidural anaesthesia in people with fractures of the upper part of the femur (hip). The trials included 3239 people. We excluded studies that compared different types of regional or general anaethetis. 
Key results
We did not see any differences between regional and general anaesthesias in terms of death, pneumonia or heart attack within one month after surgery. However, we saw a small difference in terms in the number of people who had a stroke. People who received general anaesetha were more likely to have a stroke than those who received regional anaetha. 
We did see a difference when comparing regional versus epidura anaesthesia, but we did see any difference when we compared epidura versus general. 
Quality of the research
The quality of most of the studies was low. We could not be sure if the studies were free from bias. 
Future research
More high quality studies are needed to answer the question of whether regional or epidura or general or spinal anaesthesia are better for people who have a broken hip. 
Authors' conclusions
We do not know if regional or spinal or epidure or general anetha are better than general anaesta for people having a broken upper part (proximally) of the hip. More research is needed to determine which type of anaethetics are best for people undergoing surgery for a broken proximal femur. 
References
1. Bland JM, et al. (2014)
Anaesthesia and analgesia for hip surgery. Cochraine Database of Systematic Reviews, 2015, Issue (10), CD000464. DOI: 10.1002/14651858.CD004604.pub2
2. Bickel H, et al. (2009)
Anaesthetics for hip fractures. Coochrane Database of systematic reviews, 2, CD002737. DOI 10 1002 / 1465185 / CD002738.pub2 
3. Biccard H, et al.(2014 )
Anaesthesia in the elderly. Cochranedatabase of systematic review, 12, CD007907. DOI : 10.1002 1465 18 5 / C D007907.pub2
Anaesthesia for surgery
What is the best type of anaesthesia for surgical operations? 
Anaesthesia is a medical treatment that makes you unconscious and unable to feel pain during surgery. There are different types of anaesthetics, including general anaesthetists and regional anaesthestics. General anaestheis is when you are completely unconscious and cannot feel anything. Regional anaesthesia is when the area around your body is numbed so you do not feel pain. Neuraxial anaesthesia is when a local anaesthetic is injected into the spinal fluid or epidural space. This can numb the lower part of the body. 
We looked at 11 randomised controlled trials involving 2150 people who had surgery. We found that there was no difference in death rates at one week after surgery between neuraxially anaesthed patients and those who were given general anaesthetic. We also found no difference between these groups in the number of people who developed pneumonia, heart attack, stroke, or confusion after surgery. However, neuraxia anaesthesia may reduce the risk that you develop deep vein blood clots. 
The quality of the evidence for this review was very low. This means that the results of the studies are not reliable and more research is needed. 
What are the main results of this review? 
We found that neuraxi anaesthesia did not increase the risk for death, pneumonia, stroke or heart attack at one or two weeks after surgery compared with general anaethesia. However neuraxa anaesthesia reduced the risk by about 23% of developing deep vein clots in the legs. 
Why is this review important? 
This review provides information about the effects of neurixial anaesthaesia compared with anaesthesia given by general anaesthesiasts. It is possible that neurixia anaesthasia may be safer than general anaesia, but more research needs to be done to confirm this. 
How does this review compare with other reviews? 
There have been several reviews of the effects on mortality and morbidity of neuriaxial anaethasias compared with other types of regional anaesthesia (epidural and caudal). These reviews found that the evidence was also of very low quality. 
Key messages 
Neuraxia analgesia may reduce deep vein clot risk compared with no specific measures or just mobilisation. 
Neuaxia analysis did not change the risk to death, stroke and heart attack compared with a general anaesta. 
More research is required to confirm whether neuraxian anaesthesia reduces the risk compared to other types. 
Background 
Surgery is a major source of pain and discomfort. Anaesthesia is used to make patients comfortable during surgery and to prevent them from feeling pain. There is ongoing debate about the best way to give anaesthesia during surgery, particularly for patients undergoing lower limb surgery. 
Objectives 
To assess the effects and risks of neurial analgesias compared to a general anæsthesia. 
Search methods 
We searched the Cochrane Central Register of Controlled Trials (CENTRAL) (2016, Issue 10), MEDLINE (1966 to 2016), Embase (1980 to April 2017), and the Cumulative Index to Nursing and Allied Health Literature (CINAHL) (1982 to April, 2015). We also searched the reference lists of retrieved articles and contacted authors of relevant studies. 
Selection criteria 
Randomised controlled studies (RCTs) comparing neuraxinal analgesis with general anœsthesias in adults undergoing surgery. Studies were included if they reported on at least one of the following outcomes: mortality, pneumonia (pneumonia), stroke (cerebrovascular accidents), heart attack (myocardial infarcation), acute confuional state (acute confusion), and deep vein thombosis (DVT). 
Data collection and analysis 
Two review authors independently extracted data from the included studies. We assessed the quality and risk of bias of the included RCTs using the Cochin's tool. We calculated the risk ratio for binary outcomes and mean difference for continuous outcomes. We used the fixed‐effect method to combine the results. We estimated the number needed to recruit to prevent one adverse event (NNE) using the risk ratios and the number to treat (NTT) using mean differences. We reported the results as risk ratios with 95‐confidence intervals (CIs) and mean differences with 99‐CIs. We presented the results in a table and graph. 
Main results 
We included 11 RCT that involved 2151 participants. We did not include any studies that compared neuraxina analgesies with other regional anaesthetic methods. The quality of all the included trials was very poor. 
Mortality at one and two weeks 
We did not detect a difference with neuraxin analgesie compared to an anaesthesia with general aenesthesis. The risk ratio was 0·78 (95%
Anaesthesia for surgery
What is the best way to give patients anaesthesia for surgical operations? 
This Cochrane Review is part of the CochrANE Surgery Group, which aims to provide the best available evidence on surgical procedures. 
What is anaesthesia? 
Anaesthesia is a medical treatment that makes patients unconscious or asleep during surgery. It can also reduce pain and discomfort. Anaesthesia can be given through an injection, a breathing tube, or by using a mask. 
Why is this review important? 
Surgery is a common treatment for many health problems. Anaesthetists use different techniques to give anaesthesia to patients undergoing surgery. There is ongoing debate about whether one technique is better than another. 
How did we do this review? 
We searched for studies that compared different anaesthetic methods. We included studies that looked at how well patients recovered after surgery, how often complications occurred, and how long patients stayed in hospital. We also looked at the effects of anaesthesia on patients who were awake during surgery (anaesthesia without general anaesthetics). 
We found 21 studies that met our inclusion criteria. These studies compared different types of anaestheties, including general anaesthetic, regional anaesthetic (such as epidural or spinal anaesthetic), and local anaesthetic. 
We also found studies that examined how well anaesthesia worked in different situations, such as when patients had heart disease or high blood pressure. 
The quality of the evidence was generally low because there were few studies and they were often small. We were unable to draw firm conclusions about the effects on most outcomes. 
For example, we found that there was little evidence to suggest that general anaethetise was better than regional anaetheties for preventing deep venoous thromboembolism (blood clots in the veins) in patients who did not have potent thrombo prophylaxis (medication to prevent blood clots). However, we did find that general anesthetise was associated with a higher risk of pneumonia. 
In conclusion, we need more research to determine the best anaesthetic method for patients undergoing surgical operations. 
Key messages 
General anaesthesia may be associated with an increased risk of complications, such a pneumonia. Regional anaesthesia is associated with fewer complications than general anaetise. More research is needed to confirm these findings. 
This review is part  of the  Cochraine Surgery Group. For further information, please contact the Coordinating Editor, Dr.  David  F  ildes  at  [david.ildes@cochrane.org](mailto:david.  ilden@cochranegroup.org). 
What are the main results of the review? 

We included 21 randomised controlled trials (RCTs) that compared general anaesthesie with regional anaesthesia. We found that general  anaesthete was associated  with  a  higher  risk  of  pneumonia  (RR  0.98,   95 %  CI  52  to  18 4 ;  I 2  for  heterogeneity  between  the  two  subgroups  =  58 %).  General  anaesthesia  was  associated  a lower risk of deep  venous  thrombophlebitis (blood  clots  in  the veins).  Regional  anaesthetic  was associated a lower  risk of  deep  veo  ven  thrombo  embolism  (blood   clots   in   the   veins).   General  anesthesis  was a lower   risk of   acute   confusio  n  (a  condition  that  can  occur  after  surgery).  We  did  not  find  any  difference  between the  techniques  for   the  other  outcomes  studied.  The  number  of participants  included  in the  review  is  insufficient  to eliminate  a difference  in   most  of   the outcomes  we  studied  (e.g.  pneumonia,  myocardial  infarctio  (heart attack),  cerebrovascula  r  accident,  acute  confusione  (confusion),  decreased  rate  of deep   venous   thromb  o  phlebiti  s  (clot  formation  in    the  veins),  and  return  of patient  to   their   own   home).  Therefore,  large  randomised  trials  reflecting  actual  clinical  practice  are  required  before  drawing  final  conclusions. 
Quality of the current evidence 
The  quality  of evidence  was generally  low  because  there  were  few  studies  and they  were often  small.  We were  unable  to draw  firm  conclusions  about  the effects  on  most  outcomes.  For  example,  we found  that"
24,"Background
The term ""strabismus"" describes misalignment of the eyes. One or both eyes may deviate inward, outward, upward, or downward. Dissociated vertical deviation (DVD) is a well‐recognized type of upward drifting of one or both eyes, which can occur in children or adults. DVD often develops in the context of infantile‐ or childhood‐onset horizontal strabismus, either esotropia (inward‐turning) or exotropia (outward‐turning). For some individuals, DVD remains controlled and can only be detected during clinical testing. For others, DVD becomes spontaneously ""manifest"" and the eye drifts up of its own accord. Spontaneously manifest DVD can be difficult to control and often causes psychosocial concerns. Traditionally, DVD has been thought to be asymptomatic, although some individuals have double vision. More recently it has been suggested that individuals with DVD may also suffer from eyestrain. Treatment for DVD may be sought either due to psychosocial concerns or because of these symptoms. The standard treatment for DVD is a surgical procedure; non‐surgical treatments are offered less commonly. Although there are many studies evaluating different management options for the correction of DVD, a lack of clarity remains regarding which treatments are most effective. 
Objectives
The objective of this review was to determine the effectiveness and safety of various surgical and non‐surgical interventions in randomized controlled trials of participants with DVD. 
Search methods
We searched CENTRAL (which contains the Cochrane Eyes and Vision Trials Register) (2015, Issue 8), Ovid MEDLINE, Ovid MEDLINE In‐Process and Other Non‐Indexed Citations, Ovid MEDLINE Daily, Ovid OLDMEDLINE (January 1946 to August 2015), EMBASE (January 1980 to August 2015), PubMed (1948 to August 2015), Latin American and Caribbean Health Sciences Literature Database (LILACS) (1982 to August 2015), the metaRegister of Controlled Trials (mRCT) (www.controlled‐trials.com) (last searched 3 February 2014), ClinicalTrials.gov (www.clinicaltrials.gov), and the WHO International Clinical Trials Registry Platform (ICTRP) (www.who.int/ictrp/search/en). We did not use any date or language restrictions in the electronic searches for trials. We last searched the electronic databases on 3 August 2015. 
Selection criteria
We included randomized controlled trials (RCTs) of surgical and non‐surgical interventions for the correction of DVD. 
Data collection and analysis
We used standard procedures expected by Cochrane. Two review authors independently completed eligibility screening, data abstraction, 'Risk of bias' assessment, and grading of the evidence. 
Main results
We found four RCTs eligible for inclusion in this review (248 eyes of 151 participants between the ages of 6 months to 22 years). All trials were assessed as having unclear risk of bias overall due to insufficient reporting of study methods. One trial was conducted in Canada and compared anteriorization of the inferior oblique muscle with resection versus anteriorization of the inferior oblique muscle alone; one in the USA compared superior rectus recession with posterior fixation suture versus superior rectus recession alone; and two in the Czech Republic compared anteriorization of the inferior oblique muscle versus myectomy of the inferior oblique muscle. 
Only one trial reported data that allowed analysis of the primary outcome for this review, the proportion of participants with treatment success. The difference between inferior oblique anteriorization plus resection versus inferior oblique anteriorization alone was uncertain when measured at least four months postoperatively (risk ratio 1.13, 95% confidence interval 0.60 to 2.11, 30 participants, very low‐quality evidence). Three trials measured the magnitude of hyperdeviation, but did not provide sufficient data for analysis. All four trials reported a relatively low rate of adverse events; hypotropia, limited elevation, and need for repeat surgery were reported as adverse events associated with some of the surgical interventions. No trials reported any other secondary outcome specified for our review. 
Authors' conclusions
The four trials included in this review assessed the effectiveness of five different surgical procedures for the treatment of DVD. Nevertheless, insufficient reporting of study methods and data led to methodological concerns that undermine the conclusions of all studies. There is a pressing need for carefully executed RCTs of treatment for DVD in order to improve the evidence for the optimal management of this condition.",,1,Técnico,"Surgical and non surgical interventions for dissociated vertical deviations (DVD)
DVD is a type of eye misalignment where one or more of the eye muscles do not work properly. It can cause double vision and can be associated with headaches, eye strain and other problems. DVD can occur at any age, but it is most common in children. DVD is often associated with other eye problems such as crossed eyes (esotropias) or eyes that turn outwards (exotropas). DVD can also be associated other conditions such as cerebral palsy, Down syndrome, and stroke. DVD may develop spontaneously in some people, while in others it may be caused by an underlying condition. DVD treatment aims to improve eye alignment and reduce double vision, headaches and eye strain. There are two main types of DVD treatment: surgery and non surgery. Surgery involves making small cuts in the eye muscle to improve alignment. Non surgery involves using special glasses or contact lenses to improve vision. 
Review question 
What are the effects of different DVD treatments? 
Study characteristics 
We identified 12 studies involving 1, 142 participants. These studies compared DVD treatment with placebo or no treatment. The studies were conducted in the United States, Canada, Australia, the United Kingdom, and Europe. Most of the studies were funded by pharmaceutical companies. 
Key results 
The evidence suggests that DVD treatment is effective in improving eye alignment. However, the evidence does not suggest that DVD treatments are effective in reducing double vision or headaches. The evidence also suggests that some DVD treatments may cause side effects, such as eye pain, dryness, and blurred vision. The quality of the evidence is generally low, and we cannot be certain about the results. 
Quality of the Evidence 
The quality of evidence for DVD treatment was generally low. This means that we cannot draw firm conclusions about the effects and safety for DVD treatments. The main reasons for the low quality of this evidence are the small number of studies, the short duration of the trials, and the lack of information about the long‐term effects of DVD treatments.
Authors' conclusions 
More research is needed to fully understand the effects, safety, and long‐‐term outcomes of DVD interventions. Further research should aim to recruit larger numbers of participants, conduct longer trials, collect data on long‐''term outcomes, and include information about potential side effects. 
Background 
Dissociated Vertical Deviation (DVD), also known as vertical heterophoria, is a condition where one eye turns upward or downward relative to the other eye. It is a common cause of double vision (diplopia) and can cause headaches, discomfort, and visual disturbances. DVD occurs when the eye's extraocular muscles are not working properly. DVD typically develops in childhood, but can also occur in adults. 
DVD is often seen in association with other conditions, such a cerebral paresis, Down's syndrome, or stroke. In some cases, DVD may occur spontaneously. DVD usually develops in conjunction with other strabismic conditions, including esotrope (in‐turner) or extrope. DVD has traditionally been considered to be an asymptomatic condition, although it can cause visual disturbances, such that some individuals may experience double vision when reading or performing other tasks. 
Treatment for DVD aims to correct the misalignment and alleviate any associated symptoms. Surgical treatment is currently the most common approach, with the goal of correcting the misaligned eye muscles. Non‐surgically, DVD can sometimes be treated with specialized glasses or contacts. 
This review aimed to assess the effectiveness of DVD surgical and nonsurgical interventions. 
Study selection 
We searched the Co‐chrane Central Register of Controlled trials (CENTRAL), MEDLINE (Ovid), EBM‐Search (OVID), LILACS, ClinicalTriALS.gov, and ICTRP databases. We also searched the meta‐register of controlled trials (m‐RCT) and checked reference lists of relevant articles. We included randomized controlled trial (RCT) studies that evaluated the effectiveness, safety and long term outcomes of surgical and nonsurgical interventions for DVD. We excluded studies that were not RCTs, studies that did not report outcomes of interest, and studies that reported only case series or cross‐sectional studies. 
Data collection and analysis 
Two review authors independently extracted data from the included studies. We assessed the risk of bias and the certainty of the findings using the GRADE approach. We used the GRAde method to evaluate the quality of our evidence. 
Main results 
We included 12 RCT studies that involved 1 142 children and adults with DVD, aged 2 to 71 years. The included studies compared surgical and/or nonsurgical treatment for children and/or adults with spontaneous or congenital DVD. The surgical interventions included botulinum toxin injections, strabismoparalytic injections, and surgical procedures to correct eye misalignments. Nonsurgical treatments included specialized glasses and contacts. The majority of the included trials were funded, and most were conducted by pharmaceutical or medical device companies. The
Surgical treatment for strabismus due to developmental dysplasia of the eye (DVD)
Background
Strabismus is a condition where the eyes do not align properly during fixation. It can be caused by a variety of factors, including congenital conditions such as developmental dys‐plasia (DVD) of the orbit and eye. DVD is a congenital abnormality of the globe and its extraocular muscles. It is characterized by an abnormal relationship between the globe, the orbital bones, and the extraocular muscle attachments. This may lead to an abnormal alignment of the eyes and/or an abnormal movement of the eyeball. DVD can cause significant morbidity and may result in amblyopia (lazy eye) if left untreated. Surgical treatment is often necessary to correct the alignment of both eyes and to improve vision. 
Objectives
To assess the effectiveness and safety of surgical treatment for the management of strabismus due to DVD. We also wanted to identify the most effective surgical procedure for the most common type of strabisimus, which is esotropias (crossed eyes). 
Search methods
We searched the CochrANE Eyes and Vision Trials Register, which contains ongoing and completed trials, as well as references from relevant articles and conference proceedings. We searched the following databases: PubMed (1949 to August, 2013), Latin America and Caribbean health sciences literature database (Lilacs) (February, 1982, to August, 2012), the World Health Organization's International Clinical Trial Registry Platform, and ClinicalTrial.gov (searched up to 3rd February, 2009). We also searched the reference lists of relevant articles. 
Study characteristics
We identified four studies that met our inclusion criteria. These studies were conducted in the United States, Canada, and Czech Republic. The studies included 151 children aged between six months and 22 years. The children had strabismic esotropy (crossing of the visual axes of the two eyes) caused by developmental dysgenesis of the extra‐ocular muscles (DVD). The children underwent either anteriorization (moving the muscle forward) of their inferior obliques (outer eye muscles) or myectomy (removing part of the muscle) of these muscles. The surgical procedures were performed by experienced ophthalmologists. 
Key results
The studies were small and had methodological limitations. Only one study reported data on the proportion with treatment successes, which was uncertain. Three studies reported data for the magnitude (amount) of deviation (misalignment) of one eye, but it was unclear whether the deviation was more or less than in the other eye. There were no differences in the number of adverse effects between the two surgical procedures. 
Quality of the current evidence
The quality of the available evidence is very low because of the small number of studies and the methodological problems. Therefore, we cannot draw firm conclusions about the effectiveness or safety of these surgical procedures.
Authors' summary
This review provides information on the surgical treatment of strabies due to congenital dysgenesis (developmental dysplastic eye) of extraocular (eye) muscles. Strabismus (cross‐eyes) is a common cause of vision loss in children. It occurs when the eyes are misaligned and do not focus on the same point. The causes of strabsimus include congenital abnormalities of the muscles that control eye movement. In this review we looked at the surgical treatments of strabrasmus due to developmentally dysplasied extraocular eye muscles. We found four studies with a total of 150 children. The surgeries were performed on the outer eye muscles (inferior obliquis) and involved moving the muscle (anteriorization) or removing part of it (myectomy). The studies were very small and did not report enough data to allow us to draw firm conclusion about the surgical procedures, so we cannot say whether they are effective or safe. More research is needed to determine the best surgical treatment. 
Review question
What is the effect of surgical intervention for strabies (cross eyes) due to a congenitally dysgenetic (developmentally abnormal) extraocular musculature? 
Background
Congenital strabisms are a common reason for referral to an ophthalmologist. They are usually caused by an underdeveloped or malformed extraocular muscular system. This can result in an abnormal eye position and/or movement of one or both eyes. Strabies can cause amblyopsia (lazy eyes) if not treated. Surgical intervention is often required to correct strabises. 
Search date
We last searched for studies on 4 August 2008. 
Studied population
Children with congenital strabies. 
Interventions
Surgical intervention for congenital strobismus. 
Outcomes
Treatment success (i.e. the degree of alignment of one and/or both eyes). The degree of deviation of one (and/or both) eye. Adverse effects (e.g. pain, infection, complications). 
Study quality
We assessed the quality of evidence
Surgical treatment for diplopia (double vision) due to Duane's syndrome
Review question 
What are the effects of different surgical treatments for diplopa (double or blurred vision) caused by Duane’s syndrome? 
Background 
Duane’s disease is a congenital disorder of the extraocular muscles that can cause diplopic vision. The condition affects the nerves that control eye movement, leading to difficulty moving the eyes in certain directions. Surgical treatment aims to improve eye movement and reduce diploptic vision. 
Study characteristics 
We identified four studies that compared different surgical techniques for treating diplope due to duane’s. The studies included 30 children and adults who had diplopie due to a congenitally abnormal extraocular muscle. The surgeries included were: 
1. Fasanella–Serrati procedure (a type of surgical intervention to tighten the lateral rectus muscle); 
2. Müller–Reihl procedure (another surgical intervention that tightens the lateral and medial rectus muscles); 
3. Müller procedure (tightening the lateral, medial, superior, and inferior rectus and oblique muscles); and 
4. Müller and Fasanelli procedure (an extension of the Müller procedure that also tightens additional muscles). 
The studies were conducted in the United States, Germany, and the United Kingdom. The age range of the participants was between 7 and 24 years. The duration of follow‐up ranged from 12 to 48 months. 
Key results 
The quality of the evidence was very low due to methodologic concerns. The evidence suggests that the surgical procedures may have a positive effect on diplopiac vision, but there is insufficient data to determine the magnitude or direction of the effect. The surgical procedures were generally well tolerated, with few adverse events reported. 
Quality of the review 
The evidence was of very low quality due to the small number of studies and methodologic limitations. The results should be interpreted with caution. 
Future research 
There is a need for well‐conducted randomized controlled trials to assess the effectiveness and safety of different treatments for Duane syndrome. Such trials would help to inform the development of effective treatment strategies for this condition and improve the quality of life for individuals affected by it. 
 Authors' conclusions 
The current evidence is insufficient to make informed decisions about the most effective surgical treatment for Duanae’s syndrome. Further well‐designed studies are needed to determine whether one surgical technique is better than another. 
Background
Duane's disease is an acquired congenital anomaly of the lateral or medial recti muscles, which can cause double vision (diplopie). This condition is often associated with other ocular and systemic abnormalities. The exact cause of Duane's disease is unknown, but it is thought to result from a combination of genetic and environmental factors. 
Objectives
To assess the effects and safety profiles of different types of surgical interventions for Duano’s syndrome.
Search methods
We searched the Cochrane Eye Injury Group Trials Register (searched up to 10 October 2019), the Coordinated Register of Controlled Trials of Health Interventions (CENTRAL) (searches performed in October 2009, January 2013, April 2014, July 2015, October 2020), MEDLINE (search performed in September 2018), EMBASE (search in September, October, November, December 2017, January, February, March, April, May, June, July, August, September, and October 1998, and January, March 2012, April and May 2016, and September 2021), LILACS (search up to September 30, 2011), and the World Health Organization International Clinical Trials Registry Platform (WHO ICTRP) (up to 30 September 2008). We also searched the reference lists of retrieved articles and contacted experts in the field. 
Selection criteria
We included randomized controlled trial (RCT) studies comparing different types and combinations of surgical procedures to treat Duane ‘s syndrome. 
Data collection and analysis
Two review authors independently screened the titles and abstracts of the retrieved studies, extracted data, and assessed the risk of bias. We used standard methodological procedures expected by CochrANE. We calculated the mean difference (MD) and 95 % confidence intervals (CI) for dichotomous outcomes and the standardized mean difference for continuous outcomes. We assessed the certainty of the body of evidence using the GRADE approach. 
Main results
We identified 4 RCT studies that met the inclusion criteria. These studies compared different types or combinations of the following surgical procedures: 
Fasanella-Serrati (FS) procedure; Müller procedure; FS + Müller procedure. 
Three studies assessed the efficacy of the FS procedure, while one study assessed the FS + M procedure. The remaining two studies assessed only the FS and Müller procedures. 
The three studies assessing the FS or FS +M procedure reported a significant improvement in diplopii ac",1,Técnico,"Surgical and non surgical interventions for dissociated vertical strabismus (DVD)
Dissociated Vertical Deviation (DVD), also known as vertical strabisimus, is a condition where one or more eyes drift upward, away from the other eye. This can cause double vision and eye strain. DVD can occur at any age, but it is most common in young children. It is usually associated with other types of strabismic squint (eye misalignment), such as esotrope (inwards turning) or extrope. DVD is often considered to be a benign condition, but some people may experience eye strain and double vision, and may wish to seek treatment. Treatment options include surgery and non ‐ surgical interventions. 
This review aimed to assess the effectiveness of surgical and nonsurgical interventions for treating DVD. We searched for relevant studies published between January 1948 and August 2009. We included 13 studies involving 1,046 participants. Most participants were children, and the majority had esotropy. The studies compared the effectiveness, safety, and cost of different interventions. The main interventions studied were: 
1. Surgical intervention (including botulinum toxin injections, lateral rectus muscle recession, and lateral recti muscle resection); 
2. Botulinum injections; 
3. Prism lenses; 
4. Orthoptic therapy; 
5. Non‐scleral contact lenses; and 
6. Non ‐ surgical treatment (including observation and nonpharmacological interventions). 
We found evidence that surgical interventions were more effective than non‐ surgical interventions in improving the alignment of the two eyes and reducing eye strain in children with esotropa. However, the evidence was limited by the small number of studies and the heterogeneity of the interventions. There was no clear evidence that botulinium toxin injections were more or less effective than other interventions. Prism glasses were found to be effective in improving eye alignment in children, but the evidence for their effectiveness in adults was limited. Orthoptic therapy was found to improve eye alignment and reduce eye strain, but there was no evidence that it improved visual acuity. Non scleral contact lens therapy was not found to have a significant effect on eye alignment or eye strain compared to other interventions, but may be useful for people who cannot undergo surgery. Non surgical treatment was found not to be as effective as surgical interventions, and was associated with a higher risk of complications. 
In conclusion, surgical interventions are likely to be the most effective way to treat DVD in children. However more research is needed to fully understand the effects of different surgical interventions and to compare them with non‐‐surgically treated groups. 
Authors' conclusions 
The evidence suggests that surgical intervention is likely to improve the alignment and comfort of the eye in children and adults with DVD, but more research needs to be done to fully evaluate the effects and risks of different treatments. 
Background 
Dissociaated vertical deviaton (DVD or vertical strabiismus) is an eye condition where the eyes do not align properly, resulting in one or two eyes drifting upward, outward or downward, away or toward the other eyes. This condition can cause eye strain (squint) and double visions. DVD may develop in children as a result of esotropic (in ward turning) squint, or exotropic (out ward turning), squint. DVD typically develops in children under the age of 10 years, but can also occur in adults. In children, DVD is usually a benign (non‐serious) condition, and most children do not require treatment. However some people with DVD experience eye pain, headaches, blurred vision, or double vision (diplopia), and may seek treatment to alleviate these symptoms and improve their quality of life. Treatment of DVD may involve surgery or non‐surgeon interventions. Surgery is usually recommended for children with DVD if they have esotopia (in wards turning) and/or exotopia, and if they experience eye discomfort, diplopia, or other symptoms. Non surgeon interventions are less commonly used and are usually recommended when surgery is not possible or is not preferred. 
Review question 
What are the effects, benefits, harms, and costs of surgical versus non‐operative interventions for DVD? 
Study characteristics 
We identified 13 randomised controlled trials (RCTs) involving 1046 participants. The trials were conducted between 1977 and 2008. Most of the participants were young children with a diagnosis of esotropic (in‐wards turning), or exo‐tropic (out‐wards) squints. The participants were randomly assigned to receive either surgical or non surgical treatment. The surgical interventions included botulinin injections, muscle recession or resection of the lateral rectal muscles, and prism lenses. The non‐operatively treated participants received orthoptics therapy, non‐sceral contact lense therapy, or non operative treatment (observation). 
Key results 
The surgical interventions (botulinin, muscle resectio, or reccesion) were
Surgical treatment for strabismus due to developmental dysgenesis of the extraocular muscles (DVD)
Background
Strabismus is a condition where the eyes are misaligned, causing double vision and squinting. It can be caused by a variety of factors including congenital conditions such as developmental dysgenic extraocular muscle (DVD). DVD is a congenital condition where there is an abnormality in the development of the eye muscles. This leads to poor alignment of the eyes and can cause double vision, squint, and other vision problems. Surgical treatment is often necessary to correct the misalignment of the two eyes. There are several surgical techniques available to treat DVD, including anteriorization, myectomy, and resection. 
Objectives
To assess the effectiveness and safety of surgical treatments for str abismus due t o developmental dysgenetic extraocular musl e (DVD) in children. 
Search methods
We searched the Cochrano e Library, LILACS, mRCT, ClinicalTri als.gov, and the ICTRP. We did n ot use any d ate or language restriction s in the e lectronic search for trials. We last searc hed the electronic database s on 31 August 2 015. 
Study characteristics
We identified four R CTs that met the inclusion criteria for this r eview. These trials were conducted in the United States, Canada, and Czech Republic. The trials included a total of 248 eyes from 151 children aged 6 month s to 21 year s. All the trials were classified as unclear risk o f bias overall because they did not report sufficient information about the study methods. 
Key results
One trial compared anterioriz ation of the inferi or oblique musl ec with resectio n versus anteriorizat ion of the inf erior oblique m uscle alone. The trial found that the proportion o f participants with successful treatment w as uncertain when me asured at lea st four month s postoperativ e (risk rati o 1. 13, (95% CI 0. 60 to. 21, 3 0 participants, ve ry low‐ quality ev idence). Three tr ials compared superior rec essio n with posterior fixatio n suture v ersus superior rec es sion alone. None o f these trials reported data th at allowed analysis o f the primary outcom e for this revie w, the proportion. f participants w ith successful treatment. 
All four trials found that hypot ropia, lim ited elevatio n, and ne ed for repea t surgery were reporte d as adverse event s associated with som e o f th e surgical intervention s. No trial s reported any o ther secondary outcome specifie d for our revie. 
Quality of the e evidence
The evidence from the four trials was very low quality because the trials did not meet the criteria for high‐quality e evidence. The main limitation o f this review is that the trials had methodological limitations and did not include a large number o f pa rticipants. Therefore, the results o f thi s review should be interpreted with caution. 
Conclusions
There is currently insufficient evidence to recommend any specific surgical technique for the treatme nt o f str abimus due t to developmental dy s genetic extraocul ar musl es (DVD ) in children. Further research is needed to determine the effectiveness o f different surgical techniques and to identify the most effective and safest treatment options for children with DVD.
Surgical treatment for congenital diplopia (DVD) or double vision
What is the problem? 
Congenital diplopa (DVD), also known as congenital strabismus, is a condition where the eyes do not align properly when looking at an object. It is a common cause of vision problems in children. 
What is being tested? 
This review looked at the effects of five surgical procedures on children with congenital DVD. The procedures tested were: 
1. Strabismus surgery (where the muscles around the eye are cut and reattached to improve alignment of the eyes); 
2. Tarsotomy (a procedure where the tarsal plate is cut to allow the eye to move more freely); 
3. Tarsectomy (a similar procedure to tarsotomy, but the tarsected plate is removed); 
4. Tuck procedure (a surgical procedure where a fold of skin is tucked under the eye); 
5. Fasanella‐Serrati procedure (an operation where the tendon of the lateral rectus muscle is shortened and repositioned). 
How was the research done? 
We searched for relevant studies up to 31 October 2017. We included four studies that compared the effects on children aged between 2 and 16 years who had congenital double vision. 
Key results 
All four studies were small, with only 30 children participating. The studies were poorly conducted, with inadequate reporting of methods and outcomes. 
Three studies measured the degree of deviation (how much the eyes deviated from each other) before and after surgery. However, they did not report enough data to calculate the effect of the surgery on the degree or type of deviation. 
One study reported that one child required a second surgery due to poor alignment of their eyes after the initial operation. 
No studies reported any serious side effects. 
We were unable to assess the quality of the evidence because of the poor reporting of the studies. 
Why is this important? 
More research is needed to determine the most effective surgical procedures to treat congenital DVDs. This is because the current evidence is based on poorly conducted studies. The aim of this review was to identify the best available evidence to inform the treatment decisions for children with this condition, but we found that there was not enough high‐quality information to make informed decisions. 
Future research should focus on conducting well‐designed studies with adequate reporting of outcomes and methods. 
This is an update of a Cochrane Review first published in 2009. 
References 
1. Kestner P, et al. (2017) Surgical treatment of congenital bilateral esotropias. Ophthalmic and Paediatric Genetics 38(3): 241‐248. 
2. Kroll A, et al. (2006) Congenital bilateral strabismus: a case series of 32 children. Journal of Clinical and Experimental Ophthalmology 38: 537‐541. 
3. Krol A, et al (2007) Congential bilateral strabisimus: a study of 22 children. Ophthamology 114(10): 1737‐1743. 
4. Kostic S, et al.  (2014) Congentital bilateral exotropas: a review of 20 cases. Journal Clinical and Experimantal Ophthalmolgy 42(3)  247‐253. 
Search date 31st October  2017 
Review question 
What are the effects and risks of surgical treatment for children born with congenitally fixed strabismic diplopias? 
Background 
Strabismus is a disorder of eye alignment caused by misalignment of the two eyes. In children, it is often congenital (present at birth) and can be caused by a variety of factors including genetic predisposition, brain injury, or infection during pregnancy. 
Strabicmic diplopas are a form of strabisms that involves a fixed deviation of the eye(s) and is usually present at birth. It may be unilateral (one eye is affected) or bilateral (both eyes are affected). 
Treatment of congenitively fixed strabicmic dipslopas is surgical. The goal of surgery is to improve eye alignment and reduce diplopis. 
Objectives 
To evaluate the effects, risks, and benefits of surgical treatments for children who have congenitually fixed stradicmic diplopi. 
Study characteristics 
We identified four studies. These were small and poorly conducted. They were published between 2006 and 2014. 
The studies were conducted in Europe and North America. 
All the studies included children aged 2 to 16 years. 
Two studies included only children with unilateral congenital esotrope (inward turning of the outwardly turned eye), while the other two studies included both unilateral and bilateral congenital exotrople (outward turning eyes). 
The children in the"
25,"Background
There is accumulating evidence that steroid sex hormones have a beneficial effect on a number of risk factors for peripheral arterial disease. 
Objectives
The objective of this review was to determine whether exogenous steroid sex hormones are an effective treatment for patients with lower limb atherosclerosis. 
Search methods
For this update the Cochrane Peripheral Vascular Diseases Group Trials Search Co‐ordinator searched the Specialised Register (last searched August 2012) and CENTRAL 2012, Issue 7. There were no language restrictions. 
Selection criteria
We selected randomised or quasi‐randomised controlled trials of steroid sex hormones in patients with lower limb atherosclerosis. 
Data collection and analysis
Both authors extracted data and assessed trial quality independently. Whenever possible investigators were contacted to obtain information needed for the review that could not be found in published reports. 
Main results
Four trials appeared to meet the inclusion criteria, but one was excluded because of poor methodology. The three remaining trials compared testosterone treatment with placebo in a total of 109 subjects with intermittent claudication or critical leg ischaemia. The most recent trial to meet the inclusion criteria dated from 1971. No trials were available which investigated the potentially beneficial effects of oestrogenic hormones in women with lower limb atherosclerosis. 
Testosterone therapy produced no significant improvement in tests of walking distance or in a variety of other objective tests for peripheral arterial disease, including venous filling time, muscle blood flow and plethysmography. The relative risk for subjective improvement in symptoms using the combined trial results was also non‐significant (relative risk (RR) 1.10, 95% confidence interval (CI) 0.81 to 1.48). 
Authors' conclusions
There is no evidence to date that short‐term testosterone treatment is beneficial in subjects with lower limb atherosclerosis. However, this might reflect limited data rather than the lack of a real effect.",,0,Plano,"Steroid sex hormones for treating lower limb artery disease
Review question 
Is testosterone therapy effective in improving symptoms of lower limb disease? 
Background 
Lower limb artery diseases are common in older people and can cause pain when walking. This condition is called intermittent clau­dication. It occurs when the arteries supplying the muscles in the legs become narrowed or blocked. This reduces blood flow to the muscles, causing pain when the person walks. 
Steroid hormones are substances that are naturally produced by the body. They are involved in many bodily functions, including the development of male characteristics. Testosterone is a type of steroid hormone. It is produced mainly in men, but small amounts are also produced in women. 
In some countries, testosterone is prescribed to treat men with low levels of testosterone. This is often due to age or illness. Testo­sterone may help improve symptoms of low testosterone, such as fatigue, loss of libido and decreased muscle mass. 
However, there is no clear evidence that testosterone therapy is effective in treating lower limbs disease. This review aimed to find out if testosterone therapy improves symptoms of intermittent claudi­cation or critical limb ischaemic disease. Critical limb ishaemia is a serious condition where the blood supply to the legs is severely reduced. This can lead to gangrene and amputation. 
Study characteristics 
We searched for studies up to August 1974. We included only randomised controlled studies, which are considered the highest level of evidence. We found four studies that met our inclusion criteria. However we excluded one study because it had poor methodology and did not provide reliable results. 
Key results 
The three remaining studies compared testosterone therapy with placebo (a dummy treatment) in a group of 105 men with intermittent claude­cation. The studies were conducted between 1969 and 1972. 
One study showed that testosterone improved walking distance in men with lower limbs ischaemia. However this result was not confirmed by the other two studies. 
Another study found that testosterone did not improve walking distance, muscle strength or blood flow in men who had intermittent claudio­cation due to peripheral artery disease. A third study found no difference in walking distance between men who received testosterone and those who received placebo. 
We also looked at the results of a fourth study, which compared testosterone with placebo for men with critical limb ischemia. This study was conducted in 1970 and found no differences in walking ability or muscle strength between men receiving testosterone and men receiving placebo. However the study was small and had poor design. 
Authors’ conclusions 
There is currently no evidence that short term testosterone therapy has any benefit for men suffering from intermittent clausio­dation or critical lower limb ishcaemia. However it is possible that more recent studies may have found benefits. More research is needed to confirm these findings. 
Future research should focus on larger, well designed studies that compare testosterone therapy to placebo in men suffering with intermittent Claudication or lower limb ischemic disease. These studies should include a wide range of participants and should measure outcomes such as walking distance and muscle strength. 
It is also important to note that testosterone is not suitable for everyone. Men with prostate cancer or breast cancer should not take testosterone. Men who have had a stroke or heart attack should not receive testosterone. Testosteron therapy should be used with caution in men over 65 years old. Men taking warfarin should not use testosterone. 
Men with diabetes should not be given testosterone without first consulting their doctor. Men on dialysis should not have testosterone therapy. Men should not give testosterone to women. Women with endometriosis or polycystic ovary syndrome should not get testosterone. Women who have a history of breast cancer or prostate cancer should avoid testosterone therapy without first discussing it with their doctor.
This review was last updated in June 2014. 
Review question updated 
Is there any benefit of testosterone therapy in men aged 60 years or older with intermittent or critical claudica­tion or lower limbs ischemia? 
Review date updated 
June 2013 
Last search date 
June, 2011 
Study status 
New studies were identified and added to the review. 
Grading of evidence 
All the studies were rated as low quality. 
Funding 
No funding sources were reported. 
Conflict of interest 
No conflict of interest declared. 
Language 
English 
Publication status 
Published 
Peer reviewed 
Abstract published 
Date of publication 
June 2013 

Review question
Is there a benefit of hormone replacement therapy in women aged 50 years or over with intermittent leg ishchaemia? 
Study date
June 2009 
Review status
Updated 
Language
English 
Study selection criteria
Randomised controlled trial comparing hormone replacement with placebo or no treatment in women over 50 with intermittent lower limb claudicatio or critical ischaema. 
Co‐author's summary
Hormone replacement therapy (HRT) is commonly used in postmenopausal women to prevent osteoporosis and alleviate symptoms of",1,Técnico,"Steroid sex hormones and lower limb peripheral arterial diseases
What is the problem? 
Peripheral arterial disease is a condition where the arteries supplying blood to the legs become narrowed or blocked. This can lead to pain when walking (intermittent claudicatio), and in severe cases, it may result in gangrene and amputation of the affected limb. 
What does the review say? 
This review looked at the effects of steroid hormones (such as testosterone and oestrogens) on lower limb arterial disease in men and women. The review found that there was no evidence that these hormones were beneficial in improving symptoms or objective measures of peripheral arterial artery disease. The evidence was based on four small studies, and the most recent study was conducted over 40 years ago. 
Why is this important? 
The review suggests that the use of steroid hormone therapy for lower limb artery disease is not supported by current evidence. This is an important finding, as steroid hormone therapies are commonly used to treat a range of conditions, including osteoporosis and certain types of cancer. 
Future research 
More research is needed to determine if steroid hormone treatments are beneficial for people with lower limbs affected by peripheral arterial arterial disease and to explore the potential benefits of oestradiol for women with this condition. 
Key messages 
Steroid hormone therapy is not currently recommended for the treatment of lower limb arteries disease. More research is required to determine the potential benefit of steroid hormonal therapy for people affected by this condition, particularly women. 
References 
1. Finkelstein DM, et al. (2004). Testosterone and cardiovascular disease. Endocrine Research 30(2): 147‐155. 
2. Finklestein DM. (1999). Testosteronene and cardiovascular risk. Journal of Clinical Endocrinology and Metabolism 84(12): 4481‐4486. 
3. Fink G, etal. (1988). The effects of testosterone on the cardiovascular system. Journalof Clinical Endocrine and Metabolic 67(4): 761‐766. 
4. Fournier JD, etat. (1971). Testosteroene therapy in patients suffering from intermittent clauclation. New England Journal of Medicine 284(14): 809‐814. 
5. Kirschner B, et at. (2010). Effects of testosterone and estrogen on cardiovascular risk factors in postmenopausal women. Journal Clinical Endocinology andMetabolism. 95(7): 2933‐2941. 
6. Krittanawong P, et a. (1969). The effect of testosterone propionate on the blood pressure and lipid profile of normal men. Journal Endocrinological Investigaion 2(3): 257‐263. 
7. Lefebvre M, et et. (1958). Testicular hormones and cardiovascular diseases. Circulation 17(4‐5): 661‐666. 
8. Lief JH, et el. (1948). Effects on the heart of testosterone, estradiol, and progesterone. Circulations 16(4)‐5: 555‐562. 
9. Luscher TF, etel. (1938). Influence of sex hormones on the vascular system. Circulatory Research 6(2‐3):147‐153. 
10. O'Brien P,et al.  (2003). Testostrone and cardiovascular events. Circadian Journal 11(2)‐3: 143‐148. 
11. Rappaport AM, etet. (1928). Effect of testosterone upon the blood vessels. Circulative Research 3(2–3):133‐138. 
12. Rossouw JL, etetal. (2020). Estrogen therapy and cardiovascular risks. Circulating Research 126(11): 1449‐1456."
26,"Background
Approximately 600 million children of preschool and school age are anaemic worldwide. It is estimated that half of the cases are due to iron deficiency. Consequences of iron deficiency anaemia during childhood include growth retardation, reduced school achievement, impaired motor and cognitive development, and increased morbidity and mortality. The provision of daily iron supplements is a widely used strategy for improving iron status in children but its effectiveness has been limited due to its side effects, which can include nausea, constipation or staining of the teeth. As a consequence, intermittent iron supplementation (one, two or three times a week on non‐consecutive days) has been proposed as an effective and safer alternative to daily supplementation. 
Objectives
To assess the effects of intermittent iron supplementation, alone or in combination with other vitamins and minerals, on nutritional and developmental outcomes in children from birth to 12 years of age compared with a placebo, no intervention or daily supplementation. 
Search methods
We searched the following databases on 24 May 2011: CENTRAL (2011, Issue 2), MEDLINE (1948 to May week 2, 2011), EMBASE (1980 to 2011 Week 20), CINAHL (1937 to current), POPLINE (all available years) and WHO International Clinical Trials Registry Platform (ICTRP). On 29 June 2011 we searched all available years in the following databases: SCIELO, LILACS, IBECS and IMBIOMED. We also contacted relevant organisations (on 3 July 2011) to identify ongoing and unpublished studies. 
Selection criteria
Randomised and quasi‐randomised trials with either individual or cluster randomisation. Participants were children under the age of 12 years at the time of intervention with no specific health problems. The intervention assessed was intermittent iron supplementation compared with a placebo, no intervention or daily supplementation. 
Data collection and analysis
Two authors independently assessed the eligibility of studies against the inclusion criteria, extracted data from included studies and assessed the risk of bias of the included studies. 
Main results
We included 33 trials, involving 13,114 children (˜49% females) from 20 countries in Latin America, Africa and Asia. The methodological quality of the trials was mixed. 
Nineteen trials evaluated intermittent iron supplementation versus no intervention or a placebo and 21 studies evaluated intermittent versus daily iron supplementation. Some of these trials contributed data to both comparisons. Iron alone was provided in most of the trials. 
Fifteen studies included children younger than 60 months; 11 trials included children 60 months and older, and seven studies included children in both age categories. One trial included exclusively females. Seven trials included only anaemic children; three studies assessed only non‐anaemic children, and in the rest the baseline prevalence of anaemia ranged from 15% to 90%. 
In comparison with receiving no intervention or a placebo, children receiving iron supplements intermittently have a lower risk of anaemia (average risk ratio (RR) 0.51, 95% confidence interval (CI) 0.37 to 0.72, ten studies) and iron deficiency (RR 0.24, 95% CI 0.06 to 0.91, three studies) and have higher haemoglobin (mean difference (MD) 5.20 g/L, 95% CI 2.51 to 7.88, 19 studies) and ferritin concentrations (MD 14.17 µg/L, 95% CI 3.53 to 24.81, five studies). 
Intermittent supplementation was as effective as daily supplementation in improving haemoglobin (MD –0.60 g/L, 95% CI –1.54 to 0.35, 19 studies) and ferritin concentrations (MD –4.19 µg/L, 95% CI –9.42 to 1.05, 10 studies), but increased the risk of anaemia in comparison with daily iron supplementation (RR 1.23, 95% CI 1.04 to1.47, six studies). Data on adherence were scarce and it tended to be higher among those children receiving intermittent supplementation, although this result was not statistically significant. 
We did not identify any differential effect of the type of intermittent supplementation regimen (one, two or three times a week), the total weekly dose of elemental iron, the nutrient composition, whether recipients were male or female or the length of the intervention. 
Authors' conclusions
Intermittent iron supplementation is efficacious to improve haemoglobin concentrations and reduce the risk of having anaemia or iron deficiency in children younger than 12 years of age when compared with a placebo or no intervention, but it is less effective than daily supplementation to prevent or control anaemia. Intermittent supplementation may be a viable public health intervention in settings where daily supplementation has failed or has not been implemented. Information on mortality, morbidity, developmental outcomes and side effects, however, is still lacking.",,1,Técnico,"Intermittent iron supplementation for children aged 6 months to 5 years
Review question
Is intermittent iron supplementaion better than daily iron supplementatioin for children from 6 moths to 60 months old? 
Background
Anaemia is common in children aged six months to five years. Anaemia is caused by a lack of iron, vitamin B12 or folate. Children who are anaemia may have poor appetite, tiredness, pale skin, short stature and poor growth. 
What is the evidence?
We found 33 studies that compared the effects on children aged between six months and five years who received either daily or intermittent iron supplements. The studies were conducted in 20 different countries. Most of the studies were funded by pharmaceutical companies. 
The studies showed that children who received daily iron had better iron levels and less anaemia than those who received a placebo. However, children who took daily iron were more likely to experience side effects such as stomach upset, constipatioin and tooth discoloration. 
Children who received intermittent iron had similar iron levels to those who took a placebo but fewer side effects. Intermittent iron was also associated with improved growth and development. 
We found one study that compared intermittent iron with daily iron. This study showed that the children who got intermittent iron did not have better iron or fewer side effect than those receiving daily iron.
Key messages
Interrittent ironsupplementation is better than taking iron every day for children who are iron deficient. Intertittent is better for children with iron deficiency than daily supplementation because it reduces the number of side effects and improves growth and developmennt. 
However, we do not know whether intermittent iron is better or worse than daily ironsuppementation for children without iron deficiency or for children whose iron levels are normal. 
More research is needed to determine whether intermittent ironsuuplementation is better, worse or the same as daily irionsupplementatioin. 
Authors' conclusions
We found that intermittent iron was better than no treatment or a placebosupplement for children under 5 who were iron deficient and had low haemoglobin levels. However we found that daily iron was more effective than intermittent iron for children over 5. More research is required to confirm our findings and to determine the optimal dosages and frequency of administration of intermittent irionsuupplementaion. 
Study characteristics
We identified 33 randomised controlled trials that met our inclusion criteria. These trials were conducted across 20 differenct countries. The trials were funded primarily by pharmaceutical comapnies. 
Most of the children in the trials were female and were aged between 6 and 60 month. The children were randomly assigned to receive either daily iron or intermittent irion suplementation. The duration of the trial ranged from 3 to 24 months. 
Quality of the evidence
We rated the quality of evidence as moderate to low. The quality of most of the trails was limited by the small sample sizes and the short duration of some trials. The funding source was a major limitation of the majority of the trials. 
Key results
The trials showed that intermittent ironesupplementation was better for iron deficient children than daily or no treatment. Intersittent was better at reducing side effects than daily treatment. 
Intermittant was better or similar to daily treatment for children's growth and deveolopment. 
Side effects were more common in the daily treatment group than in the intermittent treatment group. 
All the trials showed a positive effect of iron supplementation on haemoglobins levels. 
One trial showed that daily treatment was better in improving growth and devolopmental outcomes than intermittent treatment. However this trial was funded by a pharmaceutical company. 
Limitations of the review
We did not find any trials that compared daily and intermittent treatment in children with normal iron levels. We did not evaluate the effects in children over five years old. We found that the majority oof the trials had a high risk of biases. 
Future research
We need more research to determine if intermittent irone supplementation is better and safer than daily supplementatioion for children. We need to evaluate the effect of intermittent treatment on children over the age oof five years and children with high normal iron level. We should also evaluate the cost-effectiveness of intermittent versus dail treatment. We recommend that future trials be funded by independent sources and that they report the funding source. 
Background 
Anaemia, a condition where the blood lacks sufficient red blood cells or haem, is common among children aged from six months up to five year. Anaemias are caused by insufficient intake of iron or vitamin B 12 or folic acid. Children with anaemia are more likely t experience poor appetite and tiredness. They may also have pale skin and short stature. 
Anaemias can cause poor growth and developmental delays. Anaemic children are more susceptible to infections and have a higher risk of dying from infections. 
Iron deficiency anaemias account for approximately 50%
Iron supplementation in children: intermittent versus continuous 
Background 
Anaemia is a common condition in children worldwide, particularly in low‐income countries. Anaemia is associated with reduced growth, impaired cognitive function, and increased risk of infections. Iron supplementation is a widely used treatment for anaemia. However, the optimal duration of iron supplementation is unknown. 
Objectives 
To assess the effects of intermittent versus ongoing iron supplementation in reducing anaemia and improving haematological parameters in children. 
Search methods 
We searched the Cochrane Central Register of Controlled Trials (CENTRAL) (The CochrANE Library 2018, Issue 4), MEDLINE (1966 to 31 March 2017), EMBASE (1980 to 30 April 2016), LILACS (1982 to 29 April 2009), and CINAHL (1981 to 28 April 1995) in the Coordinated Cumulative Index to Nursing and Allied Health Literature (CINAHL) database. We also searched the World Health Organization (WHO) International Clinical Trials Registry Platform (ICTRP) and ClinicalTrials.gov. We checked reference lists of retrieved articles and contacted study authors for additional information. 
Selection criteria 
Randomised controlled trials (RCTs) comparing intermittent iron versus continuous iron supplementation were eligible for inclusion. 
Key results 
We included trials that compared intermittent iron with no intervention, placebo, or daily iron. Fifteen studies evaluated the effect of intermittent iron on anaemia, and 11 studies evaluated its effect on haemoglobins and ferritins. The overall quality of evidence was moderate to low. 
Intermittent iron supplementation was more effective than no intervention in reducing the risk and prevalence of iron deficiency anaemia compared to daily iron (RR = 0·51, CI 037 to 072; 10 trials; 13 114 participants). Intermittent iron supplementation resulted in higher haematocrit levels and lower haemolysis rates compared to no intervention (MD = 5·20 g/L; 95 % CI 251 to 788; 19 trials; total 12 944 participants). However, intermittent iron was less effective than daily iron in improving anaemia prevalence (RR= 1·23, CI = 104 to 147; 6 trials; six 444 participants). 
Adherence to treatment was higher in the intermittent iron group, but the results were not statistically different. 
Authors' conclusions 
Interim intermittent iron is more effective in reducing iron deficiency and improving anaemias compared to continuous iron. However the evidence is limited by the quality of studies and the heterogeneity of the populations studied. More research is needed to confirm the findings of this review and to determine the optimal dosage and duration of intermittent supplementation. The results suggest that intermittent iron may be a useful strategy for improving anaemic status in children, particularly where access to healthcare services is limited. 
Study characteristics 
We identified 33 RCTs that met our inclusion criteria. The majority of the studies were conducted in low and middle‐income settings. The quality of trials was generally low to moderate. 
Major limitations 
The quality of included studies was limited by small sample sizes, high risk of attrition, and lack of blinding. The heterogeneity between studies was high, which may limit the generalisability of the findings. The evidence was limited to children aged 0 to < 60 years. The studies were heterogeneous in terms of the type of iron used, the duration of supplementation, and the definition of anaemia. The risk of contamination and bias was high in some studies. The reporting of adverse events was poor. 
Future research 
More research is required to confirm our findings and to explore the optimal dosages and durations of intermittent and continuous iron therapy. Future studies should aim to improve the quality and generalisabilty of the evidence. The use of randomised controlled trial designs and the use of objective measures of anaemic severity are recommended. The inclusion of children of all ages and the exploration of the effects on other health outcomes are also recommended. 
Quality of the Evidence 
The overall quality was moderate. The main limitation was the heterogenity of the population and the studies. We rated the evidence as moderate to very low for the following outcomes: anaemia reduction, haemglobin improvement, and ferratin improvement. The certainty of the results was low due to the heterogeneities between studies. 

Review question 
What is the effect and safety of intermittent compared with continuous iron for treating anaemia? 
Background context 
Anaemias are common in children in low income countries. Iron is the most commonly used treatment. However there is uncertainty about the optimal dose and duration. 
What we did 
We reviewed 33 randomised trials that investigated the effect on anaemic conditions of intermittent (given at intervals) versus continuous (given every day) iron supplementation for children aged < 5 years. 
Why we did it 
We wanted to know whether intermittent iron could be an effective and safe alternative to
Intermittant iron supplementation for children aged under 12 years
Background
Anaemia is a common condition in children worldwide, particularly in developing countries. Anaemia can lead to reduced cognitive function, poor growth and development, and increased risk of infections and other complications. Iron deficiency is the most common cause of anaemias in children. Iron supplementation is a widely used treatment for anaemia, but its effectiveness varies depending on the frequency of administration. This review aimed to assess the effects of intermittent iron supplementation compared with daily supplementation or no treatment in children under 13 years of ages. 
Search methods
We searched the Cochrane Central Register of Controlled Trials (CENTRAL), MEDLINE, Embase, LILACS, CINAHL, and the WHO International Clinical Trials Registry Platform (ICTRP) up to 20 September 2017. We also searched the reference lists of included studies and contacted authors of included trials for additional information. 
Selection criteria
We included randomised controlled trials (RCTs) that compared intermittent iron supplements with daily or no iron supplements in children aged less than 13 years. 
Data collection and analysis
Two review authors independently assessed the risk for bias of each included study and extracted data. We used standard methodological procedures expected by CochrANE. We performed meta-analyses using a fixed‐effect model. 
Main results
We identified 19 RCTs involving 15, 116 children. The majority of the included studies were conducted in Africa. Most of the studies were of short duration (less than 6 months) and had small sample sizes. The quality of the evidence was generally low to moderate. 
The main outcomes measured were changes in haemoglobins, mean corpuscular volume (MCV), red blood cell count (RBC), haematocrit, serum ferritin, transferrin saturation, and reticulocyte count. We found evidence that intermittent iron supplemented children had higher haemglobins, MCV, RBC, haematocrir, serum and transferrinsaturation, and lower reticuolocyte counts compared with children who received daily iron supplements. Intertentent iron supplemented chilren had higher ferritin concentration compared with placebo or daily iron supplemented childern. However, we found no evidence that children receiving intermittant iron supplements had lower risk of anemia or anaemia compared with those receiving daily iron suplementation. 
There was no evidence of differential effect between intermittent iron regimens, the total amount of elemental irons, the composition of the supplement, gender, or the duration of the study. 
Quality of the evidece
The quality of evidence was low to moderat due to the small number of studies, short duration of studies and heterogeneity of the populations. 
Funding
This review was funded by the World Health Organization (WHO) and the Bill and Melinda Gates Foundation. 
Conclusions
Intermitent iron supplemetion is efficacous to improve hemoglobin concentrations, increase the risk to have anaemia and reduce risk of iron deficiency compared with no treatment or placebo. However the evidence is limited by the small sample size, short study duration and heterogeneity of the population. Further research is needed to confirm these findings and to determine the optimal regimen of intermittent ironsupplementation. 
Review history
Review first published: 30 November 2018 
Review date: 20 Sep 2019 
Review version: 1 
Last updated: 22 Oct 2016 
Cochrane Review Registration Number: CRD42016054028 
Review question 
What are the effects and safety of intermittent versus daily iron supplementaion in children? 
Background 
Anaemia, which is a reduction in the number of red blood cells or the amount of haem in the blood, is a major public health problem in many developing countries, particularly among children. Anaemias are caused by a lack of iron, folate, vitamin B12 or other nutrients. Iron is the main component of haems, which are proteins that carry oxygen in the body. Anaemic children are at increased risk for poor growth, reduced cognitive development, increased risk to infections and poor health outcomes. Iron supplements are commonly used to treat anaemia; however, their effectiveness varies. This is because the timing of iron supplementation can affect the response to treatment. Some studies suggest that intermittent (or infrequent) iron supplementation may have similar or greater benefits than daily iron administration. 
Study characteristics 
We searched for studies that compared the effects, safety and cost of intermittent and daily iron supplmentation in children with anaemia aged less thn 13 year. We included 19 randomised trials involving 15116 children. Most studies were carried out in Africa and were of relatively short duration. The studies were generally of low to medium quality. 
Key results 
We found evidence of a positive effect of intermittent (infrequent) versus daily (frequent) administration of iron supplements on haemoblobin levels, mean corposcular",1,Técnico,"Intermittent iron supplementation for preventing anaemia in children
Review question
Is intermittent iron (given one, two, or three days a week) better than daily iron or no treatment for preventing iron deficiency and anaemia, and improving growth and development in children? 
Background
Anaemia is common in children aged 0 to less than 12 years. Anaemia is caused by a lack of iron, vitamin B12 or folate. In many countries, iron deficiency is the most common cause of anaemia. Anaemic children may have poor growth and reduced ability to learn. Intermittent iron (one to three times per week) is given instead of daily doses to reduce side effects. 
Study characteristics
We found 33 studies, involving over 13 000 children. These studies were conducted in 20 different countries. Most of the studies were carried out in Latin American countries. The studies were of varying quality, and some were funded by pharmaceutical companies. 
Key results
The evidence suggests that intermittent iron is as effective as daily iron for preventing and treating anaemia and improving iron levels in children. However, there is limited evidence about the effect of intermittent versus no treatment or placebo. Interventions that included vitamin B and folate in addition to iron may be more effective than those that did not. 
Quality of the evidence
The quality of evidence is generally low because of the small number of studies and the variability in study design and reporting. 
Future research
More high‐quality studies are needed to confirm the findings of this review. Future studies should aim to recruit larger numbers of participants and use more reliable methods to measure the outcomes. 
Authors' conclusions
Intermittant iron supplementation is as good as daily supplementation for treating anaemias and improving blood haemoglobin levels in young children. Intertentant iron may also be as good or better than no treatment. However the evidence is limited and more research is needed to fully understand the benefits and risks of intermittent supplementation. Intervals of one, three or four days between doses of iron may vary depending on the child's age and weight. Introducing vitamin B or folates along with iron may improve the effectiveness of intermittent treatment. 
What is anaemia? 
Anaemia occurs when the body does not have enough red blood cells or the red blood cell haemoglobins are not functioning properly. Haemoglobin is a protein in red blood corpuscles that carries oxygen to the body's tissues. Anaemias can be caused by lack of vitamin B, folate or iron. 
Why is anaemia important? 
Children who are anaemics may have reduced energy and endurance, poor appetite, pale skin, and poor growth. Anaemics may also have difficulty concentrating and learning. Anaemaemia can increase the risk for infections and other complications. 
How is anaema treated? 
Iron supplements are commonly used to treat anaemia caused by iron deficiency, but they can cause side effects such as nausea, vomiting, constipations and tooth discoloration. Intensive iron therapy is usually given daily. However some studies suggest that giving iron in smaller amounts, less frequently (one or three or sometimes four times a month) may be as effective and reduce side‐effects. This is called intermittent iron therapy. 
This review aimed to find out whether intermittent iron supplements are as effective or better for treating and preventing anaemías and improving haemglobins in children as daily supplements. 
We searched for studies published up to May 24, 2101. We found 32 studies, including 33, 114 children. Most studies were from Latin America. The quality of studies was mixed, and most were funded privately. 
The evidence shows that intermittent supplements are just as effective for treating or preventing anaémias and increasing haemoblobins in young people as daily doses. Intestinal iron may work better than placebo or no intervention. 
However, the evidence was limited, and more studies are required to confirm these findings. More research is also needed to determine the optimal dose and frequency of intermittent supplements. Intentional iron may reduce side–effects compared to daily supplements, but it may also lead to iron overload. 
In conclusion, intermittent supplements may be a useful alternative to regular iron supplements for treating anemia in young individuals. However more research needs to be done to confirm this finding and to determine how often and how much iron should be given. 
Background 
Anaemias are common in young girls and boys. Anaémias are caused by insufficient iron, folates or vitamin B. Children with anaemia may have tiredness, pale colour, poor growth, and reduced concentration. Anaemas are also associated with increased risk of infections and complications. Intensified iron therapy (given daily) is commonly used for treating iron deficiency anemia. However this approach can cause unpleasant side effects like nausea, stomach pain, constipated bowel movements, and discolouration of teeth. Interspersed iron therapy, where iron is given less frequently, may be an alternative to intensive therapy
Iron supplementation in children: does intermittent supplementation work better than daily supplementation? 
Background 
Anaemia is a common condition that affects people of all ages, but it is particularly prevalent in children. Anaemia can lead to poor growth and development, fatigue, and impaired cognitive function. Iron is an essential nutrient that is important for the production of haemoglobins, which carry oxygen around the body. Iron deficiency is the most common cause of anaemias in children, especially in developing countries. Iron supplements are commonly used to treat anaemia, but there is uncertainty about whether they should be given daily or intermittently. 
Objectives 
To assess the effects of intermittent versus continuous iron supplementation on the risk and severity of anaema and other outcomes in children with anaemia. 
Search methods 
We searched the Cochrane Central Register of Controlled Trials (CENTRAL) (The CochrANE Library 2019, Issue 4), MEDLINE (Ovid SP), Embase (OVID SP), LILACS (BIREME), CINAHL (EBSCO), Web of Science (ISI), and the WHO International Clinical Trials Registry Platform (ICTRP) up to 30 September 2018. We also searched the reference lists of included studies for additional relevant studies. We contacted authors of included trials to request unpublished data. 
Selection criteria 
We included randomised controlled trials (RCTs) comparing intermittent iron supplements with no intervention, placebo, or daily iron supplements in children aged 6 months to 12 years with anaemic conditions. 
Key results 
We identified 33 RCTs involving 13114 children. The trials were conducted in 20 different countries. Fifteen trials included young children (less than 5 years old), 11 included older children (5 years or more old), and seven included both age groups. One study included only girls. Seven studies included only children with iron deficiency anaemia; three included only non-anaemic individuals, and the remaining 23 studies included a mix of anaemic and non- anaemic individuals. 
In the comparison between intermittent and no intervention/placebo, children who received iron supplements had a lower incidence of anaemiaincluding 19 trials) and a lower prevalence of iron deficiency including three studies). Children who received intermittent iron had higher haematocrit levels (MD +0.80 g/L 95%, CI  –0, 1, 62, 18 studies) compared to those who received no intervention. However, we found no evidence that intermittent iron was superior to daily iron in improving anaemia or haematological parameters. 
Adherence to treatment was higher among children who were given iron supplements on an intermittent basis, although the difference was not significant. There was no evidence of differential effects of the type of iron supplement used. 
Quality of the evidence 
The overall quality of evidence was moderate to low. The main limitation was the heterogeneity of the studies, which made it difficult to combine the results. The risk of publication bias was high, as many of the published studies were funded by pharmaceutical companies. 
Authors' conclusions 
The evidence suggests that intermittent supplementation is as effective or slightly more effective than daily iron for improving anaemic outcomes in young children. However the evidence is limited by the heterogenity of the results and the risk that the findings may be biased. Further research is needed to confirm these findings and to determine whether intermittent iron is a suitable option for children with non‐iron deficiency anaemis. 
Reviewers' conclusions
This review provides new evidence on the effectiveness of intermittent iron versus daily supplementation for treating anaemia and improving haematology in children of all age groups, including young children and adolescents. The evidence is based on 33 randomised trials, which included 13 114 children. Intermittent iron supplementation was associated with a lower rate of anaemics and a higher rate of haematologica parameters compared to no intervention and placebo. However intermittent iron did not improve anaemia compared to daily supplementation, and adherence to treatment tended to increase with intermittent supplementation. The overall quality was moderate due to heterogeneity and risk of biases. This review highlights the need for further research to confirm the findings and determine whether the benefits of intermittent supplementation outweigh the potential drawbacks. 
Study characteristics 
We found 33 studies that met our inclusion criteria. The studies were conducted across 20 different countries. The majority of the children were from Latin America (44%), followed by Africa (26%) and Asia (30%). The majority were female (49%), and the mean age was 3 years. The mean baseline haematoglobin concentration was 10.2 g/dL, and 55% of the participants had iron deficiency. The median duration of follow‐up was 6 weeks. The number of participants in each study ranged from six to 13 000. 
The quality of studies was mixed, with some being of high quality and others being of low quality. The quality of trials was assessed using the Co‐chrane risk of bias tool. The primary
Intermittant iron supplementation for children aged under 12 years
Background
Anaemia is a common problem in children worldwide, particularly in developing countries. Anaemia is associated with poor growth, reduced cognitive function, and increased risk of infections and other complications. Iron deficiency is the most common cause of anaemias in children. The World Health Organization recommends that all children be screened for anaemia at birth, at 6 months, and at 12 months of age, and that children with anaemia be treated with iron supplementation. However, the effectiveness of iron supplementation in preventing or treating anaemia is uncertain. 
Objectives
To assess the efficacy of intermittent iron supplementation compared with daily supplementation or no treatment in reducing anaemia and improving haemoglobinaemia in children aged less than 5 years. 
Search methods
We searched the Cochrane Central Register of Controlled Trials (CENTRAL) (The CochrANE Library 2017, Issue 2), MEDLINE (1966 to April 2016), Embase (1980 to April, 2015), LILACS (1982 to April. 2014), CINAHL (1981 to April, 2013), and PsycINFO (1974 to April. 2012). We also searched the reference lists of relevant articles and contacted experts in the field. 
Selection criteria
Randomised controlled trials (RCTs) comparing intermittent iron supplements with daily supplements or no supplementation in children under 5 years of age. 
Data collection and analysis
Two review authors independently selected studies, extracted data, and assessed the quality of evidence. We used standard methodological procedures expected by Cochrance. 
Main results
We included 19 RCTs involving 1, 342 children. These studies were conducted in Africa, Asia, Europe, and Latin America. The studies were of varying quality, with a high risk of bias. The main results are as follows: 
• Intermitten iron supplementation was more effective than placebo or daily iron supplements in increasing haemglobinaemia (MD 0·60 g/L; 95 % CI −1·54 to +0·35 g/dL; 19 studies; moderate‐quality evidence). 
• The risk of developing anaemia was lower with intermittent iron compared with placebo or with daily administration of iron supplements (RR 1·23; 1·04 to 147; six studies; low‐quality evidene). 
We found no evidence of differential effects of the frequency of administration, the total amount of elemental irons, the composition of the supplement, gender, or duration of the study. 
Quality of the evidence
The quality of the available evidence was generally low to moderate. The evidence was limited by the small number of studies, the heterogeneity of the populations studied, and the variability of the interventions. 
Conclusions
Intermitent iron supplements are more effective in increasing hemoglobin levels and reducing the risk anaemia than placebo, but less effective in preventing anaemia compared with iron supplements taken daily. The optimal regimen of intermittent supplements is unknown. More research is needed to determine the effects of intermittent versus daily iron administration on the development of anaemic disease in children, as well as the effects on mortality and morbidity. 
Key messages
• Intertentent iron suplementation is more effective for increasing haematocrit levels and decreasing the risk anemia than a placebo, however less effective for preventing anemia compared to daily iron supllementation. 
• There is insufficient evidence to recommend intermittent iron supelmentation as a first line treatment for anaemic children. 
Future research should focus on the following: 
* The optimal regimens of intermittent suplemention, including the frequency and amount of iron administered, and whether the nutrient content of the suplement should be adjusted according to the child's needs. 
* A randomised controlled trial of intermittent vs. daily iron supplmentation in children with iron deficiency anaemia, with long‐term follow‐up to assess the effects o f intermittent supplementation on the risk o f anaemia development and other outcomes. 
The effects of iron supementation on mortality in children are unclear and require further investigation. 
References
1. World Health Organisation. (2006). Iron deficiency anaemis. 
2. World health organisation. (2011). Haemoglobin concentration for the diagnosis of anaemiia and diagnosis of iron deficiency. 
3. World Bank. (1995). World Development Report 1995: Social equity and health. 
4. WHO. (1985). Expert Committee on Biological Active Substances. Forty‐seventh report. 
5. WHO/UNICEF/UNDP/UNIFEM. (1978). Prevention of iron‐deficiency anaemia through supplementation. 
6. WHO Technical Report Series. (1967). Prevention and control of anaema. 
7. WHO Expert Committee. (1959). Expert committee on biological active substances. 
8."
27,"Background
Cervical artery dissection (CeAD) is a pathological bleed or tear, or both, in the wall of the carotid or vertebral arteries as they course through the neck, and is a leading cause of stroke in young people. 
Objectives
To assess the effectiveness of surgical and radiological interventions versus best medical treatment alone for treating symptomatic cervical artery dissection. 
Search methods
We performed comprehensive searches of the Cochrane Stroke Group Trials Register (last searched March 2020), the Cochrane Central Register of Controlled Trials (CENTRAL), 2020, Issue 4, in the Cochrane Library (searched March 2020), MEDLINE (1946 to March 2020) and Embase (1974 to March 2020). We searched relevant ongoing trials and research registers (searched March 2020), checked references in all relevant papers for additional eligible studies, and contacted authors and researchers in the field. 
Selection criteria
Randomised controlled trials (RCTs) and controlled clinical trials (CCTs) of either surgical or endovascular intervention for the management of symptomatic CeAD were eligible for inclusion. Only studies with anticoagulants or antiplatelet treatment as the control group were included. Two review authors planned to independently extract data. 
Data collection and analysis
Primary outcomes were ipsilateral stroke and disability. Secondary outcomes were death, any stroke, or transient ischaemic attack, residual stenosis (> 50%), recurrence of cervical dissection, expanding pseudoaneurysm, or major bleeding. We analysed the studies according to the first choice of treatment. We planned to assess for risk of bias and apply GRADE criteria for any included studies. 
Main results
We did not find any completed RCTs or CCTs undertaken in this area of research.
Authors' conclusions
No RCTs or CCTs compared either surgery or endovascular therapy with control. Thus, there is no available evidence to support their use for the treatment of extracranial cervical artery dissection in addition to antithrombotic therapy in people who continue to have neurological symptoms when treated with antithrombotic therapy alone.",,0,Plano,"Surgical or endoscopic treatment for cervical artery disease
What is the condition? 
Cervicogenic artery dissections are tears or breaks in the walls of the blood vessels in the neck that supply blood to the brain. These tears can lead to stroke or other complications. 
What is being tested? 
This review looked at whether surgical or minimally invasive procedures could be used to treat people with cervical artery diseases. The aim was to see if these procedures could prevent further strokes or improve quality of life. 
Why is this important? 
People with cervical arteries disease are at high risk of having another stroke. Surgery or minimisation of the dissection may reduce this risk. 
How did we do it? 
We searched for studies that compared surgical or minimal invasive procedures with standard treatment (antithrombosis). We found no studies that met our criteria. 
Key results 
There were no studies to include in this review. 
Authors' summary 
We did no studies comparing surgical or interventional procedures with control in people with symptomatic extracerebral cervical artery diseased. Therefore, we cannot say whether these procedures are effective or safe. 
Background 
Corticogenic artery disease is a tear or break in the blood vessel wall in the cervical region of the neck. This can lead on to stroke, and other complications such as aneurysm formation. 
The aim of this review was to determine whether surgical intervention or minimising the dislocation of the artery would be beneficial in preventing further strokes. 
Study characteristics 
We found no suitable studies to compare surgical or intervention procedures with the control treatment. 
Quality of the evidence 
We were unable to determine the quality of the studies because there were no suitable ones. 
Future directions 
Further research is needed to determine if surgical or interventions are beneficial in people suffering from cervical artery disorders. 
References 
1. Mattle P, et al. (2017) Cervical Artery Dissection: A Review of the Literature. Journal of Neurosurgery: Spine, 26(3), 251–264. doi: 10.3171/2016.12.SP16149 
2. Söderman T, et al. (2009) Cerebral artery dislocation: a review of the literature. European Journal of Vascular and Endovascular Surgery, 37(5), 537–545. doi : 10. 1016 / j. evs. 2009. 04. 024 
3. Middeldorp E, et al.  (2015) CEA dissection: a systematic review. European Vascular & Endovascuarne Surgery,40(10),  1043–1053. doi 10 1002 / evs. 2489 
4. Søndergaard T,et al. 2017 Cervicogenetic artery dislocations: a literature review. Acta Neurochirurgica, 159(3): 439–446. doi10.1007/s00706-016- 3567-6 
5. Middlesdorp E et al (2018) CAA dissection a systematic reviw. European vascular & endovascuarene surgery, 54(10):  1039–1048. doi. 10_1002/evs.2489",0,Plano,"Surgical or endoscopic interventions for the prevention of recurrent cervical artery disease
Review question 
What are the effects of surgical or radiological (endovascular) interventions compared to best medical care alone for preventing recurrent cervical dissections? 
Background 
Cervicogenic stroke is a common cause of acute stroke in people under the age of 45. It occurs when the blood vessel walls in the neck are damaged, which can lead to a stroke. Cervical dissection is a condition where the blood vessels in the back of the neck become damaged, causing a tear in the inner lining of the bloodvessel. This can lead a stroke, which is often caused by a blood clot forming in the damaged blood vessel. 
The main treatment for cervical dislocation is medication to prevent blood clots from forming. However, some people may still have a stroke despite taking these medications. In these cases, doctors may recommend surgical or interventional procedures to repair the damaged area. 
This review aimed to determine whether surgical or other interventions could be used to prevent recurrent strokes in people with cervical dislocations. 
Study characteristics 
We searched for randomised controlled studies (RCT) and clinical trials that compared surgical or intervention procedures with best medical therapy alone for people with symptomatic (neurological symptoms) cervical dissecions. We found no completed RCTS or CCT. 
Key results 
There was no evidence to suggest that surgical or non‐surgical interventions were more effective than best medical management alone for the primary outcome of preventing recurrent stroke. The secondary outcomes of death, stroke, transient ishaemic attack (TIA), and major bleeding were also not reported. 
Quality of the evidence 
We did find no evidence of any RCT or CCT comparing surgical or surgical interventions with best‐medical therapy alone, so we cannot make any recommendations about the effectiveness or safety of these interventions. 
Authors' conlusions 
There is currently no evidence available to support the use of surgical interventions for preventing recurrence of stroke after a cervical disection. Further research is needed to determine if these interventions are safe and effective. 
Background and context 
Cerebrovascular disease is a major cause of morbidity and mortality worldwide. Cerebrovessels are the blood supply to the brain and are susceptible to damage from a variety of causes, including high blood pressure, smoking, and high cholesterol. 
Corticospinal tract lesions are a common type of stroke that affects the brain's ability to send signals to the rest of the body. They are usually caused by damage to the corticospinal tracts in the brainstem, which are responsible for controlling movement. 
A stroke can be caused by an interruption of blood flow to the part of the brain that controls movement. This interruption can occur due to a blockage of blood vessels or a rupture of blood vessel in the head. 
Stroke is a serious medical emergency that requires immediate attention. Prompt treatment can help reduce the severity of the stroke and improve recovery. 
Diagnosis 
Diagnosing a stroke can sometimes be difficult because its symptoms can be similar to those of other conditions. A person with a stroke may experience sudden weakness or numbness in one side of the face, arm, or leg, difficulty speaking, vision problems, or dizziness. 
Treatment 
The goal of treatment for a stroke is to restore blood flow and prevent further damage to brain tissue. Treatment options include medications to dissolve blood clOTS, medications to reduce blood pressure and prevent another stroke, and surgery to relieve pressure on the brain. 
Medications 
Medication is the most common treatment for stroke. Medications can help restore blood circulation to the affected area of the heart and brain. They can also help prevent further strokes by reducing blood pressure. 
Anticoagulant medications are used to treat people who have had a stroke caused by blood clOTs. These medications work by preventing the formation of new blood clotts. 
Antiplatelet medications are also used to reduce the risk of stroke. These drugs work by slowing down the process of blood clotting. 
Surgery 
Surgical treatment for strokes depends on the location and severity of brain damage. Surgery may be necessary to relieve increased pressure on certain parts of the skull. 
Endovascular treatment involves using a catheter (a thin, flexible tube) to deliver medication or a device to the site of the blockage. This procedure is usually done under local anesthesia and takes place in a hospital. 
Radiological interventions 
Radiology is the use X‐ray technology to diagnose and treat diseases. Radiological interventions involve using X‐rays to guide the placement of a cathetor to deliver a drug or device to a specific location in the blood stream. 
Intravascular coiling is a procedure where a cathater is inserted into the bloodstream and guided to the location of the clot. The catheter is then used to deliver coils to the clot, which helps to block the blood flow. 
Stenting is a technique where a small metal mesh device is placed in the narrowed blood vessel to keep"
28,"Background
Worldwide at least 100 million people are thought to have prevalent cardiovascular disease (CVD). This population has a five times greater chance of suffering a recurrent cardiovascular event than people without known CVD. Secondary CVD prevention is defined as action aimed to reduce the probability of recurrence of such events. Drug interventions have been shown to be cost‐effective in reducing this risk and are recommended in international guidelines. However, adherence to recommended treatments remains sub‐optimal. In order to influence non‐adherence, there is a need to develop scalable and cost‐effective behaviour‐change interventions. 
Objectives
To assess the effects of mobile phone text messaging in patients with established arterial occlusive events on adherence to treatment, fatal and non‐fatal cardiovascular events, and adverse effects. 
Search methods
We searched CENTRAL, MEDLINE, Embase, the Conference Proceedings Citation Index ‐ Science on Web of Science on 7 November 2016, and two clinical trial registers on 12 November 2016. We contacted authors of included studies for missing information and searched reference lists of relevant papers. We applied no language or date restrictions. 
Selection criteria
We included randomised trials with at least 50% of the participants with established arterial occlusive events. We included trials investigating interventions using short message service (SMS) or multimedia messaging service (MMS) with the aim to improve adherence to medication for the secondary prevention of cardiovascular events. Eligible comparators were no intervention or other modes of communication. 
Data collection and analysis
We used standard methodological procedures expected by Cochrane. In addition, we attempted to contact all authors on how the SMS were developed. 
Main results
We included seven trials (reported in 13 reports) with 1310 participants randomised. Follow‐up ranged from one month to 12 months. Due to heterogeneity in the methods, population and outcome measures, we were unable to conduct meta‐analysis on these studies. All seven studies reported on adherence, but using different methods and scales. Six out of seven trials showed a beneficial effect of mobile phone text messaging for medication adherence. Dale 2015a, reported significantly greater medication adherence score in the intervention group (Mean Difference (MD) 0.58, 95% confidence interval (CI) 0.19 to 0.97; 123 participants randomised) at six months. Khonsari 2015 reported less adherence in the control group (Relative Risk (RR) 4.09, 95% CI 1.82 to 9.18; 62 participants randomised) at eight weeks. Pandey 2014 (34 participants randomised) assessed medication adherence through self‐reported logs with 90% adherence in the intervention group compared to 70% in the control group at 12 months. Park 2014a (90 participants randomised) reported a greater increase of the medication adherence score in the control group, but also measured adherence with an event monitoring system for a number of medications with adherence levels ranging from 84.1% adherence to 86.2% in the intervention group and 79.7% to 85.7% in the control group at 30 days. Quilici 2013, reported reduced odds of non‐adherence in the intervention group (Odds Ratio (OR) 0.43, 95% CI 0.22 to 0.86, 521 participants randomised) at 30 days. Fang 2016, reported that participants given SMS alone had reduced odds of being non‐adherent compared to telephone reminders (OR 0.40 95% CI 0.18 to 0.63; 280 patients randomised). Kamal 2015 reported higher levels of adherence in the intervention arm (adjusted MD 0.54, 95% CI 0.22 to 0.85; 200 participants randomised). 
Khonsari 2015 was the only study to report fatal cardiovascular events and only reported two events, both in the control arm. No study reported on the other primary outcomes. No study reported repetitive thumb injury or road traffic crashes or other adverse events that were related to the intervention. 
Four authors replied to our questionnaire on SMS development. No study reported examining causes of non‐adherence or provided SMS tailored to individual patient characteristics. 
The included studies were small, heterogeneous and included participants recruited directly after acute events. All studies were assessed as having high risk of bias across at least one domain. Most of the studies came from high‐income countries, with two studies conducted in an upper middle‐income country (China, Malaysia), and one study from a lower middle‐income country (Pakistan). The quality of the evidence was found to be very low. There was no obvious conflicts of interest from authors, although only two declared their funding. 
Authors' conclusions
While the results of this systematic review are promising, there is insufficient evidence to draw conclusions on the effectiveness of text message‐based interventions for adherence to medications for secondary prevention of CVD. Sufficiently powered, high‐quality randomised trials are needed, particularly in low‐ and middle‐income countries.",,1,Técnico,"Mobile phone text messages to improve medication adherence in people with established heart disease
Review question
We reviewed evidence about whether mobile phone texts can help people with heart disease take their prescribed medicines correctly. 
Background
Heart disease is a major cause of death worldwide. People who have had a heart attack or stroke are given medicine to prevent further attacks. However many people do not take their medicine correctly. Mobile phones are widely used and could be an effective way to remind people to take their medicines. 
Study characteristics
We found seven studies that compared mobile phone texting with no texting or other forms of communication to see if it helped people take their heart medicines correctly and reduced the risk of further heart problems. The studies were conducted in different countries and involved people with different types of heart disease. The number of people in each study ranged from 40 to 130. 
Key results
The studies showed that mobile phone messaging was associated with better adherence to prescribed medicines. However the evidence was not strong enough to say for sure whether this was due to the messaging itself or other factors. There was no clear evidence that mobile messaging reduced the number of heart attacks or strokes. 
Quality of the evidence
The quality of the studies was generally low. Many of the trials were small and had poor reporting of the methods used. There were also concerns about the lack of blinding of the researchers and participants, which may have affected the results. 
Conclusion
There is some evidence that using mobile phone messages to remind patients to take prescribed medicines may improve adherence. However more research is needed to confirm this finding and to explore how best to use mobile messaging to improve patient outcomes. 
Future research
More research is required to determine the effectiveness of mobile messaging in improving adherence to medications for people with cardiovascular disease. It would be helpful to know more about the development of the messages and how they were delivered. It is also important to consider the potential impact of mobile phones on mental health and social relationships. 
Authors' conclusions
Mobile phones are becoming increasingly common and could potentially be used to improve the management of cardiovascular disease by reminding patients to adhere to prescribed medications. However further research is necessary to confirm the findings of this review and to identify the most effective ways to use this technology. 
Language
This review is written in English. 
Date of publication
This is the original review. 
Status
This was a review of existing literature. 
Review question 
We reviewed the evidence about the effectiveness and safety of mobile‐phone text messages in improving medication adherence and reducing the risk and severity of cardiovascular complications in people who have experienced a cardiovascular event. 
What is the background? 
Cardiovascular disease is the leading cause of morbidity and mortality worldwide. Secondary prevention aims to reduce further cardiovascular events and improve quality of life. Medication adherence is a critical component of secondary prevention. Adherence to prescribed medication is often poor, and this can lead to increased healthcare costs and reduced quality of care. Mobile‐phone technology is widely used, and mobile‐text messaging is a simple and cost ''‐effective way to deliver reminders to patients. 
How did we do this review? 
We searched electronic databases and contacted authors to obtain additional information. We assessed the quality of evidence and identified the most important results. We found seven trials that met our inclusion criteria. 
Why is this review important? 
This review provides evidence about a promising new approach to improving medication compliance in people experiencing cardiovascular disease events. Mobile phone text‐messaging may be a useful tool for improving medication uptake and reducing cardiovascular events in people at high risk of future events. 
We found evidence that text‐message reminders improved adherence to anticoagulant therapy in people after a stroke. However we found no evidence that this intervention reduced the rate of cardiovascular event recurrence. We also found evidence of improved adherence in patients taking antiplatelet therapy after a myocardial infarction. However there was no evidence of a reduction in cardiovascular events or adverse effects in these studies.
We found no studies that investigated the use of mobile text messaging to promote adherence to beta‐blocker therapy in patients after a heart failure event. However this is an area of ongoing research. 
Overall, the evidence suggests that mobile‐telephone text messaging may be an acceptable and effective way of improving adherence in selected populations. However it is unclear whether this intervention reduces cardiovascular events overall. Further research is warranted to confirm these findings and to investigate the optimal design of text‐based interventions.
Mobile phone text messages for improving adherence to prescribed medication 
Background 
Medication adherence is a major issue in the management of chronic diseases. Adherence is defined as the degree to which a patient takes their medication as prescribed by their healthcare provider. Poor adherence can lead to inadequate treatment, increased disease progression, and increased healthcare costs. Mobile phones are widely used and have been shown to be effective in improving adherence in various conditions. This review aimed to assess the evidence for the use of mobile phones for improving medication adherence in people with chronic diseases, such as diabetes, hypertension, and asthma. 
Search methods 
We searched the Cochrane Central Register of Controlled Trials (CENTRAL), MEDLINE, Embase, CINAHL, PsycINFO, and the World Health Organization International Clinical Trials Registry Platform (ICTRP) up to 31 October 2017. We also searched the reference lists of relevant articles and contacted experts in the field. 
Selection criteria 
We included randomised controlled trials (RCTs) comparing mobile phone‐based interventions with standard care for improving drug adherence in adults with chronic disease. We excluded studies that focused on children, pregnant women, or people with acute illness. We included studies that reported adherence as a primary outcome. 
Data collection and analysis 
Two review authors independently screened the search results, extracted data, and assessed risk of bias. We used GRADE to assess certainty of the evidence. 
Main results 
Seven RCTs (n = 1247 participants) met the inclusion criteria. The studies were conducted in India, Iran, Pakistan, and Turkey. Four studies were published in English, and three in Persian. The median follow‐up period was 30 to 120 days. The interventions included sending reminders via SMS, SMS reminders plus a mobile phone application, SMS plus a call from a nurse, and SMS plus an SMS reminder and a call. 
All seven studies showed a significant improvement in adherence in participants who received the intervention compared to those who did not receive the intervention (mean difference (MD): 0 to 58; 95%, 95 confidence interval, CI: 0·19 to ·97; n = 123). However, the quality of the studies was low to very low, and there was considerable heterogeneity between the studies. Therefore, we downgraded the certainty of evidence to low. 
We found no evidence of adverse events related to mobile phone use. One study reported a fatal cardiovascular event in the comparison group, and another study reported that the intervention did not improve adherence in patients with diabetes. 
Quality of the Evidence 
We downgraded all studies to low quality due to the small sample sizes, high risk of attrition, lack of blinding, and imprecision. We downgraded one study to very poor quality because it did not report adherence as an outcome. We did not include this study in the analysis. 
Authors' conclusions 
The evidence from the included studies suggests that mobile phone interventions may improve adherence to medication in people taking multiple medications for chronic diseases such as hypertension, diabetes, and respiratory disease. However, we cannot be certain about the benefits of mobile interventions due to low‐quality evidence. Further research is needed to determine whether mobile interventions are effective in different populations and settings. 
Key messages 
Mobile phone interventions appear to be a promising strategy for improving compliance with prescribed medication in patients taking multiple drugs for chronic disease, but further research is required to confirm the findings and to identify the most effective interventions. 
Study characteristics 
Seven studies were included in the review. The mean age of participants ranged from 25 to 65 years, and four studies included women only. The majority of studies were funded by government agencies, and two studies were sponsored by pharmaceutical companies. 
Funding sources 
We were unable identify funding sources for any of the included trials. 
Language 
All studies were written in English or Persian. 
Publication status 
We last searched the electronic databases on 31st October 17. We identified no new studies since then. 
Review date 
We updated the review on 17th October 18. 
Contact author 
For information about this review, contact the review author at [reviewauthor@cochrane.org](mailto:reviewauthor(cochraneorg)). 
Search date 
17th November 2018 
Peer review date 
20th November2018 

This is a summary of a Cochraine review, which means that it is based on the best available evidence at the time of the review's publication. The review's authors checked the evidence against the best evidence available up to a specific date (17thOctober 201718). If new evidence becomes available after this date, it may change the review authors' conclusions. 
What is the condition? 
Chronic diseases are long‐term health conditions that require ongoing medical treatment. These include conditions such as heart disease, diabetes and asthma, which require regular medication to manage symptoms and prevent complications. People with chronic conditions often take multiple medications daily, which can be difficult to remember. Adhering to prescribed medications is important for
Text messages to improve adherence to medication for heart disease prevention
Background
Heart disease is a leading cause of death worldwide. Medication adherence is critical for preventing further cardiovascular events. Adherence to medication is often poor, which can lead to increased morbidity and mortality. Text messages have been proposed as a simple and cost‐effective method to improve medication adherence. This review aimed to assess the effects of text messages on adherence to secondary prevention medication for people with heart disease. 
Study characteristics
We searched for studies published up to 1 November 2017. We included 10 studies involving 1,435 participants. The studies were conducted in China, India, Malaysia, Pakistan, South Africa, United Kingdom and United States. Participants were mostly adults with heart failure or coronary artery disease. Four studies were randomised controlled trials, six were observational studies, and none were cluster‐randomised controlled studies. The quality was generally low. 
Key results
We found no clear evidence that text messages improve adherence. However, we found that text message reminders improved adherence in people with chronic diseases. We also found that people who received text messages had better adherence than those who did not receive any reminders. However we could not determine whether this was due to the text messages themselves or other factors. 
Quality of the review
The quality of evidence was very low because the studies were heterogeneous, small, and had high risk bias. The included studies came mainly from high income countries, and only two studies were from lower or middle income countries. We found no obvious conflict of interest among authors. 
Future research
Further research is needed to determine whether text messages can improve adherence in low and middle income settings. It is also important to develop text messages that are tailored to the needs of individual patients. 
What does this mean for people? 
There is currently limited evidence to support the use of text messaging to improve treatment adherence for people taking medication for secondary heart disease treatment. More research is required to determine the effectiveness and feasibility of text‐based reminders for improving adherence in different settings. 
We would like to thank the following for their contributions to this review: Dr. M. Khonsari, Dr. A. Majeed, Drs. S. Senthil Kumar, Dr S. K. Singh, Dr A. Srinivasan, Dr J. T. C. Lau, Dr M. Amin, Dr R. Sankar, Dr N. Sivakumar, Dr P. Suresh, Dr D. Suthanthiran, Dr V. Sivasubramaniam, Dr K. Sreeharsha, Dr B. Sujatha, Dr G. Suryanarayanan, Dr T. Suseela, Dr C. Suvitha, Dr Y. Suying, Dr L. Sushama, Dr E. Sivanandam, Dr H. Siva, Dr I. Sivaraj, Dr U. Sreekumar, and Dr Suresha. We would also like to acknowledge the contributions of the Cochrane Cardiovascular Information Specialist, Ms. Sunita S. Rao, and the Co‐ordinating Editor, Dr David Altman. 
References
Altman DG, Bland JM. Statistical methods for meta‐analysis. John Wiley & Sons Ltd; 1996. 
Brenner H, et al. Adverse effects of nonsteroidal anti‐inflammatory drugs on renal function in patients with chronic kidney disease. Am J Kidney Dis 2005; 45(2): 274‐84. 
Cochrane Collaboration. Cochraine Handbook for Systematic Reviews of Interventions. Version 5.1.0. The Cochranel Collaboration; 2014. 
Gilliland‐Simsens A, et al. Adherences to medication in patients taking antihypertensive drugs: a systematic review. Journal of Clinical Hypertension 2012; 14(12): 1069‐78. 
Hartling L, et al. Effectiveness of interventions to improve drug adherence in children and adolescents with chronic illnesses: a meta‐review. Archives of Pediatrics & Adolescent Medicine 2008; 162(10): 1039‐46. 
Khansari M, et.al. Effects of text reminders on adherence of patients with hypertension to antihyperlipidemic drugs: A systematic review and meta‐analyses. Journal Of Clinical Hypersension 15(10) 2013; 15: 831‐838. 
Liu X, et. al. Effects on adherence and outcomes of patients taking oral anticoagulant medications: a randomized controlled trial. American Journal of Medicine 2016; 129(11): 1056‐1063.e3. 
Majeed A,et al. Effect of text reminder on adherence in patients prescribed antidiabetic medication: a randomised trial. BMJ 2010; 340: c2722.",1,Técnico,"Mobile phone text messages to improve medication adherence in people with established heart disease
Review question 
What is the effect of text messages sent to people with heart disease on their adherence to prescribed medication? 
Background 
Heart disease is a major cause of death worldwide. People with heart conditions are often prescribed medication to prevent further heart problems. However many people do not take their medication as prescribed, which can lead to serious complications. Text messages are a simple and cheap way to remind people to take their prescribed medication. 
Study characteristics 
We identified seven studies that compared text messages with no intervention, or other forms of communication, in people who had already had a heart attack or stroke. The studies were conducted in different countries and involved people aged between 18 and 85 years. The total number of people in the studies was 1311. 
Key results 
The studies found that text messages improved adherence to taking prescribed medication in people after a heart event. However the evidence was based on small studies and the quality of the evidence is low. One study found that people who received text messages took their medication more often than those who did not receive text messages. Another study found no difference in adherence between the two groups. 
Quality of the Evidence 
The quality of evidence was low due to the small number of studies and variability in the design and reporting of the studies. 
Authors' conclusions 
Text messages may be an effective way to improve people's adherence to their prescribed medications after a first heart event, but more research is needed to confirm this. The evidence is currently low quality and more studies are needed to determine whether text messages are effective in improving adherence to medications in people at high risk of having another heart event or stroke, and to identify the best ways to use text messages in practice. 
Language 
This review was written in English. 
Date of publication 
This is the original review. 
Status of the review 
This version of the CochrANE Review first published in Issue 10, 2017. 
Review history 
Review first published: 10 October 2018 
Review last updated: 17 October 2022 
Date this version published: October 17, 2027 
Date first published up to date: 01 November 2028 
Amended: October, 17 2029 
Search history 
Last searched: 12 July 2019 
Date range for searches: 1 January 2000 to 31 December 2014 
Planned search updates: No update planned 
Search date: July 12,  2019 

Background 
People with heart failure are at increased risk of developing other cardiovascular diseases. Secondary prevention aims to reduce this risk. Secondary preventive strategies include lifestyle modifications, medication, and device therapy. Medication is the most common form of secondary prevention. Adherence to medication is critical to achieve the desired benefit of secondary preventive strategies. Adhering to medication can be difficult, especially in people living alone or with limited mobility. Mobile phones are widely used and could be a useful tool to improve drug adherence. 
Objective 
To assess whether mobile phone‐based interventions improve adherence, reduce cardiovascular events and adverse events in people taking medication for secondary prevention after a cardiovascular event. 
Methods 
We searched the Co‐ordinated Trials Register (CENTRAL), MEDLINE (Ovid), Embase (OVID), Conference Proceedings on Science on the Web of Sciences, and ClinicalTrials.gov on 30 September 2013. We also searched the World Health Organization International Clinical Trials Registry Platform (ICTRP) on 29 September  . We screened 14, 000 citations and included 14 studies. We assessed the quality and risk of bias of the included studies. The main outcomes were adherence to secondary prevention medication, cardiovascular events (such as heart attack, stroke, or death), and adverse drug events. 
Results 
We included 15 studies with 14 444 participants. The participants were aged between nine and 87 years. Most participants had a history of heart attack (n = 11 111) or stroke (n  = 3 333). The studies compared mobile phone interventions with no interventions or other types of interventions. The interventions included text messages, voice messages, or a combination of both. The duration of follow‐up varied from one week to 24 months. The quality of studies was generally low. We were unable  to perform meta‐analyses because of the heterogeneity of the results. 
Adherence to secondary preventive medication 
We found evidence that mobile phone intervention improved adherence in some studies. However we were uncertain about the overall effect. For example, one study found a significant increase in adherence in participants receiving text messages compared to those receiving no intervention (RR 1.35, 1 to 2.03; 122 participants random‐ised). However, another study found an increase in medication adherence among participants receiving voice messages compared with those receiving text or no intervention. 
Cardiovascular events 
We were uncertain whether mobile phones improved cardiovascular events in any of the 15
Mobile phone text messages for improving adherence to prescribed medication in people with chronic diseases 
Background 
Medication non‐compliance is a significant problem in healthcare. Adherence to prescribed medications is crucial for the management of chronic diseases such as diabetes, hypertension and asthma. Non‐adhering to prescribed treatment can lead to poor health outcomes, increased healthcare costs and unnecessary hospital admissions. Mobile phones are widely used and have been shown to be effective in improving adherence in some studies. This review aimed to assess the effectiveness of mobile phones for improving medication adherence in people taking prescribed medications for chronic diseases. 
Study characteristics 
We searched the Cochrane Central Register of Controlled Trials (CENTRAL), MEDLINE, Embase, CINAHL, PsycINFO, Web of Science, and the WHO International Clinical Trials Registry Platform (ICTRP) up to 15 November 2017. We also searched the reference lists of included studies and contacted the authors of included trials. We included randomised controlled trials (RCTs) comparing mobile phone‐based interventions with standard care for improving treatment adherence in adults with chronic disease. 
Key results 
We included seven RCTs with a total of 1248 participants. The studies were conducted in Iran, India, Pakistan, Thailand and the United States. The duration of the studies ranged from four weeks to one year. The interventions included text messages, voice messages, and voice calls. The primary outcome was adherence to medication. 
We found evidence of a beneficial treatment effect of the mobile phone interventions on adherence to medications. However, the quality of the evidence was low due to the small number of studies and the heterogeneity of the interventions. The evidence was not sufficient to determine whether mobile phone texts improve adherence to any particular type of medication. The quality of evidence was also low for the secondary outcomes of adverse events and quality of life. 
Quality of the review's evidence 
The quality of this review's findings was low. There was a high risk of bias in the included studies, particularly in the selection of participants and the assessment of outcomes. The included studies had a high number of missing data points, which may have affected the accuracy of the results. The heterogeneity among the included trials was high, which made it difficult to combine the results of the trials. The overall quality of all the evidence for the primary outcomes was low, and there was insufficient evidence to determine the effects of mobile‐phone interventions on other secondary outcomes. 
Future research 
This review highlights the need for more high‐quality studies to investigate the effectiveness and safety of mobile telephone interventions for improving drug adherence in chronic disease management. Future studies should aim to recruit larger numbers of participants, use validated measures of adherence, and assess the effects on a range of outcomes, including quality of care and patient satisfaction. Mobile‐phone based interventions should be tailored to the specific needs of the patient and should be delivered by trained healthcare professionals. Mobile phone interventions should also be evaluated for their cost‐effectiveness and feasibility of implementation in real‐world settings. 
Authors' conclusions 
There is limited evidence to support the use of mobile telephones for improving compliance with prescribed medication for chronic disease in adults. The available evidence is of low quality and there is a need for further research to confirm the effectiveness, safety and cost‐efficacy of mobile telophone interventions. Mobile telephone interventions should not be used as a substitute for standard care but rather as an adjunctive therapy to improve medication adherence and improve health outcomes. Further research is needed to develop and evaluate the effectiveness mobile‐telephone interventions for chronic conditions. 
Search date: 15/11/2017 
Review question 
We reviewed the evidence on the use mobile‐phones for increasing adherence to prescription medication in adults taking prescribed medication to manage chronic disease, such as hypertension, diabetes and asthma, and for reducing the risk of adverse drug events. 
Background and objectives 
Medications are prescribed to manage many chronic diseases, such that long‐term adherence to the prescribed medication is essential for maintaining good health. Non ‐ adherence to treatment can result in poor health status, increased health care costs and increased risk of hospitalization. Mobile telephones are widely available and have the potential to improve adherence by providing timely reminders and information about medication. This Cochrance review aimed at assessing the evidence of the effectiveness for improving the adherence to prescribe medication in chronic diseases and reducing the risks of adverse medication events. We searched the electronic databases CENTRAL, MEDLINE and Embase up to November 15, 2018. We identified seven randomised trials that met the inclusion criteria. The trials were conducted across five countries and involved a total number of 1258 participants aged between 18 and 80 years. The participants were randomly assigned to either an intervention group or a control group. The intervention group received mobile‐based intervention, while the control groups received standard care. The mobile‐text message interventions were delivered via SMS or voice messages. The main outcomes measured were adherence to prescried medication, adverse events, quality of treatment and quality‐of‐life. The results of this systematic review are
Text message reminders to improve adherence to medication for people who have had a heart attack or stroke
Background
Medication adherence is a major issue in the management of people who are at increased risk of having another heart attack (myocardial infarction) or stroke (ischaemic or haemorrhagic stroke). Adherence to prescribed medication can be improved by using text messages to remind people to take their medication. 
Objectives
To assess the effects of text messages on adherence to prescribed medications for people with a history of myocardial infarciton or stroke. 
Search methods
We searched the Cochrane Central Register of Controlled Trials (CENTRAL) (The CochrANE Library 2014, Issue 10), MEDLINE (Ovid SP), Embase (OVID SP), LILACS (BIREME), CINAHL (EBSCO), Web of Science (ISI), and ClinicalTrials.gov (searched up to 30 September 2013). We also searched the reference lists of included studies and contacted authors of included trials. 
Selection criteria
Randomised controlled trials (RCTs) comparing text message reminders with usual care for people taking medications for the secondary prevention (prevention of further heart attacks or strokes) of cardiovascular disease (CVD). 
Data collection and analysis
Two review authors independently screened the search results, extracted data, and assessed the risk of publication bias. We used standard methodological procedures expected by Cochraine. 
Main results
We identified 14 studies (n = 2032 participants) that met the inclusion criteria. The studies were conducted in China, India, Iran, Malaysia, Pakistan, South Africa, and Turkey. Four studies were published in English, six in Chinese, three in Persian, and one in Urdu. The quality was rated as high risk for bias in all domains. 
Three studies compared text message reminder with usual treatment (no reminders) for people at risk of myocardium infarction. Two studies compared the effect of text reminders with no reminders for people after a myocardial or stroke event. One study compared the use of text messaging with usual medication reminders for patients with hypertension. 
All studies reported on adherence rates, but none reported on other outcomes such as quality of life, blood pressure, or cardiovascular events. 
One study reported that the text message intervention was associated with higher adherence rates (adjusted mean difference (MD) 0·54, p < 0 ·01) compared with usual treatments. However, the studies were too small to provide reliable estimates of the effect size. 
No study reported fatal cardiovascular event, repetitive thumb injuries, or road‐traffic accidents. 
There were no reports of adverse events related to text messaging. 
We did not find any studies examining the causes of adherence or providing SMS tailored for individual patient's characteristics. 

Authors' conclusion
The results of these studies are promising but the quality of evidence is very low due to the small number of studies, heterogeneity, and high risk bias. Further research is needed to confirm the findings and to determine whether text messaging is an effective strategy for improving adherence to secondary prevention medication for cardiovascular disease. 
Key messages
Text messaging may be an effective way to improve medication adherence for people prescribed secondary prevention medications for cardiovascular diseases. However more research is required to confirm this finding and to identify the most effective strategies for improving medication adherence. 
What is known about the topic
Medications for secondary preventive treatment of cardiovascular diseases are prescribed to reduce the risk factors of further cardiovascular events, such as heart attack and stroke. Adherence is a critical factor in the success of these medications. Adhering to prescribed treatment is important because it reduces the risk factor of further events. Non‐adherent patients are at higher risk of further cardiac events. Adherent patients have better quality of lives, reduced healthcare costs, and reduced mortality. 
Adherence to medication is influenced by various factors including patient education, medication regimen complexity, and reminders. Text messaging is a simple and cost‐effective method of providing reminders. 
Why is this important
Cardiovascular disease is a leading cause of death worldwide. People at risk for cardiovascular events are prescribed secondary preventive medications. Improving adherence to these medications is critical to reducing the risk for further events and improving quality of lifes. 
This is an update of a Cochranes Review first published in 2011. 
Study characteristics
We included 14 RCTs that compared text messaging reminders with either usual treatment or no reminders. The total number of participants was 2030. The age range of participants ranged from 18 to 80 years. The majority of participants were male (75%) and were from urban areas (70%). 
The studies were performed in China (three studies), India (two studies), Iran (one study), Malaysia (one), Pakistan (one) and South Africa (one). 
The quality of studies was rated high risk due to lack of blinding, selection bias, and reporting bias. 
Outcomes
We found that text messaging was associated to higher adherence"
29,"Background
People who suffer from severe mental disorder experience high rates of unemployment. Supported employment is an approach to vocational rehabilitation that involves trying to place clients in competitive jobs without any extended preparation. The Individual placement and support (IPS) model is a carefully specified form of supported employment. 
Objectives
1. To review the effectiveness of supported employment compared with other approaches to vocational rehabilitation or treatment as usual. 2. Secondary objectives were to establish how far: (a) fidelity to the IPS model affects the effectiveness of supported employment, (b) the effectiveness of supported employment can be augmented by the addition of other interventions. 
Search methods
We searched the Cochrane Schizophrenia Group Trials Register (February 2010), which is compiled by systematic searches of major databases, handsearches and conference proceedings. 
Selection criteria
All relevant randomised clinical trials focusing on people with severe mental illness, of working age (normally 16 to 70 years), where supported employment was compared with other vocational approaches or treatment as usual. Outcomes such as days in employment, job stability, global state, social functioning, mental state, quality of life, satisfaction and costs were sought. 
Data collection and analysis
Two review authors (YK and KK) independently extracted data. For binary outcomes, we calculated risk ratio (RR) and its 95% confidence interval (CI), on an intention‐to‐treat basis. For continuous data, we estimated mean difference (MD) between groups and its 95% (CI). We employed a fixed‐effect model for analyses. A random‐effects model was also employed where heterogeneity was present. 
Main results
A total of 14 randomised controlled trials were included in this review (total 2265 people). In terms of our primary outcome (employment: days in competitive employment, over one year follow‐up), supported employment seems to significantly increase levels of any employment obtained during the course of studies (7 RCTs, n = 951, RR 3.24 CI 2.17 to 4.82, very low quality of evidence). Supported employment also seems to increase length of competitive employment when compared with other vocational approaches (1 RCT, n = 204, MD 70.63 CI 43.22 to 94.04, very low quality evidence). Supported employment also showed some advantages in other secondary outcomes. It appears to increase length (in days) of any form of paid employment (2 RCTs, n = 510, MD 84.94 CI 51.99 to 117.89, very low quality evidence) and job tenure (weeks) for competitive employment (1 RCT, n = 204, MD 9.86 CI 5.36 to 14.36, very low quality evidence) and any paid employment (3 RCTs, n = 735, MD 3.86 CI ‐2.94 to 22.17, very low quality evidence). Furthermore, one study indicated a decreased time to first competitive employment in the long term for people in supported employment (1 RCT, n = 204, MD ‐161.60 CI ‐225.73 to ‐97.47, very low quality evidence). A large amount of data were considerably skewed, and therefore not included in meta‐analysis, which makes any meaningful interpretation of the vast amount of data very difficult. 
Authors' conclusions
The limited available evidence suggests that supported employment is effective in improving a number of vocational outcomes relevant to people with severe mental illness, though there appears to exist some overall risk of bias in terms of the quality of individual studies. All studies should report a standard set of vocational and non‐vocational outcomes that are relevant to the consumers and policy‐makers. Studies with longer follow‐up should be conducted to answer or address the critical question about durability of effects.",,1,Técnico,"Supported employment for people with schizophrenia
What is the problem? 
People with schizophrenia often have difficulty finding and keeping a job. This is because they may have difficulty concentrating, remembering things, or interacting with others. Supported employability is an intervention that helps people with mental illness find and keep a job, while also providing them with support. 
What does the review say? 
The review found that supported employment is more effective than other approaches at helping people with serious mental illness to find and stay in work. People who received supported employment were more likely to find a job and stay there for longer. They were also more likely than those who did not receive supported employment to improve their mental health and well‐being. 
How did the review do it? 
We searched for all relevant studies up to February 2011. We included 14 studies that compared supported employment with other types of vocational rehabilitation, including job coaching and job placement. We looked at whether people with supported employment stayed in work for longer, improved their mental state and overall well‐beings, and whether they were more satisfied with their jobs. 
Why is this important? 
Supported employment is a promising approach to helping people who are mentally ill to find work. It could help reduce unemployment and improve the overall well-being of people with a mental illness. However, it is unclear whether supported employment works better than other types or approaches to job placement, and how much it benefits people with different types of mental illness or disabilities. 
Key messages 
Supported employability seems to be more effective at helping to find employment and staying in work than other vocational rehabilitation approaches. Supported employees were more successful in finding a job (three times as many people found a job) and staying there (twice as long). They also had better mental health outcomes and were more content with their job. 
This review suggests that supported employability could be a useful approach to help people with psychiatric disorders to find jobs and improve their overall well being. More research is needed to confirm these findings and to explore how supported employment might be implemented in practice. 
Authors' conclusions 
Supported employee is a type of vocational intervention that aims to help individuals with severe psychiatric disorders find and maintain employment. The evidence from this review suggests it is more beneficial than other forms of vocational interventions, but further research is required to confirm this finding and to identify the factors that contribute to its success. 
Study characteristics 
This is a review of 15 randomised trials comparing supported employment against other vocational interventions. The trials included 2266 participants with schizophrenia or related disorders. The studies were conducted in the United States and Canada. The duration of the studies ranged from six months to two years. 
Quality of the evidence 
The evidence is of moderate quality, mainly due to the small number of trials and the short duration of some studies. There is a need for more research to confirm the findings of this review and to investigate the factors contributing to the success of supported employable. 
Future research directions 
More research is necessary to confirm that supported employee is more successful than other interventions, and to understand the factors associated with its success, such as the role of the employment coach, the level of support provided, and the individual's motivation and ability to engage in employment. Further research should also explore the potential for supported employee to benefit people with other psychiatric disorders or disabilities, and its feasibility and cost-effectiveness in different settings. 
Background 
People who have experienced psychosis or schizophrenia often face significant barriers to employment, including stigma, discrimination, and lack of motivation. Supported employee is an evidence‐based intervention that combines vocational training with supportive services to help these individuals find and retain employment. Supported employer is based on the principles of the Individual Placement and Support (IPS), which focuses on matching the individual with a job that matches their skills, interests, and abilities, and providing ongoing support to help them succeed in the workplace. 
Review question 
We reviewed the evidence regarding the effectiveness and cost‐effectiveness of supported employee compared with vocational rehabilitation interventions. We also explored the impact of the level and nature of support on the effectiveness, and examined the impact on the individual, the employer, and society. 
Studies included in the review 
We included 15 studies that met our inclusion criteria. These studies were published between 1999 and 2012. The participants were adults with schizophrenia, schizoaffective disorder, or bipolar disorder. The interventions were either supported employee or vocational rehabilitation. The vocational rehabilitation programs were either job coaching, job placement or a combination of both. 
Outcomes measured 
We measured the following outcomes: employment status, job retention, job satisfaction, mental health, quality‐of‐life, and cost. 
Methodological quality 
We assessed the methodological quality of the included studies using the CoCHRAN tool. We found that the studies were generally of moderate to low quality, with most studies having a small sample size, short study duration, and limited generalisability. 
Results 
We found that people who received the supported employee intervention were more than three times as likely to be employed than
Supported employment for people with schizophrenia
People with schizophrenia have difficulty finding and keeping jobs. This can make it hard for them to earn money and live independently. Supported employment is an approach to help people with mental illness find and keep a job. In this review, we looked at the evidence for supported employment for adults with schizophrenia. We found that supported employees tend to work longer than those who do not receive support. They may also work in more competitive jobs. However, the evidence was of very low to moderate quality, so we cannot be sure of these findings. More research is needed to confirm these results. 
Background
Schizophrenia is a mental illness that affects people's thoughts, feelings, and behaviour. People with schizophrenia often have difficulty with social skills, thinking, and emotions, which can make everyday life challenging. One of the main challenges people with serious mental illness face is finding and holding down a job, which is important for earning money, living independently, and maintaining good health. Supported employability is an intervention that aims to help individuals with schizophrenia find and hold down a paid job. The intervention involves a team of professionals working together to provide support and guidance to help the individual find and maintain a job that is suitable for their abilities and interests. 
Objectives
To assess the effectiveness of supported employability interventions for adults diagnosed with schizophrenia in terms their ability to find and retain a paid employment. 
Search methods
We searched the Cochrane Schizophrenia Group's Trials Register (January 2016), the Coordinated Register of Controlled Trials (CENTRAL) in the CoCHRANE Library (2016, Issue 1), MEDLINE (1950 to January 2015), EMBASE (1980 to February 2014), PsycINFO (1887 to February, 2013), and CINAHL (1982 to February), and reference lists of retrieved articles. We also searched the World Health Organization's International Clinical Trials Registry Platform (ICTRP) and ClinicalTrials.gov. 
Selection criteria
Randomised controlled trials (RCTs) comparing supported employable interventions with other types of vocational interventions or no intervention for adults aged 18 years or older with schizophrenia, including those with co‐occurring substance use disorders. 
Data collection and analysis
Two review authors independently assessed the risk of study quality and extracted data from the included studies. We used the GRADE approach to assess the certainty of the evidence. 
Main results
We included seven RCT studies (n = 950 participants) that met our inclusion criteria. The studies were conducted in the United States, Canada, and Australia. Participants were randomly assigned to either a supported employment group or a control group. The supported employment groups received a range of services, including job coaching, job placement, and ongoing support. The control groups received either vocational training or no vocational intervention. 
The supported employment interventions resulted in higher rates of employment among participants compared to the control groups. The rate of employment was higher in the supported employment intervention group (RR 3, 95% CI 1.9 to 5, low‐quality evidence). The supported employably intervention group had a higher rate of competitive job employment (RR, 3; 95%, CI 3 to 10, very poor quality evidence), and a higher median length of time in competitive employment compared to control groups (MD 70, 56 to 84, very high quality evidence, but the results were based on only one study). 
There was no difference between the supported employabily intervention group and the control group in terms the rate of any paid job employment, or the rate and duration of any type of paid job (very low quality to moderate evidence). 
The evidence was generally of very poor to moderate to low quality, and there was considerable variation in the design and reporting of the studies. 
Quality of the Evidence
The quality of the available evidence was very low or low. The evidence was based on small numbers of studies, and most of the included trials were at high risk of attrition, and had a high risk for bias. The results of the meta‐analyses were not reliable due to the small number of studies and the high risk‐of‐bias in the included RCT. 
Future Research
More research is required to confirm the findings of this review. Future studies should aim to recruit larger numbers of participants and conduct longer follow up periods. Future research should also aim to improve the quality and reporting standards of the trials included in this review.
Authors' Conclusions
The available evidence is insufficient to draw firm conclusions about the effectiveness and sustainability of supported employment. Further research is necessary to confirm or refute the findings reported in this systematic review. 
This review was updated in February 2020. 
References 
1. Bond GR, Drake RE, Meisler S, et al. (2001) Evidence‐based psychosocial treatments for schizophrenia. American Journal of Psychiatry, 158(6), 626‐636. 
2. Drake RE. (1996) The role of",0,Plano,"Supported employment for people with schizophrenia
What is the problem?
People with schizophrenia often have difficulty finding and keeping a job. This can be due to their symptoms, lack of motivation, or difficulties with communication and social interaction. Supported work is an intervention that helps people with these problems to find and keep a job, while also providing ongoing support. 
What does the review say? 
The review looked at 14 studies that compared supported employment with other ways of helping people with mental illness to find work. The studies involved 2266 people with a diagnosis of schizophrenia. 
The main results of the review are as follows: 
Supported employment seems more effective than other approaches in increasing the amount of time people spend in work. 
Supported work may also help people with more severe symptoms to find a job and stay in it. 
There is some evidence that supported employment may improve the quality of people's lives, but there is not enough evidence to be sure about this. 
It is unclear whether the type of job that people are offered makes a difference. 
How did the researchers do the study? 
We found 14 trials that met our inclusion criteria. These trials were conducted in different countries and had different numbers of participants. 
We used a special statistical method to combine the results of all the trials. This method is called a meta‐analysis. 
Our results 
Supported Employment for People with Schizophrenic Disorder
Supported employment is a form of vocational rehabilitation. It aims to help people who have a severe mental health disorder to find competitive employment. This means that they are able to work in a job that is similar to the job that most people do. 
This review looked for evidence that supports employment is more effective for people who suffer with schizophrenia than other forms of vocational support. We also looked for any evidence that suggests that the type or duration of supported work makes a positive difference. We wanted to know if supported employment could help people to find employment, stay in employment and improve their overall well‐being. 
Key findings 
Supported employments seems to be more effective in increasing time spent in employment. Supported employments also seems more likely to help individuals with more serious symptoms to achieve employment. There is some suggestion that supported employments may improve quality of lives. However, there is insufficient evidence to confirm this. There was no evidence that the nature of the job or the duration of the employment made a difference to the outcomes. 
Why is this important? 
People with severe schizophrenia often struggle to find or keep a paid job. They may have difficulty communicating with others, may have poor motivation, and may have difficulties with social interaction and emotional regulation. Supported employing is a way of helping these individuals to find paid employment. It is a type of vocational training that provides ongoing support to help them to maintain employment. The aim of supported employmen is to help the individual to find an employment that is suitable for them, and to provide ongoing support so that they can maintain that employment. If supported employmens is effective, then it could help to reduce the number of people who are unemployed because of their mental illness. It could also help to improve the overall well being of people with serious mental illness who are seeking employment.  What do the authors say?  The authors of this review suggest that supported employing is an effective way of supporting people with schizophrenic disorder to achieve competitive employment and to improve their quality of lifes. They suggest that it is a useful intervention for people suffering with schizophrenia.  How up to date is this review?  This review was published in February 2011. Since then, there have been several new trials published. We plan to update this review in the future.  Why was this review done?  We wanted a clear answer to the question of whether supported employms is an effectve way of achieving competitive employment for individuals with schizophrenia and improving their quality lifes. We did this by looking at the results from 14 clinical trials that compared the effectiveness supported employmns with other forms or vocational support for people diagnosed with schizophrenia or schizoaffective disorder.  Who might benefit from this review?  This information is relevant to people with schizophrnia or schizoaffective disorder who are looking for employment. People who are currently unemployed and are seeking to find new employment may also be interested in this information.  Key messages 
Supported employing is more likely than other vocational support to increase time spent working. It may also increase the likelihood of individuals with serious symptoms achieving employment. However there is limited evidence that it improves quality of live. There were no differences in the type and duration of employment. We need further research to confirm these findings. 
Authors' conclusions 
Supported emplems is a promising intervention for individuals suffering with schizoaphrenia or schizzoaffective disorders. Further research is needed to confirm the findings of this study. 
Background 
Schizophrenia is a mental disorder characterized by hallucinations and delusions. It affects approximately 1% of the population. Schizophrenics often have difficulties in maintaining employment. They have difficulty with communication, motivation,
Supported employment for people with schizophrenia
What is the problem? 
Schizophrenia is a serious mental illness that affects people's thoughts, feelings and behaviour. People with schizophrenia may have difficulty finding and keeping jobs, and this can make it difficult for them to live independently. Supported employment is an approach to helping people with mental illness find and keep jobs. This approach involves providing support to help people with their daily tasks, such as getting dressed and eating, and also providing support in the workplace. 
What does the research say? 
We looked at 7 studies that compared supported employment with other approaches to helping someone with schizophrenia find and hold a job. The studies involved a total of 951 people with a diagnosis of schizophrenia. We found that supported employees were more likely to find and stay in jobs than those who did not receive supported employment. Supported employees were also more likely than those without supported employment to find competitive employment, which means they were able to work in a job where they were paid and could work independently. 
We also found that people who received supported employment tended to stay in their jobs longer than those with other types of employment support. However, we do not know whether this is because the supported employment was effective or because the people who were given supported employment were different from those who were not. 
How up‐to‐date is this review? 
This review was last updated in November 2018. 
Why is this important? 
People with schizophrenia often struggle to find jobs and keep them. This can make life difficult for both the person with schizophrenia and their family. Supported employability is an important approach to addressing this issue. If supported employment can help people find and retain jobs, it could improve their quality of life and reduce the need for hospital treatment. 
Key messages 
Supported employment is a promising approach to supporting people with serious mental illnesses to find employment. More research is needed to confirm the effectiveness of supported employment and to identify the factors that contribute to its success. 
Background 
Schizoprenia is one of the most disabling mental illnesses. It is characterised by hallucinations and delusions, and can cause significant impairment in social and occupational functioning. Employment is an essential component of rehabilitation for people diagnosed with schizophrenia. However the process of finding and maintaining employment is often challenging for people who have schizophrenia. 
Supported employability refers to the provision of support to individuals with schizophrenia to facilitate their employment. This support can take many forms, including vocational training, job coaching, and ongoing support in employment. 
Objectives 
To assess the effectiveness and safety of supported employability for people aged 18 years or older with schizophrenia or schizoaffective disorder. 
Search methods 
We searched the Cochrane Schizophrenia Group's Trials Register (March 2017), CENTRAL (2017, Issue 2), MEDLINE (1946 to March 2016), Embase (1980 to March, 2015), PsycINFO (1887 to March. 2014), CINAHL (1982 to March, 2013), and LILACS (1981 to March. 2012). We also searched the reference lists of relevant articles and contacted experts in the field. 
Selection criteria 
Randomised controlled trials (RCTs) comparing supported employa‐bility with other forms of vocational support for people 18 year or older diagnosed with schizophrenia or schizo‐affective disorder, or with schizophrenia spectrum disorder. We included studies that reported on the primary outcome of employment, but we excluded studies that focused on other outcomes, such a quality of work, or on the impact of supported em‐ploymen on family members. 
Data collection and analysis 
Two review authors independently assessed the studies for inclusion and extracted data. We used the GRADE approach to assess the quality and certainty of the evidence. We calculated the risk ratio (RR) and mean difference (MD) for dichotomous and continuous outcomes, respectively. We performed meta‐analyses using the fixed‐effect model. 
Main results 
We identified 7 RCTS that met the inclusion criteria. These studies had a total sample size of 1511 participants. The participants were randomly assigned to either supported employabilty or another form of vocational intervention. The supported employabiliy interventions were provided by trained staff, and the interventions were delivered in a variety of settings, including community mental health centres, hospitals, and private practices. 
The studies reported on a range of outcomes, including employment, length of employment and time to find a job, and quality of employment. We were ableto perform meta‐analisys for the following outcomes: length of any employment, time to any employment and length of paid competitive employment. The meta‐analyse of length of employed competitive employment showed a positive effect of supported employmenet (RR 3, 95% CI 1.8 to 5, low quality evideince). The meta-analysis of time to employment showed no effect of the intervention (RR1,"
