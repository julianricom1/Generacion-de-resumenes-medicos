{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "879a8293",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\OneDrive\\Documents\\MAIA\\Semestre 4\\Despliegue de Soluciones\\__REPOS__\\Generacion-de-resumenes.-medicos\\.venv_generacion\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os, sys, math, json, random, gc, csv, time\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch\n",
    "from datasets import Dataset\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM, AutoTokenizer,\n",
    "    DataCollatorForLanguageModeling, TrainingArguments, Trainer\n",
    ")\n",
    "from transformers.trainer_callback import TrainerCallback, EarlyStoppingCallback\n",
    "from peft import LoraConfig, get_peft_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8f7a5c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "CUDA: NVIDIA GeForce RTX 3090\n"
     ]
    }
   ],
   "source": [
    "MODEL_ID = \"meta-llama/Llama-3.2-3B-Instruct\"\n",
    "CUT_OFF_LEN = 1024\n",
    "LOSS_WEIGHTS = [0.3, 0.3, 0.2, 0.1, 0.1]\n",
    "EVAL_STEPS = 300\n",
    "MAX_NEW_TOKENS = 256\n",
    "TEMPERATURE = 0.2\n",
    "TOP_P = 0.9\n",
    "OUTPUT_DIR = \"outputs/llama3.2-3b-pls-qlora\"\n",
    "METRICS_CSV = f\"{OUTPUT_DIR}/training_metrics.csv\"\n",
    "\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# Device explícito\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Device:\", device)\n",
    "if device == \"cuda\":\n",
    "    print(\"CUDA:\", torch.cuda.get_device_name(0))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1963c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "HERE = Path.cwd()\n",
    "found = None\n",
    "for p in [HERE] + list(HERE.parents):\n",
    "    if (p / \"metricas\").is_dir():\n",
    "        found = p\n",
    "        break\n",
    "if not found:\n",
    "    raise RuntimeError(\"No se encontró la carpeta 'metricas' en ningún ancestro desde este notebook.\")\n",
    "if str(found) not in sys.path:\n",
    "    sys.path.insert(0, str(found))\n",
    "\n",
    "from metricas.metrics_client import getLoss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed25dd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 218)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cargar el dataset\n",
    "\n",
    "N_TRAIN = 1500  #  None para usar todo \n",
    "df = pd.read_csv(\"../../data/pls_abstract_pairs_with_metrics.csv\")\n",
    "\n",
    "train_df = df[df[\"split\"] == \"train\"].reset_index(drop=True)\n",
    "val_df   = df[df[\"split\"] == \"test\"].reset_index(drop=True)  \n",
    "\n",
    "if N_TRAIN is not None:\n",
    "    train_df = train_df.sample(n=min(N_TRAIN, len(train_df)), random_state=42).reset_index(drop=True)\n",
    "\n",
    "len(train_df), len(val_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ae558bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 500/500 [00:00<00:00, 2534.00 examples/s]\n",
      "Map: 100%|██████████| 218/218 [00:00<00:00, 2025.74 examples/s]\n"
     ]
    }
   ],
   "source": [
    "SYSTEM_PROMPT = (\n",
    "    \"You simplify clinical trial protocol text into a plain-language summary for the general public. \"\n",
    "    \"Keep to 6–8th grade readability, avoid diagnoses and speculation, no hallucinations, \"\n",
    "    \"and preserve key facts (objective, population, interventions, outcomes, timelines, safety).\"\n",
    ")\n",
    "USER_PREFIX = \"Using the following clinical trial protocol text as input, create a plain language summary.\\n\\n\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_ID, use_fast=True, token=os.getenv(\"HF_TOKEN\"))\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "def build_chat(src: str, tgt: str):\n",
    "    return [\n",
    "        {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "        {\"role\": \"user\", \"content\": USER_PREFIX + str(src)},\n",
    "        {\"role\": \"assistant\", \"content\": str(tgt)},\n",
    "    ]\n",
    "\n",
    "def encode_supervised(batch):\n",
    "    chats = [build_chat(s, t) for s, t in zip(batch[\"source_text\"], batch[\"target_text\"])]\n",
    "    texts = [tokenizer.apply_chat_template(c, tokenize=False, add_generation_prompt=False) for c in chats]\n",
    "    out = tokenizer(texts, truncation=True, max_length=CUT_OFF_LEN, padding=False)\n",
    "    return out\n",
    "\n",
    "hf_train = Dataset.from_pandas(train_df[[\"source_text\",\"target_text\"]]).map(\n",
    "    encode_supervised, batched=True, remove_columns=[\"source_text\",\"target_text\"]\n",
    ")\n",
    "hf_val = Dataset.from_pandas(val_df[[\"source_text\",\"target_text\"]]).map(\n",
    "    encode_supervised, batched=True, remove_columns=[\"source_text\",\"target_text\"]\n",
    ")\n",
    "\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer, mlm=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c3466dc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:01<00:00,  1.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model device: cuda:0\n",
      "Trainable: 24.31M / 3237.06M (0.75%)\n"
     ]
    }
   ],
   "source": [
    "MODEL_ID = \"meta-llama/Llama-3.2-3B-Instruct\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_ID, use_fast=True, token=os.getenv(\"HF_TOKEN\"))\n",
    "tokenizer.padding_side = \"right\"\n",
    "\n",
    "\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# FP16 en GPU; NO device_map=\"auto\" para que no se vaya a CPU\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_ID,\n",
    "    torch_dtype=torch.float16\n",
    ").to(device)\n",
    "\n",
    "# Solo LoRA (sin prepare_model_for_kbit_training)\n",
    "lora_cfg = LoraConfig(\n",
    "    r=16, lora_alpha=32, lora_dropout=0.05, bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    "    target_modules=[\"q_proj\",\"k_proj\",\"v_proj\",\"o_proj\",\"gate_proj\",\"up_proj\",\"down_proj\"]\n",
    ")\n",
    "model = get_peft_model(model, lora_cfg)\n",
    "model.config.use_cache = False \n",
    "model.config.pad_token_id = tokenizer.pad_token_id\n",
    "model.gradient_checkpointing_enable()\n",
    "model.enable_input_require_grads() \n",
    "model.train()\n",
    "\n",
    "# Sanity\n",
    "print(\"Model device:\", next(model.parameters()).device)\n",
    "trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "total = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Trainable: {trainable/1e6:.2f}M / {total/1e6:.2f}M ({100*trainable/total:.2f}%)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "86c6716c",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def eval_composite_loss(model, tokenizer, val_df, loss_weights, sample_size=64):\n",
    "    if len(val_df) == 0:\n",
    "        return None\n",
    "    sub = val_df.sample(n=min(sample_size, len(val_df)), random_state=42).reset_index(drop=True)\n",
    "    prompts = [\n",
    "        tokenizer.apply_chat_template(\n",
    "            [\n",
    "                {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "                {\"role\": \"user\", \"content\": USER_PREFIX + s}\n",
    "            ],\n",
    "            tokenize=False, add_generation_prompt=True\n",
    "        )\n",
    "        for s in sub[\"source_text\"].tolist()\n",
    "    ]\n",
    "    inputs = tokenizer(prompts, return_tensors=\"pt\", padding=True, truncation=True, max_length=CUT_OFF_LEN).to(device)\n",
    "    gen = model.generate(\n",
    "        **inputs, max_new_tokens=MAX_NEW_TOKENS, do_sample=True,\n",
    "        temperature=TEMPERATURE, top_p=TOP_P\n",
    "    )\n",
    "    outs = tokenizer.batch_decode(gen[:, inputs[\"input_ids\"].shape[1]:], skip_special_tokens=True)\n",
    "\n",
    "    losses = getLoss(\n",
    "        sub[\"source_text\"].tolist(),\n",
    "        sub[\"target_text\"].tolist(),\n",
    "        outs,\n",
    "        weights=loss_weights\n",
    "    )\n",
    "    if isinstance(losses, list):\n",
    "        return float(sum(losses)/len(losses)), losses\n",
    "    return float(losses), [float(losses)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde5dca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainValLogger(TrainerCallback):\n",
    "    def __init__(self, csv_path=METRICS_CSV):\n",
    "        self.csv_path = csv_path\n",
    "        os.makedirs(os.path.dirname(self.csv_path), exist_ok=True)\n",
    "        if not os.path.exists(self.csv_path):\n",
    "            with open(self.csv_path, \"w\", newline=\"\") as f:\n",
    "                csv.writer(f).writerow([\"step\",\"train_loss\",\"eval_loss\",\"lr\",\"timestamp\"])\n",
    "    def on_log(self, args, state, control, **kwargs):\n",
    "        logs = kwargs.get(\"logs\", {})\n",
    "        with open(self.csv_path, \"a\", newline=\"\") as f:\n",
    "            csv.writer(f).writerow([\n",
    "                state.global_step,\n",
    "                logs.get(\"loss\"),\n",
    "                logs.get(\"eval_loss\"),\n",
    "                logs.get(\"learning_rate\"),\n",
    "                time.time()\n",
    "            ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f216d2bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num training steps (approx): 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using EarlyStoppingCallback without load_best_model_at_end=True. Once training is finished, the best model will not be loaded automatically.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='16' max='16' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [16/16 05:17, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=16, training_loss=1.865557312965393, metrics={'train_runtime': 339.6342, 'train_samples_per_second': 1.472, 'train_steps_per_second': 0.047, 'total_flos': 8731495982407680.0, 'train_loss': 1.865557312965393, 'epoch': 1.0})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ajusta tu TrainingArguments así:\n",
    "args = TrainingArguments(\n",
    "    output_dir=\"outputs/llama3.2-3b-pls-lora-fp16\",\n",
    "    per_device_train_batch_size=2,\n",
    "    per_device_eval_batch_size=2,\n",
    "    gradient_accumulation_steps=16,   \n",
    "    num_train_epochs=3,\n",
    "    fp16=True,  \n",
    "    learning_rate=1e-4,\n",
    "    warmup_ratio=0.05,\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    logging_steps=25,\n",
    "    logging_first_step=True, \n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=25,\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=100,\n",
    "    save_total_limit=2,\n",
    "    optim=\"adamw_torch\",\n",
    "    metric_for_best_model=\"eval_loss\",     \n",
    "    report_to=\"none\",\n",
    "    disable_tqdm=False   \n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=hf_train,\n",
    "    eval_dataset=hf_val,\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "trainer.add_callback(TrainValLogger(METRICS_CSV))\n",
    "trainer.add_callback(EarlyStoppingCallback(early_stopping_patience=4, early_stopping_threshold=1e-4))\n",
    "\n",
    "\n",
    "print(\"Num training steps (approx):\", math.ceil(len(hf_train)/ (args.per_device_train_batch_size) / args.gradient_accumulation_steps) * int(args.num_train_epochs))\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "03624be0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guardado en: outputs\\llama3.2-3b-pls-qlora\\final\n",
      "Métricas registradas en: outputs/llama3.2-3b-pls-qlora/training_metrics.csv\n"
     ]
    }
   ],
   "source": [
    "save_dir = Path(OUTPUT_DIR) / \"final\"\n",
    "save_dir.mkdir(parents=True, exist_ok=True)\n",
    "trainer.model.save_pretrained(save_dir)\n",
    "tokenizer.save_pretrained(save_dir)\n",
    "print(\"Guardado en:\", save_dir)\n",
    "\n",
    "print(\"Métricas registradas en:\", METRICS_CSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ce5658bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Background\n",
      "Urinary schistosomiasis is caused by an intravascular infection with parasitic Schistosoma haematobium worms. The adult worms typically migrate to the venous plexus of the human bladder and excrete eggs which the infected person passes in their urine. Chronic infection can cause substantial morbidity and long‐term complications as the eggs become trapped in human tissues causing inflammation and fibrosis. We summarised evidence of drugs active against the infection. This is new edition of a review first published in 1997. \n",
      "Objectives\n",
      "To evaluate the efficacy and safety of drugs for treating urinary schistosomiasis.\n",
      "Search methods\n",
      "We searched the Cochrane Infectious Diseases Group Specialized Register, MEDLINE, CENTRAL, EMBASE and LILACS and reference lists of articles up to 23 May 2014. \n",
      "Selection criteria\n",
      "Randomized controlled trials (RCTs) of antischistosomal drugs and drug combinations compared to placebo, no intervention, or each other. \n",
      "Data collection and analysis\n",
      "Two researchers independently screened the records, extracted the data and assessed risk of bias. The primary efficacy outcomes were parasitological failure (defined as the continued presence of S. haematobium eggs in the urine at time points greater than one month after treatment), and percent reduction of egg counts from baseline. We presented dichotomous data as risk ratios (RR), and continuous data as mean difference (MD), alongside their 95% confidence intervals (CIs). Where appropriate we combined trials in meta analyses or tables. We assessed the quality of evidence using the GRADE approach. \n",
      "Main results\n",
      "We included 30 RCTs enrolling 8165 participants in this review. Twenty‐four trials were conducted in children in sub‐Saharan Africa, and 21 trials were over 20 years old. Many studies were assessed as being at unclear risk of bias due to inadequate descriptions of study methods. \n",
      "Praziquantel \n",
      "On average, a single 40 mg/kg dose of praziquantel reduced the proportion of people still excreting eggs in their urine by around 60% compared to placebo at one to two months after treatment (treatment failure: RR 0.42, 95% CI 0.29 to 0.59, 864 participants, seven trials, high quality evidence). The proportion of people cured with praziquantel varied substantially between trials, from 22.5% to 83.3%, but was higher than 60% in five of the seven trials. At one to two months following praziquantel treatment at 40 mg/kg, the mean number of schistosome eggs in the urine was reduced by over 95% in five out of six trials (678 participants, six trials, high quality evidence). \n",
      "Splitting praziquantel 40 mg/kg into two doses over 12 hours probably has no benefits over a single dose, and in a single trial of 220 participants the split dose caused more vomiting (RR 0.5, 95% CI 0.29 to 0.86) and dizziness (RR 0.39, 95% CI 0.16 to 0.94). \n",
      "Metrifonate \n",
      "A single dose of metrifonate 10 mg/kg reduced egg excretion (210 participants, one trial, at eight months), but was only marginally better than placebo at achieving cure at one month (RR 0.83, 95% CI 0.74 to 0.94, 142 participants, one trial). In a single trial comparing one, two and three doses, the absolute number of participants cured improved from 47% after one dose to 81% after three doses (93 participants, one trial, low quality evidence). \n",
      "Two small trials compared 40 mg/kg single dose praziquantel with two or three doses of 10 mg/kg metrifonate and found no clear evidence of differences in cure (metrifonate 2 x 10 mg/kg at one month: RR 1.03, 95% CI 0.8 to 1.34, 72 participants, one trial; metrifonate 3 x 10 mg/kg at three months: RR 0.33, 95% CI 0.07 to 1.57, 100 participants, one trial. In one trial both drugs performed badly and in one trial both performed well. \n",
      "Other drugs \n",
      "Three trials have evaluated the antimalarial artesunate; with inconsistent results. Substantial antischistosomal effects were only seen in one of the three trials, which was at unclear risk of bias due to poor reporting of the trial methods. Similarly, another anti‐malarial mefloquine has been evaluated in two small trials with inconsistent effects. \n",
      "Adverse events were described as mild for all evaluated drugs, but adverse event monitoring and reporting was generally of low quality. \n",
      "Authors' conclusions\n",
      "Praziquantel 40 mg/kg is the most studied drug for treating urinary schistosomiasis, and has the strongest evidence base. \n",
      "Potential strategies to improve future treatments for schistosomiasis include the combination of praziquantel with metrifonate, or with antimalarial drugs with antischistosomal properties such as artesunate and mefloquine. Evaluation of these combinations requires rigorous, adequately powered trials using standardized outcome measures. \n",
      "\n",
      "\n",
      "\n",
      "\n",
      " TEXTO GENERADO: \n",
      "\n",
      "\n",
      "Here's a simplified version of the above clinical trial protocol:\n",
      "\n",
      "**What is Urinary Schistosomiasis?**\n",
      "\n",
      "Schistosomiasis (also known as snail fever) is a disease that affects millions of people worldwide. It is caused by tiny parasites called worms that live inside our bodies. These worms are usually harmless when they infect healthy individuals, but if left untreated, they can cause serious health problems like kidney damage and infertility.\n",
      "\n",
      "**How Does Treatment Work?**\n",
      "\n",
      "There are several medications available to treat urinary schistosomiaisis. Praziquantel is the most commonly used medication. Studies have shown that it reduces the amount of worm eggs in the urine and cures many patients within a few weeks. However, some patients may not respond fully to the treatment.\n",
      "\n",
      "**What Are the Side Effects of Medications Used to Treat Urinary Schistosoma?**\n",
      "\n",
      "The side effects of the medications used to treat urinary schistomiasis are generally mild. Some patients may experience nausea, diarrhea, abdominal pain, headache, and fatigue while taking these medications.\n",
      "\n",
      "**Which Medication Is Most Effective?**\n",
      "\n",
      "Based on current research, praziquantel is considered the most effective medication for treating urinary schistomiasiis. A single dose of 40 milligrams per kilogram of body weight is recommended. \n",
      "\n",
      "**Combination Therapy**\n",
      "\n",
      "Researchers suggest combining praziquantel (a common medication for treating urinary schismosis) with other medications like metrifonate (another medication for treating urinary schismoasis) or antimalarial drugs (medications used to prevent malaria).\n",
      "\n",
      "**Future Research Directions**\n",
      "\n",
      "More research is needed to develop better treatments for urinary schistosomiasiis. Researchers should focus on developing new medications and evaluating their effectiveness in large-scale trials. Additionally, there is a need for standardization of treatment protocols and outcome measures to ensure consistency across different regions and populations.\n"
     ]
    }
   ],
   "source": [
    "SYSTEM_PROMPT = (\"You simplify clinical trial protocol text into a plain-language summary for the general public. \"\n",
    "                 \"Keep to 6–8th grade readability, avoid diagnoses and speculation, no hallucinations, \"\n",
    "                 \"and preserve key facts (objective, population, interventions, outcomes, timelines, safety).\")\n",
    "USER_PREFIX = \"Using the following clinical trial protocol text as input, create a plain language summary.\\n\\n\"\n",
    "\n",
    "def build_chat_infer(src: str):\n",
    "    return [\n",
    "        {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "        {\"role\": \"user\", \"content\": USER_PREFIX + src},\n",
    "    ]\n",
    "\n",
    "demo_src = val_df.iloc[0][\"source_text\"]\n",
    "print(demo_src, '\\n\\n')\n",
    "print('\\n\\n', \"TEXTO GENERADO:\", '\\n\\n')\n",
    "chat = build_chat_infer(demo_src)\n",
    "prompt = tokenizer.apply_chat_template(chat, tokenize=False, add_generation_prompt=True)\n",
    "\n",
    "model.eval()\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "gen = model.generate(\n",
    "    **inputs,\n",
    "    max_new_tokens=512,\n",
    "    do_sample=False,             \n",
    "    temperature=None,\n",
    "    top_p=None,\n",
    "    no_repeat_ngram_size=6,      \n",
    "    repetition_penalty=1.15,     \n",
    "    eos_token_id=tokenizer.eos_token_id,\n",
    "    pad_token_id=tokenizer.pad_token_id,\n",
    ")\n",
    "print(tokenizer.decode(gen[0][inputs[\"input_ids\"].shape[1]:], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "46d93405",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "need at least one array to concatenate",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 28\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(xs_ev): plt\u001b[38;5;241m.\u001b[39mplot(xs_ev, ys_ev, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-o\u001b[39m\u001b[38;5;124m\"\u001b[39m, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meval_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m,  lw\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, ms\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m)\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# Eje Y ajustado sin “aire”\u001b[39;00m\n\u001b[1;32m---> 28\u001b[0m vals \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43my\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mys_tr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mys_ev\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(vals):\n\u001b[0;32m     30\u001b[0m     vmin, vmax \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(np\u001b[38;5;241m.\u001b[39mnanmin(vals)), \u001b[38;5;28mfloat\u001b[39m(np\u001b[38;5;241m.\u001b[39mnanmax(vals))\n",
      "\u001b[1;31mValueError\u001b[0m: need at least one array to concatenate"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 900x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd, numpy as np, matplotlib.pyplot as plt\n",
    "\n",
    "dfm = pd.read_csv(METRICS_CSV)\n",
    "\n",
    "# Tipado y limpieza\n",
    "for c in (\"step\",\"train_loss\",\"eval_loss\",\"lr\"):\n",
    "    if c in dfm.columns:\n",
    "        dfm[c] = pd.to_numeric(dfm[c], errors=\"coerce\")\n",
    "dfm = dfm.rename(columns={\"step\": \"step_num\"})\n",
    "dfm = dfm.dropna(subset=[\"train_loss\",\"eval_loss\",\"lr\"], how=\"all\")\n",
    "\n",
    "# Ordenar y consolidar posibles duplicados por step\n",
    "dfm = dfm.sort_values(\"step_num\")\n",
    "dfm = dfm.groupby(\"step_num\", as_index=False).last()\n",
    "\n",
    "def _series(df, col):\n",
    "    s = df[[\"step_num\", col]].dropna()\n",
    "    return s[\"step_num\"].to_numpy(dtype=float), s[col].to_numpy(dtype=float)\n",
    "\n",
    "xs_tr, ys_tr = _series(dfm, \"train_loss\")\n",
    "xs_ev, ys_ev = _series(dfm, \"eval_loss\")\n",
    "\n",
    "plt.figure(figsize=(9,5))\n",
    "if len(xs_tr): plt.plot(xs_tr, ys_tr, \"-o\", label=\"train_loss\", lw=2, ms=4)\n",
    "if len(xs_ev): plt.plot(xs_ev, ys_ev, \"-o\", label=\"eval_loss\",  lw=2, ms=4)\n",
    "\n",
    "# Eje Y ajustado sin “aire”\n",
    "vals = np.concatenate([y for y in [ys_tr, ys_ev] if len(y)])\n",
    "if len(vals):\n",
    "    vmin, vmax = float(np.nanmin(vals)), float(np.nanmax(vals))\n",
    "    pad = max(1e-4, 0.08*(vmax - vmin))\n",
    "    plt.ylim(vmin - pad, vmax + pad)\n",
    "\n",
    "plt.xlabel(\"step\"); plt.ylabel(\"loss\"); plt.title(\"Training vs Validation Loss\")\n",
    "plt.grid(alpha=0.3); plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4062e8fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "# from peft import PeftModel\n",
    "\n",
    "# base = AutoModelForCausalLM.from_pretrained(MODEL_ID, torch_dtype=torch.float16).to(device)\n",
    "# tok  = AutoTokenizer.from_pretrained(MODEL_ID, use_fast=True)\n",
    "# tok.pad_token = tok.eos_token\n",
    "\n",
    "# lora = PeftModel.from_pretrained(base, (Path(OUTPUT_DIR)/\"final\").as_posix()).to(device)\n",
    "# lora.eval()\n",
    "# print(\"Adapters cargados OK.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_generacion",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
